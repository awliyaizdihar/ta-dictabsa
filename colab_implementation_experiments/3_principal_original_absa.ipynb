{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef3ffc4-42a6-4053-808d-d2cbdc1eb9c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ef3ffc4-42a6-4053-808d-d2cbdc1eb9c6",
        "outputId": "f197113b-390e-44a8-fd72-22bd13858904",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  2 22:32:29 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c8aa038-18bb-4141-a50a-83ff41246bfb",
      "metadata": {
        "id": "5c8aa038-18bb-4141-a50a-83ff41246bfb"
      },
      "source": [
        "# Clone git and requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7170737d-2b56-42d1-8675-39d20269562b",
      "metadata": {
        "id": "7170737d-2b56-42d1-8675-39d20269562b"
      },
      "outputs": [],
      "source": [
        "!rm -rf ta-dictabsa/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade469f0-cd14-4546-b7b3-fbbe01f69c2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ade469f0-cd14-4546-b7b3-fbbe01f69c2d",
        "outputId": "380708d1-931d-45a5-bf83-312958891aff",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ta-dictabsa'...\n",
            "remote: Enumerating objects: 406, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 406 (delta 7), reused 14 (delta 5), pack-reused 390\u001b[K\n",
            "Receiving objects: 100% (406/406), 5.10 MiB | 10.00 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/awliyaizdihar/ta-dictabsa.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd05800-1d71-495f-a355-01dcd96309b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fd05800-1d71-495f-a355-01dcd96309b9",
        "outputId": "3d32baf5-43ae-4037-c229-cf22802b0b36",
        "scrolled": true,
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from -r ta-dictabsa/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r ta-dictabsa/requirements.txt (line 2)) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r ta-dictabsa/requirements.txt (line 3)) (4.41.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r ta-dictabsa/requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r ta-dictabsa/requirements.txt (line 2)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r ta-dictabsa/requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r ta-dictabsa/requirements.txt (line 3)) (4.66.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ta-dictabsa/requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ta-dictabsa/requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r ta-dictabsa/requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r ta-dictabsa/requirements.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ta-dictabsa/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ta-dictabsa/requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ta-dictabsa/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r ta-dictabsa/requirements.txt (line 3)) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r ta-dictabsa/requirements.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ta-dictabsa/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d037735-0f76-4c8c-9776-0a4cad546307",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d037735-0f76-4c8c-9776-0a4cad546307",
        "outputId": "cd6f975c-73a6-42e5-a1cd-b0215e3f1d3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "092c9164-1ed1-4f22-8aa1-8de6333a8859",
      "metadata": {
        "editable": true,
        "id": "092c9164-1ed1-4f22-8aa1-8de6333a8859",
        "tags": []
      },
      "source": [
        "# Training dataset on model**(bert_spc)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "617b218f-1d4b-4768-94e0-f5fbc92fbb31"
      },
      "source": [
        "# Training with bert-base-uncased"
      ],
      "id": "617b218f-1d4b-4768-94e0-f5fbc92fbb31"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "96ab59be-a5b4-43c4-8c9a-98d7cf75db49",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# menyesuaikan tokenizer BERT untuk bert-base-uncased\n",
        "\n",
        "path = 'ta-dictabsa/train.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[34] = \"            bert = BertModel.from_pretrained(opt.pretrained_bert_name, return_dict=False)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)\n",
        "\n",
        "path = 'ta-dictabsa/train_insert.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[34] = \"            bert = BertModel.from_pretrained(opt.pretrained_bert_name, return_dict=False)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)\n",
        "\n",
        "path = 'ta-dictabsa/data_utils.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[100] = \"        self.tokenizer = BertTokenizer.from_pretrained(pretrained_bert_name)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "id": "96ab59be-a5b4-43c4-8c9a-98d7cf75db49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "pssq6u_KYLX9",
        "tags": []
      },
      "source": [
        "## bert-base-uncased Baseline"
      ],
      "id": "pssq6u_KYLX9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "dHCcjEJqYLX_",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8bf675ec-aafb-42b8-85d9-8c9ba5ccee97",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 247kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 29.9MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 59.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.14MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:01<00:00, 347MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_ori\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f46eb812e60>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/train.tsv', 'test': './datasets/ulasan_combined/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-08 05:47:27\n",
            "loss: 0.9003, acc: 0.6350\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 05:48:11\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-08 05:48:21\n",
            "loss: 0.8761, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-06-08 05:48:56\n",
            "loss: 0.8448, acc: 0.6714\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 05:49:34\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-08 05:49:51\n",
            "loss: 0.8236, acc: 0.6667\n",
            "E2E-ABSA >>> 2024-06-08 05:50:26\n",
            "loss: 0.8119, acc: 0.6736\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 05:50:56\n",
            ">>> val_acc: 0.6710, val_precision: 0.5400 val_recall: 0.6710, val_f1: 0.5818\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.671\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-08 05:51:22\n",
            "loss: 0.8028, acc: 0.6632\n",
            "E2E-ABSA >>> 2024-06-08 05:51:57\n",
            "loss: 0.7883, acc: 0.6755\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 05:52:18\n",
            ">>> val_acc: 0.6824, val_precision: 0.5642 val_recall: 0.6824, val_f1: 0.5852\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6824\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-08 05:52:58\n",
            "loss: 0.7426, acc: 0.6953\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 05:53:46\n",
            ">>> val_acc: 0.6696, val_precision: 0.5643 val_recall: 0.6696, val_f1: 0.6019\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6696\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-08 05:53:55\n",
            "loss: 0.6573, acc: 0.7375\n",
            "E2E-ABSA >>> 2024-06-08 05:54:30\n",
            "loss: 0.7015, acc: 0.7042\n",
            "E2E-ABSA >>> 2024-06-08 05:55:09\n",
            ">>> val_acc: 0.6121, val_precision: 0.6201 val_recall: 0.6121, val_f1: 0.6076\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6121\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-08 05:55:32\n",
            "loss: 0.6858, acc: 0.7273\n",
            "E2E-ABSA >>> 2024-06-08 05:56:08\n",
            "loss: 0.6916, acc: 0.7196\n",
            "E2E-ABSA >>> 2024-06-08 05:56:38\n",
            ">>> val_acc: 0.6750, val_precision: 0.6083 val_recall: 0.6750, val_f1: 0.6108\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.675\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-08 05:57:08\n",
            "loss: 0.6727, acc: 0.7289\n",
            "E2E-ABSA >>> 2024-06-08 05:57:44\n",
            "loss: 0.6684, acc: 0.7299\n",
            "E2E-ABSA >>> 2024-06-08 05:58:06\n",
            ">>> val_acc: 0.6853, val_precision: 0.6121 val_recall: 0.6853, val_f1: 0.5942\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-08 05:58:38\n",
            "loss: 0.6144, acc: 0.7514\n",
            "E2E-ABSA >>> 2024-06-08 05:59:28\n",
            ">>> val_acc: 0.6710, val_precision: 0.6168 val_recall: 0.6710, val_f1: 0.6291\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.671\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-08 05:59:41\n",
            "loss: 0.5825, acc: 0.7266\n",
            "E2E-ABSA >>> 2024-06-08 06:00:16\n",
            "loss: 0.5933, acc: 0.7441\n",
            "E2E-ABSA >>> 2024-06-08 06:00:57\n",
            ">>> val_acc: 0.6803, val_precision: 0.6104 val_recall: 0.6803, val_f1: 0.6118\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-08 06:01:11\n",
            "loss: 0.5626, acc: 0.7766\n",
            "E2E-ABSA >>> 2024-06-08 06:01:46\n",
            "loss: 0.5642, acc: 0.7777\n",
            "E2E-ABSA >>> 2024-06-08 06:02:18\n",
            ">>> val_acc: 0.6622, val_precision: 0.6301 val_recall: 0.6622, val_f1: 0.6408\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6622\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-08 06:02:48\n",
            "loss: 0.5224, acc: 0.7861\n",
            "E2E-ABSA >>> 2024-06-08 06:03:23\n",
            "loss: 0.5541, acc: 0.7793\n",
            "E2E-ABSA >>> 2024-06-08 06:03:47\n",
            ">>> val_acc: 0.6810, val_precision: 0.6240 val_recall: 0.6810, val_f1: 0.6331\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-08 06:04:18\n",
            "loss: 0.5222, acc: 0.7862\n",
            "E2E-ABSA >>> 2024-06-08 06:05:08\n",
            ">>> val_acc: 0.6600, val_precision: 0.6161 val_recall: 0.6600, val_f1: 0.6268\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-08 06:05:13\n",
            "loss: 0.4587, acc: 0.7969\n",
            "E2E-ABSA >>> 2024-06-08 06:05:48\n",
            "loss: 0.5332, acc: 0.7857\n",
            "E2E-ABSA >>> 2024-06-08 06:06:30\n",
            ">>> val_acc: 0.6725, val_precision: 0.6395 val_recall: 0.6725, val_f1: 0.6419\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6725\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-08 06:06:50\n",
            "loss: 0.4648, acc: 0.7969\n",
            "E2E-ABSA >>> 2024-06-08 06:07:25\n",
            "loss: 0.4839, acc: 0.7996\n",
            "E2E-ABSA >>> 2024-06-08 06:07:59\n",
            ">>> val_acc: 0.6494, val_precision: 0.6187 val_recall: 0.6494, val_f1: 0.6305\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-08 06:08:20\n",
            "loss: 0.4588, acc: 0.8073\n",
            "E2E-ABSA >>> 2024-06-08 06:08:55\n",
            "loss: 0.4688, acc: 0.8066\n",
            "E2E-ABSA >>> 2024-06-08 06:09:20\n",
            ">>> val_acc: 0.6682, val_precision: 0.6119 val_recall: 0.6682, val_f1: 0.6283\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-08 06:09:50\n",
            "loss: 0.4562, acc: 0.8073\n",
            "E2E-ABSA >>> 2024-06-08 06:10:42\n",
            ">>> val_acc: 0.6519, val_precision: 0.6114 val_recall: 0.6519, val_f1: 0.6250\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-08 06:10:45\n",
            "loss: 0.4830, acc: 0.7812\n",
            "E2E-ABSA >>> 2024-06-08 06:11:20\n",
            "loss: 0.4460, acc: 0.8108\n",
            "E2E-ABSA >>> 2024-06-08 06:12:03\n",
            ">>> val_acc: 0.6391, val_precision: 0.6135 val_recall: 0.6391, val_f1: 0.6241\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-08 06:12:15\n",
            "loss: 0.4178, acc: 0.8379\n",
            "E2E-ABSA >>> 2024-06-08 06:12:50\n",
            "loss: 0.4275, acc: 0.8243\n",
            "E2E-ABSA >>> 2024-06-08 06:13:25\n",
            ">>> val_acc: 0.6622, val_precision: 0.6232 val_recall: 0.6622, val_f1: 0.6343\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-08 06:13:45\n",
            "loss: 0.3927, acc: 0.8382\n",
            "E2E-ABSA >>> 2024-06-08 06:14:20\n",
            "loss: 0.4036, acc: 0.8293\n",
            "E2E-ABSA >>> 2024-06-08 06:14:47\n",
            ">>> val_acc: 0.6384, val_precision: 0.6240 val_recall: 0.6384, val_f1: 0.6233\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-08 06:15:15\n",
            "loss: 0.3929, acc: 0.8359\n",
            "E2E-ABSA >>> 2024-06-08 06:16:08\n",
            ">>> val_acc: 0.6739, val_precision: 0.6189 val_recall: 0.6739, val_f1: 0.6311\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-08 06:16:09\n",
            "loss: 0.2941, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-08 06:16:45\n",
            "loss: 0.4081, acc: 0.8173\n",
            "E2E-ABSA >>> 2024-06-08 06:17:30\n",
            ">>> val_acc: 0.6718, val_precision: 0.6158 val_recall: 0.6718, val_f1: 0.6264\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-08 06:17:40\n",
            "loss: 0.3582, acc: 0.8460\n",
            "E2E-ABSA >>> 2024-06-08 06:18:15\n",
            "loss: 0.4030, acc: 0.8325\n",
            "E2E-ABSA >>> 2024-06-08 06:18:51\n",
            ">>> val_acc: 0.6409, val_precision: 0.6265 val_recall: 0.6409, val_f1: 0.6317\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-08 06:19:10\n",
            "loss: 0.3818, acc: 0.8317\n",
            "E2E-ABSA >>> 2024-06-08 06:19:45\n",
            "loss: 0.3908, acc: 0.8289\n",
            "E2E-ABSA >>> 2024-06-08 06:20:13\n",
            ">>> val_acc: 0.6679, val_precision: 0.6242 val_recall: 0.6679, val_f1: 0.6361\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-08 06:20:40\n",
            "loss: 0.3441, acc: 0.8553\n",
            "E2E-ABSA >>> 2024-06-08 06:21:15\n",
            "loss: 0.3811, acc: 0.8362\n",
            "E2E-ABSA >>> 2024-06-08 06:21:35\n",
            ">>> val_acc: 0.6661, val_precision: 0.6184 val_recall: 0.6661, val_f1: 0.6273\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-08 06:22:10\n",
            "loss: 0.3617, acc: 0.8444\n",
            "E2E-ABSA >>> 2024-06-08 06:22:56\n",
            ">>> val_acc: 0.6405, val_precision: 0.6266 val_recall: 0.6405, val_f1: 0.6288\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-08 06:23:04\n",
            "loss: 0.3246, acc: 0.8646\n",
            "E2E-ABSA >>> 2024-06-08 06:23:40\n",
            "loss: 0.3676, acc: 0.8453\n",
            "E2E-ABSA >>> 2024-06-08 06:24:18\n",
            ">>> val_acc: 0.6757, val_precision: 0.6223 val_recall: 0.6757, val_f1: 0.6324\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-08 06:24:34\n",
            "loss: 0.3542, acc: 0.8490\n",
            "E2E-ABSA >>> 2024-06-08 06:25:10\n",
            "loss: 0.3447, acc: 0.8556\n",
            "E2E-ABSA >>> 2024-06-08 06:25:39\n",
            ">>> val_acc: 0.6519, val_precision: 0.6211 val_recall: 0.6519, val_f1: 0.6334\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-08 06:26:05\n",
            "loss: 0.3234, acc: 0.8533\n",
            "E2E-ABSA >>> 2024-06-08 06:26:40\n",
            "loss: 0.3466, acc: 0.8477\n",
            "E2E-ABSA >>> 2024-06-08 06:27:01\n",
            ">>> val_acc: 0.6359, val_precision: 0.6241 val_recall: 0.6359, val_f1: 0.6227\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-08 06:27:35\n",
            "loss: 0.3243, acc: 0.8672\n",
            "E2E-ABSA >>> 2024-06-08 06:28:22\n",
            ">>> val_acc: 0.6437, val_precision: 0.6147 val_recall: 0.6437, val_f1: 0.6260\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-08 06:28:29\n",
            "loss: 0.2925, acc: 0.8688\n",
            "E2E-ABSA >>> 2024-06-08 06:29:05\n",
            "loss: 0.3309, acc: 0.8531\n",
            "E2E-ABSA >>> 2024-06-08 06:29:44\n",
            ">>> val_acc: 0.6004, val_precision: 0.6237 val_recall: 0.6004, val_f1: 0.6077\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-08 06:29:59\n",
            "loss: 0.3365, acc: 0.8580\n",
            "E2E-ABSA >>> 2024-06-08 06:30:35\n",
            "loss: 0.3554, acc: 0.8481\n",
            "E2E-ABSA >>> 2024-06-08 06:31:05\n",
            ">>> val_acc: 0.6426, val_precision: 0.6160 val_recall: 0.6426, val_f1: 0.6237\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-08 06:31:29\n",
            "loss: 0.2967, acc: 0.8704\n",
            "E2E-ABSA >>> 2024-06-08 06:32:05\n",
            "loss: 0.3251, acc: 0.8575\n",
            "E2E-ABSA >>> 2024-06-08 06:32:27\n",
            ">>> val_acc: 0.6565, val_precision: 0.6133 val_recall: 0.6565, val_f1: 0.6273\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-08 06:32:59\n",
            "loss: 0.3200, acc: 0.8587\n",
            "E2E-ABSA >>> 2024-06-08 06:33:49\n",
            ">>> val_acc: 0.6405, val_precision: 0.6197 val_recall: 0.6405, val_f1: 0.6289\n",
            "E2E-ABSA >>> 2024-06-08 06:33:49\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6725, val_precision: 0.6395 val_recall: 0.6725, val_f1: 0.6419\n",
            "you can download the best model from state_dict/bert_spc_combined_ori_val_f1_0.6725\n",
            ">>> test_acc: 0.6386, test_precision: 0.5991, test_recall: 0.6386, test_f1: 0.5999\n"
          ]
        }
      ],
      "source": [
        "# 8-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_ori --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "dHCcjEJqYLX_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bert-base-uncased Concatenation"
      ],
      "metadata": {
        "id": "coyAZT8JND-0"
      },
      "id": "coyAZT8JND-0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "9W1ucQNMYe7R",
        "tags": []
      },
      "source": [
        "### base-uncased s1 concat"
      ],
      "id": "9W1ucQNMYe7R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "yv4QWCqZYe7T",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "604a9e51-29e8-4c3c-bdf9-cf4a032572cf",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 332kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 27.0MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 31.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.81MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:02<00:00, 206MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fb1da81ae60>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/a_raw_know/train.tsv', 'test': './datasets/ulasan_combined/a_raw_know/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-08 15:18:22\n",
            "loss: 0.9199, acc: 0.6294\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:19:10\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-08 15:19:25\n",
            "loss: 0.8606, acc: 0.6510\n",
            "E2E-ABSA >>> 2024-06-08 15:20:00\n",
            "loss: 0.8435, acc: 0.6739\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:20:39\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-08 15:20:56\n",
            "loss: 0.8262, acc: 0.6693\n",
            "E2E-ABSA >>> 2024-06-08 15:21:32\n",
            "loss: 0.8264, acc: 0.6748\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:22:02\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-08 15:22:27\n",
            "loss: 0.8297, acc: 0.6701\n",
            "E2E-ABSA >>> 2024-06-08 15:23:03\n",
            "loss: 0.8270, acc: 0.6726\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:23:25\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-08 15:23:59\n",
            "loss: 0.8163, acc: 0.6732\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:24:48\n",
            ">>> val_acc: 0.6885, val_precision: 0.5776 val_recall: 0.6885, val_f1: 0.5800\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6885\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-08 15:24:56\n",
            "loss: 0.7803, acc: 0.6906\n",
            "E2E-ABSA >>> 2024-06-08 15:25:32\n",
            "loss: 0.7997, acc: 0.6755\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:26:12\n",
            ">>> val_acc: 0.6849, val_precision: 0.5628 val_recall: 0.6849, val_f1: 0.5686\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-08 15:26:28\n",
            "loss: 0.8109, acc: 0.6832\n",
            "E2E-ABSA >>> 2024-06-08 15:27:04\n",
            "loss: 0.8082, acc: 0.6693\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:27:35\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-08 15:28:00\n",
            "loss: 0.7853, acc: 0.6645\n",
            "E2E-ABSA >>> 2024-06-08 15:28:35\n",
            "loss: 0.7798, acc: 0.6715\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:28:58\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-08 15:29:31\n",
            "loss: 0.7641, acc: 0.6787\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:30:21\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-08 15:30:27\n",
            "loss: 0.8212, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-06-08 15:31:02\n",
            "loss: 0.7532, acc: 0.6730\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:31:44\n",
            ">>> val_acc: 0.6785, val_precision: 0.5608 val_recall: 0.6785, val_f1: 0.5935\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6785\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-08 15:31:59\n",
            "loss: 0.6872, acc: 0.7094\n",
            "E2E-ABSA >>> 2024-06-08 15:32:35\n",
            "loss: 0.7139, acc: 0.6875\n",
            "E2E-ABSA >>> 2024-06-08 15:33:08\n",
            ">>> val_acc: 0.6888, val_precision: 0.6318 val_recall: 0.6888, val_f1: 0.5971\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6888\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-08 15:33:37\n",
            "loss: 0.6696, acc: 0.6924\n",
            "E2E-ABSA >>> 2024-06-08 15:34:13\n",
            "loss: 0.7001, acc: 0.6905\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 15:34:37\n",
            ">>> val_acc: 0.6856, val_precision: 0.5507 val_recall: 0.6856, val_f1: 0.5603\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-08 15:35:08\n",
            "loss: 0.6574, acc: 0.7195\n",
            "E2E-ABSA >>> 2024-06-08 15:36:00\n",
            ">>> val_acc: 0.6902, val_precision: 0.6560 val_recall: 0.6902, val_f1: 0.5813\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-08 15:36:04\n",
            "loss: 0.7107, acc: 0.6927\n",
            "E2E-ABSA >>> 2024-06-08 15:36:40\n",
            "loss: 0.6692, acc: 0.7020\n",
            "E2E-ABSA >>> 2024-06-08 15:37:22\n",
            ">>> val_acc: 0.6803, val_precision: 0.6223 val_recall: 0.6803, val_f1: 0.6155\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6803\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-08 15:37:41\n",
            "loss: 0.6052, acc: 0.7292\n",
            "E2E-ABSA >>> 2024-06-08 15:38:17\n",
            "loss: 0.6290, acc: 0.7261\n",
            "E2E-ABSA >>> 2024-06-08 15:38:51\n",
            ">>> val_acc: 0.6600, val_precision: 0.6167 val_recall: 0.6600, val_f1: 0.6162\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.66\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-08 15:39:19\n",
            "loss: 0.5899, acc: 0.7292\n",
            "E2E-ABSA >>> 2024-06-08 15:39:55\n",
            "loss: 0.6081, acc: 0.7273\n",
            "E2E-ABSA >>> 2024-06-08 15:40:21\n",
            ">>> val_acc: 0.6568, val_precision: 0.6141 val_recall: 0.6568, val_f1: 0.6224\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6568\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-08 15:40:58\n",
            "loss: 0.5633, acc: 0.7626\n",
            "E2E-ABSA >>> 2024-06-08 15:41:51\n",
            ">>> val_acc: 0.6359, val_precision: 0.6231 val_recall: 0.6359, val_f1: 0.6249\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6359\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-08 15:42:01\n",
            "loss: 0.5929, acc: 0.7422\n",
            "E2E-ABSA >>> 2024-06-08 15:42:37\n",
            "loss: 0.5576, acc: 0.7622\n",
            "E2E-ABSA >>> 2024-06-08 15:43:21\n",
            ">>> val_acc: 0.6476, val_precision: 0.6223 val_recall: 0.6476, val_f1: 0.6316\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6476\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-08 15:43:40\n",
            "loss: 0.5377, acc: 0.7695\n",
            "E2E-ABSA >>> 2024-06-08 15:44:16\n",
            "loss: 0.5406, acc: 0.7571\n",
            "E2E-ABSA >>> 2024-06-08 15:44:51\n",
            ">>> val_acc: 0.6554, val_precision: 0.6179 val_recall: 0.6554, val_f1: 0.6257\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-08 15:45:11\n",
            "loss: 0.5221, acc: 0.7768\n",
            "E2E-ABSA >>> 2024-06-08 15:45:47\n",
            "loss: 0.5347, acc: 0.7680\n",
            "E2E-ABSA >>> 2024-06-08 15:46:14\n",
            ">>> val_acc: 0.6632, val_precision: 0.6254 val_recall: 0.6632, val_f1: 0.6356\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6632\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-08 15:46:49\n",
            "loss: 0.5019, acc: 0.7883\n",
            "E2E-ABSA >>> 2024-06-08 15:47:44\n",
            ">>> val_acc: 0.6611, val_precision: 0.6131 val_recall: 0.6611, val_f1: 0.6265\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-08 15:47:45\n",
            "loss: 0.3783, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-08 15:48:21\n",
            "loss: 0.4988, acc: 0.7843\n",
            "E2E-ABSA >>> 2024-06-08 15:49:06\n",
            ">>> val_acc: 0.6458, val_precision: 0.6240 val_recall: 0.6458, val_f1: 0.6329\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-08 15:49:16\n",
            "loss: 0.4203, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-08 15:49:52\n",
            "loss: 0.4713, acc: 0.7954\n",
            "E2E-ABSA >>> 2024-06-08 15:50:29\n",
            ">>> val_acc: 0.6053, val_precision: 0.6290 val_recall: 0.6053, val_f1: 0.6153\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-08 15:50:48\n",
            "loss: 0.4219, acc: 0.8149\n",
            "E2E-ABSA >>> 2024-06-08 15:51:23\n",
            "loss: 0.4702, acc: 0.7928\n",
            "E2E-ABSA >>> 2024-06-08 15:51:52\n",
            ">>> val_acc: 0.6686, val_precision: 0.6270 val_recall: 0.6686, val_f1: 0.6389\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6686\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-08 15:52:21\n",
            "loss: 0.4068, acc: 0.8224\n",
            "E2E-ABSA >>> 2024-06-08 15:52:56\n",
            "loss: 0.4536, acc: 0.7979\n",
            "E2E-ABSA >>> 2024-06-08 15:53:16\n",
            ">>> val_acc: 0.6529, val_precision: 0.6137 val_recall: 0.6529, val_f1: 0.6243\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-08 15:53:52\n",
            "loss: 0.4294, acc: 0.8113\n",
            "E2E-ABSA >>> 2024-06-08 15:54:39\n",
            ">>> val_acc: 0.6359, val_precision: 0.6213 val_recall: 0.6359, val_f1: 0.6271\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-08 15:54:48\n",
            "loss: 0.3814, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-06-08 15:55:23\n",
            "loss: 0.4051, acc: 0.8216\n",
            "E2E-ABSA >>> 2024-06-08 15:56:02\n",
            ">>> val_acc: 0.6703, val_precision: 0.6244 val_recall: 0.6703, val_f1: 0.6323\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-08 15:56:19\n",
            "loss: 0.4058, acc: 0.8294\n",
            "E2E-ABSA >>> 2024-06-08 15:56:55\n",
            "loss: 0.4091, acc: 0.8193\n",
            "E2E-ABSA >>> 2024-06-08 15:57:25\n",
            ">>> val_acc: 0.6281, val_precision: 0.6272 val_recall: 0.6281, val_f1: 0.6261\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-08 15:57:50\n",
            "loss: 0.4117, acc: 0.8142\n",
            "E2E-ABSA >>> 2024-06-08 15:58:26\n",
            "loss: 0.4078, acc: 0.8227\n",
            "E2E-ABSA >>> 2024-06-08 15:58:47\n",
            ">>> val_acc: 0.6320, val_precision: 0.6208 val_recall: 0.6320, val_f1: 0.6228\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-08 15:59:22\n",
            "loss: 0.3877, acc: 0.8359\n",
            "E2E-ABSA >>> 2024-06-08 16:00:10\n",
            ">>> val_acc: 0.5844, val_precision: 0.6286 val_recall: 0.5844, val_f1: 0.5994\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-08 16:00:17\n",
            "loss: 0.3970, acc: 0.8219\n",
            "E2E-ABSA >>> 2024-06-08 16:00:53\n",
            "loss: 0.3744, acc: 0.8401\n",
            "E2E-ABSA >>> 2024-06-08 16:01:33\n",
            ">>> val_acc: 0.6039, val_precision: 0.6308 val_recall: 0.6039, val_f1: 0.6156\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-08 16:01:49\n",
            "loss: 0.3332, acc: 0.8523\n",
            "E2E-ABSA >>> 2024-06-08 16:02:24\n",
            "loss: 0.3734, acc: 0.8307\n",
            "E2E-ABSA >>> 2024-06-08 16:02:56\n",
            ">>> val_acc: 0.6313, val_precision: 0.6180 val_recall: 0.6313, val_f1: 0.6210\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-08 16:03:20\n",
            "loss: 0.3436, acc: 0.8548\n",
            "E2E-ABSA >>> 2024-06-08 16:03:56\n",
            "loss: 0.3777, acc: 0.8389\n",
            "E2E-ABSA >>> 2024-06-08 16:04:18\n",
            ">>> val_acc: 0.6412, val_precision: 0.6196 val_recall: 0.6412, val_f1: 0.6288\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-08 16:04:51\n",
            "loss: 0.3953, acc: 0.8186\n",
            "E2E-ABSA >>> 2024-06-08 16:05:41\n",
            ">>> val_acc: 0.6426, val_precision: 0.6230 val_recall: 0.6426, val_f1: 0.6316\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-08 16:05:47\n",
            "loss: 0.3173, acc: 0.8477\n",
            "E2E-ABSA >>> 2024-06-08 16:06:22\n",
            "loss: 0.3508, acc: 0.8416\n",
            "E2E-ABSA >>> 2024-06-08 16:07:03\n",
            ">>> val_acc: 0.6416, val_precision: 0.6133 val_recall: 0.6416, val_f1: 0.6242\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-08 16:07:18\n",
            "loss: 0.3205, acc: 0.8359\n",
            "E2E-ABSA >>> 2024-06-08 16:07:53\n",
            "loss: 0.3517, acc: 0.8388\n",
            "E2E-ABSA >>> 2024-06-08 16:08:26\n",
            ">>> val_acc: 0.6671, val_precision: 0.6171 val_recall: 0.6671, val_f1: 0.6280\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-08 16:08:49\n",
            "loss: 0.3890, acc: 0.8418\n",
            "E2E-ABSA >>> 2024-06-08 16:09:25\n",
            "loss: 0.3740, acc: 0.8342\n",
            "E2E-ABSA >>> 2024-06-08 16:09:49\n",
            ">>> val_acc: 0.6195, val_precision: 0.6355 val_recall: 0.6195, val_f1: 0.6267\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-08 16:10:20\n",
            "loss: 0.3402, acc: 0.8509\n",
            "E2E-ABSA >>> 2024-06-08 16:11:12\n",
            ">>> val_acc: 0.6362, val_precision: 0.6134 val_recall: 0.6362, val_f1: 0.6217\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-08 16:11:16\n",
            "loss: 0.3946, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-08 16:11:52\n",
            "loss: 0.3457, acc: 0.8477\n",
            "E2E-ABSA >>> 2024-06-08 16:12:34\n",
            ">>> val_acc: 0.6409, val_precision: 0.6226 val_recall: 0.6409, val_f1: 0.6304\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-08 16:12:47\n",
            "loss: 0.3528, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-08 16:13:23\n",
            "loss: 0.3327, acc: 0.8488\n",
            "E2E-ABSA >>> 2024-06-08 16:13:57\n",
            ">>> val_acc: 0.6153, val_precision: 0.6189 val_recall: 0.6153, val_f1: 0.6170\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-08 16:14:18\n",
            "loss: 0.2828, acc: 0.8792\n",
            "E2E-ABSA >>> 2024-06-08 16:14:54\n",
            "loss: 0.3255, acc: 0.8613\n",
            "E2E-ABSA >>> 2024-06-08 16:15:20\n",
            ">>> val_acc: 0.6568, val_precision: 0.6178 val_recall: 0.6568, val_f1: 0.6311\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-08 16:15:50\n",
            "loss: 0.3053, acc: 0.8571\n",
            "E2E-ABSA >>> 2024-06-08 16:16:43\n",
            ">>> val_acc: 0.6401, val_precision: 0.6177 val_recall: 0.6401, val_f1: 0.6259\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-08 16:16:45\n",
            "loss: 0.3821, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-08 16:17:21\n",
            "loss: 0.3454, acc: 0.8374\n",
            "E2E-ABSA >>> 2024-06-08 16:18:05\n",
            ">>> val_acc: 0.6096, val_precision: 0.6160 val_recall: 0.6096, val_f1: 0.6118\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-08 16:18:17\n",
            "loss: 0.3042, acc: 0.8652\n",
            "E2E-ABSA >>> 2024-06-08 16:18:52\n",
            "loss: 0.3045, acc: 0.8655\n",
            "E2E-ABSA >>> 2024-06-08 16:19:28\n",
            ">>> val_acc: 0.6387, val_precision: 0.6270 val_recall: 0.6387, val_f1: 0.6321\n",
            "E2E-ABSA >>> 2024-06-08 16:19:28\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6686, val_precision: 0.6270 val_recall: 0.6686, val_f1: 0.6389\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.6686\n",
            ">>> test_acc: 0.6377, test_precision: 0.5597, test_recall: 0.6377, test_f1: 0.5790\n"
          ]
        }
      ],
      "source": [
        "# 8-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "yv4QWCqZYe7T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "e3245243-fd59-4086-a095-466d984cd3e8",
        "tags": []
      },
      "source": [
        "### base-uncased s2 concat"
      ],
      "id": "e3245243-fd59-4086-a095-466d984cd3e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "8f5cbdd2-753d-448d-a1c8-f9b0d31ade7d",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e4a1c68d-945e-4284-982c-af959fd39637",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f3277c23640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/f_raw_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/f_raw_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 07:17:47\n",
            "loss: 0.9055, acc: 0.6375\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:17:58\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 07:18:01\n",
            "loss: 0.8768, acc: 0.6432\n",
            "E2E-ABSA >>> 2024-06-04 07:18:09\n",
            "loss: 0.8400, acc: 0.6714\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:18:18\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 07:18:22\n",
            "loss: 0.8265, acc: 0.6693\n",
            "E2E-ABSA >>> 2024-06-04 07:18:31\n",
            "loss: 0.8271, acc: 0.6757\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:18:38\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 07:18:44\n",
            "loss: 0.8367, acc: 0.6658\n",
            "E2E-ABSA >>> 2024-06-04 07:18:53\n",
            "loss: 0.8263, acc: 0.6715\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:18:58\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 07:19:06\n",
            "loss: 0.8023, acc: 0.6745\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:19:18\n",
            ">>> val_acc: 0.6760, val_precision: 0.5749 val_recall: 0.6760, val_f1: 0.6114\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.676\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 07:19:20\n",
            "loss: 0.7306, acc: 0.6937\n",
            "E2E-ABSA >>> 2024-06-04 07:19:29\n",
            "loss: 0.7699, acc: 0.6802\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:19:38\n",
            ">>> val_acc: 0.6213, val_precision: 0.5869 val_recall: 0.6213, val_f1: 0.6012\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 07:19:42\n",
            "loss: 0.7285, acc: 0.7074\n",
            "E2E-ABSA >>> 2024-06-04 07:19:50\n",
            "loss: 0.7577, acc: 0.6884\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:19:57\n",
            ">>> val_acc: 0.6906, val_precision: 0.5849 val_recall: 0.6906, val_f1: 0.5936\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 07:20:03\n",
            "loss: 0.7436, acc: 0.6756\n",
            "E2E-ABSA >>> 2024-06-04 07:20:12\n",
            "loss: 0.7371, acc: 0.6897\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:20:17\n",
            ">>> val_acc: 0.6867, val_precision: 0.5784 val_recall: 0.6867, val_f1: 0.5665\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 07:20:25\n",
            "loss: 0.6990, acc: 0.7106\n",
            "E2E-ABSA >>> 2024-06-04 07:20:36\n",
            ">>> val_acc: 0.6728, val_precision: 0.6075 val_recall: 0.6728, val_f1: 0.6206\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6728\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 07:20:38\n",
            "loss: 0.7277, acc: 0.6836\n",
            "E2E-ABSA >>> 2024-06-04 07:20:46\n",
            "loss: 0.6880, acc: 0.7139\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:20:56\n",
            ">>> val_acc: 0.6700, val_precision: 0.5793 val_recall: 0.6700, val_f1: 0.6181\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 07:20:59\n",
            "loss: 0.6382, acc: 0.7422\n",
            "E2E-ABSA >>> 2024-06-04 07:21:08\n",
            "loss: 0.6561, acc: 0.7299\n",
            "E2E-ABSA >>> 2024-06-04 07:21:15\n",
            ">>> val_acc: 0.6892, val_precision: 0.5874 val_recall: 0.6892, val_f1: 0.6096\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 07:21:21\n",
            "loss: 0.6132, acc: 0.7539\n",
            "E2E-ABSA >>> 2024-06-04 07:21:29\n",
            "loss: 0.6433, acc: 0.7332\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 07:21:35\n",
            ">>> val_acc: 0.6771, val_precision: 0.5758 val_recall: 0.6771, val_f1: 0.6118\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 07:21:42\n",
            "loss: 0.6048, acc: 0.7564\n",
            "E2E-ABSA >>> 2024-06-04 07:21:54\n",
            ">>> val_acc: 0.6750, val_precision: 0.6120 val_recall: 0.6750, val_f1: 0.6188\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 07:21:55\n",
            "loss: 0.5700, acc: 0.7708\n",
            "E2E-ABSA >>> 2024-06-04 07:22:04\n",
            "loss: 0.6235, acc: 0.7450\n",
            "E2E-ABSA >>> 2024-06-04 07:22:14\n",
            ">>> val_acc: 0.6654, val_precision: 0.6104 val_recall: 0.6654, val_f1: 0.6194\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 07:22:17\n",
            "loss: 0.5482, acc: 0.7917\n",
            "E2E-ABSA >>> 2024-06-04 07:22:25\n",
            "loss: 0.5822, acc: 0.7606\n",
            "E2E-ABSA >>> 2024-06-04 07:22:33\n",
            ">>> val_acc: 0.6263, val_precision: 0.6203 val_recall: 0.6263, val_f1: 0.6177\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 07:22:38\n",
            "loss: 0.5507, acc: 0.7729\n",
            "E2E-ABSA >>> 2024-06-04 07:22:47\n",
            "loss: 0.5785, acc: 0.7559\n",
            "E2E-ABSA >>> 2024-06-04 07:22:53\n",
            ">>> val_acc: 0.6639, val_precision: 0.6036 val_recall: 0.6639, val_f1: 0.6197\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 07:23:00\n",
            "loss: 0.5445, acc: 0.7872\n",
            "E2E-ABSA >>> 2024-06-04 07:23:13\n",
            ">>> val_acc: 0.6540, val_precision: 0.5952 val_recall: 0.6540, val_f1: 0.6139\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 07:23:13\n",
            "loss: 0.5511, acc: 0.7891\n",
            "E2E-ABSA >>> 2024-06-04 07:23:22\n",
            "loss: 0.5218, acc: 0.7934\n",
            "E2E-ABSA >>> 2024-06-04 07:23:32\n",
            ">>> val_acc: 0.6561, val_precision: 0.6005 val_recall: 0.6561, val_f1: 0.6151\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 07:23:35\n",
            "loss: 0.4796, acc: 0.8105\n",
            "E2E-ABSA >>> 2024-06-04 07:23:44\n",
            "loss: 0.5032, acc: 0.8011\n",
            "E2E-ABSA >>> 2024-06-04 07:23:52\n",
            ">>> val_acc: 0.6696, val_precision: 0.6103 val_recall: 0.6696, val_f1: 0.6133\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 07:23:57\n",
            "loss: 0.4891, acc: 0.7879\n",
            "E2E-ABSA >>> 2024-06-04 07:24:05\n",
            "loss: 0.4867, acc: 0.7989\n",
            "E2E-ABSA >>> 2024-06-04 07:24:12\n",
            ">>> val_acc: 0.6345, val_precision: 0.5998 val_recall: 0.6345, val_f1: 0.6098\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 07:24:18\n",
            "loss: 0.4754, acc: 0.8102\n",
            "E2E-ABSA >>> 2024-06-04 07:24:31\n",
            ">>> val_acc: 0.6714, val_precision: 0.6168 val_recall: 0.6714, val_f1: 0.6150\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 07:24:32\n",
            "loss: 0.3949, acc: 0.7969\n",
            "E2E-ABSA >>> 2024-06-04 07:24:40\n",
            "loss: 0.5094, acc: 0.7867\n",
            "E2E-ABSA >>> 2024-06-04 07:24:51\n",
            ">>> val_acc: 0.6341, val_precision: 0.6089 val_recall: 0.6341, val_f1: 0.6195\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 07:24:53\n",
            "loss: 0.3904, acc: 0.8482\n",
            "E2E-ABSA >>> 2024-06-04 07:25:02\n",
            "loss: 0.4696, acc: 0.8081\n",
            "E2E-ABSA >>> 2024-06-04 07:25:10\n",
            ">>> val_acc: 0.6469, val_precision: 0.6076 val_recall: 0.6469, val_f1: 0.6208\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6469\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 07:25:16\n",
            "loss: 0.4164, acc: 0.8341\n",
            "E2E-ABSA >>> 2024-06-04 07:25:24\n",
            "loss: 0.4492, acc: 0.8117\n",
            "E2E-ABSA >>> 2024-06-04 07:25:31\n",
            ">>> val_acc: 0.6671, val_precision: 0.5984 val_recall: 0.6671, val_f1: 0.6108\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 07:25:38\n",
            "loss: 0.4429, acc: 0.8158\n",
            "E2E-ABSA >>> 2024-06-04 07:25:46\n",
            "loss: 0.4577, acc: 0.8057\n",
            "E2E-ABSA >>> 2024-06-04 07:25:51\n",
            ">>> val_acc: 0.6206, val_precision: 0.6174 val_recall: 0.6206, val_f1: 0.6088\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 07:26:00\n",
            "loss: 0.4228, acc: 0.8206\n",
            "E2E-ABSA >>> 2024-06-04 07:26:11\n",
            ">>> val_acc: 0.6462, val_precision: 0.6100 val_recall: 0.6462, val_f1: 0.6231\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6462\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 07:26:13\n",
            "loss: 0.3795, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 07:26:22\n",
            "loss: 0.4104, acc: 0.8261\n",
            "E2E-ABSA >>> 2024-06-04 07:26:31\n",
            ">>> val_acc: 0.6497, val_precision: 0.6061 val_recall: 0.6497, val_f1: 0.6172\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 07:26:35\n",
            "loss: 0.4186, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-06-04 07:26:44\n",
            "loss: 0.4160, acc: 0.8256\n",
            "E2E-ABSA >>> 2024-06-04 07:26:51\n",
            ">>> val_acc: 0.6366, val_precision: 0.6110 val_recall: 0.6366, val_f1: 0.6154\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 07:26:57\n",
            "loss: 0.3842, acc: 0.8351\n",
            "E2E-ABSA >>> 2024-06-04 07:27:06\n",
            "loss: 0.4053, acc: 0.8267\n",
            "E2E-ABSA >>> 2024-06-04 07:27:11\n",
            ">>> val_acc: 0.6487, val_precision: 0.6094 val_recall: 0.6487, val_f1: 0.6232\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6487\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-04 07:27:20\n",
            "loss: 0.3769, acc: 0.8451\n",
            "E2E-ABSA >>> 2024-06-04 07:27:31\n",
            ">>> val_acc: 0.6107, val_precision: 0.6242 val_recall: 0.6107, val_f1: 0.6168\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-04 07:27:33\n",
            "loss: 0.3533, acc: 0.8562\n",
            "E2E-ABSA >>> 2024-06-04 07:27:42\n",
            "loss: 0.3665, acc: 0.8422\n",
            "E2E-ABSA >>> 2024-06-04 07:27:51\n",
            ">>> val_acc: 0.6377, val_precision: 0.5981 val_recall: 0.6377, val_f1: 0.6123\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-04 07:27:55\n",
            "loss: 0.3601, acc: 0.8452\n",
            "E2E-ABSA >>> 2024-06-04 07:28:03\n",
            "loss: 0.3794, acc: 0.8372\n",
            "E2E-ABSA >>> 2024-06-04 07:28:11\n",
            ">>> val_acc: 0.6089, val_precision: 0.6133 val_recall: 0.6089, val_f1: 0.6060\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-04 07:28:16\n",
            "loss: 0.3361, acc: 0.8548\n",
            "E2E-ABSA >>> 2024-06-04 07:28:25\n",
            "loss: 0.3727, acc: 0.8385\n",
            "E2E-ABSA >>> 2024-06-04 07:28:30\n",
            ">>> val_acc: 0.6409, val_precision: 0.6132 val_recall: 0.6409, val_f1: 0.6243\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6409\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-04 07:28:38\n",
            "loss: 0.3489, acc: 0.8410\n",
            "E2E-ABSA >>> 2024-06-04 07:28:50\n",
            ">>> val_acc: 0.6195, val_precision: 0.6066 val_recall: 0.6195, val_f1: 0.6120\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-04 07:28:52\n",
            "loss: 0.3674, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-04 07:29:00\n",
            "loss: 0.3480, acc: 0.8534\n",
            "E2E-ABSA >>> 2024-06-04 07:29:10\n",
            ">>> val_acc: 0.6579, val_precision: 0.6094 val_recall: 0.6579, val_f1: 0.6235\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-04 07:29:14\n",
            "loss: 0.3832, acc: 0.8391\n",
            "E2E-ABSA >>> 2024-06-04 07:29:22\n",
            "loss: 0.3703, acc: 0.8424\n",
            "E2E-ABSA >>> 2024-06-04 07:29:30\n",
            ">>> val_acc: 0.6675, val_precision: 0.6083 val_recall: 0.6675, val_f1: 0.6201\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-04 07:29:36\n",
            "loss: 0.3405, acc: 0.8457\n",
            "E2E-ABSA >>> 2024-06-04 07:29:44\n",
            "loss: 0.3603, acc: 0.8407\n",
            "E2E-ABSA >>> 2024-06-04 07:29:50\n",
            ">>> val_acc: 0.6252, val_precision: 0.6141 val_recall: 0.6252, val_f1: 0.6192\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-04 07:29:58\n",
            "loss: 0.3438, acc: 0.8466\n",
            "E2E-ABSA >>> 2024-06-04 07:30:10\n",
            ">>> val_acc: 0.6075, val_precision: 0.6069 val_recall: 0.6075, val_f1: 0.6051\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-04 07:30:11\n",
            "loss: 0.3195, acc: 0.8542\n",
            "E2E-ABSA >>> 2024-06-04 07:30:20\n",
            "loss: 0.3295, acc: 0.8549\n",
            "E2E-ABSA >>> 2024-06-04 07:30:31\n",
            ">>> val_acc: 0.6416, val_precision: 0.6036 val_recall: 0.6416, val_f1: 0.6165\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-04 07:30:34\n",
            "loss: 0.3413, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-06-04 07:30:42\n",
            "loss: 0.3511, acc: 0.8373\n",
            "E2E-ABSA >>> 2024-06-04 07:30:50\n",
            ">>> val_acc: 0.5886, val_precision: 0.6116 val_recall: 0.5886, val_f1: 0.5960\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-04 07:30:56\n",
            "loss: 0.2959, acc: 0.8708\n",
            "E2E-ABSA >>> 2024-06-04 07:31:04\n",
            "loss: 0.3493, acc: 0.8504\n",
            "E2E-ABSA >>> 2024-06-04 07:31:10\n",
            ">>> val_acc: 0.6472, val_precision: 0.6108 val_recall: 0.6472, val_f1: 0.6234\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-04 07:31:18\n",
            "loss: 0.3096, acc: 0.8735\n",
            "E2E-ABSA >>> 2024-06-04 07:31:31\n",
            ">>> val_acc: 0.6437, val_precision: 0.6104 val_recall: 0.6437, val_f1: 0.6233\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-04 07:31:31\n",
            "loss: 0.3636, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-04 07:31:40\n",
            "loss: 0.3324, acc: 0.8507\n",
            "E2E-ABSA >>> 2024-06-04 07:31:50\n",
            ">>> val_acc: 0.6181, val_precision: 0.6176 val_recall: 0.6181, val_f1: 0.6173\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-04 07:31:53\n",
            "loss: 0.3232, acc: 0.8652\n",
            "E2E-ABSA >>> 2024-06-04 07:32:02\n",
            "loss: 0.3181, acc: 0.8632\n",
            "E2E-ABSA >>> 2024-06-04 07:32:11\n",
            ">>> val_acc: 0.6377, val_precision: 0.6165 val_recall: 0.6377, val_f1: 0.6230\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 44.\n",
            "E2E-ABSA >>> 2024-06-04 07:32:15\n",
            "loss: 0.2891, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-04 07:32:24\n",
            "loss: 0.3250, acc: 0.8558\n",
            "E2E-ABSA >>> 2024-06-04 07:32:30\n",
            ">>> val_acc: 0.6302, val_precision: 0.6099 val_recall: 0.6302, val_f1: 0.6187\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 45.\n",
            "E2E-ABSA >>> 2024-06-04 07:32:37\n",
            "loss: 0.3559, acc: 0.8469\n",
            "E2E-ABSA >>> 2024-06-04 07:32:50\n",
            ">>> val_acc: 0.5879, val_precision: 0.6080 val_recall: 0.5879, val_f1: 0.5967\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 46.\n",
            "E2E-ABSA >>> 2024-06-04 07:32:51\n",
            "loss: 0.3099, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 07:32:59\n",
            "loss: 0.3220, acc: 0.8618\n",
            "E2E-ABSA >>> 2024-06-04 07:33:10\n",
            ">>> val_acc: 0.5929, val_precision: 0.6152 val_recall: 0.5929, val_f1: 0.5994\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 47.\n",
            "E2E-ABSA >>> 2024-06-04 07:33:13\n",
            "loss: 0.3352, acc: 0.8393\n",
            "E2E-ABSA >>> 2024-06-04 07:33:22\n",
            "loss: 0.3251, acc: 0.8433\n",
            "E2E-ABSA >>> 2024-06-04 07:33:30\n",
            ">>> val_acc: 0.6437, val_precision: 0.6072 val_recall: 0.6437, val_f1: 0.6183\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 48.\n",
            "E2E-ABSA >>> 2024-06-04 07:33:35\n",
            "loss: 0.3239, acc: 0.8462\n",
            "E2E-ABSA >>> 2024-06-04 07:33:43\n",
            "loss: 0.3242, acc: 0.8524\n",
            "E2E-ABSA >>> 2024-06-04 07:33:50\n",
            ">>> val_acc: 0.6348, val_precision: 0.6061 val_recall: 0.6348, val_f1: 0.6177\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 49.\n",
            "E2E-ABSA >>> 2024-06-04 07:33:57\n",
            "loss: 0.3289, acc: 0.8520\n",
            "E2E-ABSA >>> 2024-06-04 07:34:05\n",
            "loss: 0.3253, acc: 0.8586\n",
            "E2E-ABSA >>> 2024-06-04 07:34:10\n",
            ">>> val_acc: 0.6149, val_precision: 0.6034 val_recall: 0.6149, val_f1: 0.6086\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 50.\n",
            "E2E-ABSA >>> 2024-06-04 07:34:19\n",
            "loss: 0.3234, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 07:34:30\n",
            ">>> val_acc: 0.6224, val_precision: 0.6161 val_recall: 0.6224, val_f1: 0.6149\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 51.\n",
            "E2E-ABSA >>> 2024-06-04 07:34:32\n",
            "loss: 0.2950, acc: 0.8724\n",
            "E2E-ABSA >>> 2024-06-04 07:34:41\n",
            "loss: 0.3170, acc: 0.8589\n",
            "E2E-ABSA >>> 2024-06-04 07:34:50\n",
            ">>> val_acc: 0.6178, val_precision: 0.6111 val_recall: 0.6178, val_f1: 0.6140\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 52.\n",
            "E2E-ABSA >>> 2024-06-04 07:34:55\n",
            "loss: 0.2971, acc: 0.8880\n",
            "E2E-ABSA >>> 2024-06-04 07:35:03\n",
            "loss: 0.3098, acc: 0.8670\n",
            "E2E-ABSA >>> 2024-06-04 07:35:11\n",
            ">>> val_acc: 0.6345, val_precision: 0.6098 val_recall: 0.6345, val_f1: 0.6193\n",
            "E2E-ABSA >>> 2024-06-04 07:35:11\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6409, val_precision: 0.6132 val_recall: 0.6409, val_f1: 0.6243\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.6409\n",
            ">>> test_acc: 0.6157, test_precision: 0.5686, test_recall: 0.6157, test_f1: 0.5862\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "8f5cbdd2-753d-448d-a1c8-f9b0d31ade7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "c9108c5a-3eb2-4fc2-b013-17bab67379b6",
        "tags": []
      },
      "source": [
        "### base-uncased s3 concat"
      ],
      "id": "c9108c5a-3eb2-4fc2-b013-17bab67379b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "c5854043-5c0e-43c3-ac8d-a5e228d20d19",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f5fd935c-2938-4a05-8881-1a2caf2db5dc",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fe8cf61f640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/e_raw_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/e_raw_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 14:54:27\n",
            "loss: 0.9038, acc: 0.6369\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 14:54:38\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 14:54:40\n",
            "loss: 0.8823, acc: 0.6328\n",
            "E2E-ABSA >>> 2024-06-04 14:54:49\n",
            "loss: 0.8393, acc: 0.6683\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 14:54:58\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 14:55:02\n",
            "loss: 0.8139, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-04 14:55:10\n",
            "loss: 0.8033, acc: 0.6715\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 14:55:17\n",
            ">>> val_acc: 0.6636, val_precision: 0.5580 val_recall: 0.6636, val_f1: 0.5966\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6636\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 14:55:23\n",
            "loss: 0.7940, acc: 0.6684\n",
            "E2E-ABSA >>> 2024-06-04 14:55:32\n",
            "loss: 0.7854, acc: 0.6766\n",
            "E2E-ABSA >>> 2024-06-04 14:55:37\n",
            ">>> val_acc: 0.6821, val_precision: 0.6134 val_recall: 0.6821, val_f1: 0.5848\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 14:55:45\n",
            "loss: 0.7295, acc: 0.7044\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 14:55:56\n",
            ">>> val_acc: 0.6750, val_precision: 0.5669 val_recall: 0.6750, val_f1: 0.6002\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.675\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 14:55:58\n",
            "loss: 0.6593, acc: 0.7219\n",
            "E2E-ABSA >>> 2024-06-04 14:56:07\n",
            "loss: 0.6910, acc: 0.7130\n",
            "E2E-ABSA >>> 2024-06-04 14:56:16\n",
            ">>> val_acc: 0.6245, val_precision: 0.6100 val_recall: 0.6245, val_f1: 0.6160\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6245\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 14:56:20\n",
            "loss: 0.6724, acc: 0.7301\n",
            "E2E-ABSA >>> 2024-06-04 14:56:28\n",
            "loss: 0.6856, acc: 0.7222\n",
            "E2E-ABSA >>> 2024-06-04 14:56:36\n",
            ">>> val_acc: 0.6707, val_precision: 0.6102 val_recall: 0.6707, val_f1: 0.6121\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 14:56:41\n",
            "loss: 0.6858, acc: 0.7169\n",
            "E2E-ABSA >>> 2024-06-04 14:56:50\n",
            "loss: 0.6547, acc: 0.7288\n",
            "E2E-ABSA >>> 2024-06-04 14:56:55\n",
            ">>> val_acc: 0.6728, val_precision: 0.6029 val_recall: 0.6728, val_f1: 0.5980\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 14:57:03\n",
            "loss: 0.6034, acc: 0.7588\n",
            "E2E-ABSA >>> 2024-06-04 14:57:15\n",
            ">>> val_acc: 0.6835, val_precision: 0.6161 val_recall: 0.6835, val_f1: 0.6149\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 14:57:16\n",
            "loss: 0.6447, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-04 14:57:24\n",
            "loss: 0.6142, acc: 0.7468\n",
            "E2E-ABSA >>> 2024-06-04 14:57:34\n",
            ">>> val_acc: 0.6831, val_precision: 0.6109 val_recall: 0.6831, val_f1: 0.6220\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6831\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 14:57:38\n",
            "loss: 0.5348, acc: 0.7891\n",
            "E2E-ABSA >>> 2024-06-04 14:57:46\n",
            "loss: 0.5700, acc: 0.7696\n",
            "E2E-ABSA >>> 2024-06-04 14:57:54\n",
            ">>> val_acc: 0.6469, val_precision: 0.6178 val_recall: 0.6469, val_f1: 0.6231\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6469\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 14:58:00\n",
            "loss: 0.5565, acc: 0.7734\n",
            "E2E-ABSA >>> 2024-06-04 14:58:08\n",
            "loss: 0.5619, acc: 0.7698\n",
            "E2E-ABSA >>> 2024-06-04 14:58:14\n",
            ">>> val_acc: 0.6519, val_precision: 0.6048 val_recall: 0.6519, val_f1: 0.6215\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 14:58:21\n",
            "loss: 0.5539, acc: 0.7706\n",
            "E2E-ABSA >>> 2024-06-04 14:58:33\n",
            ">>> val_acc: 0.6316, val_precision: 0.6168 val_recall: 0.6316, val_f1: 0.6236\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6316\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 14:58:34\n",
            "loss: 0.3904, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-04 14:58:43\n",
            "loss: 0.5161, acc: 0.7706\n",
            "E2E-ABSA >>> 2024-06-04 14:58:53\n",
            ">>> val_acc: 0.6774, val_precision: 0.6158 val_recall: 0.6774, val_f1: 0.6226\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 14:58:56\n",
            "loss: 0.4949, acc: 0.7951\n",
            "E2E-ABSA >>> 2024-06-04 14:59:04\n",
            "loss: 0.4933, acc: 0.8010\n",
            "E2E-ABSA >>> 2024-06-04 14:59:12\n",
            ">>> val_acc: 0.6671, val_precision: 0.6197 val_recall: 0.6671, val_f1: 0.6246\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6671\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 14:59:18\n",
            "loss: 0.4555, acc: 0.8187\n",
            "E2E-ABSA >>> 2024-06-04 14:59:26\n",
            "loss: 0.4793, acc: 0.8004\n",
            "E2E-ABSA >>> 2024-06-04 14:59:32\n",
            ">>> val_acc: 0.6558, val_precision: 0.6066 val_recall: 0.6558, val_f1: 0.6237\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 14:59:39\n",
            "loss: 0.4777, acc: 0.7946\n",
            "E2E-ABSA >>> 2024-06-04 14:59:51\n",
            ">>> val_acc: 0.6409, val_precision: 0.6160 val_recall: 0.6409, val_f1: 0.6260\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6409\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 14:59:52\n",
            "loss: 0.5169, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-06-04 15:00:01\n",
            "loss: 0.4500, acc: 0.8177\n",
            "E2E-ABSA >>> 2024-06-04 15:00:11\n",
            ">>> val_acc: 0.6650, val_precision: 0.6214 val_recall: 0.6650, val_f1: 0.6362\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.665\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 15:00:14\n",
            "loss: 0.3735, acc: 0.8379\n",
            "E2E-ABSA >>> 2024-06-04 15:00:23\n",
            "loss: 0.4237, acc: 0.8229\n",
            "E2E-ABSA >>> 2024-06-04 15:00:31\n",
            ">>> val_acc: 0.6021, val_precision: 0.6297 val_recall: 0.6021, val_f1: 0.6045\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 15:00:36\n",
            "loss: 0.4081, acc: 0.8214\n",
            "E2E-ABSA >>> 2024-06-04 15:00:44\n",
            "loss: 0.4375, acc: 0.8105\n",
            "E2E-ABSA >>> 2024-06-04 15:00:50\n",
            ">>> val_acc: 0.6746, val_precision: 0.6175 val_recall: 0.6746, val_f1: 0.6338\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 15:00:57\n",
            "loss: 0.4184, acc: 0.8203\n",
            "E2E-ABSA >>> 2024-06-04 15:01:10\n",
            ">>> val_acc: 0.6693, val_precision: 0.6131 val_recall: 0.6693, val_f1: 0.6266\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 15:01:10\n",
            "loss: 0.3300, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-04 15:01:19\n",
            "loss: 0.4258, acc: 0.8107\n",
            "E2E-ABSA >>> 2024-06-04 15:01:29\n",
            ">>> val_acc: 0.6622, val_precision: 0.6172 val_recall: 0.6622, val_f1: 0.6323\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 15:01:32\n",
            "loss: 0.3419, acc: 0.8638\n",
            "E2E-ABSA >>> 2024-06-04 15:01:40\n",
            "loss: 0.3914, acc: 0.8364\n",
            "E2E-ABSA >>> 2024-06-04 15:01:49\n",
            ">>> val_acc: 0.6544, val_precision: 0.6113 val_recall: 0.6544, val_f1: 0.6218\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 15:01:53\n",
            "loss: 0.3665, acc: 0.8534\n",
            "E2E-ABSA >>> 2024-06-04 15:02:01\n",
            "loss: 0.4148, acc: 0.8265\n",
            "E2E-ABSA >>> 2024-06-04 15:02:08\n",
            ">>> val_acc: 0.6817, val_precision: 0.6144 val_recall: 0.6817, val_f1: 0.6242\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 15:02:14\n",
            "loss: 0.3672, acc: 0.8479\n",
            "E2E-ABSA >>> 2024-06-04 15:02:23\n",
            "loss: 0.4168, acc: 0.8220\n",
            "E2E-ABSA >>> 2024-06-04 15:02:27\n",
            ">>> val_acc: 0.6391, val_precision: 0.6147 val_recall: 0.6391, val_f1: 0.6181\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 15:02:36\n",
            "loss: 0.3642, acc: 0.8450\n",
            "E2E-ABSA >>> 2024-06-04 15:02:47\n",
            ">>> val_acc: 0.6476, val_precision: 0.6176 val_recall: 0.6476, val_f1: 0.6262\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 15:02:49\n",
            "loss: 0.3608, acc: 0.8646\n",
            "E2E-ABSA >>> 2024-06-04 15:02:57\n",
            "loss: 0.3768, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-04 15:03:06\n",
            ">>> val_acc: 0.6750, val_precision: 0.6154 val_recall: 0.6750, val_f1: 0.6274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 15:03:10\n",
            "loss: 0.3577, acc: 0.8490\n",
            "E2E-ABSA >>> 2024-06-04 15:03:19\n",
            "loss: 0.3653, acc: 0.8429\n",
            "E2E-ABSA >>> 2024-06-04 15:03:26\n",
            ">>> val_acc: 0.6512, val_precision: 0.6165 val_recall: 0.6512, val_f1: 0.6293\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 15:03:32\n",
            "loss: 0.3431, acc: 0.8576\n",
            "E2E-ABSA >>> 2024-06-04 15:03:40\n",
            "loss: 0.3590, acc: 0.8492\n",
            "E2E-ABSA >>> 2024-06-04 15:03:45\n",
            ">>> val_acc: 0.6497, val_precision: 0.6147 val_recall: 0.6497, val_f1: 0.6279\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-04 15:03:53\n",
            "loss: 0.3408, acc: 0.8587\n",
            "E2E-ABSA >>> 2024-06-04 15:04:05\n",
            ">>> val_acc: 0.6114, val_precision: 0.6081 val_recall: 0.6114, val_f1: 0.6066\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-04 15:04:06\n",
            "loss: 0.2762, acc: 0.8688\n",
            "E2E-ABSA >>> 2024-06-04 15:04:15\n",
            "loss: 0.3257, acc: 0.8542\n",
            "E2E-ABSA >>> 2024-06-04 15:04:24\n",
            ">>> val_acc: 0.6380, val_precision: 0.6133 val_recall: 0.6380, val_f1: 0.6239\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-04 15:04:28\n",
            "loss: 0.3134, acc: 0.8693\n",
            "E2E-ABSA >>> 2024-06-04 15:04:36\n",
            "loss: 0.3518, acc: 0.8503\n",
            "E2E-ABSA >>> 2024-06-04 15:04:43\n",
            ">>> val_acc: 0.6387, val_precision: 0.6124 val_recall: 0.6387, val_f1: 0.6228\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-04 15:04:49\n",
            "loss: 0.3117, acc: 0.8557\n",
            "E2E-ABSA >>> 2024-06-04 15:04:58\n",
            "loss: 0.3508, acc: 0.8441\n",
            "E2E-ABSA >>> 2024-06-04 15:05:03\n",
            ">>> val_acc: 0.6625, val_precision: 0.6125 val_recall: 0.6625, val_f1: 0.6287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-04 15:05:11\n",
            "loss: 0.3248, acc: 0.8512\n",
            "E2E-ABSA >>> 2024-06-04 15:05:22\n",
            ">>> val_acc: 0.6284, val_precision: 0.6114 val_recall: 0.6284, val_f1: 0.6191\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-04 15:05:24\n",
            "loss: 0.3595, acc: 0.8516\n",
            "E2E-ABSA >>> 2024-06-04 15:05:32\n",
            "loss: 0.3378, acc: 0.8578\n",
            "E2E-ABSA >>> 2024-06-04 15:05:42\n",
            ">>> val_acc: 0.6632, val_precision: 0.6110 val_recall: 0.6632, val_f1: 0.6168\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-04 15:05:45\n",
            "loss: 0.3141, acc: 0.8656\n",
            "E2E-ABSA >>> 2024-06-04 15:05:53\n",
            "loss: 0.3353, acc: 0.8554\n",
            "E2E-ABSA >>> 2024-06-04 15:06:01\n",
            ">>> val_acc: 0.6586, val_precision: 0.6106 val_recall: 0.6586, val_f1: 0.6245\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-04 15:06:06\n",
            "loss: 0.3139, acc: 0.8711\n",
            "E2E-ABSA >>> 2024-06-04 15:06:15\n",
            "loss: 0.3183, acc: 0.8628\n",
            "E2E-ABSA >>> 2024-06-04 15:06:21\n",
            ">>> val_acc: 0.6373, val_precision: 0.6127 val_recall: 0.6373, val_f1: 0.6186\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-04 15:06:28\n",
            "loss: 0.3047, acc: 0.8672\n",
            "E2E-ABSA >>> 2024-06-04 15:06:40\n",
            ">>> val_acc: 0.6536, val_precision: 0.6112 val_recall: 0.6536, val_f1: 0.6264\n",
            "E2E-ABSA >>> 2024-06-04 15:06:40\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6650, val_precision: 0.6214 val_recall: 0.6650, val_f1: 0.6362\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.665\n",
            ">>> test_acc: 0.6339, test_precision: 0.5796, test_recall: 0.6339, test_f1: 0.5960\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "c5854043-5c0e-43c3-ac8d-a5e228d20d19"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "MhiXDrOyYtNl",
        "tags": []
      },
      "source": [
        "### base-uncased s4 concat"
      ],
      "id": "MhiXDrOyYtNl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "tDiW1Cd2YtNm",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "04db419c-9b79-45d1-99a2-58a7f1ce334b",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 253kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 6.45MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 6.33MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 570/570 [00:00<00:00, 5.08MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:02<00:00, 161MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5532.\n",
            "> testing dataset count: 2300.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7df12cc12e60>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/b_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/b_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-08 16:39:27\n",
            "loss: 0.9043, acc: 0.6388\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 16:40:13\n",
            ">>> val_acc: 0.6739, val_precision: 0.4541 val_recall: 0.6739, val_f1: 0.5426\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6739\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-08 16:40:29\n",
            "loss: 0.8611, acc: 0.6690\n",
            "E2E-ABSA >>> 2024-06-08 16:41:05\n",
            "loss: 0.8297, acc: 0.6781\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 16:41:41\n",
            ">>> val_acc: 0.6739, val_precision: 0.4541 val_recall: 0.6739, val_f1: 0.5426\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-08 16:42:00\n",
            "loss: 0.7875, acc: 0.6829\n",
            "E2E-ABSA >>> 2024-06-08 16:42:35\n",
            "loss: 0.8032, acc: 0.6794\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 16:43:02\n",
            ">>> val_acc: 0.6739, val_precision: 0.4541 val_recall: 0.6739, val_f1: 0.5426\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-08 16:43:31\n",
            "loss: 0.7714, acc: 0.6813\n",
            "E2E-ABSA >>> 2024-06-08 16:44:24\n",
            ">>> val_acc: 0.6757, val_precision: 0.6029 val_recall: 0.6757, val_f1: 0.5872\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6757\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-08 16:44:34\n",
            "loss: 0.7032, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-08 16:45:10\n",
            "loss: 0.7748, acc: 0.6800\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 16:45:53\n",
            ">>> val_acc: 0.6739, val_precision: 0.4541 val_recall: 0.6739, val_f1: 0.5426\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-08 16:46:05\n",
            "loss: 0.7548, acc: 0.6589\n",
            "E2E-ABSA >>> 2024-06-08 16:46:41\n",
            "loss: 0.7487, acc: 0.6731\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 16:47:14\n",
            ">>> val_acc: 0.6764, val_precision: 0.5772 val_recall: 0.6764, val_f1: 0.5617\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-08 16:47:36\n",
            "loss: 0.7653, acc: 0.6845\n",
            "E2E-ABSA >>> 2024-06-08 16:48:11\n",
            "loss: 0.7366, acc: 0.6910\n",
            "E2E-ABSA >>> 2024-06-08 16:48:35\n",
            ">>> val_acc: 0.6678, val_precision: 0.6203 val_recall: 0.6678, val_f1: 0.6201\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6678\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-08 16:49:09\n",
            "loss: 0.7279, acc: 0.6756\n",
            "E2E-ABSA >>> 2024-06-08 16:49:58\n",
            ">>> val_acc: 0.6880, val_precision: 0.7157 val_recall: 0.6880, val_f1: 0.5874\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-08 16:50:04\n",
            "loss: 0.6608, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-08 16:50:39\n",
            "loss: 0.6877, acc: 0.7091\n",
            "E2E-ABSA >>> 2024-06-08 16:51:19\n",
            ">>> val_acc: 0.6779, val_precision: 0.7201 val_recall: 0.6779, val_f1: 0.5555\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-08 16:51:34\n",
            "loss: 0.6949, acc: 0.6948\n",
            "E2E-ABSA >>> 2024-06-08 16:52:10\n",
            "loss: 0.6751, acc: 0.7098\n",
            "E2E-ABSA >>> 2024-06-08 16:52:40\n",
            ">>> val_acc: 0.6887, val_precision: 0.6475 val_recall: 0.6887, val_f1: 0.6271\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6887\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-08 16:53:11\n",
            "loss: 0.6081, acc: 0.7482\n",
            "E2E-ABSA >>> 2024-06-08 16:53:47\n",
            "loss: 0.6457, acc: 0.7224\n",
            "E2E-ABSA >>> 2024-06-08 16:54:07\n",
            ">>> val_acc: 0.6638, val_precision: 0.6332 val_recall: 0.6638, val_f1: 0.6313\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6638\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-08 16:54:49\n",
            "loss: 0.6120, acc: 0.7339\n",
            "E2E-ABSA >>> 2024-06-08 16:55:35\n",
            ">>> val_acc: 0.6602, val_precision: 0.6235 val_recall: 0.6602, val_f1: 0.6316\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6602\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-08 16:55:46\n",
            "loss: 0.5307, acc: 0.7578\n",
            "E2E-ABSA >>> 2024-06-08 16:56:21\n",
            "loss: 0.6067, acc: 0.7288\n",
            "E2E-ABSA >>> 2024-06-08 16:56:59\n",
            ">>> val_acc: 0.6558, val_precision: 0.6257 val_recall: 0.6558, val_f1: 0.6356\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6558\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-08 16:57:23\n",
            "loss: 0.5195, acc: 0.7770\n",
            "E2E-ABSA >>> 2024-06-08 16:57:59\n",
            "loss: 0.5480, acc: 0.7620\n",
            "E2E-ABSA >>> 2024-06-08 16:58:26\n",
            ">>> val_acc: 0.6916, val_precision: 0.6542 val_recall: 0.6916, val_f1: 0.6110\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-08 16:58:54\n",
            "loss: 0.5176, acc: 0.7821\n",
            "E2E-ABSA >>> 2024-06-08 16:59:47\n",
            ">>> val_acc: 0.6529, val_precision: 0.6311 val_recall: 0.6529, val_f1: 0.6378\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6529\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-08 16:59:51\n",
            "loss: 0.4199, acc: 0.8375\n",
            "E2E-ABSA >>> 2024-06-08 17:00:26\n",
            "loss: 0.5130, acc: 0.7786\n",
            "E2E-ABSA >>> 2024-06-08 17:01:11\n",
            ">>> val_acc: 0.5774, val_precision: 0.6334 val_recall: 0.5774, val_f1: 0.5972\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-08 17:01:22\n",
            "loss: 0.4298, acc: 0.8164\n",
            "E2E-ABSA >>> 2024-06-08 17:01:57\n",
            "loss: 0.4710, acc: 0.7959\n",
            "E2E-ABSA >>> 2024-06-08 17:02:32\n",
            ">>> val_acc: 0.6699, val_precision: 0.6264 val_recall: 0.6699, val_f1: 0.6343\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-08 17:02:53\n",
            "loss: 0.4312, acc: 0.8189\n",
            "E2E-ABSA >>> 2024-06-08 17:03:28\n",
            "loss: 0.4553, acc: 0.8054\n",
            "E2E-ABSA >>> 2024-06-08 17:03:53\n",
            ">>> val_acc: 0.6580, val_precision: 0.6274 val_recall: 0.6580, val_f1: 0.6373\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-08 17:04:23\n",
            "loss: 0.4303, acc: 0.8081\n",
            "E2E-ABSA >>> 2024-06-08 17:05:14\n",
            ">>> val_acc: 0.5936, val_precision: 0.6304 val_recall: 0.5936, val_f1: 0.6078\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-08 17:05:19\n",
            "loss: 0.3932, acc: 0.8413\n",
            "E2E-ABSA >>> 2024-06-08 17:05:54\n",
            "loss: 0.4295, acc: 0.8241\n",
            "E2E-ABSA >>> 2024-06-08 17:06:35\n",
            ">>> val_acc: 0.6663, val_precision: 0.6184 val_recall: 0.6663, val_f1: 0.6258\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-08 17:06:49\n",
            "loss: 0.3927, acc: 0.8219\n",
            "E2E-ABSA >>> 2024-06-08 17:07:25\n",
            "loss: 0.4065, acc: 0.8228\n",
            "E2E-ABSA >>> 2024-06-08 17:07:56\n",
            ">>> val_acc: 0.6544, val_precision: 0.6135 val_recall: 0.6544, val_f1: 0.6258\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-08 17:08:55\n",
            "loss: 0.4060, acc: 0.8207\n",
            "E2E-ABSA >>> 2024-06-08 17:09:17\n",
            ">>> val_acc: 0.6356, val_precision: 0.6170 val_recall: 0.6356, val_f1: 0.6246\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-08 17:09:50\n",
            "loss: 0.3930, acc: 0.8285\n",
            "E2E-ABSA >>> 2024-06-08 17:10:38\n",
            ">>> val_acc: 0.6215, val_precision: 0.6186 val_recall: 0.6215, val_f1: 0.6196\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-08 17:10:46\n",
            "loss: 0.2957, acc: 0.8571\n",
            "E2E-ABSA >>> 2024-06-08 17:11:21\n",
            "loss: 0.3655, acc: 0.8316\n",
            "E2E-ABSA >>> 2024-06-08 17:11:59\n",
            ">>> val_acc: 0.6714, val_precision: 0.6206 val_recall: 0.6714, val_f1: 0.6203\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-08 17:12:16\n",
            "loss: 0.3515, acc: 0.8320\n",
            "E2E-ABSA >>> 2024-06-08 17:12:52\n",
            "loss: 0.3759, acc: 0.8252\n",
            "E2E-ABSA >>> 2024-06-08 17:13:21\n",
            ">>> val_acc: 0.6114, val_precision: 0.6155 val_recall: 0.6114, val_f1: 0.6134\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-08 17:13:47\n",
            "loss: 0.3484, acc: 0.8425\n",
            "E2E-ABSA >>> 2024-06-08 17:14:42\n",
            ">>> val_acc: 0.6320, val_precision: 0.6167 val_recall: 0.6320, val_f1: 0.6231\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-08 17:14:42\n",
            "loss: 0.3426, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-08 17:15:18\n",
            "loss: 0.3413, acc: 0.8493\n",
            "E2E-ABSA >>> 2024-06-08 17:16:03\n",
            ">>> val_acc: 0.6544, val_precision: 0.6077 val_recall: 0.6544, val_f1: 0.6180\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-08 17:16:13\n",
            "loss: 0.3224, acc: 0.8707\n",
            "E2E-ABSA >>> 2024-06-08 17:16:48\n",
            "loss: 0.3423, acc: 0.8503\n",
            "E2E-ABSA >>> 2024-06-08 17:17:24\n",
            ">>> val_acc: 0.6432, val_precision: 0.6114 val_recall: 0.6432, val_f1: 0.6226\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-08 17:17:44\n",
            "loss: 0.3286, acc: 0.8504\n",
            "E2E-ABSA >>> 2024-06-08 17:18:19\n",
            "loss: 0.3499, acc: 0.8389\n",
            "E2E-ABSA >>> 2024-06-08 17:18:45\n",
            ">>> val_acc: 0.5900, val_precision: 0.6105 val_recall: 0.5900, val_f1: 0.5952\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-08 17:19:14\n",
            "loss: 0.3148, acc: 0.8592\n",
            "E2E-ABSA >>> 2024-06-08 17:20:06\n",
            ">>> val_acc: 0.6153, val_precision: 0.6215 val_recall: 0.6153, val_f1: 0.6183\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-08 17:20:10\n",
            "loss: 0.2824, acc: 0.8562\n",
            "E2E-ABSA >>> 2024-06-08 17:20:45\n",
            "loss: 0.3150, acc: 0.8614\n",
            "E2E-ABSA >>> 2024-06-08 17:21:27\n",
            ">>> val_acc: 0.6392, val_precision: 0.6121 val_recall: 0.6392, val_f1: 0.6132\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-08 17:21:40\n",
            "loss: 0.3263, acc: 0.8716\n",
            "E2E-ABSA >>> 2024-06-08 17:22:16\n",
            "loss: 0.3242, acc: 0.8663\n",
            "E2E-ABSA >>> 2024-06-08 17:22:49\n",
            ">>> val_acc: 0.6471, val_precision: 0.6058 val_recall: 0.6471, val_f1: 0.6179\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-08 17:23:11\n",
            "loss: 0.3008, acc: 0.8623\n",
            "E2E-ABSA >>> 2024-06-08 17:23:46\n",
            "loss: 0.3275, acc: 0.8552\n",
            "E2E-ABSA >>> 2024-06-08 17:24:10\n",
            ">>> val_acc: 0.6146, val_precision: 0.6137 val_recall: 0.6146, val_f1: 0.6135\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-08 17:24:42\n",
            "loss: 0.3209, acc: 0.8530\n",
            "E2E-ABSA >>> 2024-06-08 17:25:31\n",
            ">>> val_acc: 0.6150, val_precision: 0.6130 val_recall: 0.6150, val_f1: 0.6140\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-08 17:25:37\n",
            "loss: 0.2643, acc: 0.8889\n",
            "E2E-ABSA >>> 2024-06-08 17:26:12\n",
            "loss: 0.2940, acc: 0.8702\n",
            "E2E-ABSA >>> 2024-06-08 17:26:52\n",
            ">>> val_acc: 0.6135, val_precision: 0.6113 val_recall: 0.6135, val_f1: 0.6093\n",
            "E2E-ABSA >>> 2024-06-08 17:26:52\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6529, val_precision: 0.6311 val_recall: 0.6529, val_f1: 0.6378\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.6529\n",
            ">>> test_acc: 0.6222, test_precision: 0.5766, test_recall: 0.6222, test_f1: 0.5891\n"
          ]
        }
      ],
      "source": [
        "# 8-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "tDiW1Cd2YtNm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "IZIIIipzY1lp",
        "tags": []
      },
      "source": [
        "### base-uncased s5 concat"
      ],
      "id": "IZIIIipzY1lp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "V0RNq-z4Y1lq",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b297d793-7f50-486b-ba3f-38a35d06be77",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7a284222ae60>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/c_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/c_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-08 17:39:38\n",
            "loss: 0.8760, acc: 0.6669\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:40:23\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6774\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-08 17:40:34\n",
            "loss: 0.8098, acc: 0.6968\n",
            "E2E-ABSA >>> 2024-06-08 17:41:10\n",
            "loss: 0.8295, acc: 0.6747\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:41:46\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-08 17:42:05\n",
            "loss: 0.8357, acc: 0.6736\n",
            "E2E-ABSA >>> 2024-06-08 17:42:40\n",
            "loss: 0.8293, acc: 0.6778\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:43:07\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-08 17:43:36\n",
            "loss: 0.8230, acc: 0.6782\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:44:28\n",
            ">>> val_acc: 0.6807, val_precision: 0.6805 val_recall: 0.6807, val_f1: 0.5546\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6807\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-08 17:44:39\n",
            "loss: 0.9110, acc: 0.6016\n",
            "E2E-ABSA >>> 2024-06-08 17:45:15\n",
            "loss: 0.8129, acc: 0.6771\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:45:58\n",
            ">>> val_acc: 0.6803, val_precision: 0.5837 val_recall: 0.6803, val_f1: 0.5621\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6803\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-08 17:46:17\n",
            "loss: 0.8085, acc: 0.6661\n",
            "E2E-ABSA >>> 2024-06-08 17:46:53\n",
            "loss: 0.7712, acc: 0.6815\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:47:26\n",
            ">>> val_acc: 0.6814, val_precision: 0.6107 val_recall: 0.6814, val_f1: 0.5623\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6814\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-08 17:47:54\n",
            "loss: 0.7205, acc: 0.7107\n",
            "E2E-ABSA >>> 2024-06-08 17:48:31\n",
            "loss: 0.7638, acc: 0.6875\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:48:54\n",
            ">>> val_acc: 0.6810, val_precision: 0.6051 val_recall: 0.6810, val_f1: 0.5589\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-08 17:49:25\n",
            "loss: 0.7409, acc: 0.6854\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:50:15\n",
            ">>> val_acc: 0.6828, val_precision: 0.6094 val_recall: 0.6828, val_f1: 0.5641\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6828\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-08 17:50:28\n",
            "loss: 0.7365, acc: 0.6914\n",
            "E2E-ABSA >>> 2024-06-08 17:51:04\n",
            "loss: 0.7349, acc: 0.6923\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:51:44\n",
            ">>> val_acc: 0.6767, val_precision: 0.5649 val_recall: 0.6767, val_f1: 0.5868\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6767\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-08 17:52:06\n",
            "loss: 0.6613, acc: 0.7238\n",
            "E2E-ABSA >>> 2024-06-08 17:52:42\n",
            "loss: 0.7124, acc: 0.7067\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 17:53:13\n",
            ">>> val_acc: 0.6669, val_precision: 0.5608 val_recall: 0.6669, val_f1: 0.5978\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6669\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-08 17:53:44\n",
            "loss: 0.6763, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-08 17:54:20\n",
            "loss: 0.6836, acc: 0.7103\n",
            "E2E-ABSA >>> 2024-06-08 17:54:40\n",
            ">>> val_acc: 0.6546, val_precision: 0.6005 val_recall: 0.6546, val_f1: 0.6118\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6546\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-08 17:55:23\n",
            "loss: 0.6410, acc: 0.7262\n",
            "E2E-ABSA >>> 2024-06-08 17:56:10\n",
            ">>> val_acc: 0.6430, val_precision: 0.6044 val_recall: 0.6430, val_f1: 0.6044\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-08 17:56:18\n",
            "loss: 0.6381, acc: 0.7240\n",
            "E2E-ABSA >>> 2024-06-08 17:56:54\n",
            "loss: 0.6331, acc: 0.7293\n",
            "E2E-ABSA >>> 2024-06-08 17:57:31\n",
            ">>> val_acc: 0.6542, val_precision: 0.5906 val_recall: 0.6542, val_f1: 0.6023\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-08 17:57:49\n",
            "loss: 0.6201, acc: 0.7439\n",
            "E2E-ABSA >>> 2024-06-08 17:58:24\n",
            "loss: 0.6036, acc: 0.7475\n",
            "E2E-ABSA >>> 2024-06-08 17:58:52\n",
            ">>> val_acc: 0.6329, val_precision: 0.5945 val_recall: 0.6329, val_f1: 0.6045\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-08 17:59:20\n",
            "loss: 0.5793, acc: 0.7532\n",
            "E2E-ABSA >>> 2024-06-08 18:00:13\n",
            ">>> val_acc: 0.6354, val_precision: 0.6108 val_recall: 0.6354, val_f1: 0.6108\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-08 18:00:15\n",
            "loss: 0.5679, acc: 0.7625\n",
            "E2E-ABSA >>> 2024-06-08 18:00:50\n",
            "loss: 0.5490, acc: 0.7786\n",
            "E2E-ABSA >>> 2024-06-08 18:01:34\n",
            ">>> val_acc: 0.6579, val_precision: 0.6183 val_recall: 0.6579, val_f1: 0.6069\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-08 18:01:46\n",
            "loss: 0.4826, acc: 0.8184\n",
            "E2E-ABSA >>> 2024-06-08 18:02:21\n",
            "loss: 0.5248, acc: 0.7869\n",
            "E2E-ABSA >>> 2024-06-08 18:02:55\n",
            ">>> val_acc: 0.6517, val_precision: 0.5999 val_recall: 0.6517, val_f1: 0.6139\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6517\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-08 18:03:23\n",
            "loss: 0.5156, acc: 0.7913\n",
            "E2E-ABSA >>> 2024-06-08 18:03:58\n",
            "loss: 0.5075, acc: 0.7901\n",
            "E2E-ABSA >>> 2024-06-08 18:04:23\n",
            ">>> val_acc: 0.6390, val_precision: 0.6040 val_recall: 0.6390, val_f1: 0.6166\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.639\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-08 18:05:00\n",
            "loss: 0.4653, acc: 0.8176\n",
            "E2E-ABSA >>> 2024-06-08 18:05:51\n",
            ">>> val_acc: 0.6238, val_precision: 0.5953 val_recall: 0.6238, val_f1: 0.5914\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-08 18:05:55\n",
            "loss: 0.4551, acc: 0.7981\n",
            "E2E-ABSA >>> 2024-06-08 18:06:31\n",
            "loss: 0.4564, acc: 0.8158\n",
            "E2E-ABSA >>> 2024-06-08 18:07:12\n",
            ">>> val_acc: 0.5930, val_precision: 0.6031 val_recall: 0.5930, val_f1: 0.5922\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-08 18:07:26\n",
            "loss: 0.4363, acc: 0.8031\n",
            "E2E-ABSA >>> 2024-06-08 18:08:01\n",
            "loss: 0.4394, acc: 0.8161\n",
            "E2E-ABSA >>> 2024-06-08 18:08:33\n",
            ">>> val_acc: 0.6140, val_precision: 0.6108 val_recall: 0.6140, val_f1: 0.6114\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-08 18:08:57\n",
            "loss: 0.4407, acc: 0.8228\n",
            "E2E-ABSA >>> 2024-06-08 18:09:32\n",
            "loss: 0.4515, acc: 0.8147\n",
            "E2E-ABSA >>> 2024-06-08 18:09:54\n",
            ">>> val_acc: 0.6014, val_precision: 0.6185 val_recall: 0.6014, val_f1: 0.6060\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-08 18:10:27\n",
            "loss: 0.4121, acc: 0.8318\n",
            "E2E-ABSA >>> 2024-06-08 18:11:15\n",
            ">>> val_acc: 0.6383, val_precision: 0.6085 val_recall: 0.6383, val_f1: 0.6132\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-08 18:11:22\n",
            "loss: 0.3584, acc: 0.8661\n",
            "E2E-ABSA >>> 2024-06-08 18:11:58\n",
            "loss: 0.4048, acc: 0.8352\n",
            "E2E-ABSA >>> 2024-06-08 18:12:36\n",
            ">>> val_acc: 0.6513, val_precision: 0.6082 val_recall: 0.6513, val_f1: 0.6163\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-08 18:12:53\n",
            "loss: 0.3920, acc: 0.8307\n",
            "E2E-ABSA >>> 2024-06-08 18:13:28\n",
            "loss: 0.4028, acc: 0.8328\n",
            "E2E-ABSA >>> 2024-06-08 18:13:57\n",
            ">>> val_acc: 0.6477, val_precision: 0.5960 val_recall: 0.6477, val_f1: 0.6075\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-08 18:14:23\n",
            "loss: 0.3889, acc: 0.8458\n",
            "E2E-ABSA >>> 2024-06-08 18:15:18\n",
            ">>> val_acc: 0.6311, val_precision: 0.6096 val_recall: 0.6311, val_f1: 0.6186\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6311\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-08 18:15:23\n",
            "loss: 0.4239, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-08 18:15:59\n",
            "loss: 0.3638, acc: 0.8468\n",
            "E2E-ABSA >>> 2024-06-08 18:16:44\n",
            ">>> val_acc: 0.6137, val_precision: 0.5950 val_recall: 0.6137, val_f1: 0.6028\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-08 18:16:54\n",
            "loss: 0.3704, acc: 0.8448\n",
            "E2E-ABSA >>> 2024-06-08 18:17:29\n",
            "loss: 0.3823, acc: 0.8411\n",
            "E2E-ABSA >>> 2024-06-08 18:18:05\n",
            ">>> val_acc: 0.5938, val_precision: 0.6151 val_recall: 0.5938, val_f1: 0.6021\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-08 18:18:25\n",
            "loss: 0.3348, acc: 0.8683\n",
            "E2E-ABSA >>> 2024-06-08 18:19:00\n",
            "loss: 0.3549, acc: 0.8526\n",
            "E2E-ABSA >>> 2024-06-08 18:19:26\n",
            ">>> val_acc: 0.6213, val_precision: 0.6094 val_recall: 0.6213, val_f1: 0.6142\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-08 18:19:55\n",
            "loss: 0.3389, acc: 0.8630\n",
            "E2E-ABSA >>> 2024-06-08 18:20:47\n",
            ">>> val_acc: 0.6093, val_precision: 0.6020 val_recall: 0.6093, val_f1: 0.6054\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-08 18:20:50\n",
            "loss: 0.3234, acc: 0.8688\n",
            "E2E-ABSA >>> 2024-06-08 18:21:26\n",
            "loss: 0.3405, acc: 0.8608\n",
            "E2E-ABSA >>> 2024-06-08 18:22:08\n",
            ">>> val_acc: 0.6220, val_precision: 0.6069 val_recall: 0.6220, val_f1: 0.6104\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-08 18:22:21\n",
            "loss: 0.3225, acc: 0.8716\n",
            "E2E-ABSA >>> 2024-06-08 18:22:56\n",
            "loss: 0.3171, acc: 0.8672\n",
            "E2E-ABSA >>> 2024-06-08 18:23:29\n",
            ">>> val_acc: 0.6278, val_precision: 0.6067 val_recall: 0.6278, val_f1: 0.6156\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-08 18:23:52\n",
            "loss: 0.3320, acc: 0.8555\n",
            "E2E-ABSA >>> 2024-06-08 18:24:27\n",
            "loss: 0.3368, acc: 0.8579\n",
            "E2E-ABSA >>> 2024-06-08 18:24:50\n",
            ">>> val_acc: 0.6264, val_precision: 0.6023 val_recall: 0.6264, val_f1: 0.6123\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-08 18:25:22\n",
            "loss: 0.3276, acc: 0.8578\n",
            "E2E-ABSA >>> 2024-06-08 18:26:11\n",
            ">>> val_acc: 0.6336, val_precision: 0.6097 val_recall: 0.6336, val_f1: 0.6169\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-08 18:26:17\n",
            "loss: 0.3397, acc: 0.8403\n",
            "E2E-ABSA >>> 2024-06-08 18:26:53\n",
            "loss: 0.2959, acc: 0.8755\n",
            "E2E-ABSA >>> 2024-06-08 18:27:32\n",
            ">>> val_acc: 0.6043, val_precision: 0.6146 val_recall: 0.6043, val_f1: 0.6083\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-08 18:27:48\n",
            "loss: 0.3009, acc: 0.8694\n",
            "E2E-ABSA >>> 2024-06-08 18:28:23\n",
            "loss: 0.3114, acc: 0.8672\n",
            "E2E-ABSA >>> 2024-06-08 18:28:53\n",
            ">>> val_acc: 0.6267, val_precision: 0.5984 val_recall: 0.6267, val_f1: 0.6091\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-08 18:29:18\n",
            "loss: 0.2841, acc: 0.8767\n",
            "E2E-ABSA >>> 2024-06-08 18:29:54\n",
            "loss: 0.2997, acc: 0.8721\n",
            "E2E-ABSA >>> 2024-06-08 18:30:14\n",
            ">>> val_acc: 0.6115, val_precision: 0.5979 val_recall: 0.6115, val_f1: 0.6041\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-08 18:30:49\n",
            "loss: 0.3025, acc: 0.8712\n",
            "E2E-ABSA >>> 2024-06-08 18:31:35\n",
            ">>> val_acc: 0.6093, val_precision: 0.6073 val_recall: 0.6093, val_f1: 0.6080\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-08 18:31:44\n",
            "loss: 0.3244, acc: 0.8486\n",
            "E2E-ABSA >>> 2024-06-08 18:32:20\n",
            "loss: 0.3007, acc: 0.8725\n",
            "E2E-ABSA >>> 2024-06-08 18:32:56\n",
            ">>> val_acc: 0.6408, val_precision: 0.6059 val_recall: 0.6408, val_f1: 0.6184\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-08 18:33:15\n",
            "loss: 0.2710, acc: 0.8868\n",
            "E2E-ABSA >>> 2024-06-08 18:33:50\n",
            "loss: 0.3117, acc: 0.8681\n",
            "E2E-ABSA >>> 2024-06-08 18:34:17\n",
            ">>> val_acc: 0.6575, val_precision: 0.6054 val_recall: 0.6575, val_f1: 0.6153\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-08 18:34:45\n",
            "loss: 0.3100, acc: 0.8680\n",
            "E2E-ABSA >>> 2024-06-08 18:35:38\n",
            ">>> val_acc: 0.6245, val_precision: 0.6035 val_recall: 0.6245, val_f1: 0.6111\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-08 18:35:41\n",
            "loss: 0.2747, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-08 18:36:16\n",
            "loss: 0.3086, acc: 0.8639\n",
            "E2E-ABSA >>> 2024-06-08 18:36:59\n",
            ">>> val_acc: 0.6235, val_precision: 0.6103 val_recall: 0.6235, val_f1: 0.6160\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-08 18:37:11\n",
            "loss: 0.2648, acc: 0.8768\n",
            "E2E-ABSA >>> 2024-06-08 18:37:47\n",
            "loss: 0.2878, acc: 0.8759\n",
            "E2E-ABSA >>> 2024-06-08 18:38:21\n",
            ">>> val_acc: 0.6314, val_precision: 0.5994 val_recall: 0.6314, val_f1: 0.6098\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-08 18:38:42\n",
            "loss: 0.2697, acc: 0.8770\n",
            "E2E-ABSA >>> 2024-06-08 18:39:17\n",
            "loss: 0.2913, acc: 0.8719\n",
            "E2E-ABSA >>> 2024-06-08 18:39:42\n",
            ">>> val_acc: 0.5985, val_precision: 0.5995 val_recall: 0.5985, val_f1: 0.5987\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 44.\n",
            "E2E-ABSA >>> 2024-06-08 18:40:13\n",
            "loss: 0.2652, acc: 0.8878\n",
            "E2E-ABSA >>> 2024-06-08 18:41:03\n",
            ">>> val_acc: 0.6376, val_precision: 0.5999 val_recall: 0.6376, val_f1: 0.6128\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 45.\n",
            "E2E-ABSA >>> 2024-06-08 18:41:08\n",
            "loss: 0.3034, acc: 0.8458\n",
            "E2E-ABSA >>> 2024-06-08 18:41:43\n",
            "loss: 0.2846, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-08 18:42:24\n",
            ">>> val_acc: 0.6358, val_precision: 0.6014 val_recall: 0.6358, val_f1: 0.6070\n",
            "E2E-ABSA >>> 2024-06-08 18:42:24\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6311, val_precision: 0.6096 val_recall: 0.6311, val_f1: 0.6186\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.6311\n",
            ">>> test_acc: 0.6149, test_precision: 0.5604, test_recall: 0.6149, test_f1: 0.5789\n"
          ]
        }
      ],
      "source": [
        "# 8-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "V0RNq-z4Y1lq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "jFM2KFuqZG60",
        "tags": []
      },
      "source": [
        "### base-uncased s6 concat"
      ],
      "id": "jFM2KFuqZG60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "l2Uk9u3ZZG61",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "91a43b13-2452-4a08-e39d-cd99d7f9c55a",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7ec50ee1ee60>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/d_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/d_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-08 18:59:52\n",
            "loss: 0.8658, acc: 0.6656\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:00:37\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6774\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-08 19:00:48\n",
            "loss: 0.8065, acc: 0.6968\n",
            "E2E-ABSA >>> 2024-06-08 19:01:24\n",
            "loss: 0.8394, acc: 0.6747\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:02:00\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-08 19:02:19\n",
            "loss: 0.8457, acc: 0.6725\n",
            "E2E-ABSA >>> 2024-06-08 19:02:54\n",
            "loss: 0.8389, acc: 0.6769\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:03:21\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-08 19:03:49\n",
            "loss: 0.8463, acc: 0.6759\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:04:42\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-08 19:04:45\n",
            "loss: 0.9512, acc: 0.6172\n",
            "E2E-ABSA >>> 2024-06-08 19:05:20\n",
            "loss: 0.8484, acc: 0.6707\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:06:03\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-08 19:06:16\n",
            "loss: 0.8802, acc: 0.6411\n",
            "E2E-ABSA >>> 2024-06-08 19:06:51\n",
            "loss: 0.8243, acc: 0.6718\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:07:24\n",
            ">>> val_acc: 0.6770, val_precision: 0.5470 val_recall: 0.6770, val_f1: 0.5483\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.677\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-08 19:07:54\n",
            "loss: 0.7704, acc: 0.6925\n",
            "E2E-ABSA >>> 2024-06-08 19:08:29\n",
            "loss: 0.7961, acc: 0.6755\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:08:53\n",
            ">>> val_acc: 0.6774, val_precision: 0.4589 val_recall: 0.6774, val_f1: 0.5471\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-08 19:09:24\n",
            "loss: 0.7935, acc: 0.6777\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:10:14\n",
            ">>> val_acc: 0.6778, val_precision: 0.6792 val_recall: 0.6778, val_f1: 0.5480\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-08 19:10:20\n",
            "loss: 0.7594, acc: 0.6992\n",
            "E2E-ABSA >>> 2024-06-08 19:10:55\n",
            "loss: 0.7838, acc: 0.6891\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:11:35\n",
            ">>> val_acc: 0.6810, val_precision: 0.5841 val_recall: 0.6810, val_f1: 0.5698\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.681\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-08 19:11:57\n",
            "loss: 0.7293, acc: 0.7137\n",
            "E2E-ABSA >>> 2024-06-08 19:12:33\n",
            "loss: 0.7708, acc: 0.6853\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:13:04\n",
            ">>> val_acc: 0.6821, val_precision: 0.5946 val_recall: 0.6821, val_f1: 0.5702\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6821\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-08 19:13:35\n",
            "loss: 0.7368, acc: 0.7009\n",
            "E2E-ABSA >>> 2024-06-08 19:14:10\n",
            "loss: 0.7336, acc: 0.7088\n",
            "E2E-ABSA >>> 2024-06-08 19:14:31\n",
            ">>> val_acc: 0.6738, val_precision: 0.6137 val_recall: 0.6738, val_f1: 0.6088\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6738\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-08 19:15:11\n",
            "loss: 0.6831, acc: 0.7191\n",
            "E2E-ABSA >>> 2024-06-08 19:15:58\n",
            ">>> val_acc: 0.6702, val_precision: 0.6091 val_recall: 0.6702, val_f1: 0.6043\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-08 19:16:06\n",
            "loss: 0.7086, acc: 0.7109\n",
            "E2E-ABSA >>> 2024-06-08 19:16:41\n",
            "loss: 0.6992, acc: 0.7142\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:17:19\n",
            ">>> val_acc: 0.6814, val_precision: 0.5801 val_recall: 0.6814, val_f1: 0.5779\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-08 19:17:37\n",
            "loss: 0.6836, acc: 0.7194\n",
            "E2E-ABSA >>> 2024-06-08 19:18:12\n",
            "loss: 0.6728, acc: 0.7190\n",
            "E2E-ABSA >>> 2024-06-08 19:18:40\n",
            ">>> val_acc: 0.6553, val_precision: 0.6154 val_recall: 0.6553, val_f1: 0.6055\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-08 19:19:07\n",
            "loss: 0.6591, acc: 0.7051\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-08 19:20:01\n",
            ">>> val_acc: 0.6756, val_precision: 0.5695 val_recall: 0.6756, val_f1: 0.5968\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-08 19:20:03\n",
            "loss: 0.6640, acc: 0.7750\n",
            "E2E-ABSA >>> 2024-06-08 19:20:38\n",
            "loss: 0.6167, acc: 0.7524\n",
            "E2E-ABSA >>> 2024-06-08 19:21:22\n",
            ">>> val_acc: 0.6720, val_precision: 0.5923 val_recall: 0.6720, val_f1: 0.6064\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-08 19:21:33\n",
            "loss: 0.5790, acc: 0.7695\n",
            "E2E-ABSA >>> 2024-06-08 19:22:08\n",
            "loss: 0.5951, acc: 0.7599\n",
            "E2E-ABSA >>> 2024-06-08 19:22:43\n",
            ">>> val_acc: 0.6626, val_precision: 0.6014 val_recall: 0.6626, val_f1: 0.6094\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6626\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-08 19:23:11\n",
            "loss: 0.6295, acc: 0.7574\n",
            "E2E-ABSA >>> 2024-06-08 19:23:47\n",
            "loss: 0.6095, acc: 0.7508\n",
            "E2E-ABSA >>> 2024-06-08 19:24:12\n",
            ">>> val_acc: 0.6557, val_precision: 0.6034 val_recall: 0.6557, val_f1: 0.6173\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6557\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-08 19:24:49\n",
            "loss: 0.5529, acc: 0.7791\n",
            "E2E-ABSA >>> 2024-06-08 19:25:40\n",
            ">>> val_acc: 0.6463, val_precision: 0.6092 val_recall: 0.6463, val_f1: 0.6192\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6463\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-08 19:25:52\n",
            "loss: 0.4979, acc: 0.8317\n",
            "E2E-ABSA >>> 2024-06-08 19:26:28\n",
            "loss: 0.5152, acc: 0.7937\n",
            "E2E-ABSA >>> 2024-06-08 19:27:09\n",
            ">>> val_acc: 0.6503, val_precision: 0.6026 val_recall: 0.6503, val_f1: 0.6179\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-08 19:27:23\n",
            "loss: 0.5056, acc: 0.8063\n",
            "E2E-ABSA >>> 2024-06-08 19:27:58\n",
            "loss: 0.5233, acc: 0.7835\n",
            "E2E-ABSA >>> 2024-06-08 19:28:30\n",
            ">>> val_acc: 0.6582, val_precision: 0.6068 val_recall: 0.6582, val_f1: 0.6191\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-08 19:28:53\n",
            "loss: 0.5311, acc: 0.7808\n",
            "E2E-ABSA >>> 2024-06-08 19:29:29\n",
            "loss: 0.5070, acc: 0.7923\n",
            "E2E-ABSA >>> 2024-06-08 19:29:51\n",
            ">>> val_acc: 0.6484, val_precision: 0.6125 val_recall: 0.6484, val_f1: 0.6254\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6484\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-08 19:30:26\n",
            "loss: 0.4864, acc: 0.7985\n",
            "E2E-ABSA >>> 2024-06-08 19:31:14\n",
            ">>> val_acc: 0.6441, val_precision: 0.6067 val_recall: 0.6441, val_f1: 0.6104\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-08 19:31:21\n",
            "loss: 0.4495, acc: 0.8155\n",
            "E2E-ABSA >>> 2024-06-08 19:31:57\n",
            "loss: 0.4805, acc: 0.8099\n",
            "E2E-ABSA >>> 2024-06-08 19:32:35\n",
            ">>> val_acc: 0.6582, val_precision: 0.6074 val_recall: 0.6582, val_f1: 0.6203\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-08 19:32:52\n",
            "loss: 0.4752, acc: 0.8086\n",
            "E2E-ABSA >>> 2024-06-08 19:33:27\n",
            "loss: 0.4670, acc: 0.8024\n",
            "E2E-ABSA >>> 2024-06-08 19:33:56\n",
            ">>> val_acc: 0.6542, val_precision: 0.6022 val_recall: 0.6542, val_f1: 0.6119\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-08 19:34:22\n",
            "loss: 0.4604, acc: 0.8083\n",
            "E2E-ABSA >>> 2024-06-08 19:35:17\n",
            ">>> val_acc: 0.6293, val_precision: 0.6161 val_recall: 0.6293, val_f1: 0.6219\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-08 19:35:18\n",
            "loss: 0.4386, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-08 19:35:53\n",
            "loss: 0.3982, acc: 0.8321\n",
            "E2E-ABSA >>> 2024-06-08 19:36:38\n",
            ">>> val_acc: 0.6097, val_precision: 0.6174 val_recall: 0.6097, val_f1: 0.6130\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-08 19:36:48\n",
            "loss: 0.4152, acc: 0.8599\n",
            "E2E-ABSA >>> 2024-06-08 19:37:24\n",
            "loss: 0.4217, acc: 0.8382\n",
            "E2E-ABSA >>> 2024-06-08 19:37:59\n",
            ">>> val_acc: 0.6227, val_precision: 0.6069 val_recall: 0.6227, val_f1: 0.6138\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-08 19:38:19\n",
            "loss: 0.3964, acc: 0.8359\n",
            "E2E-ABSA >>> 2024-06-08 19:38:54\n",
            "loss: 0.4082, acc: 0.8345\n",
            "E2E-ABSA >>> 2024-06-08 19:39:20\n",
            ">>> val_acc: 0.6155, val_precision: 0.6102 val_recall: 0.6155, val_f1: 0.6127\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-08 19:39:50\n",
            "loss: 0.4028, acc: 0.8404\n",
            "E2E-ABSA >>> 2024-06-08 19:40:41\n",
            ">>> val_acc: 0.6474, val_precision: 0.6142 val_recall: 0.6474, val_f1: 0.6255\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6474\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-08 19:40:53\n",
            "loss: 0.3973, acc: 0.8313\n",
            "E2E-ABSA >>> 2024-06-08 19:41:29\n",
            "loss: 0.3962, acc: 0.8369\n",
            "E2E-ABSA >>> 2024-06-08 19:42:11\n",
            ">>> val_acc: 0.6166, val_precision: 0.6086 val_recall: 0.6166, val_f1: 0.6067\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-08 19:42:24\n",
            "loss: 0.3518, acc: 0.8581\n",
            "E2E-ABSA >>> 2024-06-08 19:42:59\n",
            "loss: 0.3644, acc: 0.8526\n",
            "E2E-ABSA >>> 2024-06-08 19:43:32\n",
            ">>> val_acc: 0.6296, val_precision: 0.6076 val_recall: 0.6296, val_f1: 0.6169\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-08 19:43:54\n",
            "loss: 0.3895, acc: 0.8477\n",
            "E2E-ABSA >>> 2024-06-08 19:44:30\n",
            "loss: 0.3731, acc: 0.8502\n",
            "E2E-ABSA >>> 2024-06-08 19:44:53\n",
            ">>> val_acc: 0.6401, val_precision: 0.6120 val_recall: 0.6401, val_f1: 0.6150\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-08 19:45:25\n",
            "loss: 0.3859, acc: 0.8503\n",
            "E2E-ABSA >>> 2024-06-08 19:46:14\n",
            ">>> val_acc: 0.6021, val_precision: 0.6121 val_recall: 0.6021, val_f1: 0.6006\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-08 19:46:20\n",
            "loss: 0.3902, acc: 0.8090\n",
            "E2E-ABSA >>> 2024-06-08 19:46:56\n",
            "loss: 0.3364, acc: 0.8543\n",
            "E2E-ABSA >>> 2024-06-08 19:47:35\n",
            ">>> val_acc: 0.6119, val_precision: 0.6168 val_recall: 0.6119, val_f1: 0.6107\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-08 19:47:51\n",
            "loss: 0.3047, acc: 0.8806\n",
            "E2E-ABSA >>> 2024-06-08 19:48:27\n",
            "loss: 0.3539, acc: 0.8578\n",
            "E2E-ABSA >>> 2024-06-08 19:48:56\n",
            ">>> val_acc: 0.6028, val_precision: 0.6218 val_recall: 0.6028, val_f1: 0.6107\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-08 19:49:22\n",
            "loss: 0.3359, acc: 0.8533\n",
            "E2E-ABSA >>> 2024-06-08 19:49:57\n",
            "loss: 0.3534, acc: 0.8496\n",
            "E2E-ABSA >>> 2024-06-08 19:50:17\n",
            ">>> val_acc: 0.6358, val_precision: 0.6128 val_recall: 0.6358, val_f1: 0.6223\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-08 19:50:52\n",
            "loss: 0.3387, acc: 0.8548\n",
            "E2E-ABSA >>> 2024-06-08 19:51:39\n",
            ">>> val_acc: 0.6097, val_precision: 0.6054 val_recall: 0.6097, val_f1: 0.6075\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-08 19:51:48\n",
            "loss: 0.3667, acc: 0.8389\n",
            "E2E-ABSA >>> 2024-06-08 19:52:23\n",
            "loss: 0.3387, acc: 0.8552\n",
            "E2E-ABSA >>> 2024-06-08 19:53:00\n",
            ">>> val_acc: 0.6057, val_precision: 0.6011 val_recall: 0.6057, val_f1: 0.6006\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-08 19:53:19\n",
            "loss: 0.3529, acc: 0.8491\n",
            "E2E-ABSA >>> 2024-06-08 19:53:54\n",
            "loss: 0.3464, acc: 0.8583\n",
            "E2E-ABSA >>> 2024-06-08 19:54:21\n",
            ">>> val_acc: 0.6542, val_precision: 0.6042 val_recall: 0.6542, val_f1: 0.6182\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-08 19:54:49\n",
            "loss: 0.3270, acc: 0.8492\n",
            "E2E-ABSA >>> 2024-06-08 19:55:42\n",
            ">>> val_acc: 0.5836, val_precision: 0.6154 val_recall: 0.5836, val_f1: 0.5901\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-08 19:55:44\n",
            "loss: 0.4002, acc: 0.8571\n",
            "E2E-ABSA >>> 2024-06-08 19:56:20\n",
            "loss: 0.3528, acc: 0.8452\n",
            "E2E-ABSA >>> 2024-06-08 19:57:03\n",
            ">>> val_acc: 0.6347, val_precision: 0.6079 val_recall: 0.6347, val_f1: 0.6185\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-08 19:57:15\n",
            "loss: 0.3264, acc: 0.8713\n",
            "E2E-ABSA >>> 2024-06-08 19:57:50\n",
            "loss: 0.3214, acc: 0.8675\n",
            "E2E-ABSA >>> 2024-06-08 19:58:24\n",
            ">>> val_acc: 0.6376, val_precision: 0.6027 val_recall: 0.6376, val_f1: 0.6156\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-08 19:58:46\n",
            "loss: 0.3037, acc: 0.8699\n",
            "E2E-ABSA >>> 2024-06-08 19:59:21\n",
            "loss: 0.3298, acc: 0.8579\n",
            "E2E-ABSA >>> 2024-06-08 19:59:45\n",
            ">>> val_acc: 0.6108, val_precision: 0.6059 val_recall: 0.6108, val_f1: 0.6082\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 44.\n",
            "E2E-ABSA >>> 2024-06-08 20:00:16\n",
            "loss: 0.3010, acc: 0.8771\n",
            "E2E-ABSA >>> 2024-06-08 20:01:06\n",
            ">>> val_acc: 0.6162, val_precision: 0.6070 val_recall: 0.6162, val_f1: 0.6096\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 45.\n",
            "E2E-ABSA >>> 2024-06-08 20:01:11\n",
            "loss: 0.3359, acc: 0.8625\n",
            "E2E-ABSA >>> 2024-06-08 20:01:47\n",
            "loss: 0.3094, acc: 0.8777\n",
            "E2E-ABSA >>> 2024-06-08 20:02:27\n",
            ">>> val_acc: 0.6445, val_precision: 0.6012 val_recall: 0.6445, val_f1: 0.6154\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 46.\n",
            "E2E-ABSA >>> 2024-06-08 20:02:42\n",
            "loss: 0.3240, acc: 0.8854\n",
            "E2E-ABSA >>> 2024-06-08 20:03:18\n",
            "loss: 0.3225, acc: 0.8724\n",
            "E2E-ABSA >>> 2024-06-08 20:03:49\n",
            ">>> val_acc: 0.5920, val_precision: 0.6162 val_recall: 0.5920, val_f1: 0.6015\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 47.\n",
            "E2E-ABSA >>> 2024-06-08 20:04:13\n",
            "loss: 0.2992, acc: 0.8795\n",
            "E2E-ABSA >>> 2024-06-08 20:04:48\n",
            "loss: 0.3190, acc: 0.8702\n",
            "E2E-ABSA >>> 2024-06-08 20:05:10\n",
            ">>> val_acc: 0.6285, val_precision: 0.5977 val_recall: 0.6285, val_f1: 0.6103\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 48.\n",
            "E2E-ABSA >>> 2024-06-08 20:05:43\n",
            "loss: 0.2914, acc: 0.8848\n",
            "E2E-ABSA >>> 2024-06-08 20:06:31\n",
            ">>> val_acc: 0.6144, val_precision: 0.6125 val_recall: 0.6144, val_f1: 0.6134\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 49.\n",
            "E2E-ABSA >>> 2024-06-08 20:06:39\n",
            "loss: 0.3607, acc: 0.8641\n",
            "E2E-ABSA >>> 2024-06-08 20:07:14\n",
            "loss: 0.3184, acc: 0.8653\n",
            "E2E-ABSA >>> 2024-06-08 20:07:51\n",
            ">>> val_acc: 0.5898, val_precision: 0.6091 val_recall: 0.5898, val_f1: 0.5986\n",
            "E2E-ABSA >>> 2024-06-08 20:07:51\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6474, val_precision: 0.6142 val_recall: 0.6474, val_f1: 0.6255\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.6474\n",
            ">>> test_acc: 0.6332, test_precision: 0.5691, test_recall: 0.6332, test_f1: 0.5851\n"
          ]
        }
      ],
      "source": [
        "# 8-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "l2Uk9u3ZZG61"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bert-base-uncased Insertion"
      ],
      "metadata": {
        "id": "zyVpCf3XNQ1A"
      },
      "id": "zyVpCf3XNQ1A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "07438f4a-c61f-4611-99f9-2abed1b78294",
        "tags": []
      },
      "source": [
        "### base-uncased s1 insert"
      ],
      "id": "07438f4a-c61f-4611-99f9-2abed1b78294"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "5c279085-0081-4e9c-8655-209cfed982d0",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "be090bb9-e2f2-4789-ffca-f260fd6e091a",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100%|██████████████████| 48.0/48.0 [00:00<00:00, 309kB/s]\n",
            "vocab.txt: 100%|█████████████████████████████| 232k/232k [00:00<00:00, 3.49MB/s]\n",
            "tokenizer.json: 100%|████████████████████████| 466k/466k [00:00<00:00, 5.34MB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████████| 570/570 [00:00<00:00, 4.69MB/s]\n",
            "model.safetensors: 100%|█████████████████████| 440M/440M [00:05<00:00, 86.7MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fa20051b760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 02:49:59\n",
            "loss: 0.8876, acc: 0.6431\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 02:50:10\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 02:50:12\n",
            "loss: 0.8647, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-04 02:50:21\n",
            "loss: 0.8339, acc: 0.6739\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 02:50:30\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 02:50:34\n",
            "loss: 0.8210, acc: 0.6680\n",
            "E2E-ABSA >>> 2024-06-04 02:50:42\n",
            "loss: 0.8160, acc: 0.6723\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 02:50:49\n",
            ">>> val_acc: 0.6860, val_precision: 0.5189 val_recall: 0.6860, val_f1: 0.5603\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.686\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 02:50:56\n",
            "loss: 0.8146, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-04 02:51:04\n",
            "loss: 0.8082, acc: 0.6697\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 02:51:09\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 02:51:17\n",
            "loss: 0.8122, acc: 0.6771\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 02:51:28\n",
            ">>> val_acc: 0.6696, val_precision: 0.5421 val_recall: 0.6696, val_f1: 0.5832\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6696\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 02:51:30\n",
            "loss: 0.7657, acc: 0.6906\n",
            "E2E-ABSA >>> 2024-06-04 02:51:39\n",
            "loss: 0.7805, acc: 0.6833\n",
            "E2E-ABSA >>> 2024-06-04 02:51:48\n",
            ">>> val_acc: 0.6121, val_precision: 0.6010 val_recall: 0.6121, val_f1: 0.6004\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6121\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 02:51:52\n",
            "loss: 0.7868, acc: 0.6861\n",
            "E2E-ABSA >>> 2024-06-04 02:52:01\n",
            "loss: 0.7740, acc: 0.6775\n",
            "E2E-ABSA >>> 2024-06-04 02:52:08\n",
            ">>> val_acc: 0.6753, val_precision: 0.5965 val_recall: 0.6753, val_f1: 0.6027\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6753\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 02:52:14\n",
            "loss: 0.7637, acc: 0.6590\n",
            "E2E-ABSA >>> 2024-06-04 02:52:22\n",
            "loss: 0.7592, acc: 0.6730\n",
            "E2E-ABSA >>> 2024-06-04 02:52:28\n",
            ">>> val_acc: 0.6881, val_precision: 0.6145 val_recall: 0.6881, val_f1: 0.5998\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 02:52:35\n",
            "loss: 0.7103, acc: 0.6936\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 02:52:47\n",
            ">>> val_acc: 0.6849, val_precision: 0.5063 val_recall: 0.6849, val_f1: 0.5639\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 02:52:48\n",
            "loss: 0.7852, acc: 0.6484\n",
            "E2E-ABSA >>> 2024-06-04 02:52:57\n",
            "loss: 0.7126, acc: 0.6837\n",
            "E2E-ABSA >>> 2024-06-04 02:53:06\n",
            ">>> val_acc: 0.6728, val_precision: 0.6090 val_recall: 0.6728, val_f1: 0.6182\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6728\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 02:53:10\n",
            "loss: 0.6856, acc: 0.6844\n",
            "E2E-ABSA >>> 2024-06-04 02:53:19\n",
            "loss: 0.6926, acc: 0.6987\n",
            "E2E-ABSA >>> 2024-06-04 02:53:26\n",
            ">>> val_acc: 0.6764, val_precision: 0.6260 val_recall: 0.6764, val_f1: 0.6284\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6764\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 02:53:32\n",
            "loss: 0.6188, acc: 0.7344\n",
            "E2E-ABSA >>> 2024-06-04 02:53:40\n",
            "loss: 0.6561, acc: 0.7264\n",
            "E2E-ABSA >>> 2024-06-04 02:53:46\n",
            ">>> val_acc: 0.6920, val_precision: 0.6293 val_recall: 0.6920, val_f1: 0.6160\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 02:53:53\n",
            "loss: 0.6317, acc: 0.7266\n",
            "E2E-ABSA >>> 2024-06-04 02:54:05\n",
            ">>> val_acc: 0.6764, val_precision: 0.6554 val_recall: 0.6764, val_f1: 0.6191\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 02:54:06\n",
            "loss: 0.7030, acc: 0.7240\n",
            "E2E-ABSA >>> 2024-06-04 02:54:15\n",
            "loss: 0.6212, acc: 0.7215\n",
            "E2E-ABSA >>> 2024-06-04 02:54:25\n",
            ">>> val_acc: 0.6845, val_precision: 0.6272 val_recall: 0.6845, val_f1: 0.6311\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6845\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 02:54:28\n",
            "loss: 0.5563, acc: 0.7448\n",
            "E2E-ABSA >>> 2024-06-04 02:54:37\n",
            "loss: 0.5811, acc: 0.7454\n",
            "E2E-ABSA >>> 2024-06-04 02:54:44\n",
            ">>> val_acc: 0.6451, val_precision: 0.6330 val_recall: 0.6451, val_f1: 0.6269\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 02:54:50\n",
            "loss: 0.5495, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-06-04 02:54:58\n",
            "loss: 0.5590, acc: 0.7598\n",
            "E2E-ABSA >>> 2024-06-04 02:55:04\n",
            ">>> val_acc: 0.6348, val_precision: 0.6322 val_recall: 0.6348, val_f1: 0.6319\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6348\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 02:55:11\n",
            "loss: 0.5150, acc: 0.7731\n",
            "E2E-ABSA >>> 2024-06-04 02:55:24\n",
            ">>> val_acc: 0.5755, val_precision: 0.6507 val_recall: 0.5755, val_f1: 0.5931\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 02:55:24\n",
            "loss: 0.5533, acc: 0.7500\n",
            "E2E-ABSA >>> 2024-06-04 02:55:33\n",
            "loss: 0.4815, acc: 0.7975\n",
            "E2E-ABSA >>> 2024-06-04 02:55:43\n",
            ">>> val_acc: 0.6615, val_precision: 0.6241 val_recall: 0.6615, val_f1: 0.6365\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6615\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 02:55:46\n",
            "loss: 0.4650, acc: 0.8203\n",
            "E2E-ABSA >>> 2024-06-04 02:55:55\n",
            "loss: 0.4793, acc: 0.8054\n",
            "E2E-ABSA >>> 2024-06-04 02:56:03\n",
            ">>> val_acc: 0.6472, val_precision: 0.6220 val_recall: 0.6472, val_f1: 0.6259\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 02:56:08\n",
            "loss: 0.4267, acc: 0.8214\n",
            "E2E-ABSA >>> 2024-06-04 02:56:16\n",
            "loss: 0.4579, acc: 0.8073\n",
            "E2E-ABSA >>> 2024-06-04 02:56:22\n",
            ">>> val_acc: 0.6639, val_precision: 0.6279 val_recall: 0.6639, val_f1: 0.6391\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6639\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 02:56:29\n",
            "loss: 0.3975, acc: 0.8344\n",
            "E2E-ABSA >>> 2024-06-04 02:56:42\n",
            ">>> val_acc: 0.6888, val_precision: 0.6379 val_recall: 0.6888, val_f1: 0.6359\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 02:56:42\n",
            "loss: 0.4245, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-04 02:56:51\n",
            "loss: 0.4204, acc: 0.8299\n",
            "E2E-ABSA >>> 2024-06-04 02:57:02\n",
            ">>> val_acc: 0.6586, val_precision: 0.6265 val_recall: 0.6586, val_f1: 0.6339\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 02:57:04\n",
            "loss: 0.3542, acc: 0.8549\n",
            "E2E-ABSA >>> 2024-06-04 02:57:12\n",
            "loss: 0.3913, acc: 0.8394\n",
            "E2E-ABSA >>> 2024-06-04 02:57:21\n",
            ">>> val_acc: 0.6600, val_precision: 0.6205 val_recall: 0.6600, val_f1: 0.6273\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 02:57:25\n",
            "loss: 0.3542, acc: 0.8666\n",
            "E2E-ABSA >>> 2024-06-04 02:57:34\n",
            "loss: 0.3689, acc: 0.8528\n",
            "E2E-ABSA >>> 2024-06-04 02:57:40\n",
            ">>> val_acc: 0.6686, val_precision: 0.6290 val_recall: 0.6686, val_f1: 0.6282\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 02:57:47\n",
            "loss: 0.3471, acc: 0.8627\n",
            "E2E-ABSA >>> 2024-06-04 02:57:55\n",
            "loss: 0.3658, acc: 0.8512\n",
            "E2E-ABSA >>> 2024-06-04 02:58:00\n",
            ">>> val_acc: 0.6242, val_precision: 0.6280 val_recall: 0.6242, val_f1: 0.6260\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 02:58:08\n",
            "loss: 0.3463, acc: 0.8575\n",
            "E2E-ABSA >>> 2024-06-04 02:58:20\n",
            ">>> val_acc: 0.6330, val_precision: 0.6297 val_recall: 0.6330, val_f1: 0.6313\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 02:58:22\n",
            "loss: 0.3279, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-04 02:58:30\n",
            "loss: 0.3300, acc: 0.8745\n",
            "E2E-ABSA >>> 2024-06-04 02:58:39\n",
            ">>> val_acc: 0.6842, val_precision: 0.6204 val_recall: 0.6842, val_f1: 0.6228\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 02:58:43\n",
            "loss: 0.3854, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-04 02:58:52\n",
            "loss: 0.3196, acc: 0.8733\n",
            "E2E-ABSA >>> 2024-06-04 02:58:59\n",
            ">>> val_acc: 0.6369, val_precision: 0.6319 val_recall: 0.6369, val_f1: 0.6274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 02:59:05\n",
            "loss: 0.3080, acc: 0.8863\n",
            "E2E-ABSA >>> 2024-06-04 02:59:13\n",
            "loss: 0.3077, acc: 0.8819\n",
            "E2E-ABSA >>> 2024-06-04 02:59:18\n",
            ">>> val_acc: 0.6217, val_precision: 0.6311 val_recall: 0.6217, val_f1: 0.6245\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-04 02:59:26\n",
            "loss: 0.2752, acc: 0.8919\n",
            "E2E-ABSA >>> 2024-06-04 02:59:38\n",
            ">>> val_acc: 0.6082, val_precision: 0.6229 val_recall: 0.6082, val_f1: 0.6094\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-04 02:59:39\n",
            "loss: 0.2568, acc: 0.9031\n",
            "E2E-ABSA >>> 2024-06-04 02:59:48\n",
            "loss: 0.2679, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-04 02:59:57\n",
            ">>> val_acc: 0.6394, val_precision: 0.6305 val_recall: 0.6394, val_f1: 0.6337\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-04 03:00:01\n",
            "loss: 0.2394, acc: 0.9162\n",
            "E2E-ABSA >>> 2024-06-04 03:00:09\n",
            "loss: 0.2952, acc: 0.8928\n",
            "E2E-ABSA >>> 2024-06-04 03:00:17\n",
            ">>> val_acc: 0.6508, val_precision: 0.6309 val_recall: 0.6508, val_f1: 0.6377\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-04 03:00:22\n",
            "loss: 0.2374, acc: 0.9081\n",
            "E2E-ABSA >>> 2024-06-04 03:00:31\n",
            "loss: 0.2709, acc: 0.8955\n",
            "E2E-ABSA >>> 2024-06-04 03:00:36\n",
            ">>> val_acc: 0.6291, val_precision: 0.6277 val_recall: 0.6291, val_f1: 0.6277\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-04 03:00:44\n",
            "loss: 0.2464, acc: 0.9008\n",
            "E2E-ABSA >>> 2024-06-04 03:00:56\n",
            ">>> val_acc: 0.6444, val_precision: 0.6312 val_recall: 0.6444, val_f1: 0.6334\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-04 03:00:57\n",
            "loss: 0.1883, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-04 03:01:05\n",
            "loss: 0.2677, acc: 0.8917\n",
            "E2E-ABSA >>> 2024-06-04 03:01:15\n",
            ">>> val_acc: 0.6604, val_precision: 0.6307 val_recall: 0.6604, val_f1: 0.6413\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6604\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-04 03:01:19\n",
            "loss: 0.2460, acc: 0.9078\n",
            "E2E-ABSA >>> 2024-06-04 03:01:27\n",
            "loss: 0.2490, acc: 0.9036\n",
            "E2E-ABSA >>> 2024-06-04 03:01:35\n",
            ">>> val_acc: 0.6615, val_precision: 0.6219 val_recall: 0.6615, val_f1: 0.6353\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-04 03:01:41\n",
            "loss: 0.2364, acc: 0.9082\n",
            "E2E-ABSA >>> 2024-06-04 03:01:49\n",
            "loss: 0.2516, acc: 0.9051\n",
            "E2E-ABSA >>> 2024-06-04 03:01:55\n",
            ">>> val_acc: 0.6291, val_precision: 0.6307 val_recall: 0.6291, val_f1: 0.6298\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-04 03:02:02\n",
            "loss: 0.2213, acc: 0.9190\n",
            "E2E-ABSA >>> 2024-06-04 03:02:14\n",
            ">>> val_acc: 0.6220, val_precision: 0.6235 val_recall: 0.6220, val_f1: 0.6198\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-04 03:02:15\n",
            "loss: 0.2104, acc: 0.9010\n",
            "E2E-ABSA >>> 2024-06-04 03:02:24\n",
            "loss: 0.2084, acc: 0.9247\n",
            "E2E-ABSA >>> 2024-06-04 03:02:34\n",
            ">>> val_acc: 0.6444, val_precision: 0.6276 val_recall: 0.6444, val_f1: 0.6351\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-04 03:02:37\n",
            "loss: 0.2148, acc: 0.9184\n",
            "E2E-ABSA >>> 2024-06-04 03:02:45\n",
            "loss: 0.2286, acc: 0.9136\n",
            "E2E-ABSA >>> 2024-06-04 03:02:53\n",
            ">>> val_acc: 0.6149, val_precision: 0.6338 val_recall: 0.6149, val_f1: 0.6234\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-04 03:02:58\n",
            "loss: 0.2016, acc: 0.9229\n",
            "E2E-ABSA >>> 2024-06-04 03:03:07\n",
            "loss: 0.2251, acc: 0.9125\n",
            "E2E-ABSA >>> 2024-06-04 03:03:13\n",
            ">>> val_acc: 0.6394, val_precision: 0.6264 val_recall: 0.6394, val_f1: 0.6301\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-04 03:03:20\n",
            "loss: 0.2217, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-04 03:03:32\n",
            ">>> val_acc: 0.6504, val_precision: 0.6261 val_recall: 0.6504, val_f1: 0.6356\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-04 03:03:33\n",
            "loss: 0.1146, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 03:03:41\n",
            "loss: 0.2139, acc: 0.9242\n",
            "E2E-ABSA >>> 2024-06-04 03:03:52\n",
            ">>> val_acc: 0.6469, val_precision: 0.6278 val_recall: 0.6469, val_f1: 0.6361\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-04 03:03:54\n",
            "loss: 0.1900, acc: 0.9180\n",
            "E2E-ABSA >>> 2024-06-04 03:04:03\n",
            "loss: 0.1929, acc: 0.9223\n",
            "E2E-ABSA >>> 2024-06-04 03:04:11\n",
            ">>> val_acc: 0.6323, val_precision: 0.6281 val_recall: 0.6323, val_f1: 0.6276\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 44.\n",
            "E2E-ABSA >>> 2024-06-04 03:04:16\n",
            "loss: 0.1934, acc: 0.9408\n",
            "E2E-ABSA >>> 2024-06-04 03:04:24\n",
            "loss: 0.2017, acc: 0.9251\n",
            "E2E-ABSA >>> 2024-06-04 03:04:31\n",
            ">>> val_acc: 0.6480, val_precision: 0.6257 val_recall: 0.6480, val_f1: 0.6339\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 45.\n",
            "E2E-ABSA >>> 2024-06-04 03:04:37\n",
            "loss: 0.1983, acc: 0.9227\n",
            "E2E-ABSA >>> 2024-06-04 03:04:50\n",
            ">>> val_acc: 0.6281, val_precision: 0.6255 val_recall: 0.6281, val_f1: 0.6267\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 46.\n",
            "E2E-ABSA >>> 2024-06-04 03:04:50\n",
            "loss: 0.1452, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 03:04:59\n",
            "loss: 0.1904, acc: 0.9291\n",
            "E2E-ABSA >>> 2024-06-04 03:05:09\n",
            ">>> val_acc: 0.6238, val_precision: 0.6294 val_recall: 0.6238, val_f1: 0.6250\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 47.\n",
            "E2E-ABSA >>> 2024-06-04 03:05:12\n",
            "loss: 0.2032, acc: 0.9174\n",
            "E2E-ABSA >>> 2024-06-04 03:05:20\n",
            "loss: 0.2144, acc: 0.9189\n",
            "E2E-ABSA >>> 2024-06-04 03:05:29\n",
            ">>> val_acc: 0.6575, val_precision: 0.6135 val_recall: 0.6575, val_f1: 0.6287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 48.\n",
            "E2E-ABSA >>> 2024-06-04 03:05:33\n",
            "loss: 0.1804, acc: 0.9327\n",
            "E2E-ABSA >>> 2024-06-04 03:05:42\n",
            "loss: 0.1986, acc: 0.9223\n",
            "E2E-ABSA >>> 2024-06-04 03:05:48\n",
            ">>> val_acc: 0.6142, val_precision: 0.6290 val_recall: 0.6142, val_f1: 0.6211\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 49.\n",
            "E2E-ABSA >>> 2024-06-04 03:05:55\n",
            "loss: 0.1793, acc: 0.9252\n",
            "E2E-ABSA >>> 2024-06-04 03:06:03\n",
            "loss: 0.1863, acc: 0.9233\n",
            "E2E-ABSA >>> 2024-06-04 03:06:08\n",
            ">>> val_acc: 0.6256, val_precision: 0.6305 val_recall: 0.6256, val_f1: 0.6251\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 50.\n",
            "E2E-ABSA >>> 2024-06-04 03:06:16\n",
            "loss: 0.1659, acc: 0.9325\n",
            "E2E-ABSA >>> 2024-06-04 03:06:27\n",
            ">>> val_acc: 0.6483, val_precision: 0.6259 val_recall: 0.6483, val_f1: 0.6346\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 51.\n",
            "E2E-ABSA >>> 2024-06-04 03:06:29\n",
            "loss: 0.1839, acc: 0.9271\n",
            "E2E-ABSA >>> 2024-06-04 03:06:37\n",
            "loss: 0.1619, acc: 0.9320\n",
            "E2E-ABSA >>> 2024-06-04 03:06:46\n",
            ">>> val_acc: 0.6483, val_precision: 0.6223 val_recall: 0.6483, val_f1: 0.6328\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 52.\n",
            "E2E-ABSA >>> 2024-06-04 03:06:50\n",
            "loss: 0.1499, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 03:06:59\n",
            "loss: 0.1704, acc: 0.9350\n",
            "E2E-ABSA >>> 2024-06-04 03:07:06\n",
            ">>> val_acc: 0.6345, val_precision: 0.6214 val_recall: 0.6345, val_f1: 0.6270\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 53.\n",
            "E2E-ABSA >>> 2024-06-04 03:07:12\n",
            "loss: 0.1671, acc: 0.9340\n",
            "E2E-ABSA >>> 2024-06-04 03:07:20\n",
            "loss: 0.1678, acc: 0.9320\n",
            "E2E-ABSA >>> 2024-06-04 03:07:25\n",
            ">>> val_acc: 0.6114, val_precision: 0.6283 val_recall: 0.6114, val_f1: 0.6191\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 54.\n",
            "E2E-ABSA >>> 2024-06-04 03:07:33\n",
            "loss: 0.1643, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-04 03:07:44\n",
            ">>> val_acc: 0.6469, val_precision: 0.6234 val_recall: 0.6469, val_f1: 0.6331\n",
            "E2E-ABSA >>> 2024-06-04 03:07:44\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6604, val_precision: 0.6307 val_recall: 0.6604, val_f1: 0.6413\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.6604\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "5c279085-0081-4e9c-8655-209cfed982d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "ff3acfb4-3583-49b3-8405-6721ea61fdbc",
        "tags": []
      },
      "source": [
        "### base-uncased s2 insert"
      ],
      "id": "ff3acfb4-3583-49b3-8405-6721ea61fdbc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "863fbc41-c013-4c0e-af3c-4ed47bd3fdf9",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "c5e6436d-df73-4a75-f0f6-6401bb405b38",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7feab2727760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/y_insert_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/y_insert_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 06:29:13\n",
            "loss: 0.9059, acc: 0.6344\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 06:29:24\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 06:29:26\n",
            "loss: 0.8623, acc: 0.6458\n",
            "E2E-ABSA >>> 2024-06-04 06:29:35\n",
            "loss: 0.8366, acc: 0.6714\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 06:29:44\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 06:29:48\n",
            "loss: 0.8084, acc: 0.6706\n",
            "E2E-ABSA >>> 2024-06-04 06:29:56\n",
            "loss: 0.8105, acc: 0.6753\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 06:30:03\n",
            ">>> val_acc: 0.6774, val_precision: 0.5668 val_recall: 0.6774, val_f1: 0.5996\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6774\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 06:30:10\n",
            "loss: 0.8032, acc: 0.6632\n",
            "E2E-ABSA >>> 2024-06-04 06:30:18\n",
            "loss: 0.7923, acc: 0.6704\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 06:30:23\n",
            ">>> val_acc: 0.6870, val_precision: 0.5751 val_recall: 0.6870, val_f1: 0.5876\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 06:30:31\n",
            "loss: 0.7459, acc: 0.6810\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 06:30:42\n",
            ">>> val_acc: 0.6607, val_precision: 0.5780 val_recall: 0.6607, val_f1: 0.6152\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6607\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 06:30:44\n",
            "loss: 0.6769, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-04 06:30:53\n",
            "loss: 0.6979, acc: 0.7099\n",
            "E2E-ABSA >>> 2024-06-04 06:31:02\n",
            ">>> val_acc: 0.6146, val_precision: 0.6314 val_recall: 0.6146, val_f1: 0.6158\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6146\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 06:31:06\n",
            "loss: 0.6855, acc: 0.7145\n",
            "E2E-ABSA >>> 2024-06-04 06:31:15\n",
            "loss: 0.6939, acc: 0.6931\n",
            "E2E-ABSA >>> 2024-06-04 06:31:22\n",
            ">>> val_acc: 0.6512, val_precision: 0.6252 val_recall: 0.6512, val_f1: 0.6314\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6512\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 06:31:28\n",
            "loss: 0.6899, acc: 0.7114\n",
            "E2E-ABSA >>> 2024-06-04 06:31:37\n",
            "loss: 0.6557, acc: 0.7258\n",
            "E2E-ABSA >>> 2024-06-04 06:31:42\n",
            ">>> val_acc: 0.6281, val_precision: 0.6427 val_recall: 0.6281, val_f1: 0.6010\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 06:31:50\n",
            "loss: 0.6086, acc: 0.7323\n",
            "E2E-ABSA >>> 2024-06-04 06:32:01\n",
            ">>> val_acc: 0.6810, val_precision: 0.5997 val_recall: 0.6810, val_f1: 0.6085\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 06:32:03\n",
            "loss: 0.5908, acc: 0.7383\n",
            "E2E-ABSA >>> 2024-06-04 06:32:11\n",
            "loss: 0.5990, acc: 0.7478\n",
            "E2E-ABSA >>> 2024-06-04 06:32:21\n",
            ">>> val_acc: 0.6845, val_precision: 0.5755 val_recall: 0.6845, val_f1: 0.6089\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 06:32:24\n",
            "loss: 0.5327, acc: 0.7672\n",
            "E2E-ABSA >>> 2024-06-04 06:32:33\n",
            "loss: 0.5654, acc: 0.7545\n",
            "E2E-ABSA >>> 2024-06-04 06:32:40\n",
            ">>> val_acc: 0.6718, val_precision: 0.6169 val_recall: 0.6718, val_f1: 0.6293\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 06:32:46\n",
            "loss: 0.5124, acc: 0.7979\n",
            "E2E-ABSA >>> 2024-06-04 06:32:54\n",
            "loss: 0.5328, acc: 0.7786\n",
            "E2E-ABSA >>> 2024-06-04 06:33:00\n",
            ">>> val_acc: 0.6703, val_precision: 0.6214 val_recall: 0.6703, val_f1: 0.6355\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6703\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 06:33:08\n",
            "loss: 0.4924, acc: 0.7926\n",
            "E2E-ABSA >>> 2024-06-04 06:33:20\n",
            ">>> val_acc: 0.6586, val_precision: 0.6227 val_recall: 0.6586, val_f1: 0.6266\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 06:33:21\n",
            "loss: 0.4709, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-04 06:33:29\n",
            "loss: 0.4807, acc: 0.8013\n",
            "E2E-ABSA >>> 2024-06-04 06:33:39\n",
            ">>> val_acc: 0.6710, val_precision: 0.6196 val_recall: 0.6710, val_f1: 0.6315\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 06:33:42\n",
            "loss: 0.4903, acc: 0.8003\n",
            "E2E-ABSA >>> 2024-06-04 06:33:51\n",
            "loss: 0.4533, acc: 0.8166\n",
            "E2E-ABSA >>> 2024-06-04 06:33:59\n",
            ">>> val_acc: 0.6750, val_precision: 0.6214 val_recall: 0.6750, val_f1: 0.6325\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 06:34:04\n",
            "loss: 0.4246, acc: 0.8396\n",
            "E2E-ABSA >>> 2024-06-04 06:34:12\n",
            "loss: 0.4296, acc: 0.8270\n",
            "E2E-ABSA >>> 2024-06-04 06:34:18\n",
            ">>> val_acc: 0.6217, val_precision: 0.6495 val_recall: 0.6217, val_f1: 0.6270\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 06:34:25\n",
            "loss: 0.3779, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-06-04 06:34:38\n",
            ">>> val_acc: 0.6401, val_precision: 0.6244 val_recall: 0.6401, val_f1: 0.6287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 06:34:38\n",
            "loss: 0.3905, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-04 06:34:47\n",
            "loss: 0.3860, acc: 0.8380\n",
            "E2E-ABSA >>> 2024-06-04 06:34:57\n",
            ">>> val_acc: 0.6547, val_precision: 0.6270 val_recall: 0.6547, val_f1: 0.6382\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6547\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 06:35:00\n",
            "loss: 0.3604, acc: 0.8672\n",
            "E2E-ABSA >>> 2024-06-04 06:35:09\n",
            "loss: 0.3512, acc: 0.8603\n",
            "E2E-ABSA >>> 2024-06-04 06:35:17\n",
            ">>> val_acc: 0.6654, val_precision: 0.6324 val_recall: 0.6654, val_f1: 0.6422\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6654\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 06:35:22\n",
            "loss: 0.3522, acc: 0.8493\n",
            "E2E-ABSA >>> 2024-06-04 06:35:30\n",
            "loss: 0.3800, acc: 0.8446\n",
            "E2E-ABSA >>> 2024-06-04 06:35:37\n",
            ">>> val_acc: 0.6565, val_precision: 0.6306 val_recall: 0.6565, val_f1: 0.6392\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 06:35:44\n",
            "loss: 0.3122, acc: 0.8656\n",
            "E2E-ABSA >>> 2024-06-04 06:35:56\n",
            ">>> val_acc: 0.6817, val_precision: 0.6163 val_recall: 0.6817, val_f1: 0.6217\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 06:35:57\n",
            "loss: 0.2800, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-04 06:36:05\n",
            "loss: 0.3066, acc: 0.8810\n",
            "E2E-ABSA >>> 2024-06-04 06:36:16\n",
            ">>> val_acc: 0.6618, val_precision: 0.6279 val_recall: 0.6618, val_f1: 0.6402\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 06:36:18\n",
            "loss: 0.2435, acc: 0.9085\n",
            "E2E-ABSA >>> 2024-06-04 06:36:26\n",
            "loss: 0.2980, acc: 0.8779\n",
            "E2E-ABSA >>> 2024-06-04 06:36:35\n",
            ">>> val_acc: 0.6629, val_precision: 0.6210 val_recall: 0.6629, val_f1: 0.6291\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 06:36:40\n",
            "loss: 0.2485, acc: 0.8990\n",
            "E2E-ABSA >>> 2024-06-04 06:36:48\n",
            "loss: 0.2811, acc: 0.8853\n",
            "E2E-ABSA >>> 2024-06-04 06:36:55\n",
            ">>> val_acc: 0.6536, val_precision: 0.6248 val_recall: 0.6536, val_f1: 0.6351\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 06:37:01\n",
            "loss: 0.2719, acc: 0.8964\n",
            "E2E-ABSA >>> 2024-06-04 06:37:09\n",
            "loss: 0.2987, acc: 0.8860\n",
            "E2E-ABSA >>> 2024-06-04 06:37:14\n",
            ">>> val_acc: 0.6575, val_precision: 0.6099 val_recall: 0.6575, val_f1: 0.6256\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 06:37:22\n",
            "loss: 0.2492, acc: 0.9038\n",
            "E2E-ABSA >>> 2024-06-04 06:37:34\n",
            ">>> val_acc: 0.6259, val_precision: 0.6340 val_recall: 0.6259, val_f1: 0.6269\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 06:37:36\n",
            "loss: 0.2096, acc: 0.9323\n",
            "E2E-ABSA >>> 2024-06-04 06:37:44\n",
            "loss: 0.2299, acc: 0.9148\n",
            "E2E-ABSA >>> 2024-06-04 06:37:53\n",
            ">>> val_acc: 0.6639, val_precision: 0.6147 val_recall: 0.6639, val_f1: 0.6275\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 06:37:57\n",
            "loss: 0.2364, acc: 0.9115\n",
            "E2E-ABSA >>> 2024-06-04 06:38:05\n",
            "loss: 0.2427, acc: 0.9024\n",
            "E2E-ABSA >>> 2024-06-04 06:38:12\n",
            ">>> val_acc: 0.6195, val_precision: 0.6302 val_recall: 0.6195, val_f1: 0.6212\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 06:38:19\n",
            "loss: 0.2558, acc: 0.8958\n",
            "E2E-ABSA >>> 2024-06-04 06:38:27\n",
            "loss: 0.2417, acc: 0.9004\n",
            "E2E-ABSA >>> 2024-06-04 06:38:32\n",
            ">>> val_acc: 0.6234, val_precision: 0.6232 val_recall: 0.6234, val_f1: 0.6184\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-04 06:38:40\n",
            "loss: 0.2328, acc: 0.9154\n",
            "E2E-ABSA >>> 2024-06-04 06:38:51\n",
            ">>> val_acc: 0.6117, val_precision: 0.6195 val_recall: 0.6117, val_f1: 0.6149\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-04 06:38:53\n",
            "loss: 0.1705, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 06:39:01\n",
            "loss: 0.2077, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-04 06:39:11\n",
            ">>> val_acc: 0.6337, val_precision: 0.6184 val_recall: 0.6337, val_f1: 0.6233\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-04 06:39:15\n",
            "loss: 0.1825, acc: 0.9304\n",
            "E2E-ABSA >>> 2024-06-04 06:39:23\n",
            "loss: 0.2097, acc: 0.9175\n",
            "E2E-ABSA >>> 2024-06-04 06:39:30\n",
            ">>> val_acc: 0.6398, val_precision: 0.6230 val_recall: 0.6398, val_f1: 0.6296\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-04 06:39:36\n",
            "loss: 0.1874, acc: 0.9329\n",
            "E2E-ABSA >>> 2024-06-04 06:39:44\n",
            "loss: 0.2037, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-04 06:39:50\n",
            ">>> val_acc: 0.6472, val_precision: 0.6137 val_recall: 0.6472, val_f1: 0.6256\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-04 06:39:57\n",
            "loss: 0.1803, acc: 0.9348\n",
            "E2E-ABSA >>> 2024-06-04 06:40:09\n",
            ">>> val_acc: 0.6455, val_precision: 0.6155 val_recall: 0.6455, val_f1: 0.6268\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-04 06:40:11\n",
            "loss: 0.1117, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 06:40:19\n",
            "loss: 0.2067, acc: 0.9149\n",
            "E2E-ABSA >>> 2024-06-04 06:40:29\n",
            ">>> val_acc: 0.6490, val_precision: 0.6101 val_recall: 0.6490, val_f1: 0.6238\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-04 06:40:32\n",
            "loss: 0.1510, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-06-04 06:40:40\n",
            "loss: 0.1846, acc: 0.9250\n",
            "E2E-ABSA >>> 2024-06-04 06:40:48\n",
            ">>> val_acc: 0.6536, val_precision: 0.6150 val_recall: 0.6536, val_f1: 0.6279\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-04 06:40:53\n",
            "loss: 0.1628, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-04 06:41:02\n",
            "loss: 0.1820, acc: 0.9322\n",
            "E2E-ABSA >>> 2024-06-04 06:41:08\n",
            ">>> val_acc: 0.6146, val_precision: 0.6205 val_recall: 0.6146, val_f1: 0.6168\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-04 06:41:15\n",
            "loss: 0.2031, acc: 0.9268\n",
            "E2E-ABSA >>> 2024-06-04 06:41:27\n",
            ">>> val_acc: 0.6313, val_precision: 0.6173 val_recall: 0.6313, val_f1: 0.6217\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-04 06:41:28\n",
            "loss: 0.1418, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-06-04 06:41:36\n",
            "loss: 0.1832, acc: 0.9314\n",
            "E2E-ABSA >>> 2024-06-04 06:41:46\n",
            ">>> val_acc: 0.6234, val_precision: 0.6110 val_recall: 0.6234, val_f1: 0.6152\n",
            "E2E-ABSA >>> 2024-06-04 06:41:46\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6654, val_precision: 0.6324 val_recall: 0.6654, val_f1: 0.6422\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.6654\n",
            ">>> test_acc: 0.6513, test_precision: 0.6041, test_recall: 0.6513, test_f1: 0.6175\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "863fbc41-c013-4c0e-af3c-4ed47bd3fdf9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "9d729ffc-1372-4ff0-939b-4cc9cb3d445b",
        "tags": []
      },
      "source": [
        "### base-uncased s3 insert"
      ],
      "id": "9d729ffc-1372-4ff0-939b-4cc9cb3d445b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "a9c787a2-6ca7-453b-aa10-1fe245e90dd5",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a9125e10-f101-41c1-9bc3-d18ceb2ad3f5",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f427842b760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/z_insert_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/z_insert_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 15:29:54\n",
            "loss: 0.9038, acc: 0.6338\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 15:30:05\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 15:30:07\n",
            "loss: 0.8862, acc: 0.6536\n",
            "E2E-ABSA >>> 2024-06-04 15:30:16\n",
            "loss: 0.8416, acc: 0.6734\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 15:30:25\n",
            ">>> val_acc: 0.6849, val_precision: 0.5600 val_recall: 0.6849, val_f1: 0.5643\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6849\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 15:30:29\n",
            "loss: 0.8085, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-04 15:30:37\n",
            "loss: 0.8014, acc: 0.6731\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 15:30:44\n",
            ">>> val_acc: 0.6767, val_precision: 0.5577 val_recall: 0.6767, val_f1: 0.5900\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6767\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 15:30:51\n",
            "loss: 0.7976, acc: 0.6710\n",
            "E2E-ABSA >>> 2024-06-04 15:30:59\n",
            "loss: 0.7834, acc: 0.6777\n",
            "E2E-ABSA >>> 2024-06-04 15:31:04\n",
            ">>> val_acc: 0.6618, val_precision: 0.6112 val_recall: 0.6618, val_f1: 0.6028\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6618\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 15:31:13\n",
            "loss: 0.7322, acc: 0.6934\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 15:31:24\n",
            ">>> val_acc: 0.6721, val_precision: 0.5709 val_recall: 0.6721, val_f1: 0.6085\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6721\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 15:31:26\n",
            "loss: 0.6621, acc: 0.7250\n",
            "E2E-ABSA >>> 2024-06-04 15:31:34\n",
            "loss: 0.6920, acc: 0.7156\n",
            "E2E-ABSA >>> 2024-06-04 15:31:44\n",
            ">>> val_acc: 0.6171, val_precision: 0.6249 val_recall: 0.6171, val_f1: 0.6139\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6171\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 15:31:48\n",
            "loss: 0.6709, acc: 0.7386\n",
            "E2E-ABSA >>> 2024-06-04 15:31:56\n",
            "loss: 0.6872, acc: 0.7192\n",
            "E2E-ABSA >>> 2024-06-04 15:32:03\n",
            ">>> val_acc: 0.6739, val_precision: 0.6070 val_recall: 0.6739, val_f1: 0.6109\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 15:32:09\n",
            "loss: 0.6795, acc: 0.7243\n",
            "E2E-ABSA >>> 2024-06-04 15:32:18\n",
            "loss: 0.6665, acc: 0.7292\n",
            "E2E-ABSA >>> 2024-06-04 15:32:23\n",
            ">>> val_acc: 0.6813, val_precision: 0.5817 val_recall: 0.6813, val_f1: 0.5841\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 15:32:31\n",
            "loss: 0.6037, acc: 0.7697\n",
            "E2E-ABSA >>> 2024-06-04 15:32:42\n",
            ">>> val_acc: 0.6583, val_precision: 0.6125 val_recall: 0.6583, val_f1: 0.6273\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6583\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 15:32:44\n",
            "loss: 0.6365, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-04 15:32:52\n",
            "loss: 0.6074, acc: 0.7473\n",
            "E2E-ABSA >>> 2024-06-04 15:33:02\n",
            ">>> val_acc: 0.6810, val_precision: 0.6162 val_recall: 0.6810, val_f1: 0.6205\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 15:33:05\n",
            "loss: 0.5652, acc: 0.7781\n",
            "E2E-ABSA >>> 2024-06-04 15:33:14\n",
            "loss: 0.5886, acc: 0.7670\n",
            "E2E-ABSA >>> 2024-06-04 15:33:21\n",
            ">>> val_acc: 0.6714, val_precision: 0.6171 val_recall: 0.6714, val_f1: 0.6260\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 15:33:27\n",
            "loss: 0.5435, acc: 0.7910\n",
            "E2E-ABSA >>> 2024-06-04 15:33:35\n",
            "loss: 0.5558, acc: 0.7786\n",
            "E2E-ABSA >>> 2024-06-04 15:33:41\n",
            ">>> val_acc: 0.6607, val_precision: 0.6061 val_recall: 0.6607, val_f1: 0.6225\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 15:33:48\n",
            "loss: 0.5178, acc: 0.7940\n",
            "E2E-ABSA >>> 2024-06-04 15:34:00\n",
            ">>> val_acc: 0.6501, val_precision: 0.6072 val_recall: 0.6501, val_f1: 0.6215\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 15:34:01\n",
            "loss: 0.3931, acc: 0.8542\n",
            "E2E-ABSA >>> 2024-06-04 15:34:09\n",
            "loss: 0.5079, acc: 0.7946\n",
            "E2E-ABSA >>> 2024-06-04 15:34:19\n",
            ">>> val_acc: 0.6547, val_precision: 0.6282 val_recall: 0.6547, val_f1: 0.6338\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6547\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 15:34:23\n",
            "loss: 0.4554, acc: 0.8212\n",
            "E2E-ABSA >>> 2024-06-04 15:34:31\n",
            "loss: 0.4908, acc: 0.7960\n",
            "E2E-ABSA >>> 2024-06-04 15:34:39\n",
            ">>> val_acc: 0.6888, val_precision: 0.6143 val_recall: 0.6888, val_f1: 0.5967\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 15:34:44\n",
            "loss: 0.4681, acc: 0.8115\n",
            "E2E-ABSA >>> 2024-06-04 15:34:53\n",
            "loss: 0.4769, acc: 0.8039\n",
            "E2E-ABSA >>> 2024-06-04 15:34:59\n",
            ">>> val_acc: 0.6529, val_precision: 0.6087 val_recall: 0.6529, val_f1: 0.6225\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 15:35:06\n",
            "loss: 0.4511, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-04 15:35:18\n",
            ">>> val_acc: 0.6337, val_precision: 0.6094 val_recall: 0.6337, val_f1: 0.6197\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 15:35:19\n",
            "loss: 0.4390, acc: 0.8516\n",
            "E2E-ABSA >>> 2024-06-04 15:35:27\n",
            "loss: 0.4380, acc: 0.8200\n",
            "E2E-ABSA >>> 2024-06-04 15:35:37\n",
            ">>> val_acc: 0.6686, val_precision: 0.6112 val_recall: 0.6686, val_f1: 0.6177\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 15:35:40\n",
            "loss: 0.4235, acc: 0.8164\n",
            "E2E-ABSA >>> 2024-06-04 15:35:48\n",
            "loss: 0.4279, acc: 0.8229\n",
            "E2E-ABSA >>> 2024-06-04 15:35:57\n",
            ">>> val_acc: 0.6220, val_precision: 0.6239 val_recall: 0.6220, val_f1: 0.6119\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 15:36:01\n",
            "loss: 0.3847, acc: 0.8460\n",
            "E2E-ABSA >>> 2024-06-04 15:36:10\n",
            "loss: 0.4173, acc: 0.8293\n",
            "E2E-ABSA >>> 2024-06-04 15:36:16\n",
            ">>> val_acc: 0.6600, val_precision: 0.6055 val_recall: 0.6600, val_f1: 0.6220\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 15:36:23\n",
            "loss: 0.4042, acc: 0.8234\n",
            "E2E-ABSA >>> 2024-06-04 15:36:35\n",
            ">>> val_acc: 0.6597, val_precision: 0.6209 val_recall: 0.6597, val_f1: 0.6327\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 15:36:36\n",
            "loss: 0.2908, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-04 15:36:44\n",
            "loss: 0.4139, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-04 15:36:55\n",
            ">>> val_acc: 0.6544, val_precision: 0.6127 val_recall: 0.6544, val_f1: 0.6274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 15:36:57\n",
            "loss: 0.3357, acc: 0.8661\n",
            "E2E-ABSA >>> 2024-06-04 15:37:06\n",
            "loss: 0.3932, acc: 0.8320\n",
            "E2E-ABSA >>> 2024-06-04 15:37:14\n",
            ">>> val_acc: 0.6472, val_precision: 0.6127 val_recall: 0.6472, val_f1: 0.6240\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 15:37:19\n",
            "loss: 0.3429, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 15:37:27\n",
            "loss: 0.3854, acc: 0.8384\n",
            "E2E-ABSA >>> 2024-06-04 15:37:34\n",
            ">>> val_acc: 0.6355, val_precision: 0.6111 val_recall: 0.6355, val_f1: 0.6140\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 15:37:40\n",
            "loss: 0.3716, acc: 0.8495\n",
            "E2E-ABSA >>> 2024-06-04 15:37:48\n",
            "loss: 0.3994, acc: 0.8291\n",
            "E2E-ABSA >>> 2024-06-04 15:37:53\n",
            ">>> val_acc: 0.6458, val_precision: 0.6220 val_recall: 0.6458, val_f1: 0.6220\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 15:38:01\n",
            "loss: 0.3750, acc: 0.8337\n",
            "E2E-ABSA >>> 2024-06-04 15:38:12\n",
            ">>> val_acc: 0.6423, val_precision: 0.6195 val_recall: 0.6423, val_f1: 0.6270\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 15:38:14\n",
            "loss: 0.3467, acc: 0.8542\n",
            "E2E-ABSA >>> 2024-06-04 15:38:23\n",
            "loss: 0.3533, acc: 0.8518\n",
            "E2E-ABSA >>> 2024-06-04 15:38:32\n",
            ">>> val_acc: 0.6693, val_precision: 0.6157 val_recall: 0.6693, val_f1: 0.6289\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 15:38:36\n",
            "loss: 0.3912, acc: 0.8255\n",
            "E2E-ABSA >>> 2024-06-04 15:38:44\n",
            "loss: 0.3603, acc: 0.8433\n",
            "E2E-ABSA >>> 2024-06-04 15:38:51\n",
            ">>> val_acc: 0.6519, val_precision: 0.6137 val_recall: 0.6519, val_f1: 0.6242\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 15:38:57\n",
            "loss: 0.3552, acc: 0.8464\n",
            "E2E-ABSA >>> 2024-06-04 15:39:05\n",
            "loss: 0.3569, acc: 0.8463\n",
            "E2E-ABSA >>> 2024-06-04 15:39:10\n",
            ">>> val_acc: 0.6551, val_precision: 0.6222 val_recall: 0.6551, val_f1: 0.6348\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6551\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-04 15:39:19\n",
            "loss: 0.3316, acc: 0.8620\n",
            "E2E-ABSA >>> 2024-06-04 15:39:30\n",
            ">>> val_acc: 0.6131, val_precision: 0.6217 val_recall: 0.6131, val_f1: 0.6128\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-04 15:39:32\n",
            "loss: 0.2782, acc: 0.8719\n",
            "E2E-ABSA >>> 2024-06-04 15:39:40\n",
            "loss: 0.3296, acc: 0.8609\n",
            "E2E-ABSA >>> 2024-06-04 15:39:50\n",
            ">>> val_acc: 0.6220, val_precision: 0.6105 val_recall: 0.6220, val_f1: 0.6159\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-04 15:39:53\n",
            "loss: 0.3101, acc: 0.8679\n",
            "E2E-ABSA >>> 2024-06-04 15:40:02\n",
            "loss: 0.3476, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 15:40:09\n",
            ">>> val_acc: 0.6302, val_precision: 0.6095 val_recall: 0.6302, val_f1: 0.6176\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-04 15:40:15\n",
            "loss: 0.3072, acc: 0.8658\n",
            "E2E-ABSA >>> 2024-06-04 15:40:23\n",
            "loss: 0.3281, acc: 0.8583\n",
            "E2E-ABSA >>> 2024-06-04 15:40:28\n",
            ">>> val_acc: 0.6355, val_precision: 0.6144 val_recall: 0.6355, val_f1: 0.6216\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-04 15:40:36\n",
            "loss: 0.3018, acc: 0.8764\n",
            "E2E-ABSA >>> 2024-06-04 15:40:48\n",
            ">>> val_acc: 0.6554, val_precision: 0.6131 val_recall: 0.6554, val_f1: 0.6259\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-04 15:40:49\n",
            "loss: 0.3222, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 15:40:57\n",
            "loss: 0.3291, acc: 0.8626\n",
            "E2E-ABSA >>> 2024-06-04 15:41:07\n",
            ">>> val_acc: 0.6401, val_precision: 0.6221 val_recall: 0.6401, val_f1: 0.6301\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-04 15:41:10\n",
            "loss: 0.2649, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-04 15:41:19\n",
            "loss: 0.3104, acc: 0.8683\n",
            "E2E-ABSA >>> 2024-06-04 15:41:26\n",
            ">>> val_acc: 0.6597, val_precision: 0.6094 val_recall: 0.6597, val_f1: 0.6244\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-04 15:41:32\n",
            "loss: 0.3077, acc: 0.8789\n",
            "E2E-ABSA >>> 2024-06-04 15:41:40\n",
            "loss: 0.3215, acc: 0.8678\n",
            "E2E-ABSA >>> 2024-06-04 15:41:46\n",
            ">>> val_acc: 0.6227, val_precision: 0.6161 val_recall: 0.6227, val_f1: 0.6193\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-04 15:41:53\n",
            "loss: 0.2678, acc: 0.8885\n",
            "E2E-ABSA >>> 2024-06-04 15:42:05\n",
            ">>> val_acc: 0.6526, val_precision: 0.6160 val_recall: 0.6526, val_f1: 0.6291\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-04 15:42:06\n",
            "loss: 0.3088, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 15:42:15\n",
            "loss: 0.3002, acc: 0.8689\n",
            "E2E-ABSA >>> 2024-06-04 15:42:25\n",
            ">>> val_acc: 0.6433, val_precision: 0.6214 val_recall: 0.6433, val_f1: 0.6297\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-04 15:42:28\n",
            "loss: 0.3180, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 15:42:36\n",
            "loss: 0.3056, acc: 0.8585\n",
            "E2E-ABSA >>> 2024-06-04 15:42:44\n",
            ">>> val_acc: 0.6259, val_precision: 0.6254 val_recall: 0.6259, val_f1: 0.6255\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-04 15:42:49\n",
            "loss: 0.2770, acc: 0.8844\n",
            "E2E-ABSA >>> 2024-06-04 15:42:57\n",
            "loss: 0.2987, acc: 0.8703\n",
            "E2E-ABSA >>> 2024-06-04 15:43:03\n",
            ">>> val_acc: 0.6274, val_precision: 0.6181 val_recall: 0.6274, val_f1: 0.6210\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-04 15:43:10\n",
            "loss: 0.2725, acc: 0.8824\n",
            "E2E-ABSA >>> 2024-06-04 15:43:23\n",
            ">>> val_acc: 0.6472, val_precision: 0.6145 val_recall: 0.6472, val_f1: 0.6274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-04 15:43:23\n",
            "loss: 0.2255, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-04 15:43:32\n",
            "loss: 0.2995, acc: 0.8704\n",
            "E2E-ABSA >>> 2024-06-04 15:43:42\n",
            ">>> val_acc: 0.6650, val_precision: 0.6156 val_recall: 0.6650, val_f1: 0.6263\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-04 15:43:45\n",
            "loss: 0.3005, acc: 0.8555\n",
            "E2E-ABSA >>> 2024-06-04 15:43:53\n",
            "loss: 0.2883, acc: 0.8736\n",
            "E2E-ABSA >>> 2024-06-04 15:44:01\n",
            ">>> val_acc: 0.6462, val_precision: 0.6219 val_recall: 0.6462, val_f1: 0.6319\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 44.\n",
            "E2E-ABSA >>> 2024-06-04 15:44:06\n",
            "loss: 0.2566, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-04 15:44:14\n",
            "loss: 0.2953, acc: 0.8622\n",
            "E2E-ABSA >>> 2024-06-04 15:44:21\n",
            ">>> val_acc: 0.6526, val_precision: 0.6173 val_recall: 0.6526, val_f1: 0.6303\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 45.\n",
            "E2E-ABSA >>> 2024-06-04 15:44:27\n",
            "loss: 0.2833, acc: 0.8680\n",
            "E2E-ABSA >>> 2024-06-04 15:44:40\n",
            ">>> val_acc: 0.5801, val_precision: 0.6222 val_recall: 0.5801, val_f1: 0.5969\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 46.\n",
            "E2E-ABSA >>> 2024-06-04 15:44:40\n",
            "loss: 0.3243, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 15:44:49\n",
            "loss: 0.2834, acc: 0.8822\n",
            "E2E-ABSA >>> 2024-06-04 15:45:00\n",
            ">>> val_acc: 0.6217, val_precision: 0.6235 val_recall: 0.6217, val_f1: 0.6171\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 47.\n",
            "E2E-ABSA >>> 2024-06-04 15:45:02\n",
            "loss: 0.2796, acc: 0.8728\n",
            "E2E-ABSA >>> 2024-06-04 15:45:10\n",
            "loss: 0.2953, acc: 0.8701\n",
            "E2E-ABSA >>> 2024-06-04 15:45:19\n",
            ">>> val_acc: 0.6476, val_precision: 0.6147 val_recall: 0.6476, val_f1: 0.6274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 48.\n",
            "E2E-ABSA >>> 2024-06-04 15:45:23\n",
            "loss: 0.2671, acc: 0.8822\n",
            "E2E-ABSA >>> 2024-06-04 15:45:32\n",
            "loss: 0.3156, acc: 0.8655\n",
            "E2E-ABSA >>> 2024-06-04 15:45:38\n",
            ">>> val_acc: 0.6171, val_precision: 0.6212 val_recall: 0.6171, val_f1: 0.6190\n",
            "E2E-ABSA >>> 2024-06-04 15:45:38\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6551, val_precision: 0.6222 val_recall: 0.6551, val_f1: 0.6348\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.6551\n",
            ">>> test_acc: 0.6381, test_precision: 0.5959, test_recall: 0.6381, test_f1: 0.6090\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "a9c787a2-6ca7-453b-aa10-1fe245e90dd5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "134b0bdc-bec1-4300-9e51-fab24dcc3d10",
        "tags": []
      },
      "source": [
        "### base-uncased s4 insert"
      ],
      "id": "134b0bdc-bec1-4300-9e51-fab24dcc3d10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "afd6f59c-362a-41a9-96fe-49e2a835c8a0",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "1bcf1a2e-4bdb-449b-d3bf-eaadfef16937",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 270kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 5.11MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 25.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.32MB/s]\n",
            "model.safetensors: 100% 440M/440M [00:02<00:00, 166MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f0dada1af80>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/j_insert_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/j_insert_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-06 14:10:08\n",
            "loss: 0.8874, acc: 0.6362\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 14:10:54\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-06 14:11:04\n",
            "loss: 0.8692, acc: 0.6484\n",
            "E2E-ABSA >>> 2024-06-06 14:11:39\n",
            "loss: 0.8410, acc: 0.6729\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 14:12:17\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-06 14:12:34\n",
            "loss: 0.8226, acc: 0.6680\n",
            "E2E-ABSA >>> 2024-06-06 14:13:09\n",
            "loss: 0.8220, acc: 0.6706\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 14:13:39\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-06 14:14:04\n",
            "loss: 0.8162, acc: 0.6580\n",
            "E2E-ABSA >>> 2024-06-06 14:14:39\n",
            "loss: 0.8087, acc: 0.6682\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 14:15:01\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-06 14:15:34\n",
            "loss: 0.7942, acc: 0.6751\n",
            "E2E-ABSA >>> 2024-06-06 14:16:22\n",
            ">>> val_acc: 0.6622, val_precision: 0.5804 val_recall: 0.6622, val_f1: 0.5956\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6622\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-06 14:16:30\n",
            "loss: 0.7569, acc: 0.6937\n",
            "E2E-ABSA >>> 2024-06-06 14:17:06\n",
            "loss: 0.7743, acc: 0.6807\n",
            "E2E-ABSA >>> 2024-06-06 14:17:45\n",
            ">>> val_acc: 0.6409, val_precision: 0.5919 val_recall: 0.6409, val_f1: 0.6065\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6409\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-06 14:18:02\n",
            "loss: 0.7462, acc: 0.7031\n",
            "E2E-ABSA >>> 2024-06-06 14:18:37\n",
            "loss: 0.7476, acc: 0.6793\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 14:19:08\n",
            ">>> val_acc: 0.6899, val_precision: 0.6275 val_recall: 0.6899, val_f1: 0.5705\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-06 14:19:32\n",
            "loss: 0.7501, acc: 0.6618\n",
            "E2E-ABSA >>> 2024-06-06 14:20:07\n",
            "loss: 0.7413, acc: 0.6763\n",
            "E2E-ABSA >>> 2024-06-06 14:20:30\n",
            ">>> val_acc: 0.6895, val_precision: 0.6268 val_recall: 0.6895, val_f1: 0.6304\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6895\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-06 14:21:06\n",
            "loss: 0.6929, acc: 0.7018\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 14:21:55\n",
            ">>> val_acc: 0.6885, val_precision: 0.5223 val_recall: 0.6885, val_f1: 0.5854\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-06 14:22:01\n",
            "loss: 0.7123, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-06 14:22:36\n",
            "loss: 0.6874, acc: 0.6961\n",
            "E2E-ABSA >>> 2024-06-06 14:23:17\n",
            ">>> val_acc: 0.6931, val_precision: 0.6309 val_recall: 0.6931, val_f1: 0.6103\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-06 14:23:31\n",
            "loss: 0.5950, acc: 0.7344\n",
            "E2E-ABSA >>> 2024-06-06 14:24:06\n",
            "loss: 0.6463, acc: 0.7263\n",
            "E2E-ABSA >>> 2024-06-06 14:24:38\n",
            ">>> val_acc: 0.6792, val_precision: 0.6340 val_recall: 0.6792, val_f1: 0.6397\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6792\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-06 14:25:08\n",
            "loss: 0.5863, acc: 0.7393\n",
            "E2E-ABSA >>> 2024-06-06 14:25:44\n",
            "loss: 0.6254, acc: 0.7279\n",
            "E2E-ABSA >>> 2024-06-06 14:26:07\n",
            ">>> val_acc: 0.6906, val_precision: 0.6476 val_recall: 0.6906, val_f1: 0.6402\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6906\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-06 14:26:45\n",
            "loss: 0.5819, acc: 0.7493\n",
            "E2E-ABSA >>> 2024-06-06 14:27:36\n",
            ">>> val_acc: 0.6792, val_precision: 0.6615 val_recall: 0.6792, val_f1: 0.6315\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-06 14:27:40\n",
            "loss: 0.6171, acc: 0.7604\n",
            "E2E-ABSA >>> 2024-06-06 14:28:15\n",
            "loss: 0.5469, acc: 0.7684\n",
            "E2E-ABSA >>> 2024-06-06 14:28:58\n",
            ">>> val_acc: 0.6806, val_precision: 0.6420 val_recall: 0.6806, val_f1: 0.6534\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6806\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-06 14:29:17\n",
            "loss: 0.4997, acc: 0.8038\n",
            "E2E-ABSA >>> 2024-06-06 14:29:52\n",
            "loss: 0.5353, acc: 0.7776\n",
            "E2E-ABSA >>> 2024-06-06 14:30:26\n",
            ">>> val_acc: 0.6515, val_precision: 0.6496 val_recall: 0.6515, val_f1: 0.6443\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-06 14:30:47\n",
            "loss: 0.5085, acc: 0.7844\n",
            "E2E-ABSA >>> 2024-06-06 14:31:22\n",
            "loss: 0.4965, acc: 0.7902\n",
            "E2E-ABSA >>> 2024-06-06 14:31:48\n",
            ">>> val_acc: 0.5993, val_precision: 0.6620 val_recall: 0.5993, val_f1: 0.6223\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-06 14:32:17\n",
            "loss: 0.4807, acc: 0.8036\n",
            "E2E-ABSA >>> 2024-06-06 14:33:09\n",
            ">>> val_acc: 0.6494, val_precision: 0.6532 val_recall: 0.6494, val_f1: 0.6511\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-06 14:33:12\n",
            "loss: 0.3514, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-06 14:33:47\n",
            "loss: 0.4038, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-06-06 14:34:31\n",
            ">>> val_acc: 0.6703, val_precision: 0.6432 val_recall: 0.6703, val_f1: 0.6534\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6703\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-06 14:34:44\n",
            "loss: 0.3687, acc: 0.8457\n",
            "E2E-ABSA >>> 2024-06-06 14:35:20\n",
            "loss: 0.3823, acc: 0.8366\n",
            "E2E-ABSA >>> 2024-06-06 14:35:55\n",
            ">>> val_acc: 0.6739, val_precision: 0.6533 val_recall: 0.6739, val_f1: 0.6617\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6739\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-06 14:36:21\n",
            "loss: 0.3427, acc: 0.8583\n",
            "E2E-ABSA >>> 2024-06-06 14:36:56\n",
            "loss: 0.3664, acc: 0.8526\n",
            "E2E-ABSA >>> 2024-06-06 14:37:23\n",
            ">>> val_acc: 0.6515, val_precision: 0.6562 val_recall: 0.6515, val_f1: 0.6528\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-06 14:37:51\n",
            "loss: 0.3560, acc: 0.8680\n",
            "E2E-ABSA >>> 2024-06-06 14:38:45\n",
            ">>> val_acc: 0.6650, val_precision: 0.6458 val_recall: 0.6650, val_f1: 0.6512\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-06 14:38:46\n",
            "loss: 0.2128, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-06 14:39:21\n",
            "loss: 0.3024, acc: 0.8840\n",
            "E2E-ABSA >>> 2024-06-06 14:40:06\n",
            ">>> val_acc: 0.6472, val_precision: 0.6413 val_recall: 0.6472, val_f1: 0.6419\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-06 14:40:16\n",
            "loss: 0.2401, acc: 0.9152\n",
            "E2E-ABSA >>> 2024-06-06 14:40:51\n",
            "loss: 0.3006, acc: 0.8940\n",
            "E2E-ABSA >>> 2024-06-06 14:41:28\n",
            ">>> val_acc: 0.6519, val_precision: 0.6332 val_recall: 0.6519, val_f1: 0.6409\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-06 14:41:46\n",
            "loss: 0.2811, acc: 0.8942\n",
            "E2E-ABSA >>> 2024-06-06 14:42:21\n",
            "loss: 0.2976, acc: 0.8865\n",
            "E2E-ABSA >>> 2024-06-06 14:42:49\n",
            ">>> val_acc: 0.6472, val_precision: 0.6436 val_recall: 0.6472, val_f1: 0.6421\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-06 14:43:16\n",
            "loss: 0.2769, acc: 0.8947\n",
            "E2E-ABSA >>> 2024-06-06 14:43:51\n",
            "loss: 0.2896, acc: 0.8888\n",
            "E2E-ABSA >>> 2024-06-06 14:44:11\n",
            ">>> val_acc: 0.6504, val_precision: 0.6549 val_recall: 0.6504, val_f1: 0.6514\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-06 14:44:46\n",
            "loss: 0.2453, acc: 0.9100\n",
            "E2E-ABSA >>> 2024-06-06 14:45:33\n",
            ">>> val_acc: 0.6419, val_precision: 0.6449 val_recall: 0.6419, val_f1: 0.6434\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-06 14:45:41\n",
            "loss: 0.1876, acc: 0.9271\n",
            "E2E-ABSA >>> 2024-06-06 14:46:16\n",
            "loss: 0.2191, acc: 0.9178\n",
            "E2E-ABSA >>> 2024-06-06 14:46:54\n",
            ">>> val_acc: 0.6664, val_precision: 0.6355 val_recall: 0.6664, val_f1: 0.6453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-06 14:47:11\n",
            "loss: 0.2469, acc: 0.9115\n",
            "E2E-ABSA >>> 2024-06-06 14:47:46\n",
            "loss: 0.2418, acc: 0.9126\n",
            "E2E-ABSA >>> 2024-06-06 14:48:16\n",
            ">>> val_acc: 0.6259, val_precision: 0.6460 val_recall: 0.6259, val_f1: 0.6269\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-06 14:48:41\n",
            "loss: 0.2342, acc: 0.9184\n",
            "E2E-ABSA >>> 2024-06-06 14:49:16\n",
            "loss: 0.2211, acc: 0.9182\n",
            "E2E-ABSA >>> 2024-06-06 14:49:37\n",
            ">>> val_acc: 0.6345, val_precision: 0.6422 val_recall: 0.6345, val_f1: 0.6377\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-06 14:50:11\n",
            "loss: 0.1758, acc: 0.9388\n",
            "E2E-ABSA >>> 2024-06-06 14:50:59\n",
            ">>> val_acc: 0.6256, val_precision: 0.6412 val_recall: 0.6256, val_f1: 0.6326\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-06 14:51:06\n",
            "loss: 0.1727, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-06 14:51:41\n",
            "loss: 0.1965, acc: 0.9323\n",
            "E2E-ABSA >>> 2024-06-06 14:52:21\n",
            ">>> val_acc: 0.6522, val_precision: 0.6408 val_recall: 0.6522, val_f1: 0.6455\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-06 14:52:36\n",
            "loss: 0.1953, acc: 0.9304\n",
            "E2E-ABSA >>> 2024-06-06 14:53:11\n",
            "loss: 0.1914, acc: 0.9336\n",
            "E2E-ABSA >>> 2024-06-06 14:53:42\n",
            ">>> val_acc: 0.6220, val_precision: 0.6490 val_recall: 0.6220, val_f1: 0.6296\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-06 14:54:06\n",
            "loss: 0.1673, acc: 0.9347\n",
            "E2E-ABSA >>> 2024-06-06 14:54:41\n",
            "loss: 0.1948, acc: 0.9256\n",
            "E2E-ABSA >>> 2024-06-06 14:55:04\n",
            ">>> val_acc: 0.6380, val_precision: 0.6485 val_recall: 0.6380, val_f1: 0.6410\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-06 14:55:36\n",
            "loss: 0.1717, acc: 0.9423\n",
            "E2E-ABSA >>> 2024-06-06 14:56:26\n",
            ">>> val_acc: 0.6316, val_precision: 0.6535 val_recall: 0.6316, val_f1: 0.6410\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-06 14:56:31\n",
            "loss: 0.1085, acc: 0.9648\n",
            "E2E-ABSA >>> 2024-06-06 14:57:06\n",
            "loss: 0.1868, acc: 0.9386\n",
            "E2E-ABSA >>> 2024-06-06 14:57:47\n",
            ">>> val_acc: 0.6465, val_precision: 0.6394 val_recall: 0.6465, val_f1: 0.6423\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-06 14:58:01\n",
            "loss: 0.1575, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-06 14:58:36\n",
            "loss: 0.1709, acc: 0.9366\n",
            "E2E-ABSA >>> 2024-06-06 14:59:09\n",
            ">>> val_acc: 0.6675, val_precision: 0.6406 val_recall: 0.6675, val_f1: 0.6498\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-06 14:59:31\n",
            "loss: 0.1405, acc: 0.9541\n",
            "E2E-ABSA >>> 2024-06-06 15:00:07\n",
            "loss: 0.1554, acc: 0.9463\n",
            "E2E-ABSA >>> 2024-06-06 15:00:31\n",
            ">>> val_acc: 0.6423, val_precision: 0.6409 val_recall: 0.6423, val_f1: 0.6409\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-06 15:01:02\n",
            "loss: 0.1347, acc: 0.9503\n",
            "E2E-ABSA >>> 2024-06-06 15:01:52\n",
            ">>> val_acc: 0.6487, val_precision: 0.6365 val_recall: 0.6487, val_f1: 0.6420\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-06 15:01:56\n",
            "loss: 0.1692, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-06 15:02:32\n",
            "loss: 0.1436, acc: 0.9515\n",
            "E2E-ABSA >>> 2024-06-06 15:03:14\n",
            ">>> val_acc: 0.6213, val_precision: 0.6421 val_recall: 0.6213, val_f1: 0.6283\n",
            "E2E-ABSA >>> 2024-06-06 15:03:14\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6739, val_precision: 0.6533 val_recall: 0.6739, val_f1: 0.6617\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.6739\n",
            ">>> test_acc: 0.6242, test_precision: 0.5844, test_recall: 0.6242, test_f1: 0.5993\n"
          ]
        }
      ],
      "source": [
        "# 6-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "afd6f59c-362a-41a9-96fe-49e2a835c8a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "a4379c4a-eadf-420d-82e8-2a399d98e515",
        "tags": []
      },
      "source": [
        "### base-uncased s5 insert"
      ],
      "id": "a4379c4a-eadf-420d-82e8-2a399d98e515"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "6af10c9c-12e6-4598-9709-c2ee62204c9a",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "62e1e674-5f91-4050-bd99-1f4599955b27",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x785492812f80>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-06 15:09:09\n",
            "loss: 0.9015, acc: 0.6325\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 15:09:55\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-06 15:10:11\n",
            "loss: 0.8809, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-06-06 15:10:47\n",
            "loss: 0.8450, acc: 0.6709\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 15:11:25\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-06 15:11:41\n",
            "loss: 0.8204, acc: 0.6693\n",
            "E2E-ABSA >>> 2024-06-06 15:12:17\n",
            "loss: 0.8142, acc: 0.6723\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 15:12:46\n",
            ">>> val_acc: 0.6863, val_precision: 0.5772 val_recall: 0.6863, val_f1: 0.5593\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-06 15:13:18\n",
            "loss: 0.8124, acc: 0.6684\n",
            "E2E-ABSA >>> 2024-06-06 15:13:54\n",
            "loss: 0.8028, acc: 0.6741\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 15:14:15\n",
            ">>> val_acc: 0.6813, val_precision: 0.5586 val_recall: 0.6813, val_f1: 0.5819\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6813\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-06 15:15:06\n",
            "loss: 0.7773, acc: 0.6797\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 15:15:54\n",
            ">>> val_acc: 0.6803, val_precision: 0.5599 val_recall: 0.6803, val_f1: 0.5880\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6803\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-06 15:16:09\n",
            "loss: 0.7102, acc: 0.6813\n",
            "E2E-ABSA >>> 2024-06-06 15:16:44\n",
            "loss: 0.7433, acc: 0.6885\n",
            "E2E-ABSA >>> 2024-06-06 15:17:23\n",
            ">>> val_acc: 0.6078, val_precision: 0.6270 val_recall: 0.6078, val_f1: 0.6159\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6078\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-06 15:17:45\n",
            "loss: 0.7349, acc: 0.6875\n",
            "E2E-ABSA >>> 2024-06-06 15:18:21\n",
            "loss: 0.7269, acc: 0.6840\n",
            "E2E-ABSA >>> 2024-06-06 15:18:52\n",
            ">>> val_acc: 0.6540, val_precision: 0.5915 val_recall: 0.6540, val_f1: 0.6125\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-06 15:19:16\n",
            "loss: 0.7340, acc: 0.6820\n",
            "E2E-ABSA >>> 2024-06-06 15:19:51\n",
            "loss: 0.7107, acc: 0.6946\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 15:20:13\n",
            ">>> val_acc: 0.6838, val_precision: 0.5648 val_recall: 0.6838, val_f1: 0.5797\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-06 15:20:46\n",
            "loss: 0.6327, acc: 0.7289\n",
            "E2E-ABSA >>> 2024-06-06 15:21:35\n",
            ">>> val_acc: 0.6863, val_precision: 0.5948 val_recall: 0.6863, val_f1: 0.5738\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-06 15:21:41\n",
            "loss: 0.6605, acc: 0.7070\n",
            "E2E-ABSA >>> 2024-06-06 15:22:16\n",
            "loss: 0.6518, acc: 0.7042\n",
            "E2E-ABSA >>> 2024-06-06 15:22:56\n",
            ">>> val_acc: 0.6863, val_precision: 0.6227 val_recall: 0.6863, val_f1: 0.6166\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-06 15:23:22\n",
            "loss: 0.5394, acc: 0.7578\n",
            "E2E-ABSA >>> 2024-06-06 15:23:58\n",
            "loss: 0.6022, acc: 0.7371\n",
            "E2E-ABSA >>> 2024-06-06 15:24:30\n",
            ">>> val_acc: 0.6813, val_precision: 0.6261 val_recall: 0.6813, val_f1: 0.6343\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6813\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-06 15:25:00\n",
            "loss: 0.5609, acc: 0.7588\n",
            "E2E-ABSA >>> 2024-06-06 15:25:36\n",
            "loss: 0.5757, acc: 0.7515\n",
            "E2E-ABSA >>> 2024-06-06 15:26:00\n",
            ">>> val_acc: 0.6714, val_precision: 0.6491 val_recall: 0.6714, val_f1: 0.6240\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-06 15:26:31\n",
            "loss: 0.5471, acc: 0.7699\n",
            "E2E-ABSA >>> 2024-06-06 15:27:21\n",
            ">>> val_acc: 0.6845, val_precision: 0.6444 val_recall: 0.6845, val_f1: 0.6340\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-06 15:27:26\n",
            "loss: 0.5864, acc: 0.7552\n",
            "E2E-ABSA >>> 2024-06-06 15:28:01\n",
            "loss: 0.5106, acc: 0.7902\n",
            "E2E-ABSA >>> 2024-06-06 15:28:43\n",
            ">>> val_acc: 0.6462, val_precision: 0.6391 val_recall: 0.6462, val_f1: 0.6297\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-06 15:28:56\n",
            "loss: 0.4691, acc: 0.8056\n",
            "E2E-ABSA >>> 2024-06-06 15:29:31\n",
            "loss: 0.5094, acc: 0.7808\n",
            "E2E-ABSA >>> 2024-06-06 15:30:05\n",
            ">>> val_acc: 0.6824, val_precision: 0.6370 val_recall: 0.6824, val_f1: 0.6480\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6824\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-06 15:30:33\n",
            "loss: 0.4195, acc: 0.8365\n",
            "E2E-ABSA >>> 2024-06-06 15:31:09\n",
            "loss: 0.4421, acc: 0.8199\n",
            "E2E-ABSA >>> 2024-06-06 15:31:34\n",
            ">>> val_acc: 0.5840, val_precision: 0.6473 val_recall: 0.5840, val_f1: 0.6037\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-06 15:32:03\n",
            "loss: 0.4893, acc: 0.8006\n",
            "E2E-ABSA >>> 2024-06-06 15:32:55\n",
            ">>> val_acc: 0.6597, val_precision: 0.6319 val_recall: 0.6597, val_f1: 0.6423\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-06 15:32:58\n",
            "loss: 0.3467, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-06 15:33:33\n",
            "loss: 0.4126, acc: 0.8374\n",
            "E2E-ABSA >>> 2024-06-06 15:34:17\n",
            ">>> val_acc: 0.6540, val_precision: 0.6391 val_recall: 0.6540, val_f1: 0.6459\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-06 15:34:28\n",
            "loss: 0.3801, acc: 0.8477\n",
            "E2E-ABSA >>> 2024-06-06 15:35:03\n",
            "loss: 0.3559, acc: 0.8608\n",
            "E2E-ABSA >>> 2024-06-06 15:35:39\n",
            ">>> val_acc: 0.6686, val_precision: 0.6378 val_recall: 0.6686, val_f1: 0.6494\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6686\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-06 15:36:06\n",
            "loss: 0.2927, acc: 0.8828\n",
            "E2E-ABSA >>> 2024-06-06 15:36:41\n",
            "loss: 0.3353, acc: 0.8690\n",
            "E2E-ABSA >>> 2024-06-06 15:37:08\n",
            ">>> val_acc: 0.6572, val_precision: 0.6293 val_recall: 0.6572, val_f1: 0.6398\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-06 15:37:36\n",
            "loss: 0.3217, acc: 0.8742\n",
            "E2E-ABSA >>> 2024-06-06 15:38:29\n",
            ">>> val_acc: 0.6696, val_precision: 0.6246 val_recall: 0.6696, val_f1: 0.6387\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-06 15:38:31\n",
            "loss: 0.2669, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-06 15:39:06\n",
            "loss: 0.2744, acc: 0.8990\n",
            "E2E-ABSA >>> 2024-06-06 15:39:51\n",
            ">>> val_acc: 0.6096, val_precision: 0.6432 val_recall: 0.6096, val_f1: 0.6218\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-06 15:40:01\n",
            "loss: 0.1765, acc: 0.9330\n",
            "E2E-ABSA >>> 2024-06-06 15:40:36\n",
            "loss: 0.2745, acc: 0.8931\n",
            "E2E-ABSA >>> 2024-06-06 15:41:13\n",
            ">>> val_acc: 0.6249, val_precision: 0.6325 val_recall: 0.6249, val_f1: 0.6282\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-06 15:41:31\n",
            "loss: 0.2569, acc: 0.8966\n",
            "E2E-ABSA >>> 2024-06-06 15:42:06\n",
            "loss: 0.2690, acc: 0.8972\n",
            "E2E-ABSA >>> 2024-06-06 15:42:34\n",
            ">>> val_acc: 0.6472, val_precision: 0.6309 val_recall: 0.6472, val_f1: 0.6361\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-06 15:43:01\n",
            "loss: 0.2421, acc: 0.9243\n",
            "E2E-ABSA >>> 2024-06-06 15:43:36\n",
            "loss: 0.2598, acc: 0.9076\n",
            "E2E-ABSA >>> 2024-06-06 15:43:56\n",
            ">>> val_acc: 0.6426, val_precision: 0.6323 val_recall: 0.6426, val_f1: 0.6355\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-06 15:44:31\n",
            "loss: 0.2096, acc: 0.9194\n",
            "E2E-ABSA >>> 2024-06-06 15:45:17\n",
            ">>> val_acc: 0.6671, val_precision: 0.6272 val_recall: 0.6671, val_f1: 0.6339\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-06 15:45:26\n",
            "loss: 0.2253, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-06 15:46:01\n",
            "loss: 0.2063, acc: 0.9274\n",
            "E2E-ABSA >>> 2024-06-06 15:46:39\n",
            ">>> val_acc: 0.6856, val_precision: 0.6244 val_recall: 0.6856, val_f1: 0.6284\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-06 15:46:56\n",
            "loss: 0.2080, acc: 0.9245\n",
            "E2E-ABSA >>> 2024-06-06 15:47:31\n",
            "loss: 0.2093, acc: 0.9248\n",
            "E2E-ABSA >>> 2024-06-06 15:48:01\n",
            ">>> val_acc: 0.6469, val_precision: 0.6403 val_recall: 0.6469, val_f1: 0.6428\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-06 15:48:26\n",
            "loss: 0.1482, acc: 0.9497\n",
            "E2E-ABSA >>> 2024-06-06 15:49:01\n",
            "loss: 0.1930, acc: 0.9306\n",
            "E2E-ABSA >>> 2024-06-06 15:49:22\n",
            ">>> val_acc: 0.6355, val_precision: 0.6328 val_recall: 0.6355, val_f1: 0.6317\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-06 15:49:56\n",
            "loss: 0.1720, acc: 0.9466\n",
            "E2E-ABSA >>> 2024-06-06 15:50:44\n",
            ">>> val_acc: 0.6615, val_precision: 0.6386 val_recall: 0.6615, val_f1: 0.6481\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-06 15:50:51\n",
            "loss: 0.1918, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-06 15:51:26\n",
            "loss: 0.1945, acc: 0.9260\n",
            "E2E-ABSA >>> 2024-06-06 15:52:05\n",
            ">>> val_acc: 0.6750, val_precision: 0.6357 val_recall: 0.6750, val_f1: 0.6485\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-06 15:52:21\n",
            "loss: 0.1507, acc: 0.9545\n",
            "E2E-ABSA >>> 2024-06-06 15:52:56\n",
            "loss: 0.1777, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-06 15:53:27\n",
            ">>> val_acc: 0.6501, val_precision: 0.6244 val_recall: 0.6501, val_f1: 0.6331\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-06 15:53:51\n",
            "loss: 0.1400, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-06 15:54:26\n",
            "loss: 0.1676, acc: 0.9412\n",
            "E2E-ABSA >>> 2024-06-06 15:54:48\n",
            ">>> val_acc: 0.6313, val_precision: 0.6336 val_recall: 0.6313, val_f1: 0.6324\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-06 15:55:21\n",
            "loss: 0.1498, acc: 0.9463\n",
            "E2E-ABSA >>> 2024-06-06 15:56:10\n",
            ">>> val_acc: 0.6195, val_precision: 0.6299 val_recall: 0.6195, val_f1: 0.6234\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-06 15:56:16\n",
            "loss: 0.0988, acc: 0.9805\n",
            "E2E-ABSA >>> 2024-06-06 15:56:51\n",
            "loss: 0.1572, acc: 0.9391\n",
            "E2E-ABSA >>> 2024-06-06 15:57:31\n",
            ">>> val_acc: 0.6448, val_precision: 0.6356 val_recall: 0.6448, val_f1: 0.6399\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-06 15:57:46\n",
            "loss: 0.1616, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-06 15:58:21\n",
            "loss: 0.1553, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-06 15:58:53\n",
            ">>> val_acc: 0.6469, val_precision: 0.6345 val_recall: 0.6469, val_f1: 0.6401\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-06 15:59:16\n",
            "loss: 0.1595, acc: 0.9482\n",
            "E2E-ABSA >>> 2024-06-06 15:59:51\n",
            "loss: 0.1697, acc: 0.9409\n",
            "E2E-ABSA >>> 2024-06-06 16:00:15\n",
            ">>> val_acc: 0.6629, val_precision: 0.6306 val_recall: 0.6629, val_f1: 0.6368\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-06 16:00:45\n",
            "loss: 0.1234, acc: 0.9581\n",
            "E2E-ABSA >>> 2024-06-06 16:01:36\n",
            ">>> val_acc: 0.6583, val_precision: 0.6323 val_recall: 0.6583, val_f1: 0.6421\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-06 16:01:40\n",
            "loss: 0.1416, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-06-06 16:02:15\n",
            "loss: 0.1569, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-06 16:02:57\n",
            ">>> val_acc: 0.6426, val_precision: 0.6392 val_recall: 0.6426, val_f1: 0.6408\n",
            "E2E-ABSA >>> 2024-06-06 16:02:57\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6686, val_precision: 0.6378 val_recall: 0.6686, val_f1: 0.6494\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.6686\n",
            ">>> test_acc: 0.6314, test_precision: 0.5832, test_recall: 0.6314, test_f1: 0.5999\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "6af10c9c-12e6-4598-9709-c2ee62204c9a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "9ba96fdc-0583-492a-a690-78c94ed037ef",
        "tags": []
      },
      "source": [
        "### base-uncased s6 insert"
      ],
      "id": "9ba96fdc-0583-492a-a690-78c94ed037ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "3de8c438-ef61-4121-a19f-ad9d1348a5d9",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "62a6db7b-0829-418a-b6e7-f9ab3b830105",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 439079424\n",
            "> n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7bb645e1af80>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-06 16:07:08\n",
            "loss: 0.9026, acc: 0.6319\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:07:55\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-06 16:08:04\n",
            "loss: 0.8848, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-06 16:08:40\n",
            "loss: 0.8484, acc: 0.6749\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:09:17\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-06 16:09:34\n",
            "loss: 0.8475, acc: 0.6654\n",
            "E2E-ABSA >>> 2024-06-06 16:10:10\n",
            "loss: 0.8422, acc: 0.6731\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:10:39\n",
            ">>> val_acc: 0.6863, val_precision: 0.5772 val_recall: 0.6863, val_f1: 0.5593\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-06 16:11:12\n",
            "loss: 0.8373, acc: 0.6658\n",
            "E2E-ABSA >>> 2024-06-06 16:11:47\n",
            "loss: 0.8388, acc: 0.6715\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:12:08\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-06 16:12:42\n",
            "loss: 0.8353, acc: 0.6751\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:13:30\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-06 16:13:37\n",
            "loss: 0.8077, acc: 0.6969\n",
            "E2E-ABSA >>> 2024-06-06 16:14:12\n",
            "loss: 0.8252, acc: 0.6786\n",
            "E2E-ABSA >>> 2024-06-06 16:14:51\n",
            ">>> val_acc: 0.5048, val_precision: 0.5546 val_recall: 0.5048, val_f1: 0.5109\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-06 16:15:07\n",
            "loss: 0.8524, acc: 0.6804\n",
            "E2E-ABSA >>> 2024-06-06 16:15:42\n",
            "loss: 0.8529, acc: 0.6723\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:16:13\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-06 16:16:37\n",
            "loss: 0.8314, acc: 0.6691\n",
            "E2E-ABSA >>> 2024-06-06 16:17:12\n",
            "loss: 0.8298, acc: 0.6700\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:17:34\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-06 16:18:07\n",
            "loss: 0.8108, acc: 0.6760\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:18:56\n",
            ">>> val_acc: 0.6867, val_precision: 0.6833 val_recall: 0.6867, val_f1: 0.5595\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6867\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-06 16:19:04\n",
            "loss: 0.8347, acc: 0.6367\n",
            "E2E-ABSA >>> 2024-06-06 16:19:39\n",
            "loss: 0.8093, acc: 0.6676\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:20:20\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-06 16:20:34\n",
            "loss: 0.7527, acc: 0.6969\n",
            "E2E-ABSA >>> 2024-06-06 16:21:09\n",
            "loss: 0.7763, acc: 0.6790\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:21:41\n",
            ">>> val_acc: 0.6856, val_precision: 0.5689 val_recall: 0.6856, val_f1: 0.5787\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6856\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-06 16:22:15\n",
            "loss: 0.7602, acc: 0.6885\n",
            "E2E-ABSA >>> 2024-06-06 16:22:50\n",
            "loss: 0.7765, acc: 0.6871\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:23:14\n",
            ">>> val_acc: 0.6881, val_precision: 0.6312 val_recall: 0.6881, val_f1: 0.5635\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-06 16:23:45\n",
            "loss: 0.7798, acc: 0.6768\n",
            "E2E-ABSA >>> 2024-06-06 16:24:36\n",
            ">>> val_acc: 0.6703, val_precision: 0.5929 val_recall: 0.6703, val_f1: 0.5998\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6703\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-06 16:24:47\n",
            "loss: 0.7475, acc: 0.6979\n",
            "E2E-ABSA >>> 2024-06-06 16:25:23\n",
            "loss: 0.7517, acc: 0.6842\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:26:05\n",
            ">>> val_acc: 0.6870, val_precision: 0.5744 val_recall: 0.6870, val_f1: 0.5711\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-06 16:26:17\n",
            "loss: 0.7198, acc: 0.7205\n",
            "E2E-ABSA >>> 2024-06-06 16:26:52\n",
            "loss: 0.7289, acc: 0.7036\n",
            "E2E-ABSA >>> 2024-06-06 16:27:26\n",
            ">>> val_acc: 0.6774, val_precision: 0.6002 val_recall: 0.6774, val_f1: 0.6030\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6774\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-06 16:27:54\n",
            "loss: 0.7153, acc: 0.7073\n",
            "E2E-ABSA >>> 2024-06-06 16:28:29\n",
            "loss: 0.7230, acc: 0.7012\n",
            "E2E-ABSA >>> 2024-06-06 16:28:55\n",
            ">>> val_acc: 0.6551, val_precision: 0.5996 val_recall: 0.6551, val_f1: 0.6051\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6551\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-06 16:29:31\n",
            "loss: 0.7103, acc: 0.7135\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:30:23\n",
            ">>> val_acc: 0.6348, val_precision: 0.5645 val_recall: 0.6348, val_f1: 0.5975\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-06 16:30:26\n",
            "loss: 0.6573, acc: 0.7344\n",
            "E2E-ABSA >>> 2024-06-06 16:31:01\n",
            "loss: 0.6782, acc: 0.7112\n",
            "E2E-ABSA >>> 2024-06-06 16:31:44\n",
            ">>> val_acc: 0.6607, val_precision: 0.5903 val_recall: 0.6607, val_f1: 0.5991\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-06 16:31:56\n",
            "loss: 0.6937, acc: 0.7168\n",
            "E2E-ABSA >>> 2024-06-06 16:32:31\n",
            "loss: 0.6683, acc: 0.7230\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:33:06\n",
            ">>> val_acc: 0.6142, val_precision: 0.5709 val_recall: 0.6142, val_f1: 0.5907\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-06 16:33:26\n",
            "loss: 0.6223, acc: 0.7455\n",
            "E2E-ABSA >>> 2024-06-06 16:34:01\n",
            "loss: 0.6466, acc: 0.7372\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:34:28\n",
            ">>> val_acc: 0.6263, val_precision: 0.5560 val_recall: 0.6263, val_f1: 0.5889\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-06 16:34:56\n",
            "loss: 0.6319, acc: 0.7312\n",
            "E2E-ABSA >>> 2024-06-06 16:35:49\n",
            ">>> val_acc: 0.6671, val_precision: 0.5657 val_recall: 0.6671, val_f1: 0.6040\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-06 16:35:51\n",
            "loss: 0.5430, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-06-06 16:36:26\n",
            "loss: 0.6121, acc: 0.7476\n",
            "E2E-ABSA >>> 2024-06-06 16:37:11\n",
            ">>> val_acc: 0.6554, val_precision: 0.5630 val_recall: 0.6554, val_f1: 0.6021\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-06 16:37:21\n",
            "loss: 0.5379, acc: 0.7679\n",
            "E2E-ABSA >>> 2024-06-06 16:37:56\n",
            "loss: 0.6001, acc: 0.7446\n",
            "E2E-ABSA >>> 2024-06-06 16:38:32\n",
            ">>> val_acc: 0.5979, val_precision: 0.5824 val_recall: 0.5979, val_f1: 0.5849\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-06 16:38:51\n",
            "loss: 0.5448, acc: 0.7704\n",
            "E2E-ABSA >>> 2024-06-06 16:39:26\n",
            "loss: 0.5791, acc: 0.7623\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-06 16:39:54\n",
            ">>> val_acc: 0.6707, val_precision: 0.5682 val_recall: 0.6707, val_f1: 0.6063\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6707\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-06 16:40:28\n",
            "loss: 0.5239, acc: 0.7944\n",
            "E2E-ABSA >>> 2024-06-06 16:41:03\n",
            "loss: 0.5428, acc: 0.7783\n",
            "E2E-ABSA >>> 2024-06-06 16:41:23\n",
            ">>> val_acc: 0.6220, val_precision: 0.6061 val_recall: 0.6220, val_f1: 0.5984\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-06 16:41:58\n",
            "loss: 0.5204, acc: 0.7869\n",
            "E2E-ABSA >>> 2024-06-06 16:42:44\n",
            ">>> val_acc: 0.6433, val_precision: 0.5990 val_recall: 0.6433, val_f1: 0.6062\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-06 16:42:53\n",
            "loss: 0.4583, acc: 0.8229\n",
            "E2E-ABSA >>> 2024-06-06 16:43:28\n",
            "loss: 0.5178, acc: 0.7898\n",
            "E2E-ABSA >>> 2024-06-06 16:44:06\n",
            ">>> val_acc: 0.6522, val_precision: 0.5859 val_recall: 0.6522, val_f1: 0.6042\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-06 16:44:23\n",
            "loss: 0.5115, acc: 0.7852\n",
            "E2E-ABSA >>> 2024-06-06 16:44:58\n",
            "loss: 0.4985, acc: 0.7986\n",
            "E2E-ABSA >>> 2024-06-06 16:45:27\n",
            ">>> val_acc: 0.6316, val_precision: 0.5912 val_recall: 0.6316, val_f1: 0.6056\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-06 16:45:53\n",
            "loss: 0.4783, acc: 0.8003\n",
            "E2E-ABSA >>> 2024-06-06 16:46:28\n",
            "loss: 0.4796, acc: 0.8096\n",
            "E2E-ABSA >>> 2024-06-06 16:46:49\n",
            ">>> val_acc: 0.6252, val_precision: 0.6042 val_recall: 0.6252, val_f1: 0.6051\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-06 16:47:23\n",
            "loss: 0.4424, acc: 0.8190\n",
            "E2E-ABSA >>> 2024-06-06 16:48:11\n",
            ">>> val_acc: 0.6384, val_precision: 0.5901 val_recall: 0.6384, val_f1: 0.6041\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-06 16:48:18\n",
            "loss: 0.4775, acc: 0.7969\n",
            "E2E-ABSA >>> 2024-06-06 16:48:53\n",
            "loss: 0.4405, acc: 0.8245\n",
            "E2E-ABSA >>> 2024-06-06 16:49:32\n",
            ">>> val_acc: 0.6263, val_precision: 0.6051 val_recall: 0.6263, val_f1: 0.6142\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6263\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-06 16:49:49\n",
            "loss: 0.4303, acc: 0.8310\n",
            "E2E-ABSA >>> 2024-06-06 16:50:24\n",
            "loss: 0.4501, acc: 0.8242\n",
            "E2E-ABSA >>> 2024-06-06 16:50:55\n",
            ">>> val_acc: 0.6000, val_precision: 0.6045 val_recall: 0.6000, val_f1: 0.5957\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-06 16:51:19\n",
            "loss: 0.4086, acc: 0.8373\n",
            "E2E-ABSA >>> 2024-06-06 16:51:54\n",
            "loss: 0.4304, acc: 0.8278\n",
            "E2E-ABSA >>> 2024-06-06 16:52:17\n",
            ">>> val_acc: 0.6160, val_precision: 0.6057 val_recall: 0.6160, val_f1: 0.6089\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-06 16:52:49\n",
            "loss: 0.4211, acc: 0.8376\n",
            "E2E-ABSA >>> 2024-06-06 16:53:38\n",
            ">>> val_acc: 0.6188, val_precision: 0.5972 val_recall: 0.6188, val_f1: 0.6069\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-06 16:53:44\n",
            "loss: 0.4511, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-06 16:54:19\n",
            "loss: 0.4143, acc: 0.8367\n",
            "E2E-ABSA >>> 2024-06-06 16:55:00\n",
            ">>> val_acc: 0.6270, val_precision: 0.5999 val_recall: 0.6270, val_f1: 0.6117\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-06 16:55:14\n",
            "loss: 0.4156, acc: 0.8250\n",
            "E2E-ABSA >>> 2024-06-06 16:55:49\n",
            "loss: 0.4033, acc: 0.8366\n",
            "E2E-ABSA >>> 2024-06-06 16:56:21\n",
            ">>> val_acc: 0.6444, val_precision: 0.5936 val_recall: 0.6444, val_f1: 0.6112\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-06 16:56:44\n",
            "loss: 0.3800, acc: 0.8457\n",
            "E2E-ABSA >>> 2024-06-06 16:57:19\n",
            "loss: 0.3828, acc: 0.8476\n",
            "E2E-ABSA >>> 2024-06-06 16:57:43\n",
            ">>> val_acc: 0.6007, val_precision: 0.6091 val_recall: 0.6007, val_f1: 0.6048\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 37.\n",
            "E2E-ABSA >>> 2024-06-06 16:58:14\n",
            "loss: 0.3694, acc: 0.8487\n",
            "E2E-ABSA >>> 2024-06-06 16:59:05\n",
            ">>> val_acc: 0.5915, val_precision: 0.6053 val_recall: 0.5915, val_f1: 0.5979\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 38.\n",
            "E2E-ABSA >>> 2024-06-06 16:59:09\n",
            "loss: 0.3477, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-06 16:59:44\n",
            "loss: 0.3570, acc: 0.8638\n",
            "E2E-ABSA >>> 2024-06-06 17:00:26\n",
            ">>> val_acc: 0.6160, val_precision: 0.6064 val_recall: 0.6160, val_f1: 0.6091\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 39.\n",
            "E2E-ABSA >>> 2024-06-06 17:00:39\n",
            "loss: 0.3802, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-06 17:01:14\n",
            "loss: 0.3590, acc: 0.8520\n",
            "E2E-ABSA >>> 2024-06-06 17:01:48\n",
            ">>> val_acc: 0.5837, val_precision: 0.5997 val_recall: 0.5837, val_f1: 0.5893\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 40.\n",
            "E2E-ABSA >>> 2024-06-06 17:02:09\n",
            "loss: 0.3159, acc: 0.8823\n",
            "E2E-ABSA >>> 2024-06-06 17:02:44\n",
            "loss: 0.3519, acc: 0.8566\n",
            "E2E-ABSA >>> 2024-06-06 17:03:09\n",
            ">>> val_acc: 0.6433, val_precision: 0.5955 val_recall: 0.6433, val_f1: 0.6129\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 41.\n",
            "E2E-ABSA >>> 2024-06-06 17:03:39\n",
            "loss: 0.3277, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-06 17:04:31\n",
            ">>> val_acc: 0.6085, val_precision: 0.6036 val_recall: 0.6085, val_f1: 0.6059\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 42.\n",
            "E2E-ABSA >>> 2024-06-06 17:04:34\n",
            "loss: 0.3336, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-06 17:05:09\n",
            "loss: 0.3494, acc: 0.8698\n",
            "E2E-ABSA >>> 2024-06-06 17:05:53\n",
            ">>> val_acc: 0.6202, val_precision: 0.6015 val_recall: 0.6202, val_f1: 0.6065\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 43.\n",
            "E2E-ABSA >>> 2024-06-06 17:06:04\n",
            "loss: 0.3239, acc: 0.8867\n",
            "E2E-ABSA >>> 2024-06-06 17:06:39\n",
            "loss: 0.3103, acc: 0.8873\n",
            "E2E-ABSA >>> 2024-06-06 17:07:14\n",
            ">>> val_acc: 0.6270, val_precision: 0.5967 val_recall: 0.6270, val_f1: 0.6077\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 44.\n",
            "E2E-ABSA >>> 2024-06-06 17:07:34\n",
            "loss: 0.3013, acc: 0.8783\n",
            "E2E-ABSA >>> 2024-06-06 17:08:09\n",
            "loss: 0.3279, acc: 0.8710\n",
            "E2E-ABSA >>> 2024-06-06 17:08:36\n",
            ">>> val_acc: 0.6313, val_precision: 0.5995 val_recall: 0.6313, val_f1: 0.6126\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 45.\n",
            "E2E-ABSA >>> 2024-06-06 17:09:04\n",
            "loss: 0.3357, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-06 17:09:58\n",
            ">>> val_acc: 0.6011, val_precision: 0.6077 val_recall: 0.6011, val_f1: 0.6031\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 46.\n",
            "E2E-ABSA >>> 2024-06-06 17:09:59\n",
            "loss: 0.4366, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-06-06 17:10:34\n",
            "loss: 0.3100, acc: 0.8846\n",
            "E2E-ABSA >>> 2024-06-06 17:11:19\n",
            ">>> val_acc: 0.6064, val_precision: 0.6090 val_recall: 0.6064, val_f1: 0.6050\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 47.\n",
            "E2E-ABSA >>> 2024-06-06 17:11:29\n",
            "loss: 0.2752, acc: 0.8951\n",
            "E2E-ABSA >>> 2024-06-06 17:12:04\n",
            "loss: 0.2961, acc: 0.8877\n",
            "E2E-ABSA >>> 2024-06-06 17:12:41\n",
            ">>> val_acc: 0.6028, val_precision: 0.6050 val_recall: 0.6028, val_f1: 0.6011\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 48.\n",
            "E2E-ABSA >>> 2024-06-06 17:12:59\n",
            "loss: 0.2612, acc: 0.8954\n",
            "E2E-ABSA >>> 2024-06-06 17:13:34\n",
            "loss: 0.2997, acc: 0.8816\n",
            "E2E-ABSA >>> 2024-06-06 17:14:02\n",
            ">>> val_acc: 0.6266, val_precision: 0.6025 val_recall: 0.6266, val_f1: 0.6122\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 49.\n",
            "E2E-ABSA >>> 2024-06-06 17:14:29\n",
            "loss: 0.2843, acc: 0.8890\n",
            "E2E-ABSA >>> 2024-06-06 17:15:04\n",
            "loss: 0.2916, acc: 0.8870\n",
            "E2E-ABSA >>> 2024-06-06 17:15:24\n",
            ">>> val_acc: 0.6277, val_precision: 0.6025 val_recall: 0.6277, val_f1: 0.6129\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 50.\n",
            "E2E-ABSA >>> 2024-06-06 17:15:59\n",
            "loss: 0.3005, acc: 0.8794\n",
            "E2E-ABSA >>> 2024-06-06 17:16:46\n",
            ">>> val_acc: 0.6437, val_precision: 0.6076 val_recall: 0.6437, val_f1: 0.6195\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6437\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 51.\n",
            "E2E-ABSA >>> 2024-06-06 17:17:01\n",
            "loss: 0.2574, acc: 0.8984\n",
            "E2E-ABSA >>> 2024-06-06 17:17:36\n",
            "loss: 0.2743, acc: 0.8957\n",
            "E2E-ABSA >>> 2024-06-06 17:18:14\n",
            ">>> val_acc: 0.6224, val_precision: 0.6051 val_recall: 0.6224, val_f1: 0.6128\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 52.\n",
            "E2E-ABSA >>> 2024-06-06 17:18:31\n",
            "loss: 0.2739, acc: 0.8971\n",
            "E2E-ABSA >>> 2024-06-06 17:19:06\n",
            "loss: 0.2838, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-06 17:19:36\n",
            ">>> val_acc: 0.6131, val_precision: 0.6052 val_recall: 0.6131, val_f1: 0.6084\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 53.\n",
            "E2E-ABSA >>> 2024-06-06 17:20:01\n",
            "loss: 0.2705, acc: 0.8941\n",
            "E2E-ABSA >>> 2024-06-06 17:20:36\n",
            "loss: 0.2720, acc: 0.8946\n",
            "E2E-ABSA >>> 2024-06-06 17:20:57\n",
            ">>> val_acc: 0.5968, val_precision: 0.6110 val_recall: 0.5968, val_f1: 0.6034\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 54.\n",
            "E2E-ABSA >>> 2024-06-06 17:21:31\n",
            "loss: 0.2632, acc: 0.9017\n",
            "E2E-ABSA >>> 2024-06-06 17:22:19\n",
            ">>> val_acc: 0.6234, val_precision: 0.6065 val_recall: 0.6234, val_f1: 0.6136\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 55.\n",
            "E2E-ABSA >>> 2024-06-06 17:22:26\n",
            "loss: 0.2030, acc: 0.9156\n",
            "E2E-ABSA >>> 2024-06-06 17:23:01\n",
            "loss: 0.2670, acc: 0.8901\n",
            "E2E-ABSA >>> 2024-06-06 17:23:40\n",
            ">>> val_acc: 0.6188, val_precision: 0.6004 val_recall: 0.6188, val_f1: 0.6087\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 56.\n",
            "E2E-ABSA >>> 2024-06-06 17:23:56\n",
            "loss: 0.2084, acc: 0.9290\n",
            "E2E-ABSA >>> 2024-06-06 17:24:31\n",
            "loss: 0.2660, acc: 0.8984\n",
            "E2E-ABSA >>> 2024-06-06 17:25:02\n",
            ">>> val_acc: 0.6107, val_precision: 0.6024 val_recall: 0.6107, val_f1: 0.6057\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 57.\n",
            "E2E-ABSA >>> 2024-06-06 17:25:26\n",
            "loss: 0.2358, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-06 17:26:01\n",
            "loss: 0.2625, acc: 0.9055\n",
            "E2E-ABSA >>> 2024-06-06 17:26:23\n",
            ">>> val_acc: 0.6089, val_precision: 0.6157 val_recall: 0.6089, val_f1: 0.6122\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 58.\n",
            "E2E-ABSA >>> 2024-06-06 17:26:56\n",
            "loss: 0.2730, acc: 0.8988\n",
            "E2E-ABSA >>> 2024-06-06 17:27:45\n",
            ">>> val_acc: 0.6057, val_precision: 0.6119 val_recall: 0.6057, val_f1: 0.6086\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 59.\n",
            "E2E-ABSA >>> 2024-06-06 17:27:51\n",
            "loss: 0.1508, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-06 17:28:26\n",
            "loss: 0.2621, acc: 0.8982\n",
            "E2E-ABSA >>> 2024-06-06 17:29:06\n",
            ">>> val_acc: 0.6202, val_precision: 0.6023 val_recall: 0.6202, val_f1: 0.6103\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 60.\n",
            "E2E-ABSA >>> 2024-06-06 17:29:21\n",
            "loss: 0.2130, acc: 0.9234\n",
            "E2E-ABSA >>> 2024-06-06 17:29:56\n",
            "loss: 0.2467, acc: 0.9098\n",
            "E2E-ABSA >>> 2024-06-06 17:30:28\n",
            ">>> val_acc: 0.6178, val_precision: 0.6102 val_recall: 0.6178, val_f1: 0.6130\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 61.\n",
            "E2E-ABSA >>> 2024-06-06 17:30:50\n",
            "loss: 0.2413, acc: 0.9072\n",
            "E2E-ABSA >>> 2024-06-06 17:31:26\n",
            "loss: 0.2656, acc: 0.8979\n",
            "E2E-ABSA >>> 2024-06-06 17:31:50\n",
            ">>> val_acc: 0.6032, val_precision: 0.6014 val_recall: 0.6032, val_f1: 0.6007\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 62.\n",
            "E2E-ABSA >>> 2024-06-06 17:32:21\n",
            "loss: 0.2188, acc: 0.9254\n",
            "E2E-ABSA >>> 2024-06-06 17:33:11\n",
            ">>> val_acc: 0.6192, val_precision: 0.6043 val_recall: 0.6192, val_f1: 0.6111\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 63.\n",
            "E2E-ABSA >>> 2024-06-06 17:33:15\n",
            "loss: 0.2144, acc: 0.9167\n",
            "E2E-ABSA >>> 2024-06-06 17:33:51\n",
            "loss: 0.2605, acc: 0.8962\n",
            "E2E-ABSA >>> 2024-06-06 17:34:33\n",
            ">>> val_acc: 0.6220, val_precision: 0.6053 val_recall: 0.6220, val_f1: 0.6127\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 64.\n",
            "E2E-ABSA >>> 2024-06-06 17:34:45\n",
            "loss: 0.2513, acc: 0.9010\n",
            "E2E-ABSA >>> 2024-06-06 17:35:21\n",
            "loss: 0.2457, acc: 0.9095\n",
            "E2E-ABSA >>> 2024-06-06 17:35:54\n",
            ">>> val_acc: 0.6064, val_precision: 0.6046 val_recall: 0.6064, val_f1: 0.6053\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 65.\n",
            "E2E-ABSA >>> 2024-06-06 17:36:15\n",
            "loss: 0.2108, acc: 0.9146\n",
            "E2E-ABSA >>> 2024-06-06 17:36:50\n",
            "loss: 0.2443, acc: 0.9035\n",
            "E2E-ABSA >>> 2024-06-06 17:37:16\n",
            ">>> val_acc: 0.6021, val_precision: 0.6035 val_recall: 0.6021, val_f1: 0.6024\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 66.\n",
            "E2E-ABSA >>> 2024-06-06 17:37:45\n",
            "loss: 0.2515, acc: 0.9152\n",
            "E2E-ABSA >>> 2024-06-06 17:38:38\n",
            ">>> val_acc: 0.6220, val_precision: 0.5984 val_recall: 0.6220, val_f1: 0.6087\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 67.\n",
            "E2E-ABSA >>> 2024-06-06 17:38:40\n",
            "loss: 0.3443, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-06 17:39:16\n",
            "loss: 0.2356, acc: 0.9097\n",
            "E2E-ABSA >>> 2024-06-06 17:39:59\n",
            ">>> val_acc: 0.5893, val_precision: 0.6150 val_recall: 0.5893, val_f1: 0.5993\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 68.\n",
            "E2E-ABSA >>> 2024-06-06 17:40:10\n",
            "loss: 0.2374, acc: 0.9121\n",
            "E2E-ABSA >>> 2024-06-06 17:40:46\n",
            "loss: 0.2437, acc: 0.9072\n",
            "E2E-ABSA >>> 2024-06-06 17:41:21\n",
            ">>> val_acc: 0.5723, val_precision: 0.6172 val_recall: 0.5723, val_f1: 0.5904\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 69.\n",
            "E2E-ABSA >>> 2024-06-06 17:41:40\n",
            "loss: 0.2609, acc: 0.8996\n",
            "E2E-ABSA >>> 2024-06-06 17:42:15\n",
            "loss: 0.2779, acc: 0.8930\n",
            "E2E-ABSA >>> 2024-06-06 17:42:42\n",
            ">>> val_acc: 0.6131, val_precision: 0.6014 val_recall: 0.6131, val_f1: 0.6064\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 70.\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name bert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "3de8c438-ef61-4121-a19f-ad9d1348a5d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "550b9503-a399-48e5-bab1-80e691479d49"
      },
      "source": [
        "# Training with indolem/indobert-base-uncased"
      ],
      "id": "550b9503-a399-48e5-bab1-80e691479d49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "74e08822-accf-4a46-8eb7-77df2b5a8a74",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#  menyesuaikan tokenizer BERT untuk indolem/indobert-base-uncased\n",
        "path = 'ta-dictabsa/data_utils.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[100] = \"        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_bert_name)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "id": "74e08822-accf-4a46-8eb7-77df2b5a8a74"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZo-sUicrfBv"
      },
      "source": [
        "## **indolem/indobert-base-uncased** Baseline"
      ],
      "id": "bZo-sUicrfBv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tFo3n5Siq-_v",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "463181db-6786-4d08-ec99-2d068a510c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_ori\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7e27ac01e290>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/train.tsv', 'test': './datasets/ulasan_combined/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-29 14:12:38\n",
            "loss: 0.8783, acc: 0.6388\n",
            "E2E-ABSA >>> 2024-05-29 14:13:23\n",
            ">>> val_acc: 0.6952, val_precision: 0.7262 val_recall: 0.6952, val_f1: 0.6591\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6952\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-29 14:13:36\n",
            "loss: 0.7827, acc: 0.6432\n",
            "E2E-ABSA >>> 2024-05-29 14:14:10\n",
            "loss: 0.7118, acc: 0.7021\n",
            "E2E-ABSA >>> 2024-05-29 14:14:48\n",
            ">>> val_acc: 0.7400, val_precision: 0.7420 val_recall: 0.7400, val_f1: 0.7215\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.74\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-29 14:15:06\n",
            "loss: 0.5337, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-05-29 14:15:41\n",
            "loss: 0.5301, acc: 0.7741\n",
            "E2E-ABSA >>> 2024-05-29 14:16:10\n",
            ">>> val_acc: 0.7719, val_precision: 0.7548 val_recall: 0.7719, val_f1: 0.7425\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.7719\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-29 14:16:37\n",
            "loss: 0.4109, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-05-29 14:17:12\n",
            "loss: 0.4258, acc: 0.8263\n",
            "E2E-ABSA >>> 2024-05-29 14:17:33\n",
            ">>> val_acc: 0.7790, val_precision: 0.7628 val_recall: 0.7790, val_f1: 0.7588\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.779\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-29 14:18:09\n",
            "loss: 0.2768, acc: 0.8919\n",
            "E2E-ABSA >>> 2024-05-29 14:18:57\n",
            ">>> val_acc: 0.7780, val_precision: 0.7779 val_recall: 0.7780, val_f1: 0.7768\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.778\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-29 14:19:11\n",
            "loss: 0.2352, acc: 0.9187\n",
            "E2E-ABSA >>> 2024-05-29 14:19:46\n",
            "loss: 0.2617, acc: 0.9026\n",
            "E2E-ABSA >>> 2024-05-29 14:20:25\n",
            ">>> val_acc: 0.7691, val_precision: 0.7835 val_recall: 0.7691, val_f1: 0.7748\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-29 14:20:41\n",
            "loss: 0.1807, acc: 0.9347\n",
            "E2E-ABSA >>> 2024-05-29 14:21:16\n",
            "loss: 0.2125, acc: 0.9232\n",
            "E2E-ABSA >>> 2024-05-29 14:21:47\n",
            ">>> val_acc: 0.7694, val_precision: 0.7637 val_recall: 0.7694, val_f1: 0.7633\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-29 14:22:11\n",
            "loss: 0.1917, acc: 0.9338\n",
            "E2E-ABSA >>> 2024-05-29 14:22:46\n",
            "loss: 0.2035, acc: 0.9263\n",
            "E2E-ABSA >>> 2024-05-29 14:23:08\n",
            ">>> val_acc: 0.7858, val_precision: 0.7794 val_recall: 0.7858, val_f1: 0.7766\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-29 14:23:41\n",
            "loss: 0.1645, acc: 0.9395\n",
            "E2E-ABSA >>> 2024-05-29 14:24:30\n",
            ">>> val_acc: 0.7734, val_precision: 0.7801 val_recall: 0.7734, val_f1: 0.7760\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-29 14:24:36\n",
            "loss: 0.1571, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-29 14:25:11\n",
            "loss: 0.1409, acc: 0.9477\n",
            "E2E-ABSA >>> 2024-05-29 14:25:52\n",
            ">>> val_acc: 0.7840, val_precision: 0.7830 val_recall: 0.7840, val_f1: 0.7834\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.784\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-29 14:26:12\n",
            "loss: 0.1221, acc: 0.9578\n",
            "E2E-ABSA >>> 2024-05-29 14:26:48\n",
            "loss: 0.1558, acc: 0.9451\n",
            "E2E-ABSA >>> 2024-05-29 14:27:20\n",
            ">>> val_acc: 0.7698, val_precision: 0.7812 val_recall: 0.7698, val_f1: 0.7738\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-29 14:27:42\n",
            "loss: 0.1147, acc: 0.9590\n",
            "E2E-ABSA >>> 2024-05-29 14:28:17\n",
            "loss: 0.1676, acc: 0.9379\n",
            "E2E-ABSA >>> 2024-05-29 14:28:41\n",
            ">>> val_acc: 0.7805, val_precision: 0.7746 val_recall: 0.7805, val_f1: 0.7771\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-29 14:29:12\n",
            "loss: 0.1641, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-05-29 14:30:03\n",
            ">>> val_acc: 0.7730, val_precision: 0.7600 val_recall: 0.7730, val_f1: 0.7559\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-29 14:30:07\n",
            "loss: 0.1428, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-05-29 14:30:42\n",
            "loss: 0.1578, acc: 0.9381\n",
            "E2E-ABSA >>> 2024-05-29 14:31:25\n",
            ">>> val_acc: 0.7769, val_precision: 0.7780 val_recall: 0.7769, val_f1: 0.7773\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-29 14:31:37\n",
            "loss: 0.1207, acc: 0.9601\n",
            "E2E-ABSA >>> 2024-05-29 14:32:12\n",
            "loss: 0.1511, acc: 0.9458\n",
            "E2E-ABSA >>> 2024-05-29 14:32:46\n",
            ">>> val_acc: 0.7680, val_precision: 0.7597 val_recall: 0.7680, val_f1: 0.7631\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-29 14:33:07\n",
            "loss: 0.1667, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-29 14:33:42\n",
            "loss: 0.1640, acc: 0.9363\n",
            "E2E-ABSA >>> 2024-05-29 14:34:08\n",
            ">>> val_acc: 0.7371, val_precision: 0.7814 val_recall: 0.7371, val_f1: 0.7503\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-29 14:34:37\n",
            "loss: 0.1579, acc: 0.9382\n",
            "E2E-ABSA >>> 2024-05-29 14:35:29\n",
            ">>> val_acc: 0.7510, val_precision: 0.7747 val_recall: 0.7510, val_f1: 0.7592\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-29 14:35:32\n",
            "loss: 0.1239, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-29 14:36:07\n",
            "loss: 0.1733, acc: 0.9311\n",
            "E2E-ABSA >>> 2024-05-29 14:36:50\n",
            ">>> val_acc: 0.7709, val_precision: 0.7640 val_recall: 0.7709, val_f1: 0.7657\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-29 14:37:02\n",
            "loss: 0.1095, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-05-29 14:37:37\n",
            "loss: 0.1439, acc: 0.9413\n",
            "E2E-ABSA >>> 2024-05-29 14:38:12\n",
            ">>> val_acc: 0.7538, val_precision: 0.7639 val_recall: 0.7538, val_f1: 0.7581\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-29 14:38:31\n",
            "loss: 0.1222, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-05-29 14:39:06\n",
            "loss: 0.1577, acc: 0.9395\n",
            "E2E-ABSA >>> 2024-05-29 14:39:33\n",
            ">>> val_acc: 0.7620, val_precision: 0.7505 val_recall: 0.7620, val_f1: 0.7539\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-29 14:40:01\n",
            "loss: 0.1585, acc: 0.9398\n",
            "E2E-ABSA >>> 2024-05-29 14:40:55\n",
            ">>> val_acc: 0.7588, val_precision: 0.7696 val_recall: 0.7588, val_f1: 0.7625\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-29 14:40:56\n",
            "loss: 0.1651, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-29 14:41:31\n",
            "loss: 0.1794, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-05-29 14:42:16\n",
            ">>> val_acc: 0.7677, val_precision: 0.7541 val_recall: 0.7677, val_f1: 0.7572\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-29 14:42:26\n",
            "loss: 0.1345, acc: 0.9464\n",
            "E2E-ABSA >>> 2024-05-29 14:43:01\n",
            "loss: 0.1600, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-05-29 14:43:37\n",
            ">>> val_acc: 0.7570, val_precision: 0.7593 val_recall: 0.7570, val_f1: 0.7552\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-29 14:43:56\n",
            "loss: 0.1512, acc: 0.9459\n",
            "E2E-ABSA >>> 2024-05-29 14:44:31\n",
            "loss: 0.1653, acc: 0.9383\n",
            "E2E-ABSA >>> 2024-05-29 14:44:59\n",
            ">>> val_acc: 0.7464, val_precision: 0.7222 val_recall: 0.7464, val_f1: 0.7183\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-29 14:45:26\n",
            "loss: 0.1605, acc: 0.9391\n",
            "E2E-ABSA >>> 2024-05-29 14:46:01\n",
            "loss: 0.1776, acc: 0.9364\n",
            "E2E-ABSA >>> 2024-05-29 14:46:20\n",
            ">>> val_acc: 0.7542, val_precision: 0.7437 val_recall: 0.7542, val_f1: 0.7439\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-29 14:46:55\n",
            "loss: 0.1456, acc: 0.9400\n",
            "E2E-ABSA >>> 2024-05-29 14:47:42\n",
            ">>> val_acc: 0.7503, val_precision: 0.7559 val_recall: 0.7503, val_f1: 0.7518\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-05-29 14:47:50\n",
            "loss: 0.1494, acc: 0.9505\n",
            "E2E-ABSA >>> 2024-05-29 14:48:25\n",
            "loss: 0.1405, acc: 0.9476\n",
            "E2E-ABSA >>> 2024-05-29 14:49:03\n",
            ">>> val_acc: 0.7485, val_precision: 0.7356 val_recall: 0.7485, val_f1: 0.7401\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-05-29 14:49:20\n",
            "loss: 0.1508, acc: 0.9466\n",
            "E2E-ABSA >>> 2024-05-29 14:49:55\n",
            "loss: 0.1340, acc: 0.9497\n",
            "E2E-ABSA >>> 2024-05-29 14:50:25\n",
            ">>> val_acc: 0.7474, val_precision: 0.7458 val_recall: 0.7474, val_f1: 0.7459\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-05-29 14:50:50\n",
            "loss: 0.1307, acc: 0.9462\n",
            "E2E-ABSA >>> 2024-05-29 14:51:25\n",
            "loss: 0.1550, acc: 0.9360\n",
            "E2E-ABSA >>> 2024-05-29 14:51:46\n",
            ">>> val_acc: 0.7453, val_precision: 0.7575 val_recall: 0.7453, val_f1: 0.7505\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-05-29 14:52:20\n",
            "loss: 0.1663, acc: 0.9362\n",
            "E2E-ABSA >>> 2024-05-29 14:53:07\n",
            ">>> val_acc: 0.7528, val_precision: 0.7474 val_recall: 0.7528, val_f1: 0.7494\n",
            "E2E-ABSA >>> 2024-05-29 14:53:07\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7840, val_precision: 0.7830 val_recall: 0.7840, val_f1: 0.7834\n",
            "you can download the best model from state_dict/bert_spc_combined_ori_val_f1_0.784\n",
            ">>> test_acc: 0.7593, test_precision: 0.7531, test_recall: 0.7593, test_f1: 0.7545\n"
          ]
        }
      ],
      "source": [
        "# 29-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_ori --pretrained_bert_name indolem/indobert-base-uncased --log_step 100 --valset_ratio 0.5"
      ],
      "id": "tFo3n5Siq-_v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indolem Concatenation"
      ],
      "metadata": {
        "id": "jwrEwOAVLKIj"
      },
      "id": "jwrEwOAVLKIj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3n4L5tgrygD"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s1 concat"
      ],
      "id": "v3n4L5tgrygD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ad6xr71rygD",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f5abe502-b9f8-4ff2-d855-25f6707f8c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7d613b61a290>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/a_raw_know/train.tsv', 'test': './datasets/ulasan_combined/a_raw_know/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-29 15:04:39\n",
            "loss: 0.8608, acc: 0.6444\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-05-29 15:05:22\n",
            ">>> val_acc: 0.6934, val_precision: 0.6213 val_recall: 0.6934, val_f1: 0.6554\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6934\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-29 15:05:36\n",
            "loss: 0.7721, acc: 0.6589\n",
            "E2E-ABSA >>> 2024-05-29 15:06:10\n",
            "loss: 0.7135, acc: 0.6986\n",
            "E2E-ABSA >>> 2024-05-29 15:06:47\n",
            ">>> val_acc: 0.7108, val_precision: 0.7112 val_recall: 0.7108, val_f1: 0.6813\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7108\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-29 15:07:11\n",
            "loss: 0.5741, acc: 0.7565\n",
            "E2E-ABSA >>> 2024-05-29 15:07:45\n",
            "loss: 0.5899, acc: 0.7432\n",
            "E2E-ABSA >>> 2024-05-29 15:08:15\n",
            ">>> val_acc: 0.7268, val_precision: 0.6998 val_recall: 0.7268, val_f1: 0.6776\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-29 15:08:40\n",
            "loss: 0.4825, acc: 0.8003\n",
            "E2E-ABSA >>> 2024-05-29 15:09:15\n",
            "loss: 0.4972, acc: 0.7972\n",
            "E2E-ABSA >>> 2024-05-29 15:09:36\n",
            ">>> val_acc: 0.7531, val_precision: 0.7356 val_recall: 0.7531, val_f1: 0.7374\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7531\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-29 15:10:18\n",
            "loss: 0.3487, acc: 0.8620\n",
            "E2E-ABSA >>> 2024-05-29 15:11:06\n",
            ">>> val_acc: 0.7005, val_precision: 0.7800 val_recall: 0.7005, val_f1: 0.7180\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-29 15:11:13\n",
            "loss: 0.2824, acc: 0.8844\n",
            "E2E-ABSA >>> 2024-05-29 15:11:48\n",
            "loss: 0.3052, acc: 0.8760\n",
            "E2E-ABSA >>> 2024-05-29 15:12:27\n",
            ">>> val_acc: 0.7574, val_precision: 0.7708 val_recall: 0.7574, val_f1: 0.7624\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7574\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-29 15:12:50\n",
            "loss: 0.2530, acc: 0.9034\n",
            "E2E-ABSA >>> 2024-05-29 15:13:26\n",
            "loss: 0.2511, acc: 0.9089\n",
            "E2E-ABSA >>> 2024-05-29 15:13:57\n",
            ">>> val_acc: 0.7584, val_precision: 0.7534 val_recall: 0.7584, val_f1: 0.7511\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-29 15:14:21\n",
            "loss: 0.1992, acc: 0.9292\n",
            "E2E-ABSA >>> 2024-05-29 15:14:56\n",
            "loss: 0.2222, acc: 0.9178\n",
            "E2E-ABSA >>> 2024-05-29 15:15:18\n",
            ">>> val_acc: 0.7677, val_precision: 0.7555 val_recall: 0.7677, val_f1: 0.7567\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-29 15:15:51\n",
            "loss: 0.1832, acc: 0.9280\n",
            "E2E-ABSA >>> 2024-05-29 15:16:40\n",
            ">>> val_acc: 0.7570, val_precision: 0.7475 val_recall: 0.7570, val_f1: 0.7502\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-29 15:16:45\n",
            "loss: 0.1528, acc: 0.9492\n",
            "E2E-ABSA >>> 2024-05-29 15:17:21\n",
            "loss: 0.1923, acc: 0.9246\n",
            "E2E-ABSA >>> 2024-05-29 15:18:01\n",
            ">>> val_acc: 0.7567, val_precision: 0.7587 val_recall: 0.7567, val_f1: 0.7554\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-29 15:18:15\n",
            "loss: 0.1407, acc: 0.9547\n",
            "E2E-ABSA >>> 2024-05-29 15:18:50\n",
            "loss: 0.1755, acc: 0.9348\n",
            "E2E-ABSA >>> 2024-05-29 15:19:23\n",
            ">>> val_acc: 0.7435, val_precision: 0.7598 val_recall: 0.7435, val_f1: 0.7501\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-29 15:19:45\n",
            "loss: 0.1684, acc: 0.9336\n",
            "E2E-ABSA >>> 2024-05-29 15:20:20\n",
            "loss: 0.2025, acc: 0.9253\n",
            "E2E-ABSA >>> 2024-05-29 15:20:44\n",
            ">>> val_acc: 0.7641, val_precision: 0.7606 val_recall: 0.7641, val_f1: 0.7616\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-29 15:21:15\n",
            "loss: 0.1509, acc: 0.9460\n",
            "E2E-ABSA >>> 2024-05-29 15:22:06\n",
            ">>> val_acc: 0.7595, val_precision: 0.7424 val_recall: 0.7595, val_f1: 0.7429\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-29 15:22:10\n",
            "loss: 0.1142, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-29 15:22:45\n",
            "loss: 0.1698, acc: 0.9386\n",
            "E2E-ABSA >>> 2024-05-29 15:23:28\n",
            ">>> val_acc: 0.7435, val_precision: 0.7531 val_recall: 0.7435, val_f1: 0.7475\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-29 15:23:40\n",
            "loss: 0.1318, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-05-29 15:24:15\n",
            "loss: 0.1691, acc: 0.9398\n",
            "E2E-ABSA >>> 2024-05-29 15:24:49\n",
            ">>> val_acc: 0.7488, val_precision: 0.7507 val_recall: 0.7488, val_f1: 0.7386\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-29 15:25:10\n",
            "loss: 0.1646, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-05-29 15:25:45\n",
            "loss: 0.1734, acc: 0.9387\n",
            "E2E-ABSA >>> 2024-05-29 15:26:11\n",
            ">>> val_acc: 0.7346, val_precision: 0.7397 val_recall: 0.7346, val_f1: 0.7365\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-29 15:26:40\n",
            "loss: 0.1886, acc: 0.9323\n",
            "E2E-ABSA >>> 2024-05-29 15:27:32\n",
            ">>> val_acc: 0.7528, val_precision: 0.7499 val_recall: 0.7528, val_f1: 0.7504\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-29 15:27:35\n",
            "loss: 0.1451, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-29 15:28:10\n",
            "loss: 0.1802, acc: 0.9323\n",
            "E2E-ABSA >>> 2024-05-29 15:28:54\n",
            ">>> val_acc: 0.7460, val_precision: 0.7452 val_recall: 0.7460, val_f1: 0.7446\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-29 15:29:05\n",
            "loss: 0.1218, acc: 0.9512\n",
            "E2E-ABSA >>> 2024-05-29 15:29:40\n",
            "loss: 0.1720, acc: 0.9351\n",
            "E2E-ABSA >>> 2024-05-29 15:30:15\n",
            ">>> val_acc: 0.7197, val_precision: 0.7493 val_recall: 0.7197, val_f1: 0.7300\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-29 15:30:35\n",
            "loss: 0.1295, acc: 0.9498\n",
            "E2E-ABSA >>> 2024-05-29 15:31:10\n",
            "loss: 0.1648, acc: 0.9359\n",
            "E2E-ABSA >>> 2024-05-29 15:31:37\n",
            ">>> val_acc: 0.7439, val_precision: 0.7310 val_recall: 0.7439, val_f1: 0.7320\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-29 15:32:05\n",
            "loss: 0.1459, acc: 0.9430\n",
            "E2E-ABSA >>> 2024-05-29 15:32:58\n",
            ">>> val_acc: 0.7375, val_precision: 0.7408 val_recall: 0.7375, val_f1: 0.7299\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-29 15:32:59\n",
            "loss: 0.0999, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-29 15:33:34\n",
            "loss: 0.1975, acc: 0.9225\n",
            "E2E-ABSA >>> 2024-05-29 15:34:20\n",
            ">>> val_acc: 0.7417, val_precision: 0.7301 val_recall: 0.7417, val_f1: 0.7298\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-29 15:34:29\n",
            "loss: 0.1679, acc: 0.9442\n",
            "E2E-ABSA >>> 2024-05-29 15:35:04\n",
            "loss: 0.2031, acc: 0.9312\n",
            "E2E-ABSA >>> 2024-05-29 15:35:41\n",
            ">>> val_acc: 0.7169, val_precision: 0.7355 val_recall: 0.7169, val_f1: 0.7233\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-29 15:35:59\n",
            "loss: 0.1254, acc: 0.9495\n",
            "E2E-ABSA >>> 2024-05-29 15:36:34\n",
            "loss: 0.1697, acc: 0.9359\n",
            "E2E-ABSA >>> 2024-05-29 15:37:03\n",
            ">>> val_acc: 0.7481, val_precision: 0.7278 val_recall: 0.7481, val_f1: 0.7295\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-29 15:37:29\n",
            "loss: 0.1477, acc: 0.9433\n",
            "E2E-ABSA >>> 2024-05-29 15:38:04\n",
            "loss: 0.1872, acc: 0.9311\n",
            "E2E-ABSA >>> 2024-05-29 15:38:24\n",
            ">>> val_acc: 0.7425, val_precision: 0.7294 val_recall: 0.7425, val_f1: 0.7338\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-29 15:38:59\n",
            "loss: 0.1417, acc: 0.9475\n",
            "E2E-ABSA >>> 2024-05-29 15:39:46\n",
            ">>> val_acc: 0.7357, val_precision: 0.7332 val_recall: 0.7357, val_f1: 0.7340\n",
            "E2E-ABSA >>> 2024-05-29 15:39:46\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7574, val_precision: 0.7708 val_recall: 0.7574, val_f1: 0.7624\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7574\n",
            ">>> test_acc: 0.7432, test_precision: 0.7399, test_recall: 0.7432, test_f1: 0.7411\n"
          ]
        }
      ],
      "source": [
        "# 29-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "2ad6xr71rygD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOVKHz0sFPY"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s2 concat"
      ],
      "id": "ilOVKHz0sFPY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GDo-ximzsFPZ",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "78bb2bbd-8ed8-4165-8dc1-4f6ddf902d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fc9b30124d0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/f_raw_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/f_raw_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-06-03 16:05:06\n",
            "loss: 0.8673, acc: 0.6356\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-03 16:05:50\n",
            ">>> val_acc: 0.6877, val_precision: 0.6368 val_recall: 0.6877, val_f1: 0.6598\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6877\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 16:05:59\n",
            "loss: 0.7673, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-03 16:06:34\n",
            "loss: 0.7023, acc: 0.7031\n",
            "E2E-ABSA >>> 2024-06-03 16:07:11\n",
            ">>> val_acc: 0.7137, val_precision: 0.7312 val_recall: 0.7137, val_f1: 0.6879\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7137\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 16:07:31\n",
            "loss: 0.5527, acc: 0.7578\n",
            "E2E-ABSA >>> 2024-06-03 16:08:06\n",
            "loss: 0.5587, acc: 0.7648\n",
            "E2E-ABSA >>> 2024-06-03 16:08:35\n",
            ">>> val_acc: 0.7478, val_precision: 0.7267 val_recall: 0.7478, val_f1: 0.7149\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7478\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 16:09:01\n",
            "loss: 0.4500, acc: 0.8108\n",
            "E2E-ABSA >>> 2024-06-03 16:09:36\n",
            "loss: 0.4650, acc: 0.8038\n",
            "E2E-ABSA >>> 2024-06-03 16:09:56\n",
            ">>> val_acc: 0.7627, val_precision: 0.7447 val_recall: 0.7627, val_f1: 0.7415\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7627\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 16:10:34\n",
            "loss: 0.3146, acc: 0.8704\n",
            "E2E-ABSA >>> 2024-06-03 16:11:21\n",
            ">>> val_acc: 0.7698, val_precision: 0.7796 val_recall: 0.7698, val_f1: 0.7725\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7698\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 16:11:32\n",
            "loss: 0.2338, acc: 0.9094\n",
            "E2E-ABSA >>> 2024-06-03 16:12:07\n",
            "loss: 0.2679, acc: 0.9021\n",
            "E2E-ABSA >>> 2024-06-03 16:12:46\n",
            ">>> val_acc: 0.7702, val_precision: 0.7782 val_recall: 0.7702, val_f1: 0.7720\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 16:13:01\n",
            "loss: 0.2210, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-03 16:13:36\n",
            "loss: 0.2388, acc: 0.9115\n",
            "E2E-ABSA >>> 2024-06-03 16:14:06\n",
            ">>> val_acc: 0.7680, val_precision: 0.7568 val_recall: 0.7680, val_f1: 0.7606\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 16:14:30\n",
            "loss: 0.1909, acc: 0.9292\n",
            "E2E-ABSA >>> 2024-06-03 16:15:04\n",
            "loss: 0.2257, acc: 0.9163\n",
            "E2E-ABSA >>> 2024-06-03 16:15:26\n",
            ">>> val_acc: 0.7769, val_precision: 0.7670 val_recall: 0.7769, val_f1: 0.7662\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 16:15:58\n",
            "loss: 0.1540, acc: 0.9450\n",
            "E2E-ABSA >>> 2024-06-03 16:16:46\n",
            ">>> val_acc: 0.7741, val_precision: 0.7814 val_recall: 0.7741, val_f1: 0.7768\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7741\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 16:16:53\n",
            "loss: 0.1602, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 16:17:28\n",
            "loss: 0.1727, acc: 0.9353\n",
            "E2E-ABSA >>> 2024-06-03 16:18:08\n",
            ">>> val_acc: 0.7631, val_precision: 0.7832 val_recall: 0.7631, val_f1: 0.7678\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 16:18:22\n",
            "loss: 0.1447, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 16:18:56\n",
            "loss: 0.1718, acc: 0.9393\n",
            "E2E-ABSA >>> 2024-06-03 16:19:28\n",
            ">>> val_acc: 0.7435, val_precision: 0.7768 val_recall: 0.7435, val_f1: 0.7544\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 16:19:50\n",
            "loss: 0.1425, acc: 0.9521\n",
            "E2E-ABSA >>> 2024-06-03 16:20:25\n",
            "loss: 0.1857, acc: 0.9303\n",
            "E2E-ABSA >>> 2024-06-03 16:20:48\n",
            ">>> val_acc: 0.7677, val_precision: 0.7705 val_recall: 0.7677, val_f1: 0.7686\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 16:21:18\n",
            "loss: 0.1573, acc: 0.9418\n",
            "E2E-ABSA >>> 2024-06-03 16:22:08\n",
            ">>> val_acc: 0.7584, val_precision: 0.7616 val_recall: 0.7584, val_f1: 0.7486\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 16:22:12\n",
            "loss: 0.1582, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 16:22:47\n",
            "loss: 0.1673, acc: 0.9364\n",
            "E2E-ABSA >>> 2024-06-03 16:23:28\n",
            ">>> val_acc: 0.7591, val_precision: 0.7598 val_recall: 0.7591, val_f1: 0.7594\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 16:23:41\n",
            "loss: 0.1401, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-03 16:24:16\n",
            "loss: 0.1609, acc: 0.9458\n",
            "E2E-ABSA >>> 2024-06-03 16:24:48\n",
            ">>> val_acc: 0.7584, val_precision: 0.7416 val_recall: 0.7584, val_f1: 0.7393\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 16:25:09\n",
            "loss: 0.1475, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-03 16:25:44\n",
            "loss: 0.1767, acc: 0.9344\n",
            "E2E-ABSA >>> 2024-06-03 16:26:09\n",
            ">>> val_acc: 0.7194, val_precision: 0.7654 val_recall: 0.7194, val_f1: 0.7327\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 16:26:38\n",
            "loss: 0.1554, acc: 0.9420\n",
            "E2E-ABSA >>> 2024-06-03 16:27:29\n",
            ">>> val_acc: 0.7513, val_precision: 0.7736 val_recall: 0.7513, val_f1: 0.7583\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 16:27:31\n",
            "loss: 0.1257, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-03 16:28:06\n",
            "loss: 0.1911, acc: 0.9242\n",
            "E2E-ABSA >>> 2024-06-03 16:28:49\n",
            ">>> val_acc: 0.7311, val_precision: 0.7627 val_recall: 0.7311, val_f1: 0.7394\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 16:29:00\n",
            "loss: 0.1305, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-06-03 16:29:35\n",
            "loss: 0.1605, acc: 0.9356\n",
            "E2E-ABSA >>> 2024-06-03 16:30:09\n",
            ">>> val_acc: 0.7371, val_precision: 0.7525 val_recall: 0.7371, val_f1: 0.7403\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 16:30:28\n",
            "loss: 0.1477, acc: 0.9431\n",
            "E2E-ABSA >>> 2024-06-03 16:31:03\n",
            "loss: 0.1565, acc: 0.9399\n",
            "E2E-ABSA >>> 2024-06-03 16:31:29\n",
            ">>> val_acc: 0.7638, val_precision: 0.7492 val_recall: 0.7638, val_f1: 0.7499\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 16:31:57\n",
            "loss: 0.1891, acc: 0.9352\n",
            "E2E-ABSA >>> 2024-06-03 16:32:49\n",
            ">>> val_acc: 0.7574, val_precision: 0.7509 val_recall: 0.7574, val_f1: 0.7509\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 16:32:50\n",
            "loss: 0.0478, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-03 16:33:25\n",
            "loss: 0.1568, acc: 0.9423\n",
            "E2E-ABSA >>> 2024-06-03 16:34:09\n",
            ">>> val_acc: 0.7453, val_precision: 0.7290 val_recall: 0.7453, val_f1: 0.7312\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 16:34:19\n",
            "loss: 0.1584, acc: 0.9442\n",
            "E2E-ABSA >>> 2024-06-03 16:34:53\n",
            "loss: 0.1783, acc: 0.9326\n",
            "E2E-ABSA >>> 2024-06-03 16:35:29\n",
            ">>> val_acc: 0.7545, val_precision: 0.7471 val_recall: 0.7545, val_f1: 0.7495\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 16:35:47\n",
            "loss: 0.1741, acc: 0.9327\n",
            "E2E-ABSA >>> 2024-06-03 16:36:22\n",
            "loss: 0.1753, acc: 0.9350\n",
            "E2E-ABSA >>> 2024-06-03 16:36:49\n",
            ">>> val_acc: 0.7432, val_precision: 0.7285 val_recall: 0.7432, val_f1: 0.7285\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-03 16:37:16\n",
            "loss: 0.1717, acc: 0.9367\n",
            "E2E-ABSA >>> 2024-06-03 16:37:50\n",
            "loss: 0.1780, acc: 0.9304\n",
            "E2E-ABSA >>> 2024-06-03 16:38:10\n",
            ">>> val_acc: 0.7453, val_precision: 0.7326 val_recall: 0.7453, val_f1: 0.7338\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-03 16:38:44\n",
            "loss: 0.1600, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-03 16:39:30\n",
            ">>> val_acc: 0.7453, val_precision: 0.7482 val_recall: 0.7453, val_f1: 0.7465\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-03 16:39:38\n",
            "loss: 0.1527, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-03 16:40:12\n",
            "loss: 0.1580, acc: 0.9390\n",
            "E2E-ABSA >>> 2024-06-03 16:40:50\n",
            ">>> val_acc: 0.7453, val_precision: 0.7370 val_recall: 0.7453, val_f1: 0.7401\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-03 16:41:06\n",
            "loss: 0.1752, acc: 0.9401\n",
            "E2E-ABSA >>> 2024-06-03 16:41:41\n",
            "loss: 0.1483, acc: 0.9481\n",
            "E2E-ABSA >>> 2024-06-03 16:42:10\n",
            ">>> val_acc: 0.7478, val_precision: 0.7382 val_recall: 0.7478, val_f1: 0.7413\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-03 16:42:35\n",
            "loss: 0.1274, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-06-03 16:43:09\n",
            "loss: 0.1615, acc: 0.9397\n",
            "E2E-ABSA >>> 2024-06-03 16:43:30\n",
            ">>> val_acc: 0.7332, val_precision: 0.7443 val_recall: 0.7332, val_f1: 0.7379\n",
            "E2E-ABSA >>> 2024-06-03 16:43:30\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7741, val_precision: 0.7814 val_recall: 0.7741, val_f1: 0.7768\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.7741\n",
            ">>> test_acc: 0.7403, test_precision: 0.7386, test_recall: 0.7403, test_f1: 0.7391\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "GDo-ximzsFPZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1aJBtaPzN_W"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s3 concat"
      ],
      "id": "N1aJBtaPzN_W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "hChLfPm8zN_c",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "0f3458fe-c3bd-49fe-842a-8d49e97e7196",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100%|██████████████████| 42.0/42.0 [00:00<00:00, 316kB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████| 1.01k/1.01k [00:00<00:00, 4.07MB/s]\n",
            "vocab.txt: 100%|█████████████████████████████| 234k/234k [00:00<00:00, 3.81MB/s]\n",
            "added_tokens.json: 100%|█████████████████████| 2.00/2.00 [00:00<00:00, 17.1kB/s]\n",
            "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 955kB/s]\n",
            "pytorch_model.bin: 100%|█████████████████████| 445M/445M [00:05<00:00, 80.7MB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f647e92f640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/e_raw_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/e_raw_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-06-04 07:44:29\n",
            "loss: 0.8688, acc: 0.6419\n",
            "E2E-ABSA >>> 2024-06-04 07:44:40\n",
            ">>> val_acc: 0.6917, val_precision: 0.6944 val_recall: 0.6917, val_f1: 0.6544\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6917\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 07:44:42\n",
            "loss: 0.7837, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-04 07:44:51\n",
            "loss: 0.7147, acc: 0.7107\n",
            "E2E-ABSA >>> 2024-06-04 07:45:00\n",
            ">>> val_acc: 0.7659, val_precision: 0.7544 val_recall: 0.7659, val_f1: 0.7513\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7659\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 07:45:04\n",
            "loss: 0.4863, acc: 0.8008\n",
            "E2E-ABSA >>> 2024-06-04 07:45:13\n",
            "loss: 0.5156, acc: 0.7914\n",
            "E2E-ABSA >>> 2024-06-04 07:45:20\n",
            ">>> val_acc: 0.7645, val_precision: 0.7464 val_recall: 0.7645, val_f1: 0.7284\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 07:45:26\n",
            "loss: 0.3802, acc: 0.8446\n",
            "E2E-ABSA >>> 2024-06-04 07:45:34\n",
            "loss: 0.4031, acc: 0.8368\n",
            "E2E-ABSA >>> 2024-06-04 07:45:39\n",
            ">>> val_acc: 0.7829, val_precision: 0.7692 val_recall: 0.7829, val_f1: 0.7724\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7829\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 07:45:48\n",
            "loss: 0.2539, acc: 0.8997\n",
            "E2E-ABSA >>> 2024-06-04 07:45:59\n",
            ">>> val_acc: 0.7748, val_precision: 0.7819 val_recall: 0.7748, val_f1: 0.7765\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7748\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 07:46:01\n",
            "loss: 0.1992, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 07:46:10\n",
            "loss: 0.2273, acc: 0.9229\n",
            "E2E-ABSA >>> 2024-06-04 07:46:19\n",
            ">>> val_acc: 0.7325, val_precision: 0.7857 val_recall: 0.7325, val_f1: 0.7479\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 07:46:23\n",
            "loss: 0.2120, acc: 0.9290\n",
            "E2E-ABSA >>> 2024-06-04 07:46:31\n",
            "loss: 0.2067, acc: 0.9240\n",
            "E2E-ABSA >>> 2024-06-04 07:46:39\n",
            ">>> val_acc: 0.7694, val_precision: 0.7757 val_recall: 0.7694, val_f1: 0.7704\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 07:46:44\n",
            "loss: 0.1683, acc: 0.9357\n",
            "E2E-ABSA >>> 2024-06-04 07:46:53\n",
            "loss: 0.1752, acc: 0.9330\n",
            "E2E-ABSA >>> 2024-06-04 07:46:58\n",
            ">>> val_acc: 0.7648, val_precision: 0.7746 val_recall: 0.7648, val_f1: 0.7690\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 07:47:06\n",
            "loss: 0.1454, acc: 0.9490\n",
            "E2E-ABSA >>> 2024-06-04 07:47:18\n",
            ">>> val_acc: 0.7826, val_precision: 0.7799 val_recall: 0.7826, val_f1: 0.7811\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7826\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 07:47:20\n",
            "loss: 0.1297, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 07:47:28\n",
            "loss: 0.1647, acc: 0.9397\n",
            "E2E-ABSA >>> 2024-06-04 07:47:38\n",
            ">>> val_acc: 0.7805, val_precision: 0.7813 val_recall: 0.7805, val_f1: 0.7808\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 07:47:41\n",
            "loss: 0.1306, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-06-04 07:47:50\n",
            "loss: 0.1709, acc: 0.9393\n",
            "E2E-ABSA >>> 2024-06-04 07:47:57\n",
            ">>> val_acc: 0.7652, val_precision: 0.7689 val_recall: 0.7652, val_f1: 0.7666\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 07:48:03\n",
            "loss: 0.1189, acc: 0.9580\n",
            "E2E-ABSA >>> 2024-06-04 07:48:11\n",
            "loss: 0.1507, acc: 0.9466\n",
            "E2E-ABSA >>> 2024-06-04 07:48:17\n",
            ">>> val_acc: 0.7702, val_precision: 0.7767 val_recall: 0.7702, val_f1: 0.7725\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 07:48:24\n",
            "loss: 0.1821, acc: 0.9304\n",
            "E2E-ABSA >>> 2024-06-04 07:48:36\n",
            ">>> val_acc: 0.7758, val_precision: 0.7718 val_recall: 0.7758, val_f1: 0.7736\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 07:48:37\n",
            "loss: 0.0998, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-04 07:48:46\n",
            "loss: 0.1690, acc: 0.9408\n",
            "E2E-ABSA >>> 2024-06-04 07:48:56\n",
            ">>> val_acc: 0.7730, val_precision: 0.7645 val_recall: 0.7730, val_f1: 0.7603\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 07:48:59\n",
            "loss: 0.1353, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-04 07:49:07\n",
            "loss: 0.1649, acc: 0.9366\n",
            "E2E-ABSA >>> 2024-06-04 07:49:15\n",
            ">>> val_acc: 0.7698, val_precision: 0.7630 val_recall: 0.7698, val_f1: 0.7630\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 07:49:20\n",
            "loss: 0.1182, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-06-04 07:49:29\n",
            "loss: 0.1623, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-06-04 07:49:35\n",
            ">>> val_acc: 0.7474, val_precision: 0.7624 val_recall: 0.7474, val_f1: 0.7534\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 07:49:42\n",
            "loss: 0.1518, acc: 0.9390\n",
            "E2E-ABSA >>> 2024-06-04 07:49:54\n",
            ">>> val_acc: 0.7435, val_precision: 0.7600 val_recall: 0.7435, val_f1: 0.7396\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 07:49:55\n",
            "loss: 0.2686, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-04 07:50:04\n",
            "loss: 0.2089, acc: 0.9225\n",
            "E2E-ABSA >>> 2024-06-04 07:50:14\n",
            ">>> val_acc: 0.7584, val_precision: 0.7707 val_recall: 0.7584, val_f1: 0.7630\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 07:50:17\n",
            "loss: 0.1456, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-04 07:50:25\n",
            "loss: 0.1551, acc: 0.9437\n",
            "E2E-ABSA >>> 2024-06-04 07:50:33\n",
            ">>> val_acc: 0.7648, val_precision: 0.7637 val_recall: 0.7648, val_f1: 0.7634\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 07:50:38\n",
            "loss: 0.1292, acc: 0.9498\n",
            "E2E-ABSA >>> 2024-06-04 07:50:47\n",
            "loss: 0.1676, acc: 0.9367\n",
            "E2E-ABSA >>> 2024-06-04 07:50:53\n",
            ">>> val_acc: 0.7577, val_precision: 0.7612 val_recall: 0.7577, val_f1: 0.7560\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 07:51:00\n",
            "loss: 0.1260, acc: 0.9508\n",
            "E2E-ABSA >>> 2024-06-04 07:51:12\n",
            ">>> val_acc: 0.7410, val_precision: 0.7556 val_recall: 0.7410, val_f1: 0.7468\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 07:51:13\n",
            "loss: 0.2580, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-04 07:51:21\n",
            "loss: 0.1688, acc: 0.9369\n",
            "E2E-ABSA >>> 2024-06-04 07:51:32\n",
            ">>> val_acc: 0.7456, val_precision: 0.7345 val_recall: 0.7456, val_f1: 0.7344\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 07:51:34\n",
            "loss: 0.1498, acc: 0.9263\n",
            "E2E-ABSA >>> 2024-06-04 07:51:43\n",
            "loss: 0.1447, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-06-04 07:51:52\n",
            ">>> val_acc: 0.7123, val_precision: 0.7545 val_recall: 0.7123, val_f1: 0.7242\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 07:51:56\n",
            "loss: 0.1727, acc: 0.9231\n",
            "E2E-ABSA >>> 2024-06-04 07:52:04\n",
            "loss: 0.1927, acc: 0.9252\n",
            "E2E-ABSA >>> 2024-06-04 07:52:11\n",
            ">>> val_acc: 0.7627, val_precision: 0.7470 val_recall: 0.7627, val_f1: 0.7514\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 07:52:17\n",
            "loss: 0.1214, acc: 0.9556\n",
            "E2E-ABSA >>> 2024-06-04 07:52:26\n",
            "loss: 0.1399, acc: 0.9492\n",
            "E2E-ABSA >>> 2024-06-04 07:52:31\n",
            ">>> val_acc: 0.7400, val_precision: 0.7186 val_recall: 0.7400, val_f1: 0.7094\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 07:52:39\n",
            "loss: 0.1647, acc: 0.9444\n",
            "E2E-ABSA >>> 2024-06-04 07:52:50\n",
            ">>> val_acc: 0.7385, val_precision: 0.7495 val_recall: 0.7385, val_f1: 0.7426\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 07:52:52\n",
            "loss: 0.1576, acc: 0.9349\n",
            "E2E-ABSA >>> 2024-06-04 07:53:01\n",
            "loss: 0.1506, acc: 0.9385\n",
            "E2E-ABSA >>> 2024-06-04 07:53:10\n",
            ">>> val_acc: 0.7400, val_precision: 0.7244 val_recall: 0.7400, val_f1: 0.7256\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 07:53:14\n",
            "loss: 0.1664, acc: 0.9388\n",
            "E2E-ABSA >>> 2024-06-04 07:53:22\n",
            "loss: 0.1635, acc: 0.9417\n",
            "E2E-ABSA >>> 2024-06-04 07:53:29\n",
            ">>> val_acc: 0.7318, val_precision: 0.7453 val_recall: 0.7318, val_f1: 0.7358\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 07:53:35\n",
            "loss: 0.1222, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-04 07:53:44\n",
            "loss: 0.1477, acc: 0.9466\n",
            "E2E-ABSA >>> 2024-06-04 07:53:49\n",
            ">>> val_acc: 0.7194, val_precision: 0.7412 val_recall: 0.7194, val_f1: 0.7231\n",
            "E2E-ABSA >>> 2024-06-04 07:53:49\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7826, val_precision: 0.7799 val_recall: 0.7826, val_f1: 0.7811\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.7826\n",
            ">>> test_acc: 0.7716, test_precision: 0.7625, test_recall: 0.7716, test_f1: 0.7658\n"
          ]
        }
      ],
      "source": [
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "hChLfPm8zN_c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12c5fc89-de88-4e24-a35c-b3a2c7a7e19b"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s4 concat"
      ],
      "id": "12c5fc89-de88-4e24-a35c-b3a2c7a7e19b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dXsxL-COrslZ",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5e37bf57-e850-4fe0-e07c-247a97aa7cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5532.\n",
            "> testing dataset count: 1135.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7be2a942a290>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_padanan/b_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_padanan/b_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-27 15:46:08\n",
            "loss: 0.8169, acc: 0.6869\n",
            "E2E-ABSA >>> 2024-05-27 15:46:46\n",
            "loss: 0.8037, acc: 0.6831\n",
            "E2E-ABSA >>> 2024-05-27 15:47:23\n",
            "loss: 0.7772, acc: 0.6865\n",
            "E2E-ABSA >>> 2024-05-27 15:47:49\n",
            ">>> val_acc: 0.6775, val_precision: 0.6870 val_recall: 0.6775, val_f1: 0.5837\n",
            ">> saved: state_dict/bert_spc_padanan_know_val_f1_0.6775\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-27 15:48:10\n",
            "loss: 0.6880, acc: 0.6991\n",
            "E2E-ABSA >>> 2024-05-27 15:48:48\n",
            "loss: 0.6459, acc: 0.7252\n",
            "E2E-ABSA >>> 2024-05-27 15:49:25\n",
            "loss: 0.6472, acc: 0.7279\n",
            "E2E-ABSA >>> 2024-05-27 15:50:08\n",
            ">>> val_acc: 0.7207, val_precision: 0.7338 val_recall: 0.7207, val_f1: 0.7135\n",
            ">> saved: state_dict/bert_spc_padanan_know_val_f1_0.7207\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-27 15:50:13\n",
            "loss: 0.4320, acc: 0.8359\n",
            "E2E-ABSA >>> 2024-05-27 15:50:50\n",
            "loss: 0.5093, acc: 0.7940\n",
            "E2E-ABSA >>> 2024-05-27 15:51:28\n",
            "loss: 0.5259, acc: 0.7816\n",
            "E2E-ABSA >>> 2024-05-27 15:52:05\n",
            "loss: 0.5362, acc: 0.7752\n",
            "E2E-ABSA >>> 2024-05-27 15:52:28\n",
            ">>> val_acc: 0.7524, val_precision: 0.7451 val_recall: 0.7524, val_f1: 0.7464\n",
            ">> saved: state_dict/bert_spc_padanan_know_val_f1_0.7524\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-27 15:52:54\n",
            "loss: 0.4525, acc: 0.8135\n",
            "E2E-ABSA >>> 2024-05-27 15:53:32\n",
            "loss: 0.4418, acc: 0.8175\n",
            "E2E-ABSA >>> 2024-05-27 15:54:09\n",
            "loss: 0.4580, acc: 0.8092\n",
            "E2E-ABSA >>> 2024-05-27 15:54:49\n",
            ">>> val_acc: 0.7269, val_precision: 0.7200 val_recall: 0.7269, val_f1: 0.6974\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-27 15:54:55\n",
            "loss: 0.4071, acc: 0.8398\n",
            "E2E-ABSA >>> 2024-05-27 15:55:32\n",
            "loss: 0.4038, acc: 0.8357\n",
            "E2E-ABSA >>> 2024-05-27 15:56:10\n",
            "loss: 0.4239, acc: 0.8278\n",
            "E2E-ABSA >>> 2024-05-27 15:56:47\n",
            "loss: 0.4327, acc: 0.8279\n",
            "E2E-ABSA >>> 2024-05-27 15:57:07\n",
            ">>> val_acc: 0.7348, val_precision: 0.7240 val_recall: 0.7348, val_f1: 0.7267\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-27 15:57:33\n",
            "loss: 0.3261, acc: 0.8696\n",
            "E2E-ABSA >>> 2024-05-27 15:58:11\n",
            "loss: 0.3490, acc: 0.8603\n",
            "E2E-ABSA >>> 2024-05-27 15:58:48\n",
            "loss: 0.3769, acc: 0.8461\n",
            "E2E-ABSA >>> 2024-05-27 15:59:25\n",
            ">>> val_acc: 0.7313, val_precision: 0.7229 val_recall: 0.7313, val_f1: 0.7214\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-27 15:59:34\n",
            "loss: 0.3325, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-05-27 16:00:11\n",
            "loss: 0.3293, acc: 0.8649\n",
            "E2E-ABSA >>> 2024-05-27 16:00:49\n",
            "loss: 0.3479, acc: 0.8599\n",
            "E2E-ABSA >>> 2024-05-27 16:01:26\n",
            "loss: 0.3684, acc: 0.8524\n",
            "E2E-ABSA >>> 2024-05-27 16:01:43\n",
            ">>> val_acc: 0.7304, val_precision: 0.7148 val_recall: 0.7304, val_f1: 0.6901\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-27 16:02:12\n",
            "loss: 0.2916, acc: 0.8798\n",
            "E2E-ABSA >>> 2024-05-27 16:02:49\n",
            "loss: 0.3134, acc: 0.8739\n",
            "E2E-ABSA >>> 2024-05-27 16:03:27\n",
            "loss: 0.3561, acc: 0.8563\n",
            "E2E-ABSA >>> 2024-05-27 16:04:01\n",
            ">>> val_acc: 0.7128, val_precision: 0.7289 val_recall: 0.7128, val_f1: 0.7190\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-27 16:04:13\n",
            "loss: 0.2878, acc: 0.8828\n",
            "E2E-ABSA >>> 2024-05-27 16:04:50\n",
            "loss: 0.3157, acc: 0.8741\n",
            "E2E-ABSA >>> 2024-05-27 16:05:27\n",
            "loss: 0.3351, acc: 0.8658\n",
            "E2E-ABSA >>> 2024-05-27 16:06:05\n",
            "loss: 0.3504, acc: 0.8605\n",
            "E2E-ABSA >>> 2024-05-27 16:06:19\n",
            ">>> val_acc: 0.7145, val_precision: 0.6966 val_recall: 0.7145, val_f1: 0.6831\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-27 16:06:51\n",
            "loss: 0.3038, acc: 0.8779\n",
            "E2E-ABSA >>> 2024-05-27 16:07:28\n",
            "loss: 0.3178, acc: 0.8726\n",
            "E2E-ABSA >>> 2024-05-27 16:08:06\n",
            "loss: 0.3379, acc: 0.8645\n",
            "E2E-ABSA >>> 2024-05-27 16:08:36\n",
            ">>> val_acc: 0.6978, val_precision: 0.6803 val_recall: 0.6978, val_f1: 0.6299\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-27 16:08:51\n",
            "loss: 0.3004, acc: 0.8859\n",
            "E2E-ABSA >>> 2024-05-27 16:09:29\n",
            "loss: 0.3372, acc: 0.8714\n",
            "E2E-ABSA >>> 2024-05-27 16:10:06\n",
            "loss: 0.3497, acc: 0.8654\n",
            "E2E-ABSA >>> 2024-05-27 16:10:44\n",
            "loss: 0.3517, acc: 0.8608\n",
            "E2E-ABSA >>> 2024-05-27 16:10:54\n",
            ">>> val_acc: 0.6987, val_precision: 0.6807 val_recall: 0.6987, val_f1: 0.6321\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-27 16:11:30\n",
            "loss: 0.3849, acc: 0.8444\n",
            "E2E-ABSA >>> 2024-05-27 16:12:07\n",
            "loss: 0.3656, acc: 0.8508\n",
            "E2E-ABSA >>> 2024-05-27 16:12:45\n",
            "loss: 0.3731, acc: 0.8467\n",
            "E2E-ABSA >>> 2024-05-27 16:13:13\n",
            ">>> val_acc: 0.7154, val_precision: 0.6946 val_recall: 0.7154, val_f1: 0.6938\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-27 16:13:31\n",
            "loss: 0.2763, acc: 0.8854\n",
            "E2E-ABSA >>> 2024-05-27 16:14:08\n",
            "loss: 0.3257, acc: 0.8687\n",
            "E2E-ABSA >>> 2024-05-27 16:14:45\n",
            "loss: 0.3242, acc: 0.8644\n",
            "E2E-ABSA >>> 2024-05-27 16:15:31\n",
            ">>> val_acc: 0.7119, val_precision: 0.6973 val_recall: 0.7119, val_f1: 0.7013\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-27 16:15:31\n",
            "loss: 0.3574, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-05-27 16:16:09\n",
            "loss: 0.2998, acc: 0.8879\n",
            "E2E-ABSA >>> 2024-05-27 16:16:46\n",
            "loss: 0.3203, acc: 0.8707\n",
            "E2E-ABSA >>> 2024-05-27 16:17:24\n",
            "loss: 0.3285, acc: 0.8665\n",
            "E2E-ABSA >>> 2024-05-27 16:17:49\n",
            ">>> val_acc: 0.6608, val_precision: 0.7142 val_recall: 0.6608, val_f1: 0.6678\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-27 16:18:10\n",
            "loss: 0.2853, acc: 0.8850\n",
            "E2E-ABSA >>> 2024-05-27 16:18:47\n",
            "loss: 0.3106, acc: 0.8774\n",
            "E2E-ABSA >>> 2024-05-27 16:19:24\n",
            "loss: 0.3284, acc: 0.8689\n",
            "E2E-ABSA >>> 2024-05-27 16:20:06\n",
            ">>> val_acc: 0.7145, val_precision: 0.6953 val_recall: 0.7145, val_f1: 0.6974\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-27 16:20:10\n",
            "loss: 0.3121, acc: 0.8875\n",
            "E2E-ABSA >>> 2024-05-27 16:20:48\n",
            "loss: 0.3081, acc: 0.8818\n",
            "E2E-ABSA >>> 2024-05-27 16:21:25\n",
            "loss: 0.3131, acc: 0.8768\n",
            "E2E-ABSA >>> 2024-05-27 16:22:02\n",
            "loss: 0.3314, acc: 0.8673\n",
            "E2E-ABSA >>> 2024-05-27 16:22:24\n",
            ">>> val_acc: 0.7145, val_precision: 0.7065 val_recall: 0.7145, val_f1: 0.7097\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-27 16:22:48\n",
            "loss: 0.2671, acc: 0.8984\n",
            "E2E-ABSA >>> 2024-05-27 16:23:26\n",
            "loss: 0.3061, acc: 0.8788\n",
            "E2E-ABSA >>> 2024-05-27 16:24:03\n",
            "loss: 0.3171, acc: 0.8767\n",
            "E2E-ABSA >>> 2024-05-27 16:24:42\n",
            ">>> val_acc: 0.7075, val_precision: 0.7022 val_recall: 0.7075, val_f1: 0.7027\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-27 16:24:49\n",
            "loss: 0.2554, acc: 0.8958\n",
            "E2E-ABSA >>> 2024-05-27 16:25:27\n",
            "loss: 0.3080, acc: 0.8782\n",
            "E2E-ABSA >>> 2024-05-27 16:26:04\n",
            "loss: 0.3064, acc: 0.8784\n",
            "E2E-ABSA >>> 2024-05-27 16:26:41\n",
            "loss: 0.3162, acc: 0.8738\n",
            "E2E-ABSA >>> 2024-05-27 16:27:00\n",
            ">>> val_acc: 0.6934, val_precision: 0.6704 val_recall: 0.6934, val_f1: 0.6747\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-27 16:27:27\n",
            "loss: 0.2841, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-05-27 16:28:04\n",
            "loss: 0.2954, acc: 0.8841\n",
            "E2E-ABSA >>> 2024-05-27 16:28:42\n",
            "loss: 0.3074, acc: 0.8807\n",
            "E2E-ABSA >>> 2024-05-27 16:29:18\n",
            ">>> val_acc: 0.6960, val_precision: 0.6836 val_recall: 0.6960, val_f1: 0.6877\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-27 16:29:28\n",
            "loss: 0.2620, acc: 0.9038\n",
            "E2E-ABSA >>> 2024-05-27 16:30:05\n",
            "loss: 0.2964, acc: 0.8810\n",
            "E2E-ABSA >>> 2024-05-27 16:30:43\n",
            "loss: 0.2923, acc: 0.8833\n",
            "E2E-ABSA >>> 2024-05-27 16:31:20\n",
            "loss: 0.3009, acc: 0.8786\n",
            "E2E-ABSA >>> 2024-05-27 16:31:36\n",
            ">>> val_acc: 0.6846, val_precision: 0.6677 val_recall: 0.6846, val_f1: 0.6682\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-27 16:32:06\n",
            "loss: 0.2737, acc: 0.8938\n",
            "E2E-ABSA >>> 2024-05-27 16:32:43\n",
            "loss: 0.3008, acc: 0.8788\n",
            "E2E-ABSA >>> 2024-05-27 16:33:21\n",
            "loss: 0.3049, acc: 0.8768\n",
            "E2E-ABSA >>> 2024-05-27 16:33:54\n",
            ">>> val_acc: 0.6819, val_precision: 0.6786 val_recall: 0.6819, val_f1: 0.6791\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-27 16:34:07\n",
            "loss: 0.2891, acc: 0.9007\n",
            "E2E-ABSA >>> 2024-05-27 16:34:44\n",
            "loss: 0.2589, acc: 0.9011\n",
            "E2E-ABSA >>> 2024-05-27 16:35:22\n",
            "loss: 0.2751, acc: 0.8937\n",
            "E2E-ABSA >>> 2024-05-27 16:35:59\n",
            "loss: 0.2897, acc: 0.8870\n",
            "E2E-ABSA >>> 2024-05-27 16:36:12\n",
            ">>> val_acc: 0.6802, val_precision: 0.6859 val_recall: 0.6802, val_f1: 0.6825\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-27 16:36:45\n",
            "loss: 0.2441, acc: 0.9119\n",
            "E2E-ABSA >>> 2024-05-27 16:37:23\n",
            "loss: 0.2678, acc: 0.8949\n",
            "E2E-ABSA >>> 2024-05-27 16:38:00\n",
            "loss: 0.2877, acc: 0.8863\n",
            "E2E-ABSA >>> 2024-05-27 16:38:30\n",
            ">>> val_acc: 0.6696, val_precision: 0.6672 val_recall: 0.6696, val_f1: 0.6654\n",
            "E2E-ABSA >>> 2024-05-27 16:38:30\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7524, val_precision: 0.7451 val_recall: 0.7524, val_f1: 0.7464\n",
            "you can download the best model from state_dict/bert_spc_padanan_know_val_f1_0.7524\n",
            ">>> test_acc: 0.7524, test_precision: 0.7451, test_recall: 0.7524, test_f1: 0.7464\n"
          ]
        }
      ],
      "source": [
        "# 27-5 experiment 2\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset padanan_know --pretrained_bert_name indolem/indobert-base-uncased --log_step 100"
      ],
      "id": "dXsxL-COrslZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d52c0a96-4002-4cce-aa88-eb1aed3a6003"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s5 concat"
      ],
      "id": "d52c0a96-4002-4cce-aa88-eb1aed3a6003"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b7d01638-f71d-43b7-9d52-42d092e217aa",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "570a66b4-5f0b-4704-bc58-01aaf676a378",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 1134.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: padanan_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f54a390f400>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_padanan/c_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_padanan/c_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-27 18:21:47\n",
            "loss: 0.8844, acc: 0.6481\n",
            "E2E-ABSA >>> 2024-05-27 18:22:05\n",
            "loss: 0.8234, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-05-27 18:22:23\n",
            "loss: 0.7956, acc: 0.6715\n",
            "E2E-ABSA >>> 2024-05-27 18:22:35\n",
            ">>> val_acc: 0.6984, val_precision: 0.6734 val_recall: 0.6984, val_f1: 0.6610\n",
            ">> saved: state_dict/bert_spc_padanan_trim_know_val_f1_0.6984\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-27 18:22:46\n",
            "loss: 0.6233, acc: 0.7315\n",
            "E2E-ABSA >>> 2024-05-27 18:23:04\n",
            "loss: 0.6121, acc: 0.7488\n",
            "E2E-ABSA >>> 2024-05-27 18:23:22\n",
            "loss: 0.6116, acc: 0.7470\n",
            "E2E-ABSA >>> 2024-05-27 18:23:43\n",
            ">>> val_acc: 0.7328, val_precision: 0.7208 val_recall: 0.7328, val_f1: 0.7040\n",
            ">> saved: state_dict/bert_spc_padanan_trim_know_val_f1_0.7328\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-27 18:23:45\n",
            "loss: 0.3937, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-05-27 18:24:03\n",
            "loss: 0.4721, acc: 0.7998\n",
            "E2E-ABSA >>> 2024-05-27 18:24:21\n",
            "loss: 0.4896, acc: 0.8017\n",
            "E2E-ABSA >>> 2024-05-27 18:24:39\n",
            "loss: 0.4869, acc: 0.8013\n",
            "E2E-ABSA >>> 2024-05-27 18:24:50\n",
            ">>> val_acc: 0.7337, val_precision: 0.7241 val_recall: 0.7337, val_f1: 0.7029\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-27 18:25:02\n",
            "loss: 0.4258, acc: 0.8276\n",
            "E2E-ABSA >>> 2024-05-27 18:25:20\n",
            "loss: 0.4105, acc: 0.8245\n",
            "E2E-ABSA >>> 2024-05-27 18:25:38\n",
            "loss: 0.4170, acc: 0.8228\n",
            "E2E-ABSA >>> 2024-05-27 18:25:57\n",
            ">>> val_acc: 0.7390, val_precision: 0.7388 val_recall: 0.7390, val_f1: 0.6911\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-27 18:26:00\n",
            "loss: 0.3771, acc: 0.8555\n",
            "E2E-ABSA >>> 2024-05-27 18:26:18\n",
            "loss: 0.3666, acc: 0.8545\n",
            "E2E-ABSA >>> 2024-05-27 18:26:37\n",
            "loss: 0.3625, acc: 0.8550\n",
            "E2E-ABSA >>> 2024-05-27 18:26:55\n",
            "loss: 0.3825, acc: 0.8455\n",
            "E2E-ABSA >>> 2024-05-27 18:27:04\n",
            ">>> val_acc: 0.7425, val_precision: 0.7334 val_recall: 0.7425, val_f1: 0.7012\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-27 18:27:17\n",
            "loss: 0.3552, acc: 0.8589\n",
            "E2E-ABSA >>> 2024-05-27 18:27:35\n",
            "loss: 0.3342, acc: 0.8618\n",
            "E2E-ABSA >>> 2024-05-27 18:27:53\n",
            "loss: 0.3512, acc: 0.8569\n",
            "E2E-ABSA >>> 2024-05-27 18:28:11\n",
            ">>> val_acc: 0.7601, val_precision: 0.7467 val_recall: 0.7601, val_f1: 0.7460\n",
            ">> saved: state_dict/bert_spc_padanan_trim_know_val_f1_0.7601\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-27 18:28:16\n",
            "loss: 0.3161, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-05-27 18:28:34\n",
            "loss: 0.3342, acc: 0.8659\n",
            "E2E-ABSA >>> 2024-05-27 18:28:53\n",
            "loss: 0.3316, acc: 0.8675\n",
            "E2E-ABSA >>> 2024-05-27 18:29:11\n",
            "loss: 0.3437, acc: 0.8584\n",
            "E2E-ABSA >>> 2024-05-27 18:29:19\n",
            ">>> val_acc: 0.7390, val_precision: 0.7421 val_recall: 0.7390, val_f1: 0.7231\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-27 18:29:33\n",
            "loss: 0.3028, acc: 0.8734\n",
            "E2E-ABSA >>> 2024-05-27 18:29:51\n",
            "loss: 0.3131, acc: 0.8778\n",
            "E2E-ABSA >>> 2024-05-27 18:30:09\n",
            "loss: 0.3341, acc: 0.8685\n",
            "E2E-ABSA >>> 2024-05-27 18:30:26\n",
            ">>> val_acc: 0.7504, val_precision: 0.7483 val_recall: 0.7504, val_f1: 0.7490\n",
            ">> saved: state_dict/bert_spc_padanan_trim_know_val_f1_0.7504\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-27 18:30:32\n",
            "loss: 0.3081, acc: 0.8730\n",
            "E2E-ABSA >>> 2024-05-27 18:30:50\n",
            "loss: 0.2800, acc: 0.8887\n",
            "E2E-ABSA >>> 2024-05-27 18:31:08\n",
            "loss: 0.3153, acc: 0.8755\n",
            "E2E-ABSA >>> 2024-05-27 18:31:27\n",
            "loss: 0.3258, acc: 0.8682\n",
            "E2E-ABSA >>> 2024-05-27 18:31:33\n",
            ">>> val_acc: 0.7319, val_precision: 0.7265 val_recall: 0.7319, val_f1: 0.7286\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-27 18:31:49\n",
            "loss: 0.2856, acc: 0.8895\n",
            "E2E-ABSA >>> 2024-05-27 18:32:07\n",
            "loss: 0.3015, acc: 0.8797\n",
            "E2E-ABSA >>> 2024-05-27 18:32:25\n",
            "loss: 0.3137, acc: 0.8767\n",
            "E2E-ABSA >>> 2024-05-27 18:32:40\n",
            ">>> val_acc: 0.7354, val_precision: 0.7162 val_recall: 0.7354, val_f1: 0.7066\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-27 18:32:48\n",
            "loss: 0.3449, acc: 0.8656\n",
            "E2E-ABSA >>> 2024-05-27 18:33:06\n",
            "loss: 0.3136, acc: 0.8723\n",
            "E2E-ABSA >>> 2024-05-27 18:33:24\n",
            "loss: 0.3081, acc: 0.8753\n",
            "E2E-ABSA >>> 2024-05-27 18:33:42\n",
            "loss: 0.3258, acc: 0.8682\n",
            "E2E-ABSA >>> 2024-05-27 18:33:47\n",
            ">>> val_acc: 0.7169, val_precision: 0.7431 val_recall: 0.7169, val_f1: 0.7252\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-27 18:34:04\n",
            "loss: 0.3183, acc: 0.8684\n",
            "E2E-ABSA >>> 2024-05-27 18:34:23\n",
            "loss: 0.3191, acc: 0.8676\n",
            "E2E-ABSA >>> 2024-05-27 18:34:41\n",
            "loss: 0.3349, acc: 0.8642\n",
            "E2E-ABSA >>> 2024-05-27 18:34:54\n",
            ">>> val_acc: 0.7222, val_precision: 0.7061 val_recall: 0.7222, val_f1: 0.6791\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-27 18:35:03\n",
            "loss: 0.3147, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-05-27 18:35:21\n",
            "loss: 0.3025, acc: 0.8737\n",
            "E2E-ABSA >>> 2024-05-27 18:35:39\n",
            "loss: 0.3257, acc: 0.8659\n",
            "E2E-ABSA >>> 2024-05-27 18:36:01\n",
            ">>> val_acc: 0.7108, val_precision: 0.6857 val_recall: 0.7108, val_f1: 0.6801\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-27 18:36:02\n",
            "loss: 0.2476, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-05-27 18:36:20\n",
            "loss: 0.2826, acc: 0.8854\n",
            "E2E-ABSA >>> 2024-05-27 18:36:38\n",
            "loss: 0.2989, acc: 0.8765\n",
            "E2E-ABSA >>> 2024-05-27 18:36:56\n",
            "loss: 0.3183, acc: 0.8669\n",
            "E2E-ABSA >>> 2024-05-27 18:37:08\n",
            ">>> val_acc: 0.6834, val_precision: 0.7077 val_recall: 0.6834, val_f1: 0.6836\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-27 18:37:19\n",
            "loss: 0.3562, acc: 0.8571\n",
            "E2E-ABSA >>> 2024-05-27 18:37:37\n",
            "loss: 0.3257, acc: 0.8642\n",
            "E2E-ABSA >>> 2024-05-27 18:37:55\n",
            "loss: 0.3198, acc: 0.8669\n",
            "E2E-ABSA >>> 2024-05-27 18:38:15\n",
            ">>> val_acc: 0.7178, val_precision: 0.7032 val_recall: 0.7178, val_f1: 0.6983\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-27 18:38:17\n",
            "loss: 0.1995, acc: 0.9313\n",
            "E2E-ABSA >>> 2024-05-27 18:38:35\n",
            "loss: 0.2970, acc: 0.8835\n",
            "E2E-ABSA >>> 2024-05-27 18:38:54\n",
            "loss: 0.3069, acc: 0.8807\n",
            "E2E-ABSA >>> 2024-05-27 18:39:12\n",
            "loss: 0.3072, acc: 0.8792\n",
            "E2E-ABSA >>> 2024-05-27 18:39:22\n",
            ">>> val_acc: 0.7002, val_precision: 0.6839 val_recall: 0.7002, val_f1: 0.6879\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-27 18:39:34\n",
            "loss: 0.2627, acc: 0.8975\n",
            "E2E-ABSA >>> 2024-05-27 18:39:52\n",
            "loss: 0.2985, acc: 0.8838\n",
            "E2E-ABSA >>> 2024-05-27 18:40:10\n",
            "loss: 0.3029, acc: 0.8776\n",
            "E2E-ABSA >>> 2024-05-27 18:40:29\n",
            ">>> val_acc: 0.7002, val_precision: 0.7101 val_recall: 0.7002, val_f1: 0.7038\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-27 18:40:33\n",
            "loss: 0.2229, acc: 0.9097\n",
            "E2E-ABSA >>> 2024-05-27 18:40:51\n",
            "loss: 0.2785, acc: 0.8861\n",
            "E2E-ABSA >>> 2024-05-27 18:41:09\n",
            "loss: 0.2919, acc: 0.8850\n",
            "E2E-ABSA >>> 2024-05-27 18:41:27\n",
            "loss: 0.3060, acc: 0.8813\n",
            "E2E-ABSA >>> 2024-05-27 18:41:36\n",
            ">>> val_acc: 0.6808, val_precision: 0.6940 val_recall: 0.6808, val_f1: 0.6847\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-27 18:41:50\n",
            "loss: 0.2828, acc: 0.8941\n",
            "E2E-ABSA >>> 2024-05-27 18:42:08\n",
            "loss: 0.2943, acc: 0.8859\n",
            "E2E-ABSA >>> 2024-05-27 18:42:26\n",
            "loss: 0.2962, acc: 0.8837\n",
            "E2E-ABSA >>> 2024-05-27 18:42:43\n",
            ">>> val_acc: 0.7028, val_precision: 0.6811 val_recall: 0.7028, val_f1: 0.6793\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-27 18:42:48\n",
            "loss: 0.2596, acc: 0.8966\n",
            "E2E-ABSA >>> 2024-05-27 18:43:06\n",
            "loss: 0.2544, acc: 0.8948\n",
            "E2E-ABSA >>> 2024-05-27 18:43:25\n",
            "loss: 0.2659, acc: 0.8955\n",
            "E2E-ABSA >>> 2024-05-27 18:43:43\n",
            "loss: 0.2831, acc: 0.8865\n",
            "E2E-ABSA >>> 2024-05-27 18:43:51\n",
            ">>> val_acc: 0.7002, val_precision: 0.6732 val_recall: 0.7002, val_f1: 0.6693\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-27 18:44:05\n",
            "loss: 0.2321, acc: 0.9133\n",
            "E2E-ABSA >>> 2024-05-27 18:44:23\n",
            "loss: 0.2674, acc: 0.8962\n",
            "E2E-ABSA >>> 2024-05-27 18:44:41\n",
            "loss: 0.2891, acc: 0.8877\n",
            "E2E-ABSA >>> 2024-05-27 18:44:58\n",
            ">>> val_acc: 0.6772, val_precision: 0.6620 val_recall: 0.6772, val_f1: 0.6670\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-27 18:45:04\n",
            "loss: 0.2784, acc: 0.8971\n",
            "E2E-ABSA >>> 2024-05-27 18:45:22\n",
            "loss: 0.2914, acc: 0.8829\n",
            "E2E-ABSA >>> 2024-05-27 18:45:40\n",
            "loss: 0.2709, acc: 0.8953\n",
            "E2E-ABSA >>> 2024-05-27 18:45:58\n",
            "loss: 0.2797, acc: 0.8903\n",
            "E2E-ABSA >>> 2024-05-27 18:46:05\n",
            ">>> val_acc: 0.6684, val_precision: 0.6624 val_recall: 0.6684, val_f1: 0.6625\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-27 18:46:21\n",
            "loss: 0.2582, acc: 0.8999\n",
            "E2E-ABSA >>> 2024-05-27 18:46:39\n",
            "loss: 0.2690, acc: 0.8969\n",
            "E2E-ABSA >>> 2024-05-27 18:46:57\n",
            "loss: 0.2760, acc: 0.8921\n",
            "E2E-ABSA >>> 2024-05-27 18:47:12\n",
            ">>> val_acc: 0.6623, val_precision: 0.6836 val_recall: 0.6623, val_f1: 0.6432\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-27 18:47:19\n",
            "loss: 0.2813, acc: 0.9033\n",
            "E2E-ABSA >>> 2024-05-27 18:47:37\n",
            "loss: 0.2567, acc: 0.8983\n",
            "E2E-ABSA >>> 2024-05-27 18:47:56\n",
            "loss: 0.2790, acc: 0.8871\n",
            "E2E-ABSA >>> 2024-05-27 18:48:14\n",
            "loss: 0.2817, acc: 0.8861\n",
            "E2E-ABSA >>> 2024-05-27 18:48:19\n",
            ">>> val_acc: 0.6869, val_precision: 0.6684 val_recall: 0.6869, val_f1: 0.6744\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-27 18:48:36\n",
            "loss: 0.2746, acc: 0.8913\n",
            "E2E-ABSA >>> 2024-05-27 18:48:54\n",
            "loss: 0.2759, acc: 0.8916\n",
            "E2E-ABSA >>> 2024-05-27 18:49:13\n",
            "loss: 0.2773, acc: 0.8923\n",
            "E2E-ABSA >>> 2024-05-27 18:49:26\n",
            ">>> val_acc: 0.6693, val_precision: 0.6637 val_recall: 0.6693, val_f1: 0.6622\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-27 18:49:35\n",
            "loss: 0.2542, acc: 0.8912\n",
            "E2E-ABSA >>> 2024-05-27 18:49:53\n",
            "loss: 0.2482, acc: 0.9017\n",
            "E2E-ABSA >>> 2024-05-27 18:50:11\n",
            "loss: 0.2641, acc: 0.8948\n",
            "E2E-ABSA >>> 2024-05-27 18:50:33\n",
            ">>> val_acc: 0.6781, val_precision: 0.6579 val_recall: 0.6781, val_f1: 0.6642\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-05-27 18:50:33\n",
            "loss: 0.0938, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-05-27 18:50:52\n",
            "loss: 0.2323, acc: 0.9087\n",
            "E2E-ABSA >>> 2024-05-27 18:51:10\n",
            "loss: 0.2450, acc: 0.9035\n",
            "E2E-ABSA >>> 2024-05-27 18:51:28\n",
            "loss: 0.2588, acc: 0.9021\n",
            "E2E-ABSA >>> 2024-05-27 18:51:40\n",
            ">>> val_acc: 0.6825, val_precision: 0.6543 val_recall: 0.6825, val_f1: 0.6319\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-05-27 18:51:50\n",
            "loss: 0.2282, acc: 0.9170\n",
            "E2E-ABSA >>> 2024-05-27 18:52:08\n",
            "loss: 0.2429, acc: 0.9090\n",
            "E2E-ABSA >>> 2024-05-27 18:52:27\n",
            "loss: 0.2477, acc: 0.9065\n",
            "E2E-ABSA >>> 2024-05-27 18:52:47\n",
            ">>> val_acc: 0.6887, val_precision: 0.6601 val_recall: 0.6887, val_f1: 0.6651\n",
            "E2E-ABSA >>> 2024-05-27 18:52:47\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7504, val_precision: 0.7483 val_recall: 0.7504, val_f1: 0.7490\n",
            "you can download the best model from state_dict/bert_spc_padanan_trim_know_val_f1_0.7504\n",
            ">>> test_acc: 0.7504, test_precision: 0.7483, test_recall: 0.7504, test_f1: 0.7490\n"
          ]
        }
      ],
      "source": [
        "# 27-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset padanan_trim_know --pretrained_bert_name indolem/indobert-base-uncased --log_step 100"
      ],
      "id": "b7d01638-f71d-43b7-9d52-42d092e217aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d9f7f83-9452-4bd9-9c7c-791781a6a718"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s6 concat"
      ],
      "id": "6d9f7f83-9452-4bd9-9c7c-791781a6a718"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cdf5a1b0-496f-4857-be8d-b4004c684251",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "0f3458fe-c3bd-49fe-842a-8d49e97e7196",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 1134.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: padanan_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f7c0a717400>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_padanan/d_selected_knowledge/train.tsv', 'test': './datasets/ulasan_padanan/d_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-27 19:05:48\n",
            "loss: 0.8996, acc: 0.6362\n",
            "E2E-ABSA >>> 2024-05-27 19:06:06\n",
            "loss: 0.8401, acc: 0.6559\n",
            "E2E-ABSA >>> 2024-05-27 19:06:25\n",
            "loss: 0.8121, acc: 0.6642\n",
            "E2E-ABSA >>> 2024-05-27 19:06:37\n",
            ">>> val_acc: 0.6834, val_precision: 0.6553 val_recall: 0.6834, val_f1: 0.6327\n",
            ">> saved: state_dict/bert_spc_padanan_select_know_val_f1_0.6834\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-27 19:06:47\n",
            "loss: 0.6502, acc: 0.7338\n",
            "E2E-ABSA >>> 2024-05-27 19:07:05\n",
            "loss: 0.6495, acc: 0.7334\n",
            "E2E-ABSA >>> 2024-05-27 19:07:24\n",
            "loss: 0.6375, acc: 0.7362\n",
            "E2E-ABSA >>> 2024-05-27 19:07:44\n",
            ">>> val_acc: 0.7293, val_precision: 0.7193 val_recall: 0.7293, val_f1: 0.7043\n",
            ">> saved: state_dict/bert_spc_padanan_select_know_val_f1_0.7293\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-27 19:07:46\n",
            "loss: 0.3917, acc: 0.8281\n",
            "E2E-ABSA >>> 2024-05-27 19:08:05\n",
            "loss: 0.4841, acc: 0.8003\n",
            "E2E-ABSA >>> 2024-05-27 19:08:23\n",
            "loss: 0.4885, acc: 0.7993\n",
            "E2E-ABSA >>> 2024-05-27 19:08:41\n",
            "loss: 0.4891, acc: 0.7989\n",
            "E2E-ABSA >>> 2024-05-27 19:08:52\n",
            ">>> val_acc: 0.7443, val_precision: 0.7331 val_recall: 0.7443, val_f1: 0.7025\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-27 19:09:03\n",
            "loss: 0.4345, acc: 0.8155\n",
            "E2E-ABSA >>> 2024-05-27 19:09:21\n",
            "loss: 0.4236, acc: 0.8218\n",
            "E2E-ABSA >>> 2024-05-27 19:09:40\n",
            "loss: 0.4202, acc: 0.8287\n",
            "E2E-ABSA >>> 2024-05-27 19:09:59\n",
            ">>> val_acc: 0.7399, val_precision: 0.7221 val_recall: 0.7399, val_f1: 0.7008\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-27 19:10:02\n",
            "loss: 0.3518, acc: 0.8555\n",
            "E2E-ABSA >>> 2024-05-27 19:10:20\n",
            "loss: 0.4214, acc: 0.8351\n",
            "E2E-ABSA >>> 2024-05-27 19:10:38\n",
            "loss: 0.3926, acc: 0.8411\n",
            "E2E-ABSA >>> 2024-05-27 19:10:57\n",
            "loss: 0.4008, acc: 0.8350\n",
            "E2E-ABSA >>> 2024-05-27 19:11:06\n",
            ">>> val_acc: 0.7610, val_precision: 0.7482 val_recall: 0.7610, val_f1: 0.7353\n",
            ">> saved: state_dict/bert_spc_padanan_select_know_val_f1_0.761\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-27 19:11:19\n",
            "loss: 0.3118, acc: 0.8929\n",
            "E2E-ABSA >>> 2024-05-27 19:11:37\n",
            "loss: 0.3089, acc: 0.8838\n",
            "E2E-ABSA >>> 2024-05-27 19:11:56\n",
            "loss: 0.3287, acc: 0.8708\n",
            "E2E-ABSA >>> 2024-05-27 19:12:13\n",
            ">>> val_acc: 0.7531, val_precision: 0.7389 val_recall: 0.7531, val_f1: 0.7257\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-27 19:12:18\n",
            "loss: 0.2876, acc: 0.8828\n",
            "E2E-ABSA >>> 2024-05-27 19:12:36\n",
            "loss: 0.3045, acc: 0.8735\n",
            "E2E-ABSA >>> 2024-05-27 19:12:54\n",
            "loss: 0.3145, acc: 0.8722\n",
            "E2E-ABSA >>> 2024-05-27 19:13:12\n",
            "loss: 0.3215, acc: 0.8709\n",
            "E2E-ABSA >>> 2024-05-27 19:13:21\n",
            ">>> val_acc: 0.7125, val_precision: 0.7512 val_recall: 0.7125, val_f1: 0.7066\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-27 19:13:35\n",
            "loss: 0.2910, acc: 0.8894\n",
            "E2E-ABSA >>> 2024-05-27 19:13:53\n",
            "loss: 0.2960, acc: 0.8855\n",
            "E2E-ABSA >>> 2024-05-27 19:14:11\n",
            "loss: 0.3163, acc: 0.8775\n",
            "E2E-ABSA >>> 2024-05-27 19:14:28\n",
            ">>> val_acc: 0.7540, val_precision: 0.7382 val_recall: 0.7540, val_f1: 0.7380\n",
            ">> saved: state_dict/bert_spc_padanan_select_know_val_f1_0.754\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-27 19:14:34\n",
            "loss: 0.3001, acc: 0.8691\n",
            "E2E-ABSA >>> 2024-05-27 19:14:52\n",
            "loss: 0.2640, acc: 0.8963\n",
            "E2E-ABSA >>> 2024-05-27 19:15:10\n",
            "loss: 0.3027, acc: 0.8815\n",
            "E2E-ABSA >>> 2024-05-27 19:15:28\n",
            "loss: 0.3093, acc: 0.8744\n",
            "E2E-ABSA >>> 2024-05-27 19:15:35\n",
            ">>> val_acc: 0.7222, val_precision: 0.7376 val_recall: 0.7222, val_f1: 0.7277\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-27 19:15:51\n",
            "loss: 0.2648, acc: 0.8932\n",
            "E2E-ABSA >>> 2024-05-27 19:16:09\n",
            "loss: 0.2910, acc: 0.8814\n",
            "E2E-ABSA >>> 2024-05-27 19:16:27\n",
            "loss: 0.2972, acc: 0.8805\n",
            "E2E-ABSA >>> 2024-05-27 19:16:42\n",
            ">>> val_acc: 0.7425, val_precision: 0.7308 val_recall: 0.7425, val_f1: 0.7318\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-27 19:16:49\n",
            "loss: 0.3159, acc: 0.8781\n",
            "E2E-ABSA >>> 2024-05-27 19:17:07\n",
            "loss: 0.2942, acc: 0.8826\n",
            "E2E-ABSA >>> 2024-05-27 19:17:26\n",
            "loss: 0.2958, acc: 0.8797\n",
            "E2E-ABSA >>> 2024-05-27 19:17:44\n",
            "loss: 0.3099, acc: 0.8737\n",
            "E2E-ABSA >>> 2024-05-27 19:17:49\n",
            ">>> val_acc: 0.7284, val_precision: 0.7401 val_recall: 0.7284, val_f1: 0.7317\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-27 19:18:06\n",
            "loss: 0.3143, acc: 0.8757\n",
            "E2E-ABSA >>> 2024-05-27 19:18:24\n",
            "loss: 0.3146, acc: 0.8734\n",
            "E2E-ABSA >>> 2024-05-27 19:18:43\n",
            "loss: 0.3284, acc: 0.8695\n",
            "E2E-ABSA >>> 2024-05-27 19:18:56\n",
            ">>> val_acc: 0.7249, val_precision: 0.7093 val_recall: 0.7249, val_f1: 0.6707\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-27 19:19:05\n",
            "loss: 0.3294, acc: 0.8802\n",
            "E2E-ABSA >>> 2024-05-27 19:19:23\n",
            "loss: 0.3136, acc: 0.8796\n",
            "E2E-ABSA >>> 2024-05-27 19:19:41\n",
            "loss: 0.3227, acc: 0.8735\n",
            "E2E-ABSA >>> 2024-05-27 19:20:03\n",
            ">>> val_acc: 0.7328, val_precision: 0.7112 val_recall: 0.7328, val_f1: 0.7045\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-27 19:20:03\n",
            "loss: 0.3084, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-05-27 19:20:22\n",
            "loss: 0.3034, acc: 0.8848\n",
            "E2E-ABSA >>> 2024-05-27 19:20:40\n",
            "loss: 0.3077, acc: 0.8790\n",
            "E2E-ABSA >>> 2024-05-27 19:20:58\n",
            "loss: 0.3249, acc: 0.8692\n",
            "E2E-ABSA >>> 2024-05-27 19:21:10\n",
            ">>> val_acc: 0.6958, val_precision: 0.6963 val_recall: 0.6958, val_f1: 0.6879\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-27 19:21:20\n",
            "loss: 0.3105, acc: 0.8717\n",
            "E2E-ABSA >>> 2024-05-27 19:21:38\n",
            "loss: 0.3140, acc: 0.8706\n",
            "E2E-ABSA >>> 2024-05-27 19:21:57\n",
            "loss: 0.3040, acc: 0.8760\n",
            "E2E-ABSA >>> 2024-05-27 19:22:17\n",
            ">>> val_acc: 0.7205, val_precision: 0.7039 val_recall: 0.7205, val_f1: 0.6948\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-27 19:22:19\n",
            "loss: 0.2492, acc: 0.8875\n",
            "E2E-ABSA >>> 2024-05-27 19:22:37\n",
            "loss: 0.2849, acc: 0.8875\n",
            "E2E-ABSA >>> 2024-05-27 19:22:55\n",
            "loss: 0.2940, acc: 0.8807\n",
            "E2E-ABSA >>> 2024-05-27 19:23:14\n",
            "loss: 0.2982, acc: 0.8778\n",
            "E2E-ABSA >>> 2024-05-27 19:23:24\n",
            ">>> val_acc: 0.7072, val_precision: 0.6849 val_recall: 0.7072, val_f1: 0.6827\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-27 19:23:36\n",
            "loss: 0.2719, acc: 0.8916\n",
            "E2E-ABSA >>> 2024-05-27 19:23:54\n",
            "loss: 0.2919, acc: 0.8857\n",
            "E2E-ABSA >>> 2024-05-27 19:24:12\n",
            "loss: 0.3027, acc: 0.8788\n",
            "E2E-ABSA >>> 2024-05-27 19:24:31\n",
            ">>> val_acc: 0.6922, val_precision: 0.7011 val_recall: 0.6922, val_f1: 0.6961\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-27 19:24:34\n",
            "loss: 0.2360, acc: 0.9201\n",
            "E2E-ABSA >>> 2024-05-27 19:24:53\n",
            "loss: 0.2807, acc: 0.8962\n",
            "E2E-ABSA >>> 2024-05-27 19:25:11\n",
            "loss: 0.2903, acc: 0.8882\n",
            "E2E-ABSA >>> 2024-05-27 19:25:29\n",
            "loss: 0.3004, acc: 0.8844\n",
            "E2E-ABSA >>> 2024-05-27 19:25:38\n",
            ">>> val_acc: 0.6949, val_precision: 0.7256 val_recall: 0.6949, val_f1: 0.7016\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-27 19:25:51\n",
            "loss: 0.2641, acc: 0.9002\n",
            "E2E-ABSA >>> 2024-05-27 19:26:09\n",
            "loss: 0.2758, acc: 0.8950\n",
            "E2E-ABSA >>> 2024-05-27 19:26:28\n",
            "loss: 0.2840, acc: 0.8913\n",
            "E2E-ABSA >>> 2024-05-27 19:26:45\n",
            ">>> val_acc: 0.6914, val_precision: 0.6627 val_recall: 0.6914, val_f1: 0.6543\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-27 19:26:50\n",
            "loss: 0.2821, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-05-27 19:27:08\n",
            "loss: 0.2665, acc: 0.8894\n",
            "E2E-ABSA >>> 2024-05-27 19:27:26\n",
            "loss: 0.2763, acc: 0.8883\n",
            "E2E-ABSA >>> 2024-05-27 19:27:45\n",
            "loss: 0.2878, acc: 0.8836\n",
            "E2E-ABSA >>> 2024-05-27 19:27:52\n",
            ">>> val_acc: 0.7116, val_precision: 0.6910 val_recall: 0.7116, val_f1: 0.6924\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-27 19:28:07\n",
            "loss: 0.2350, acc: 0.9117\n",
            "E2E-ABSA >>> 2024-05-27 19:28:25\n",
            "loss: 0.2507, acc: 0.9038\n",
            "E2E-ABSA >>> 2024-05-27 19:28:43\n",
            "loss: 0.2718, acc: 0.8924\n",
            "E2E-ABSA >>> 2024-05-27 19:28:59\n",
            ">>> val_acc: 0.6905, val_precision: 0.6724 val_recall: 0.6905, val_f1: 0.6740\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-27 19:29:05\n",
            "loss: 0.2533, acc: 0.8915\n",
            "E2E-ABSA >>> 2024-05-27 19:29:24\n",
            "loss: 0.2692, acc: 0.8941\n",
            "E2E-ABSA >>> 2024-05-27 19:29:42\n",
            "loss: 0.2685, acc: 0.8964\n",
            "E2E-ABSA >>> 2024-05-27 19:30:00\n",
            "loss: 0.2800, acc: 0.8896\n",
            "E2E-ABSA >>> 2024-05-27 19:30:06\n",
            ">>> val_acc: 0.7063, val_precision: 0.6827 val_recall: 0.7063, val_f1: 0.6789\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-27 19:30:22\n",
            "loss: 0.2577, acc: 0.9020\n",
            "E2E-ABSA >>> 2024-05-27 19:30:40\n",
            "loss: 0.2707, acc: 0.8969\n",
            "E2E-ABSA >>> 2024-05-27 19:30:59\n",
            "loss: 0.2747, acc: 0.8919\n",
            "E2E-ABSA >>> 2024-05-27 19:31:13\n",
            ">>> val_acc: 0.6578, val_precision: 0.6761 val_recall: 0.6578, val_f1: 0.6472\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-27 19:31:21\n",
            "loss: 0.2955, acc: 0.8810\n",
            "E2E-ABSA >>> 2024-05-27 19:31:39\n",
            "loss: 0.2659, acc: 0.8913\n",
            "E2E-ABSA >>> 2024-05-27 19:31:57\n",
            "loss: 0.2795, acc: 0.8882\n",
            "E2E-ABSA >>> 2024-05-27 19:32:15\n",
            "loss: 0.2764, acc: 0.8874\n",
            "E2E-ABSA >>> 2024-05-27 19:32:20\n",
            ">>> val_acc: 0.6799, val_precision: 0.6824 val_recall: 0.6799, val_f1: 0.6795\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-27 19:32:38\n",
            "loss: 0.2956, acc: 0.8828\n",
            "E2E-ABSA >>> 2024-05-27 19:32:56\n",
            "loss: 0.2859, acc: 0.8890\n",
            "E2E-ABSA >>> 2024-05-27 19:33:14\n",
            "loss: 0.2838, acc: 0.8898\n",
            "E2E-ABSA >>> 2024-05-27 19:33:27\n",
            ">>> val_acc: 0.7011, val_precision: 0.6904 val_recall: 0.7011, val_f1: 0.6932\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-27 19:33:36\n",
            "loss: 0.2307, acc: 0.9075\n",
            "E2E-ABSA >>> 2024-05-27 19:33:55\n",
            "loss: 0.2547, acc: 0.9000\n",
            "E2E-ABSA >>> 2024-05-27 19:34:13\n",
            "loss: 0.2654, acc: 0.8948\n",
            "E2E-ABSA >>> 2024-05-27 19:34:34\n",
            ">>> val_acc: 0.6966, val_precision: 0.6805 val_recall: 0.6966, val_f1: 0.6854\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-05-27 19:34:35\n",
            "loss: 0.1419, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-27 19:34:53\n",
            "loss: 0.2402, acc: 0.9069\n",
            "E2E-ABSA >>> 2024-05-27 19:35:11\n",
            "loss: 0.2425, acc: 0.9081\n",
            "E2E-ABSA >>> 2024-05-27 19:35:30\n",
            "loss: 0.2520, acc: 0.9046\n",
            "E2E-ABSA >>> 2024-05-27 19:35:41\n",
            ">>> val_acc: 0.6975, val_precision: 0.6740 val_recall: 0.6975, val_f1: 0.6778\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-05-27 19:35:52\n",
            "loss: 0.2222, acc: 0.9213\n",
            "E2E-ABSA >>> 2024-05-27 19:36:10\n",
            "loss: 0.2496, acc: 0.9047\n",
            "E2E-ABSA >>> 2024-05-27 19:36:28\n",
            "loss: 0.2644, acc: 0.8983\n",
            "E2E-ABSA >>> 2024-05-27 19:36:48\n",
            ">>> val_acc: 0.7011, val_precision: 0.6790 val_recall: 0.7011, val_f1: 0.6817\n",
            "E2E-ABSA >>> 2024-05-27 19:36:48\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7540, val_precision: 0.7382 val_recall: 0.7540, val_f1: 0.7380\n",
            "you can download the best model from state_dict/bert_spc_padanan_select_know_val_f1_0.754\n",
            ">>> test_acc: 0.7540, test_precision: 0.7382, test_recall: 0.7540, test_f1: 0.7380\n"
          ]
        }
      ],
      "source": [
        "# 27-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset padanan_select_know --pretrained_bert_name indolem/indobert-base-uncased --log_step 100"
      ],
      "id": "cdf5a1b0-496f-4857-be8d-b4004c684251"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mN5Z6dWZ0HE"
      },
      "source": [
        "## Indolem Insertion"
      ],
      "id": "_mN5Z6dWZ0HE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xzmZnZyqkXU"
      },
      "source": [
        "### **indolem/indobert-base-uncased** s1 insert"
      ],
      "id": "5xzmZnZyqkXU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UpQrIROBqnA1",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "be090bb9-e2f2-4789-ffca-f260fd6e091a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7abe922125f0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-06-03 15:20:31\n",
            "loss: 0.8678, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-06-03 15:21:14\n",
            ">>> val_acc: 0.7005, val_precision: 0.6788 val_recall: 0.7005, val_f1: 0.6511\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7005\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 15:21:23\n",
            "loss: 0.7651, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-03 15:21:57\n",
            "loss: 0.7531, acc: 0.6976\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-03 15:22:34\n",
            ">>> val_acc: 0.6874, val_precision: 0.6232 val_recall: 0.6874, val_f1: 0.5624\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 15:22:50\n",
            "loss: 0.8697, acc: 0.6667\n",
            "E2E-ABSA >>> 2024-06-03 15:23:25\n",
            "loss: 0.7916, acc: 0.6740\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-03 15:23:54\n",
            ">>> val_acc: 0.7023, val_precision: 0.5993 val_recall: 0.7023, val_f1: 0.6194\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 15:24:19\n",
            "loss: 0.7730, acc: 0.6771\n",
            "E2E-ABSA >>> 2024-06-03 15:24:53\n",
            "loss: 0.7804, acc: 0.6850\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-03 15:25:14\n",
            ">>> val_acc: 0.6988, val_precision: 0.6008 val_recall: 0.6988, val_f1: 0.6132\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 15:25:47\n",
            "loss: 0.6777, acc: 0.7181\n",
            "E2E-ABSA >>> 2024-06-03 15:26:34\n",
            ">>> val_acc: 0.7062, val_precision: 0.7380 val_recall: 0.7062, val_f1: 0.6961\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7062\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 15:26:42\n",
            "loss: 0.5992, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-06-03 15:27:17\n",
            "loss: 0.6106, acc: 0.7495\n",
            "E2E-ABSA >>> 2024-06-03 15:27:56\n",
            ">>> val_acc: 0.6739, val_precision: 0.7591 val_recall: 0.6739, val_f1: 0.6952\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 15:28:11\n",
            "loss: 0.4831, acc: 0.8068\n",
            "E2E-ABSA >>> 2024-06-03 15:28:46\n",
            "loss: 0.4986, acc: 0.7904\n",
            "E2E-ABSA >>> 2024-06-03 15:29:16\n",
            ">>> val_acc: 0.7520, val_precision: 0.7318 val_recall: 0.7520, val_f1: 0.7299\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.752\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 15:29:41\n",
            "loss: 0.4475, acc: 0.8364\n",
            "E2E-ABSA >>> 2024-06-03 15:30:15\n",
            "loss: 0.4450, acc: 0.8270\n",
            "E2E-ABSA >>> 2024-06-03 15:30:37\n",
            ">>> val_acc: 0.7677, val_precision: 0.7601 val_recall: 0.7677, val_f1: 0.7486\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7677\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 15:31:10\n",
            "loss: 0.3428, acc: 0.8668\n",
            "E2E-ABSA >>> 2024-06-03 15:31:59\n",
            ">>> val_acc: 0.7812, val_precision: 0.7680 val_recall: 0.7812, val_f1: 0.7673\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7812\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 15:32:06\n",
            "loss: 0.3498, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-03 15:32:40\n",
            "loss: 0.3431, acc: 0.8631\n",
            "E2E-ABSA >>> 2024-06-03 15:33:20\n",
            ">>> val_acc: 0.7684, val_precision: 0.7824 val_recall: 0.7684, val_f1: 0.7713\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7684\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 15:33:40\n",
            "loss: 0.2569, acc: 0.9047\n",
            "E2E-ABSA >>> 2024-06-03 15:34:15\n",
            "loss: 0.2768, acc: 0.8915\n",
            "E2E-ABSA >>> 2024-06-03 15:34:46\n",
            ">>> val_acc: 0.7698, val_precision: 0.7754 val_recall: 0.7698, val_f1: 0.7723\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7698\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 15:35:15\n",
            "loss: 0.2003, acc: 0.9248\n",
            "E2E-ABSA >>> 2024-06-03 15:35:50\n",
            "loss: 0.2733, acc: 0.8941\n",
            "E2E-ABSA >>> 2024-06-03 15:36:13\n",
            ">>> val_acc: 0.7705, val_precision: 0.7547 val_recall: 0.7705, val_f1: 0.7457\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 15:36:43\n",
            "loss: 0.2135, acc: 0.9254\n",
            "E2E-ABSA >>> 2024-06-03 15:37:33\n",
            ">>> val_acc: 0.7691, val_precision: 0.7555 val_recall: 0.7691, val_f1: 0.7413\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 15:37:37\n",
            "loss: 0.3061, acc: 0.8958\n",
            "E2E-ABSA >>> 2024-06-03 15:38:12\n",
            "loss: 0.2252, acc: 0.9152\n",
            "E2E-ABSA >>> 2024-06-03 15:38:53\n",
            ">>> val_acc: 0.7762, val_precision: 0.7620 val_recall: 0.7762, val_f1: 0.7651\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 15:39:06\n",
            "loss: 0.1381, acc: 0.9549\n",
            "E2E-ABSA >>> 2024-06-03 15:39:40\n",
            "loss: 0.1674, acc: 0.9416\n",
            "E2E-ABSA >>> 2024-06-03 15:40:13\n",
            ">>> val_acc: 0.7439, val_precision: 0.7666 val_recall: 0.7439, val_f1: 0.7524\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 15:40:34\n",
            "loss: 0.1345, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-03 15:41:09\n",
            "loss: 0.1542, acc: 0.9480\n",
            "E2E-ABSA >>> 2024-06-03 15:41:33\n",
            ">>> val_acc: 0.7712, val_precision: 0.7698 val_recall: 0.7712, val_f1: 0.7681\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 15:42:03\n",
            "loss: 0.1523, acc: 0.9435\n",
            "E2E-ABSA >>> 2024-06-03 15:42:54\n",
            ">>> val_acc: 0.7730, val_precision: 0.7685 val_recall: 0.7730, val_f1: 0.7704\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 15:42:56\n",
            "loss: 0.1569, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 15:43:31\n",
            "loss: 0.1419, acc: 0.9485\n",
            "E2E-ABSA >>> 2024-06-03 15:44:14\n",
            ">>> val_acc: 0.7432, val_precision: 0.7685 val_recall: 0.7432, val_f1: 0.7512\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 15:44:25\n",
            "loss: 0.1531, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-03 15:44:59\n",
            "loss: 0.1100, acc: 0.9645\n",
            "E2E-ABSA >>> 2024-06-03 15:45:34\n",
            ">>> val_acc: 0.7698, val_precision: 0.7626 val_recall: 0.7698, val_f1: 0.7649\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 15:45:53\n",
            "loss: 0.0951, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 15:46:28\n",
            "loss: 0.1319, acc: 0.9559\n",
            "E2E-ABSA >>> 2024-06-03 15:46:54\n",
            ">>> val_acc: 0.7609, val_precision: 0.7564 val_recall: 0.7609, val_f1: 0.7321\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 15:47:22\n",
            "loss: 0.1269, acc: 0.9555\n",
            "E2E-ABSA >>> 2024-06-03 15:48:14\n",
            ">>> val_acc: 0.7723, val_precision: 0.7672 val_recall: 0.7723, val_f1: 0.7692\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 15:48:15\n",
            "loss: 0.0234, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-03 15:48:50\n",
            "loss: 0.1416, acc: 0.9465\n",
            "E2E-ABSA >>> 2024-06-03 15:49:34\n",
            ">>> val_acc: 0.7716, val_precision: 0.7549 val_recall: 0.7716, val_f1: 0.7547\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 15:49:44\n",
            "loss: 0.1042, acc: 0.9710\n",
            "E2E-ABSA >>> 2024-06-03 15:50:18\n",
            "loss: 0.1251, acc: 0.9585\n",
            "E2E-ABSA >>> 2024-06-03 15:50:54\n",
            ">>> val_acc: 0.7531, val_precision: 0.7624 val_recall: 0.7531, val_f1: 0.7485\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 15:51:12\n",
            "loss: 0.1435, acc: 0.9543\n",
            "E2E-ABSA >>> 2024-06-03 15:51:47\n",
            "loss: 0.1515, acc: 0.9515\n",
            "E2E-ABSA >>> 2024-06-03 15:52:14\n",
            ">>> val_acc: 0.7723, val_precision: 0.7585 val_recall: 0.7723, val_f1: 0.7543\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-03 15:52:41\n",
            "loss: 0.1386, acc: 0.9515\n",
            "E2E-ABSA >>> 2024-06-03 15:53:15\n",
            "loss: 0.1446, acc: 0.9513\n",
            "E2E-ABSA >>> 2024-06-03 15:53:35\n",
            ">>> val_acc: 0.7680, val_precision: 0.7512 val_recall: 0.7680, val_f1: 0.7504\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-03 15:54:09\n",
            "loss: 0.1115, acc: 0.9619\n",
            "E2E-ABSA >>> 2024-06-03 15:54:55\n",
            ">>> val_acc: 0.7645, val_precision: 0.7518 val_recall: 0.7645, val_f1: 0.7446\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-03 15:55:03\n",
            "loss: 0.1045, acc: 0.9714\n",
            "E2E-ABSA >>> 2024-06-03 15:55:38\n",
            "loss: 0.1415, acc: 0.9491\n",
            "E2E-ABSA >>> 2024-06-03 15:56:15\n",
            ">>> val_acc: 0.7510, val_precision: 0.7359 val_recall: 0.7510, val_f1: 0.7336\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-03 15:56:31\n",
            "loss: 0.1176, acc: 0.9622\n",
            "E2E-ABSA >>> 2024-06-03 15:57:06\n",
            "loss: 0.1149, acc: 0.9624\n",
            "E2E-ABSA >>> 2024-06-03 15:57:35\n",
            ">>> val_acc: 0.7453, val_precision: 0.7459 val_recall: 0.7453, val_f1: 0.7414\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-03 15:58:00\n",
            "loss: 0.1103, acc: 0.9679\n",
            "E2E-ABSA >>> 2024-06-03 15:58:35\n",
            "loss: 0.1479, acc: 0.9477\n",
            "E2E-ABSA >>> 2024-06-03 15:58:55\n",
            ">>> val_acc: 0.7574, val_precision: 0.7383 val_recall: 0.7574, val_f1: 0.7308\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-03 15:59:28\n",
            "loss: 0.1239, acc: 0.9577\n",
            "E2E-ABSA >>> 2024-06-03 16:00:15\n",
            ">>> val_acc: 0.7648, val_precision: 0.7498 val_recall: 0.7648, val_f1: 0.7533\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-03 16:00:22\n",
            "loss: 0.0928, acc: 0.9781\n",
            "E2E-ABSA >>> 2024-06-03 16:00:57\n",
            "loss: 0.1160, acc: 0.9568\n",
            "E2E-ABSA >>> 2024-06-03 16:01:35\n",
            ">>> val_acc: 0.7421, val_precision: 0.7419 val_recall: 0.7421, val_f1: 0.7333\n",
            "E2E-ABSA >>> 2024-06-03 16:01:35\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7698, val_precision: 0.7754 val_recall: 0.7698, val_f1: 0.7723\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7698\n",
            ">>> test_acc: 0.7576, test_precision: 0.7546, test_recall: 0.7576, test_f1: 0.7559\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "UpQrIROBqnA1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE0V9_yPyi5G"
      },
      "source": [
        "### indolem/indobert-base-uncased s2 insert"
      ],
      "id": "dE0V9_yPyi5G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g7H9Arm-wZ02",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f3b34d87-6de4-4d00-a6d4-cbb9038c4e59",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x789b08202290>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-29 21:14:15\n",
            "loss: 0.8836, acc: 0.6319\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-05-29 21:15:01\n",
            ">>> val_acc: 0.6810, val_precision: 0.5785 val_recall: 0.6810, val_f1: 0.6184\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.681\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-29 21:15:17\n",
            "loss: 0.8365, acc: 0.6302\n",
            "E2E-ABSA >>> 2024-05-29 21:15:52\n",
            "loss: 0.7836, acc: 0.6699\n",
            "E2E-ABSA >>> 2024-05-29 21:16:31\n",
            ">>> val_acc: 0.7222, val_precision: 0.7314 val_recall: 0.7222, val_f1: 0.6885\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7222\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-29 21:16:50\n",
            "loss: 0.6313, acc: 0.7370\n",
            "E2E-ABSA >>> 2024-05-29 21:17:25\n",
            "loss: 0.6023, acc: 0.7411\n",
            "E2E-ABSA >>> 2024-05-29 21:17:56\n",
            ">>> val_acc: 0.7435, val_precision: 0.7351 val_recall: 0.7435, val_f1: 0.6950\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7435\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-29 21:18:23\n",
            "loss: 0.4727, acc: 0.8108\n",
            "E2E-ABSA >>> 2024-05-29 21:18:59\n",
            "loss: 0.4929, acc: 0.7983\n",
            "E2E-ABSA >>> 2024-05-29 21:19:20\n",
            ">>> val_acc: 0.7812, val_precision: 0.7646 val_recall: 0.7812, val_f1: 0.7659\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7812\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-29 21:20:01\n",
            "loss: 0.3525, acc: 0.8503\n",
            "E2E-ABSA >>> 2024-05-29 21:20:50\n",
            ">>> val_acc: 0.7421, val_precision: 0.7961 val_recall: 0.7421, val_f1: 0.7530\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-29 21:20:57\n",
            "loss: 0.2718, acc: 0.8938\n",
            "E2E-ABSA >>> 2024-05-29 21:21:33\n",
            "loss: 0.2681, acc: 0.8917\n",
            "E2E-ABSA >>> 2024-05-29 21:22:13\n",
            ">>> val_acc: 0.7698, val_precision: 0.7924 val_recall: 0.7698, val_f1: 0.7774\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7698\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-29 21:22:36\n",
            "loss: 0.2112, acc: 0.9162\n",
            "E2E-ABSA >>> 2024-05-29 21:23:12\n",
            "loss: 0.2211, acc: 0.9128\n",
            "E2E-ABSA >>> 2024-05-29 21:23:44\n",
            ">>> val_acc: 0.7890, val_precision: 0.7828 val_recall: 0.7890, val_f1: 0.7853\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.789\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-29 21:24:15\n",
            "loss: 0.1748, acc: 0.9311\n",
            "E2E-ABSA >>> 2024-05-29 21:24:51\n",
            "loss: 0.1777, acc: 0.9323\n",
            "E2E-ABSA >>> 2024-05-29 21:25:14\n",
            ">>> val_acc: 0.7943, val_precision: 0.7865 val_recall: 0.7943, val_f1: 0.7809\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-29 21:25:47\n",
            "loss: 0.1433, acc: 0.9368\n",
            "E2E-ABSA >>> 2024-05-29 21:26:37\n",
            ">>> val_acc: 0.7826, val_precision: 0.7976 val_recall: 0.7826, val_f1: 0.7882\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7826\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-29 21:26:49\n",
            "loss: 0.0986, acc: 0.9648\n",
            "E2E-ABSA >>> 2024-05-29 21:27:25\n",
            "loss: 0.0987, acc: 0.9671\n",
            "E2E-ABSA >>> 2024-05-29 21:28:06\n",
            ">>> val_acc: 0.7787, val_precision: 0.8062 val_recall: 0.7787, val_f1: 0.7856\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-29 21:28:21\n",
            "loss: 0.1264, acc: 0.9516\n",
            "E2E-ABSA >>> 2024-05-29 21:28:56\n",
            "loss: 0.1820, acc: 0.9313\n",
            "E2E-ABSA >>> 2024-05-29 21:29:30\n",
            ">>> val_acc: 0.8021, val_precision: 0.7927 val_recall: 0.8021, val_f1: 0.7893\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.8021\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-29 21:29:59\n",
            "loss: 0.0858, acc: 0.9678\n",
            "E2E-ABSA >>> 2024-05-29 21:30:35\n",
            "loss: 0.1356, acc: 0.9493\n",
            "E2E-ABSA >>> 2024-05-29 21:30:59\n",
            ">>> val_acc: 0.8014, val_precision: 0.7959 val_recall: 0.8014, val_f1: 0.7967\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.8014\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-29 21:31:37\n",
            "loss: 0.1130, acc: 0.9560\n",
            "E2E-ABSA >>> 2024-05-29 21:32:28\n",
            ">>> val_acc: 0.7876, val_precision: 0.7948 val_recall: 0.7876, val_f1: 0.7639\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-29 21:32:33\n",
            "loss: 0.1886, acc: 0.9167\n",
            "E2E-ABSA >>> 2024-05-29 21:33:08\n",
            "loss: 0.1055, acc: 0.9565\n",
            "E2E-ABSA >>> 2024-05-29 21:33:52\n",
            ">>> val_acc: 0.7840, val_precision: 0.8020 val_recall: 0.7840, val_f1: 0.7871\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-29 21:34:04\n",
            "loss: 0.0924, acc: 0.9618\n",
            "E2E-ABSA >>> 2024-05-29 21:34:40\n",
            "loss: 0.1274, acc: 0.9504\n",
            "E2E-ABSA >>> 2024-05-29 21:35:15\n",
            ">>> val_acc: 0.7641, val_precision: 0.7840 val_recall: 0.7641, val_f1: 0.7716\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-29 21:35:36\n",
            "loss: 0.1328, acc: 0.9510\n",
            "E2E-ABSA >>> 2024-05-29 21:36:12\n",
            "loss: 0.1221, acc: 0.9535\n",
            "E2E-ABSA >>> 2024-05-29 21:36:38\n",
            ">>> val_acc: 0.7620, val_precision: 0.7944 val_recall: 0.7620, val_f1: 0.7709\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-29 21:37:08\n",
            "loss: 0.1213, acc: 0.9501\n",
            "E2E-ABSA >>> 2024-05-29 21:38:01\n",
            ">>> val_acc: 0.7950, val_precision: 0.7969 val_recall: 0.7950, val_f1: 0.7958\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-29 21:38:04\n",
            "loss: 0.1211, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-29 21:38:39\n",
            "loss: 0.1201, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-05-29 21:39:24\n",
            ">>> val_acc: 0.7954, val_precision: 0.7877 val_recall: 0.7954, val_f1: 0.7895\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-29 21:39:35\n",
            "loss: 0.0777, acc: 0.9805\n",
            "E2E-ABSA >>> 2024-05-29 21:40:11\n",
            "loss: 0.1053, acc: 0.9631\n",
            "E2E-ABSA >>> 2024-05-29 21:40:47\n",
            ">>> val_acc: 0.7858, val_precision: 0.7869 val_recall: 0.7858, val_f1: 0.7861\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-29 21:41:07\n",
            "loss: 0.0976, acc: 0.9632\n",
            "E2E-ABSA >>> 2024-05-29 21:41:43\n",
            "loss: 0.1243, acc: 0.9523\n",
            "E2E-ABSA >>> 2024-05-29 21:42:10\n",
            ">>> val_acc: 0.7950, val_precision: 0.7838 val_recall: 0.7950, val_f1: 0.7848\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-29 21:42:39\n",
            "loss: 0.1023, acc: 0.9578\n",
            "E2E-ABSA >>> 2024-05-29 21:43:33\n",
            ">>> val_acc: 0.7911, val_precision: 0.7836 val_recall: 0.7911, val_f1: 0.7863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-29 21:43:35\n",
            "loss: 0.0807, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-29 21:44:10\n",
            "loss: 0.1234, acc: 0.9507\n",
            "E2E-ABSA >>> 2024-05-29 21:44:56\n",
            ">>> val_acc: 0.7499, val_precision: 0.7804 val_recall: 0.7499, val_f1: 0.7603\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-29 21:45:06\n",
            "loss: 0.1201, acc: 0.9576\n",
            "E2E-ABSA >>> 2024-05-29 21:45:42\n",
            "loss: 0.1558, acc: 0.9438\n",
            "E2E-ABSA >>> 2024-05-29 21:46:19\n",
            ">>> val_acc: 0.7719, val_precision: 0.7831 val_recall: 0.7719, val_f1: 0.7692\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-29 21:46:37\n",
            "loss: 0.1699, acc: 0.9411\n",
            "E2E-ABSA >>> 2024-05-29 21:47:13\n",
            "loss: 0.1825, acc: 0.9346\n",
            "E2E-ABSA >>> 2024-05-29 21:47:42\n",
            ">>> val_acc: 0.7943, val_precision: 0.7840 val_recall: 0.7943, val_f1: 0.7864\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-29 21:48:09\n",
            "loss: 0.1198, acc: 0.9572\n",
            "E2E-ABSA >>> 2024-05-29 21:48:44\n",
            "loss: 0.1590, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-05-29 21:49:05\n",
            ">>> val_acc: 0.7730, val_precision: 0.7799 val_recall: 0.7730, val_f1: 0.7709\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-29 21:49:40\n",
            "loss: 0.0932, acc: 0.9700\n",
            "E2E-ABSA >>> 2024-05-29 21:50:28\n",
            ">>> val_acc: 0.7829, val_precision: 0.7793 val_recall: 0.7829, val_f1: 0.7809\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-05-29 21:50:36\n",
            "loss: 0.0661, acc: 0.9714\n",
            "E2E-ABSA >>> 2024-05-29 21:51:12\n",
            "loss: 0.0939, acc: 0.9642\n",
            "E2E-ABSA >>> 2024-05-29 21:51:51\n",
            ">>> val_acc: 0.7773, val_precision: 0.7663 val_recall: 0.7773, val_f1: 0.7697\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-05-29 21:52:08\n",
            "loss: 0.1180, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-05-29 21:52:44\n",
            "loss: 0.1133, acc: 0.9603\n",
            "E2E-ABSA >>> 2024-05-29 21:53:14\n",
            ">>> val_acc: 0.7730, val_precision: 0.7680 val_recall: 0.7730, val_f1: 0.7679\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-05-29 21:53:40\n",
            "loss: 0.0908, acc: 0.9722\n",
            "E2E-ABSA >>> 2024-05-29 21:54:15\n",
            "loss: 0.1307, acc: 0.9524\n",
            "E2E-ABSA >>> 2024-05-29 21:54:37\n",
            ">>> val_acc: 0.7410, val_precision: 0.7470 val_recall: 0.7410, val_f1: 0.7416\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-05-29 21:55:11\n",
            "loss: 0.1696, acc: 0.9368\n",
            "E2E-ABSA >>> 2024-05-29 21:56:00\n",
            ">>> val_acc: 0.7666, val_precision: 0.7641 val_recall: 0.7666, val_f1: 0.7649\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-05-29 21:56:07\n",
            "loss: 0.1161, acc: 0.9656\n",
            "E2E-ABSA >>> 2024-05-29 21:56:43\n",
            "loss: 0.1062, acc: 0.9599\n",
            "E2E-ABSA >>> 2024-05-29 21:57:23\n",
            ">>> val_acc: 0.7631, val_precision: 0.7647 val_recall: 0.7631, val_f1: 0.7634\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-05-29 21:57:39\n",
            "loss: 0.0872, acc: 0.9659\n",
            "E2E-ABSA >>> 2024-05-29 21:58:14\n",
            "loss: 0.1134, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-05-29 21:58:46\n",
            ">>> val_acc: 0.7364, val_precision: 0.7647 val_recall: 0.7364, val_f1: 0.7432\n",
            "E2E-ABSA >>> 2024-05-29 21:58:46\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.8014, val_precision: 0.7959 val_recall: 0.8014, val_f1: 0.7967\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.8014\n",
            ">>> test_acc: 0.7797, test_precision: 0.7715, test_recall: 0.7797, test_f1: 0.7696\n"
          ]
        }
      ],
      "source": [
        "# 29-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "g7H9Arm-wZ02"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLD66QjayunZ"
      },
      "source": [
        "### indolem/indobert-base-uncased s3 insert"
      ],
      "id": "lLD66QjayunZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gQMeqaaUyung",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ddee965-d321-404a-f00d-f83b4afe8068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x78e07d416290>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/z_insert_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/z_insert_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-05-29 20:24:25\n",
            "loss: 0.8764, acc: 0.6350\n",
            "E2E-ABSA >>> 2024-05-29 20:25:13\n",
            ">>> val_acc: 0.6931, val_precision: 0.7221 val_recall: 0.6931, val_f1: 0.6553\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6931\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-29 20:25:28\n",
            "loss: 0.7792, acc: 0.6484\n",
            "E2E-ABSA >>> 2024-05-29 20:26:04\n",
            "loss: 0.7127, acc: 0.7001\n",
            "E2E-ABSA >>> 2024-05-29 20:26:43\n",
            ">>> val_acc: 0.7439, val_precision: 0.7615 val_recall: 0.7439, val_f1: 0.7425\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7439\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-29 20:27:02\n",
            "loss: 0.4985, acc: 0.7904\n",
            "E2E-ABSA >>> 2024-05-29 20:27:38\n",
            "loss: 0.5071, acc: 0.7893\n",
            "E2E-ABSA >>> 2024-05-29 20:28:08\n",
            ">>> val_acc: 0.7705, val_precision: 0.7500 val_recall: 0.7705, val_f1: 0.7414\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-29 20:28:34\n",
            "loss: 0.3901, acc: 0.8307\n",
            "E2E-ABSA >>> 2024-05-29 20:29:09\n",
            "loss: 0.3964, acc: 0.8325\n",
            "E2E-ABSA >>> 2024-05-29 20:29:31\n",
            ">>> val_acc: 0.7702, val_precision: 0.7540 val_recall: 0.7702, val_f1: 0.7567\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7702\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-29 20:30:12\n",
            "loss: 0.2498, acc: 0.9036\n",
            "E2E-ABSA >>> 2024-05-29 20:31:01\n",
            ">>> val_acc: 0.7819, val_precision: 0.7807 val_recall: 0.7819, val_f1: 0.7809\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7819\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-29 20:31:15\n",
            "loss: 0.1835, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-05-29 20:31:51\n",
            "loss: 0.2124, acc: 0.9276\n",
            "E2E-ABSA >>> 2024-05-29 20:32:31\n",
            ">>> val_acc: 0.7734, val_precision: 0.7815 val_recall: 0.7734, val_f1: 0.7768\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-29 20:32:46\n",
            "loss: 0.1776, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-05-29 20:33:22\n",
            "loss: 0.1988, acc: 0.9306\n",
            "E2E-ABSA >>> 2024-05-29 20:33:54\n",
            ">>> val_acc: 0.7581, val_precision: 0.7639 val_recall: 0.7581, val_f1: 0.7555\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-29 20:34:18\n",
            "loss: 0.1944, acc: 0.9292\n",
            "E2E-ABSA >>> 2024-05-29 20:34:54\n",
            "loss: 0.2002, acc: 0.9267\n",
            "E2E-ABSA >>> 2024-05-29 20:35:17\n",
            ">>> val_acc: 0.7819, val_precision: 0.7726 val_recall: 0.7819, val_f1: 0.7757\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-29 20:35:50\n",
            "loss: 0.1498, acc: 0.9429\n",
            "E2E-ABSA >>> 2024-05-29 20:36:40\n",
            ">>> val_acc: 0.7655, val_precision: 0.7654 val_recall: 0.7655, val_f1: 0.7652\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-29 20:36:46\n",
            "loss: 0.1316, acc: 0.9492\n",
            "E2E-ABSA >>> 2024-05-29 20:37:21\n",
            "loss: 0.1660, acc: 0.9364\n",
            "E2E-ABSA >>> 2024-05-29 20:38:03\n",
            ">>> val_acc: 0.7819, val_precision: 0.7822 val_recall: 0.7819, val_f1: 0.7820\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7819\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-29 20:38:24\n",
            "loss: 0.1117, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-05-29 20:39:00\n",
            "loss: 0.1678, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-05-29 20:39:33\n",
            ">>> val_acc: 0.7719, val_precision: 0.7720 val_recall: 0.7719, val_f1: 0.7688\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-29 20:39:56\n",
            "loss: 0.1321, acc: 0.9463\n",
            "E2E-ABSA >>> 2024-05-29 20:40:31\n",
            "loss: 0.1640, acc: 0.9352\n",
            "E2E-ABSA >>> 2024-05-29 20:40:56\n",
            ">>> val_acc: 0.7666, val_precision: 0.7787 val_recall: 0.7666, val_f1: 0.7716\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-29 20:41:27\n",
            "loss: 0.1810, acc: 0.9240\n",
            "E2E-ABSA >>> 2024-05-29 20:42:19\n",
            ">>> val_acc: 0.7602, val_precision: 0.7629 val_recall: 0.7602, val_f1: 0.7500\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-29 20:42:23\n",
            "loss: 0.1447, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-05-29 20:42:59\n",
            "loss: 0.1559, acc: 0.9408\n",
            "E2E-ABSA >>> 2024-05-29 20:43:42\n",
            ">>> val_acc: 0.7766, val_precision: 0.7732 val_recall: 0.7766, val_f1: 0.7744\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-29 20:43:55\n",
            "loss: 0.0814, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-29 20:44:30\n",
            "loss: 0.1372, acc: 0.9504\n",
            "E2E-ABSA >>> 2024-05-29 20:45:05\n",
            ">>> val_acc: 0.7705, val_precision: 0.7597 val_recall: 0.7705, val_f1: 0.7601\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-29 20:45:26\n",
            "loss: 0.1597, acc: 0.9385\n",
            "E2E-ABSA >>> 2024-05-29 20:46:02\n",
            "loss: 0.1638, acc: 0.9379\n",
            "E2E-ABSA >>> 2024-05-29 20:46:28\n",
            ">>> val_acc: 0.7542, val_precision: 0.7651 val_recall: 0.7542, val_f1: 0.7582\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-29 20:46:58\n",
            "loss: 0.1173, acc: 0.9576\n",
            "E2E-ABSA >>> 2024-05-29 20:47:51\n",
            ">>> val_acc: 0.7321, val_precision: 0.7631 val_recall: 0.7321, val_f1: 0.7396\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-29 20:47:54\n",
            "loss: 0.1574, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-29 20:48:30\n",
            "loss: 0.1849, acc: 0.9294\n",
            "E2E-ABSA >>> 2024-05-29 20:49:14\n",
            ">>> val_acc: 0.7634, val_precision: 0.7569 val_recall: 0.7634, val_f1: 0.7597\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-29 20:49:26\n",
            "loss: 0.1068, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-29 20:50:01\n",
            "loss: 0.1242, acc: 0.9517\n",
            "E2E-ABSA >>> 2024-05-29 20:50:37\n",
            ">>> val_acc: 0.7602, val_precision: 0.7519 val_recall: 0.7602, val_f1: 0.7527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-29 20:50:57\n",
            "loss: 0.1407, acc: 0.9498\n",
            "E2E-ABSA >>> 2024-05-29 20:51:33\n",
            "loss: 0.1570, acc: 0.9463\n",
            "E2E-ABSA >>> 2024-05-29 20:52:00\n",
            ">>> val_acc: 0.7627, val_precision: 0.7482 val_recall: 0.7627, val_f1: 0.7449\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-29 20:52:28\n",
            "loss: 0.1534, acc: 0.9492\n",
            "E2E-ABSA >>> 2024-05-29 20:53:23\n",
            ">>> val_acc: 0.7542, val_precision: 0.7547 val_recall: 0.7542, val_f1: 0.7429\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-29 20:53:24\n",
            "loss: 0.0517, acc: 1.0000\n",
            "E2E-ABSA >>> 2024-05-29 20:54:00\n",
            "loss: 0.1890, acc: 0.9333\n",
            "E2E-ABSA >>> 2024-05-29 20:54:46\n",
            ">>> val_acc: 0.7584, val_precision: 0.7512 val_recall: 0.7584, val_f1: 0.7543\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-29 20:54:56\n",
            "loss: 0.1432, acc: 0.9576\n",
            "E2E-ABSA >>> 2024-05-29 20:55:31\n",
            "loss: 0.1593, acc: 0.9438\n",
            "E2E-ABSA >>> 2024-05-29 20:56:08\n",
            ">>> val_acc: 0.7449, val_precision: 0.7559 val_recall: 0.7449, val_f1: 0.7461\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-29 20:56:27\n",
            "loss: 0.1399, acc: 0.9519\n",
            "E2E-ABSA >>> 2024-05-29 20:57:02\n",
            "loss: 0.1540, acc: 0.9437\n",
            "E2E-ABSA >>> 2024-05-29 20:57:31\n",
            ">>> val_acc: 0.7510, val_precision: 0.7296 val_recall: 0.7510, val_f1: 0.7323\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-29 20:57:58\n",
            "loss: 0.1592, acc: 0.9383\n",
            "E2E-ABSA >>> 2024-05-29 20:58:34\n",
            "loss: 0.1706, acc: 0.9361\n",
            "E2E-ABSA >>> 2024-05-29 20:58:54\n",
            ">>> val_acc: 0.7510, val_precision: 0.7296 val_recall: 0.7510, val_f1: 0.7299\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-29 20:59:30\n",
            "loss: 0.1576, acc: 0.9413\n",
            "E2E-ABSA >>> 2024-05-29 21:00:17\n",
            ">>> val_acc: 0.7449, val_precision: 0.7470 val_recall: 0.7449, val_f1: 0.7449\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-05-29 21:00:26\n",
            "loss: 0.1698, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-05-29 21:01:01\n",
            "loss: 0.1438, acc: 0.9511\n",
            "E2E-ABSA >>> 2024-05-29 21:01:40\n",
            ">>> val_acc: 0.7531, val_precision: 0.7322 val_recall: 0.7531, val_f1: 0.7366\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-05-29 21:01:57\n",
            "loss: 0.1960, acc: 0.9310\n",
            "E2E-ABSA >>> 2024-05-29 21:02:33\n",
            "loss: 0.1625, acc: 0.9371\n",
            "E2E-ABSA >>> 2024-05-29 21:03:03\n",
            ">>> val_acc: 0.7574, val_precision: 0.7574 val_recall: 0.7574, val_f1: 0.7574\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-05-29 21:03:28\n",
            "loss: 0.1391, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-05-29 21:04:04\n",
            "loss: 0.1562, acc: 0.9451\n",
            "E2E-ABSA >>> 2024-05-29 21:04:26\n",
            ">>> val_acc: 0.7300, val_precision: 0.7477 val_recall: 0.7300, val_f1: 0.7324\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-05-29 21:05:00\n",
            "loss: 0.1301, acc: 0.9525\n",
            "E2E-ABSA >>> 2024-05-29 21:05:48\n",
            ">>> val_acc: 0.7378, val_precision: 0.7401 val_recall: 0.7378, val_f1: 0.7381\n",
            "E2E-ABSA >>> 2024-05-29 21:05:48\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7819, val_precision: 0.7822 val_recall: 0.7819, val_f1: 0.7820\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.7819\n",
            ">>> test_acc: 0.7564, test_precision: 0.7510, test_recall: 0.7564, test_f1: 0.7531\n"
          ]
        }
      ],
      "source": [
        "# 29-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "gQMeqaaUyung"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79e311a-a4fd-424e-99ad-25d8f7c7bd47"
      },
      "source": [
        "### indolem/indobert-base-uncased s4 insert"
      ],
      "id": "e79e311a-a4fd-424e-99ad-25d8f7c7bd47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EKbLdZjJcGKk",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e05d6bf2-d56d-40f1-ff8c-67964a669b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 42.0/42.0 [00:00<00:00, 280kB/s]\n",
            "vocab.txt: 100% 234k/234k [00:00<00:00, 1.95MB/s]\n",
            "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 11.0kB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 726kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.01k/1.01k [00:00<00:00, 7.69MB/s]\n",
            "pytorch_model.bin: 100% 445M/445M [00:02<00:00, 210MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7b2008213010>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/j_insert_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/j_insert_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-06-13 07:16:49\n",
            "loss: 0.8772, acc: 0.6312\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "E2E-ABSA >>> 2024-06-13 07:17:38\n",
            ">>> val_acc: 0.6952, val_precision: 0.6390 val_recall: 0.6952, val_f1: 0.6650\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6952\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-13 07:17:48\n",
            "loss: 0.7659, acc: 0.6745\n",
            "E2E-ABSA >>> 2024-06-13 07:18:24\n",
            "loss: 0.6890, acc: 0.7051\n",
            "E2E-ABSA >>> 2024-06-13 07:19:04\n",
            ">>> val_acc: 0.7698, val_precision: 0.7842 val_recall: 0.7698, val_f1: 0.7690\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7698\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-13 07:19:23\n",
            "loss: 0.4860, acc: 0.8060\n",
            "E2E-ABSA >>> 2024-06-13 07:19:59\n",
            "loss: 0.4951, acc: 0.8011\n",
            "E2E-ABSA >>> 2024-06-13 07:20:31\n",
            ">>> val_acc: 0.7854, val_precision: 0.7711 val_recall: 0.7854, val_f1: 0.7621\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-13 07:20:57\n",
            "loss: 0.3711, acc: 0.8498\n",
            "E2E-ABSA >>> 2024-06-13 07:21:33\n",
            "loss: 0.3831, acc: 0.8416\n",
            "E2E-ABSA >>> 2024-06-13 07:21:56\n",
            ">>> val_acc: 0.7929, val_precision: 0.7794 val_recall: 0.7929, val_f1: 0.7708\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7929\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-13 07:22:38\n",
            "loss: 0.2378, acc: 0.9121\n",
            "E2E-ABSA >>> 2024-06-13 07:23:29\n",
            ">>> val_acc: 0.7726, val_precision: 0.7995 val_recall: 0.7726, val_f1: 0.7790\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7726\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-13 07:23:43\n",
            "loss: 0.1806, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-06-13 07:24:20\n",
            "loss: 0.1956, acc: 0.9313\n",
            "E2E-ABSA >>> 2024-06-13 07:25:01\n",
            ">>> val_acc: 0.7645, val_precision: 0.7981 val_recall: 0.7645, val_f1: 0.7751\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-13 07:25:17\n",
            "loss: 0.1513, acc: 0.9517\n",
            "E2E-ABSA >>> 2024-06-13 07:25:53\n",
            "loss: 0.1445, acc: 0.9518\n",
            "E2E-ABSA >>> 2024-06-13 07:26:26\n",
            ">>> val_acc: 0.7645, val_precision: 0.7762 val_recall: 0.7645, val_f1: 0.7613\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-13 07:26:51\n",
            "loss: 0.1225, acc: 0.9605\n",
            "E2E-ABSA >>> 2024-06-13 07:27:27\n",
            "loss: 0.1444, acc: 0.9509\n",
            "E2E-ABSA >>> 2024-06-13 07:27:51\n",
            ">>> val_acc: 0.7908, val_precision: 0.7801 val_recall: 0.7908, val_f1: 0.7824\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7908\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-13 07:28:32\n",
            "loss: 0.0820, acc: 0.9783\n",
            "E2E-ABSA >>> 2024-06-13 07:29:24\n",
            ">>> val_acc: 0.7758, val_precision: 0.7736 val_recall: 0.7758, val_f1: 0.7711\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-13 07:29:30\n",
            "loss: 0.1227, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-06-13 07:30:06\n",
            "loss: 0.1149, acc: 0.9607\n",
            "E2E-ABSA >>> 2024-06-13 07:30:49\n",
            ">>> val_acc: 0.7972, val_precision: 0.7908 val_recall: 0.7972, val_f1: 0.7927\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7972\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-13 07:31:13\n",
            "loss: 0.1195, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-06-13 07:31:50\n",
            "loss: 0.1476, acc: 0.9536\n",
            "E2E-ABSA >>> 2024-06-13 07:32:24\n",
            ">>> val_acc: 0.7449, val_precision: 0.7867 val_recall: 0.7449, val_f1: 0.7568\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-13 07:32:47\n",
            "loss: 0.0930, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-13 07:33:23\n",
            "loss: 0.1391, acc: 0.9482\n",
            "E2E-ABSA >>> 2024-06-13 07:33:49\n",
            ">>> val_acc: 0.7837, val_precision: 0.7913 val_recall: 0.7837, val_f1: 0.7837\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-13 07:34:21\n",
            "loss: 0.0854, acc: 0.9723\n",
            "E2E-ABSA >>> 2024-06-13 07:35:14\n",
            ">>> val_acc: 0.7922, val_precision: 0.7792 val_recall: 0.7922, val_f1: 0.7809\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-13 07:35:18\n",
            "loss: 0.0770, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-13 07:35:54\n",
            "loss: 0.0960, acc: 0.9710\n",
            "E2E-ABSA >>> 2024-06-13 07:36:39\n",
            ">>> val_acc: 0.7577, val_precision: 0.7727 val_recall: 0.7577, val_f1: 0.7637\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-13 07:36:52\n",
            "loss: 0.0870, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-13 07:37:28\n",
            "loss: 0.1133, acc: 0.9619\n",
            "E2E-ABSA >>> 2024-06-13 07:38:04\n",
            ">>> val_acc: 0.7631, val_precision: 0.7778 val_recall: 0.7631, val_f1: 0.7680\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-13 07:38:25\n",
            "loss: 0.1107, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-06-13 07:39:02\n",
            "loss: 0.1319, acc: 0.9551\n",
            "E2E-ABSA >>> 2024-06-13 07:39:28\n",
            ">>> val_acc: 0.6984, val_precision: 0.7820 val_recall: 0.6984, val_f1: 0.7181\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-13 07:39:59\n",
            "loss: 0.1635, acc: 0.9397\n",
            "E2E-ABSA >>> 2024-06-13 07:40:54\n",
            ">>> val_acc: 0.7698, val_precision: 0.7795 val_recall: 0.7698, val_f1: 0.7720\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-13 07:40:56\n",
            "loss: 0.0588, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-13 07:41:33\n",
            "loss: 0.1100, acc: 0.9653\n",
            "E2E-ABSA >>> 2024-06-13 07:42:19\n",
            ">>> val_acc: 0.7773, val_precision: 0.7704 val_recall: 0.7773, val_f1: 0.7715\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-13 07:42:30\n",
            "loss: 0.1223, acc: 0.9551\n",
            "E2E-ABSA >>> 2024-06-13 07:43:07\n",
            "loss: 0.1223, acc: 0.9550\n",
            "E2E-ABSA >>> 2024-06-13 07:43:44\n",
            ">>> val_acc: 0.7652, val_precision: 0.7658 val_recall: 0.7652, val_f1: 0.7647\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-13 07:44:04\n",
            "loss: 0.1521, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-13 07:44:41\n",
            "loss: 0.1403, acc: 0.9511\n",
            "E2E-ABSA >>> 2024-06-13 07:45:09\n",
            ">>> val_acc: 0.7819, val_precision: 0.7676 val_recall: 0.7819, val_f1: 0.7682\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-13 07:45:38\n",
            "loss: 0.0889, acc: 0.9750\n",
            "E2E-ABSA >>> 2024-06-13 07:46:34\n",
            ">>> val_acc: 0.7318, val_precision: 0.7728 val_recall: 0.7318, val_f1: 0.7439\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-13 07:46:36\n",
            "loss: 0.1590, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-13 07:47:12\n",
            "loss: 0.1113, acc: 0.9651\n",
            "E2E-ABSA >>> 2024-06-13 07:47:59\n",
            ">>> val_acc: 0.7691, val_precision: 0.7563 val_recall: 0.7691, val_f1: 0.7603\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-13 07:48:09\n",
            "loss: 0.0760, acc: 0.9799\n",
            "E2E-ABSA >>> 2024-06-13 07:48:46\n",
            "loss: 0.1138, acc: 0.9634\n",
            "E2E-ABSA >>> 2024-06-13 07:49:24\n",
            ">>> val_acc: 0.7588, val_precision: 0.7571 val_recall: 0.7588, val_f1: 0.7447\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-13 07:49:43\n",
            "loss: 0.1130, acc: 0.9675\n",
            "E2E-ABSA >>> 2024-06-13 07:50:19\n",
            "loss: 0.1789, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-13 07:50:49\n",
            ">>> val_acc: 0.7439, val_precision: 0.7273 val_recall: 0.7439, val_f1: 0.7029\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-13 07:51:16\n",
            "loss: 0.1434, acc: 0.9441\n",
            "E2E-ABSA >>> 2024-06-13 07:51:53\n",
            "loss: 0.1370, acc: 0.9496\n",
            "E2E-ABSA >>> 2024-06-13 07:52:14\n",
            ">>> val_acc: 0.7513, val_precision: 0.7561 val_recall: 0.7513, val_f1: 0.7535\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-13 07:52:50\n",
            "loss: 0.1042, acc: 0.9656\n",
            "E2E-ABSA >>> 2024-06-13 07:53:39\n",
            ">>> val_acc: 0.7560, val_precision: 0.7381 val_recall: 0.7560, val_f1: 0.7309\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-13 07:53:48\n",
            "loss: 0.1064, acc: 0.9557\n",
            "E2E-ABSA >>> 2024-06-13 07:54:24\n",
            "loss: 0.1120, acc: 0.9627\n",
            "E2E-ABSA >>> 2024-06-13 07:55:04\n",
            ">>> val_acc: 0.7591, val_precision: 0.7420 val_recall: 0.7591, val_f1: 0.7447\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-13 07:55:22\n",
            "loss: 0.1074, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-06-13 07:55:58\n",
            "loss: 0.1162, acc: 0.9578\n",
            "E2E-ABSA >>> 2024-06-13 07:56:29\n",
            ">>> val_acc: 0.7471, val_precision: 0.7462 val_recall: 0.7471, val_f1: 0.7466\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-13 07:56:55\n",
            "loss: 0.1505, acc: 0.9505\n",
            "E2E-ABSA >>> 2024-06-13 07:57:32\n",
            "loss: 0.1573, acc: 0.9419\n",
            "E2E-ABSA >>> 2024-06-13 07:57:54\n",
            ">>> val_acc: 0.7456, val_precision: 0.7563 val_recall: 0.7456, val_f1: 0.7482\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-13 07:58:29\n",
            "loss: 0.1115, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-13 07:59:19\n",
            ">>> val_acc: 0.7613, val_precision: 0.7514 val_recall: 0.7613, val_f1: 0.7551\n",
            "E2E-ABSA >>> 2024-06-13 07:59:19\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7972, val_precision: 0.7908 val_recall: 0.7972, val_f1: 0.7927\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7972\n",
            ">>> test_acc: 0.7564, test_precision: 0.7478, test_recall: 0.7564, test_f1: 0.7487\n"
          ]
        }
      ],
      "source": [
        "# 13-6 experiment 2\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "EKbLdZjJcGKk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d420709e-ffd1-431a-a87d-ff0c2e0e7f9c"
      },
      "source": [
        "### indolem/indobert-base-uncased s5 insert"
      ],
      "id": "d420709e-ffd1-431a-a87d-ff0c2e0e7f9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "f4438843-08ce-418d-9baf-c9941168393e",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f7661833760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-06-04 08:20:58\n",
            "loss: 0.8589, acc: 0.6462\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 08:21:09\n",
            ">>> val_acc: 0.6323, val_precision: 0.6869 val_recall: 0.6323, val_f1: 0.6307\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6323\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 08:21:11\n",
            "loss: 0.7280, acc: 0.6927\n",
            "E2E-ABSA >>> 2024-06-04 08:21:20\n",
            "loss: 0.6290, acc: 0.7389\n",
            "E2E-ABSA >>> 2024-06-04 08:21:29\n",
            ">>> val_acc: 0.7922, val_precision: 0.7844 val_recall: 0.7922, val_f1: 0.7783\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7922\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 08:21:33\n",
            "loss: 0.3998, acc: 0.8372\n",
            "E2E-ABSA >>> 2024-06-04 08:21:42\n",
            "loss: 0.4309, acc: 0.8222\n",
            "E2E-ABSA >>> 2024-06-04 08:21:49\n",
            ">>> val_acc: 0.7964, val_precision: 0.7863 val_recall: 0.7964, val_f1: 0.7882\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7964\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 08:21:55\n",
            "loss: 0.3121, acc: 0.8759\n",
            "E2E-ABSA >>> 2024-06-04 08:22:04\n",
            "loss: 0.3315, acc: 0.8681\n",
            "E2E-ABSA >>> 2024-06-04 08:22:09\n",
            ">>> val_acc: 0.7986, val_precision: 0.7896 val_recall: 0.7986, val_f1: 0.7807\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 08:22:17\n",
            "loss: 0.1947, acc: 0.9271\n",
            "E2E-ABSA >>> 2024-06-04 08:22:28\n",
            ">>> val_acc: 0.7506, val_precision: 0.8005 val_recall: 0.7506, val_f1: 0.7607\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 08:22:30\n",
            "loss: 0.1626, acc: 0.9344\n",
            "E2E-ABSA >>> 2024-06-04 08:22:38\n",
            "loss: 0.1466, acc: 0.9495\n",
            "E2E-ABSA >>> 2024-06-04 08:22:48\n",
            ">>> val_acc: 0.7851, val_precision: 0.8000 val_recall: 0.7851, val_f1: 0.7907\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7851\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 08:22:52\n",
            "loss: 0.1470, acc: 0.9474\n",
            "E2E-ABSA >>> 2024-06-04 08:23:00\n",
            "loss: 0.1391, acc: 0.9484\n",
            "E2E-ABSA >>> 2024-06-04 08:23:08\n",
            ">>> val_acc: 0.7847, val_precision: 0.7976 val_recall: 0.7847, val_f1: 0.7868\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 08:23:13\n",
            "loss: 0.1110, acc: 0.9605\n",
            "E2E-ABSA >>> 2024-06-04 08:23:22\n",
            "loss: 0.1273, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 08:23:27\n",
            ">>> val_acc: 0.7812, val_precision: 0.7978 val_recall: 0.7812, val_f1: 0.7869\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 08:23:35\n",
            "loss: 0.0935, acc: 0.9735\n",
            "E2E-ABSA >>> 2024-06-04 08:23:47\n",
            ">>> val_acc: 0.7769, val_precision: 0.7937 val_recall: 0.7769, val_f1: 0.7831\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 08:23:48\n",
            "loss: 0.0759, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 08:23:56\n",
            "loss: 0.0869, acc: 0.9693\n",
            "E2E-ABSA >>> 2024-06-04 08:24:06\n",
            ">>> val_acc: 0.7996, val_precision: 0.8001 val_recall: 0.7996, val_f1: 0.7987\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 08:24:10\n",
            "loss: 0.0622, acc: 0.9812\n",
            "E2E-ABSA >>> 2024-06-04 08:24:18\n",
            "loss: 0.1036, acc: 0.9643\n",
            "E2E-ABSA >>> 2024-06-04 08:24:26\n",
            ">>> val_acc: 0.7901, val_precision: 0.7960 val_recall: 0.7901, val_f1: 0.7913\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 08:24:31\n",
            "loss: 0.0677, acc: 0.9785\n",
            "E2E-ABSA >>> 2024-06-04 08:24:40\n",
            "loss: 0.0952, acc: 0.9680\n",
            "E2E-ABSA >>> 2024-06-04 08:24:45\n",
            ">>> val_acc: 0.7865, val_precision: 0.7975 val_recall: 0.7865, val_f1: 0.7910\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 08:24:53\n",
            "loss: 0.1320, acc: 0.9560\n",
            "E2E-ABSA >>> 2024-06-04 08:25:05\n",
            ">>> val_acc: 0.8014, val_precision: 0.7917 val_recall: 0.8014, val_f1: 0.7934\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 08:25:06\n",
            "loss: 0.1799, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 08:25:14\n",
            "loss: 0.1464, acc: 0.9481\n",
            "E2E-ABSA >>> 2024-06-04 08:25:24\n",
            ">>> val_acc: 0.8014, val_precision: 0.7963 val_recall: 0.8014, val_f1: 0.7957\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 08:25:27\n",
            "loss: 0.0722, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-04 08:25:36\n",
            "loss: 0.0991, acc: 0.9623\n",
            "E2E-ABSA >>> 2024-06-04 08:25:44\n",
            ">>> val_acc: 0.7272, val_precision: 0.7929 val_recall: 0.7272, val_f1: 0.7436\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 08:25:49\n",
            "loss: 0.1468, acc: 0.9510\n",
            "E2E-ABSA >>> 2024-06-04 08:25:57\n",
            "loss: 0.1385, acc: 0.9520\n",
            "E2E-ABSA >>> 2024-06-04 08:26:03\n",
            ">>> val_acc: 0.7734, val_precision: 0.7810 val_recall: 0.7734, val_f1: 0.7767\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 08:26:10\n",
            "loss: 0.0868, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 08:26:23\n",
            ">>> val_acc: 0.7798, val_precision: 0.7970 val_recall: 0.7798, val_f1: 0.7836\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 08:26:23\n",
            "loss: 0.0776, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 08:26:32\n",
            "loss: 0.1137, acc: 0.9578\n",
            "E2E-ABSA >>> 2024-06-04 08:26:42\n",
            ">>> val_acc: 0.7698, val_precision: 0.7929 val_recall: 0.7698, val_f1: 0.7779\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 08:26:45\n",
            "loss: 0.0907, acc: 0.9668\n",
            "E2E-ABSA >>> 2024-06-04 08:26:53\n",
            "loss: 0.1253, acc: 0.9541\n",
            "E2E-ABSA >>> 2024-06-04 08:27:02\n",
            ">>> val_acc: 0.7833, val_precision: 0.7684 val_recall: 0.7833, val_f1: 0.7655\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 08:27:06\n",
            "loss: 0.1230, acc: 0.9598\n",
            "E2E-ABSA >>> 2024-06-04 08:27:15\n",
            "loss: 0.1488, acc: 0.9463\n",
            "E2E-ABSA >>> 2024-06-04 08:27:21\n",
            ">>> val_acc: 0.7844, val_precision: 0.7859 val_recall: 0.7844, val_f1: 0.7823\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 08:27:28\n",
            "loss: 0.0804, acc: 0.9695\n",
            "E2E-ABSA >>> 2024-06-04 08:27:41\n",
            ">>> val_acc: 0.7762, val_precision: 0.7631 val_recall: 0.7762, val_f1: 0.7552\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 08:27:41\n",
            "loss: 0.0621, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 08:27:49\n",
            "loss: 0.0925, acc: 0.9706\n",
            "E2E-ABSA >>> 2024-06-04 08:28:00\n",
            ">>> val_acc: 0.7655, val_precision: 0.7872 val_recall: 0.7655, val_f1: 0.7731\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 08:28:02\n",
            "loss: 0.0599, acc: 0.9710\n",
            "E2E-ABSA >>> 2024-06-04 08:28:11\n",
            "loss: 0.1101, acc: 0.9614\n",
            "E2E-ABSA >>> 2024-06-04 08:28:20\n",
            ">>> val_acc: 0.7698, val_precision: 0.7846 val_recall: 0.7698, val_f1: 0.7734\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 08:28:24\n",
            "loss: 0.0963, acc: 0.9555\n",
            "E2E-ABSA >>> 2024-06-04 08:28:32\n",
            "loss: 0.1251, acc: 0.9523\n",
            "E2E-ABSA >>> 2024-06-04 08:28:39\n",
            ">>> val_acc: 0.7730, val_precision: 0.7695 val_recall: 0.7730, val_f1: 0.7689\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 08:28:45\n",
            "loss: 0.1030, acc: 0.9646\n",
            "E2E-ABSA >>> 2024-06-04 08:28:54\n",
            "loss: 0.0893, acc: 0.9709\n",
            "E2E-ABSA >>> 2024-06-04 08:28:59\n",
            ">>> val_acc: 0.7677, val_precision: 0.7694 val_recall: 0.7677, val_f1: 0.7684\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-04 08:29:07\n",
            "loss: 0.1095, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-06-04 08:29:18\n",
            ">>> val_acc: 0.7744, val_precision: 0.7663 val_recall: 0.7744, val_f1: 0.7692\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-04 08:29:20\n",
            "loss: 0.1070, acc: 0.9557\n",
            "E2E-ABSA >>> 2024-06-04 08:29:28\n",
            "loss: 0.1215, acc: 0.9516\n",
            "E2E-ABSA >>> 2024-06-04 08:29:37\n",
            ">>> val_acc: 0.7378, val_precision: 0.7109 val_recall: 0.7378, val_f1: 0.7129\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-04 08:29:41\n",
            "loss: 0.2446, acc: 0.9193\n",
            "E2E-ABSA >>> 2024-06-04 08:29:50\n",
            "loss: 0.1672, acc: 0.9400\n",
            "E2E-ABSA >>> 2024-06-04 08:29:57\n",
            ">>> val_acc: 0.7709, val_precision: 0.7626 val_recall: 0.7709, val_f1: 0.7641\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-04 08:30:03\n",
            "loss: 0.0678, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-04 08:30:11\n",
            "loss: 0.1069, acc: 0.9611\n",
            "E2E-ABSA >>> 2024-06-04 08:30:16\n",
            ">>> val_acc: 0.7538, val_precision: 0.7621 val_recall: 0.7538, val_f1: 0.7531\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-04 08:30:24\n",
            "loss: 0.1118, acc: 0.9668\n",
            "E2E-ABSA >>> 2024-06-04 08:30:36\n",
            ">>> val_acc: 0.7481, val_precision: 0.7590 val_recall: 0.7481, val_f1: 0.7523\n",
            "E2E-ABSA >>> 2024-06-04 08:30:36\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7996, val_precision: 0.8001 val_recall: 0.7996, val_f1: 0.7987\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996\n",
            ">>> test_acc: 0.7746, test_precision: 0.7701, test_recall: 0.7746, test_f1: 0.7712\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "f4438843-08ce-418d-9baf-c9941168393e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2d3059-b28b-493e-89eb-114c6a0ce4c9"
      },
      "source": [
        "### indolem/indobert-base-uncased s6 insert"
      ],
      "id": "4b2d3059-b28b-493e-89eb-114c6a0ce4c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "e0632eed-dead-4d03-9551-6da3db1084fe",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 443273728\n",
            "> n_trainable_params: 110560515, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f5e5f52f760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indolem/indobert-base-uncased\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "E2E-ABSA >>> 2024-06-04 08:45:58\n",
            "loss: 0.8701, acc: 0.6425\n",
            "E2E-ABSA >>> 2024-06-04 08:46:09\n",
            ">>> val_acc: 0.6895, val_precision: 0.7001 val_recall: 0.6895, val_f1: 0.6667\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6895\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 08:46:11\n",
            "loss: 0.7750, acc: 0.6615\n",
            "E2E-ABSA >>> 2024-06-04 08:46:20\n",
            "loss: 0.6944, acc: 0.7167\n",
            "E2E-ABSA >>> 2024-06-04 08:46:29\n",
            ">>> val_acc: 0.7300, val_precision: 0.7320 val_recall: 0.7300, val_f1: 0.7141\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.73\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 08:46:33\n",
            "loss: 0.5075, acc: 0.7943\n",
            "E2E-ABSA >>> 2024-06-04 08:46:42\n",
            "loss: 0.5347, acc: 0.7829\n",
            "E2E-ABSA >>> 2024-06-04 08:46:49\n",
            ">>> val_acc: 0.7606, val_precision: 0.7465 val_recall: 0.7606, val_f1: 0.7385\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7606\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 08:46:55\n",
            "loss: 0.4271, acc: 0.8273\n",
            "E2E-ABSA >>> 2024-06-04 08:47:04\n",
            "loss: 0.4341, acc: 0.8263\n",
            "E2E-ABSA >>> 2024-06-04 08:47:09\n",
            ">>> val_acc: 0.7783, val_precision: 0.7723 val_recall: 0.7783, val_f1: 0.7748\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7783\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 08:47:17\n",
            "loss: 0.2549, acc: 0.9023\n",
            "E2E-ABSA >>> 2024-06-04 08:47:29\n",
            ">>> val_acc: 0.7542, val_precision: 0.7781 val_recall: 0.7542, val_f1: 0.7621\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 08:47:30\n",
            "loss: 0.1836, acc: 0.9281\n",
            "E2E-ABSA >>> 2024-06-04 08:47:39\n",
            "loss: 0.2326, acc: 0.9099\n",
            "E2E-ABSA >>> 2024-06-04 08:47:48\n",
            ">>> val_acc: 0.7439, val_precision: 0.7771 val_recall: 0.7439, val_f1: 0.7551\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 08:47:52\n",
            "loss: 0.2349, acc: 0.9091\n",
            "E2E-ABSA >>> 2024-06-04 08:48:00\n",
            "loss: 0.2215, acc: 0.9162\n",
            "E2E-ABSA >>> 2024-06-04 08:48:08\n",
            ">>> val_acc: 0.7684, val_precision: 0.7652 val_recall: 0.7684, val_f1: 0.7654\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 08:48:13\n",
            "loss: 0.1704, acc: 0.9357\n",
            "E2E-ABSA >>> 2024-06-04 08:48:22\n",
            "loss: 0.1902, acc: 0.9304\n",
            "E2E-ABSA >>> 2024-06-04 08:48:27\n",
            ">>> val_acc: 0.7758, val_precision: 0.7688 val_recall: 0.7758, val_f1: 0.7703\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 08:48:35\n",
            "loss: 0.1460, acc: 0.9450\n",
            "E2E-ABSA >>> 2024-06-04 08:48:47\n",
            ">>> val_acc: 0.7716, val_precision: 0.7722 val_recall: 0.7716, val_f1: 0.7719\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 08:48:48\n",
            "loss: 0.1045, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-06-04 08:48:56\n",
            "loss: 0.1430, acc: 0.9499\n",
            "E2E-ABSA >>> 2024-06-04 08:49:06\n",
            ">>> val_acc: 0.7776, val_precision: 0.7707 val_recall: 0.7776, val_f1: 0.7735\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 08:49:09\n",
            "loss: 0.1379, acc: 0.9563\n",
            "E2E-ABSA >>> 2024-06-04 08:49:18\n",
            "loss: 0.1684, acc: 0.9429\n",
            "E2E-ABSA >>> 2024-06-04 08:49:25\n",
            ">>> val_acc: 0.7638, val_precision: 0.7568 val_recall: 0.7638, val_f1: 0.7585\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 08:49:31\n",
            "loss: 0.1415, acc: 0.9473\n",
            "E2E-ABSA >>> 2024-06-04 08:49:39\n",
            "loss: 0.1886, acc: 0.9306\n",
            "E2E-ABSA >>> 2024-06-04 08:49:45\n",
            ">>> val_acc: 0.7730, val_precision: 0.7627 val_recall: 0.7730, val_f1: 0.7648\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 08:49:52\n",
            "loss: 0.1337, acc: 0.9496\n",
            "E2E-ABSA >>> 2024-06-04 08:50:04\n",
            ">>> val_acc: 0.7613, val_precision: 0.7545 val_recall: 0.7613, val_f1: 0.7371\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 08:50:05\n",
            "loss: 0.1046, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-04 08:50:14\n",
            "loss: 0.1334, acc: 0.9503\n",
            "E2E-ABSA >>> 2024-06-04 08:50:24\n",
            ">>> val_acc: 0.7613, val_precision: 0.7569 val_recall: 0.7613, val_f1: 0.7581\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 08:50:27\n",
            "loss: 0.1631, acc: 0.9253\n",
            "E2E-ABSA >>> 2024-06-04 08:50:35\n",
            "loss: 0.1835, acc: 0.9278\n",
            "E2E-ABSA >>> 2024-06-04 08:50:43\n",
            ">>> val_acc: 0.7588, val_precision: 0.7641 val_recall: 0.7588, val_f1: 0.7566\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 08:50:48\n",
            "loss: 0.1465, acc: 0.9448\n",
            "E2E-ABSA >>> 2024-06-04 08:50:56\n",
            "loss: 0.1560, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-04 08:51:02\n",
            ">>> val_acc: 0.7339, val_precision: 0.7772 val_recall: 0.7339, val_f1: 0.7469\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 08:51:09\n",
            "loss: 0.1370, acc: 0.9457\n",
            "E2E-ABSA >>> 2024-06-04 08:51:22\n",
            ">>> val_acc: 0.7591, val_precision: 0.7670 val_recall: 0.7591, val_f1: 0.7626\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 08:51:22\n",
            "loss: 0.1266, acc: 0.9766\n",
            "E2E-ABSA >>> 2024-06-04 08:51:31\n",
            "loss: 0.1210, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-06-04 08:51:41\n",
            ">>> val_acc: 0.7577, val_precision: 0.7538 val_recall: 0.7577, val_f1: 0.7521\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 08:51:44\n",
            "loss: 0.1164, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 08:51:52\n",
            "loss: 0.1742, acc: 0.9370\n",
            "E2E-ABSA >>> 2024-06-04 08:52:01\n",
            ">>> val_acc: 0.7602, val_precision: 0.7559 val_recall: 0.7602, val_f1: 0.7574\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 08:52:05\n",
            "loss: 0.1309, acc: 0.9408\n",
            "E2E-ABSA >>> 2024-06-04 08:52:14\n",
            "loss: 0.1447, acc: 0.9439\n",
            "E2E-ABSA >>> 2024-06-04 08:52:20\n",
            ">>> val_acc: 0.7368, val_precision: 0.7404 val_recall: 0.7368, val_f1: 0.7383\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 08:52:27\n",
            "loss: 0.1267, acc: 0.9523\n",
            "E2E-ABSA >>> 2024-06-04 08:52:39\n",
            ">>> val_acc: 0.7620, val_precision: 0.7579 val_recall: 0.7620, val_f1: 0.7597\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 08:52:40\n",
            "loss: 0.1359, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 08:52:48\n",
            "loss: 0.1684, acc: 0.9393\n",
            "E2E-ABSA >>> 2024-06-04 08:52:59\n",
            ">>> val_acc: 0.7538, val_precision: 0.7381 val_recall: 0.7538, val_f1: 0.7392\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 08:53:01\n",
            "loss: 0.1023, acc: 0.9621\n",
            "E2E-ABSA >>> 2024-06-04 08:53:09\n",
            "loss: 0.1572, acc: 0.9419\n",
            "E2E-ABSA >>> 2024-06-04 08:53:18\n",
            ">>> val_acc: 0.7030, val_precision: 0.7534 val_recall: 0.7030, val_f1: 0.7183\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 08:53:22\n",
            "loss: 0.1757, acc: 0.9339\n",
            "E2E-ABSA >>> 2024-06-04 08:53:31\n",
            "loss: 0.1609, acc: 0.9400\n",
            "E2E-ABSA >>> 2024-06-04 08:53:37\n",
            ">>> val_acc: 0.7453, val_precision: 0.7218 val_recall: 0.7453, val_f1: 0.7243\n",
            "E2E-ABSA >>> 2024-06-04 08:53:37\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7783, val_precision: 0.7723 val_recall: 0.7783, val_f1: 0.7748\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7783\n",
            ">>> test_acc: 0.7572, test_precision: 0.7438, test_recall: 0.7572, test_f1: 0.7477\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indolem/indobert-base-uncased --valset_ratio 0.5 --log_step 100"
      ],
      "id": "e0632eed-dead-4d03-9551-6da3db1084fe"
    },
    {
      "cell_type": "markdown",
      "id": "0a91b6b8-722f-4da5-879f-27c09bfc6050",
      "metadata": {
        "id": "0a91b6b8-722f-4da5-879f-27c09bfc6050"
      },
      "source": [
        "# Training with indobenchmark/base-p1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "yTjvX9idY9EO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#  menyesuaikan tokenizer BERT untuk indobenchmark\n",
        "path = 'ta-dictabsa/data_utils.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[100] = \"        self.tokenizer = BertTokenizer.from_pretrained(pretrained_bert_name)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "id": "yTjvX9idY9EO"
    },
    {
      "cell_type": "markdown",
      "id": "zpN-kVHeDUds",
      "metadata": {
        "id": "zpN-kVHeDUds"
      },
      "source": [
        "## **indobenchmark/indobert-base-p1** Baseline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l-4FKz9uDeDf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l-4FKz9uDeDf",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "ad6cec8b-3751-45bc-b8e7-f29d8bd1b611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_ori\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7c0383c223b0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/train.tsv', 'test': './datasets/ulasan_combined/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-03 08:05:25\n",
            "loss: 0.8694, acc: 0.6344\n",
            "E2E-ABSA >>> 2024-06-03 08:06:13\n",
            ">>> val_acc: 0.7268, val_precision: 0.7157 val_recall: 0.7268, val_f1: 0.7021\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.7268\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 08:06:23\n",
            "loss: 0.7148, acc: 0.6615\n",
            "E2E-ABSA >>> 2024-06-03 08:07:00\n",
            "loss: 0.6579, acc: 0.7046\n",
            "E2E-ABSA >>> 2024-06-03 08:07:39\n",
            ">>> val_acc: 0.7350, val_precision: 0.7470 val_recall: 0.7350, val_f1: 0.7219\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.735\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 08:08:04\n",
            "loss: 0.4783, acc: 0.8034\n",
            "E2E-ABSA >>> 2024-06-03 08:08:41\n",
            "loss: 0.4995, acc: 0.7884\n",
            "E2E-ABSA >>> 2024-06-03 08:09:12\n",
            ">>> val_acc: 0.7581, val_precision: 0.7392 val_recall: 0.7581, val_f1: 0.7256\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.7581\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 08:09:48\n",
            "loss: 0.3881, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-03 08:10:26\n",
            "loss: 0.4113, acc: 0.8372\n",
            "E2E-ABSA >>> 2024-06-03 08:10:47\n",
            ">>> val_acc: 0.7655, val_precision: 0.7671 val_recall: 0.7655, val_f1: 0.7663\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.7655\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 08:11:30\n",
            "loss: 0.2815, acc: 0.8874\n",
            "E2E-ABSA >>> 2024-06-03 08:12:20\n",
            ">>> val_acc: 0.7499, val_precision: 0.7477 val_recall: 0.7499, val_f1: 0.7487\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 08:12:27\n",
            "loss: 0.2560, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-03 08:13:04\n",
            "loss: 0.2748, acc: 0.8953\n",
            "E2E-ABSA >>> 2024-06-03 08:13:45\n",
            ">>> val_acc: 0.7336, val_precision: 0.7650 val_recall: 0.7336, val_f1: 0.7447\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 08:14:01\n",
            "loss: 0.2205, acc: 0.9077\n",
            "E2E-ABSA >>> 2024-06-03 08:14:37\n",
            "loss: 0.2344, acc: 0.9102\n",
            "E2E-ABSA >>> 2024-06-03 08:15:10\n",
            ">>> val_acc: 0.7258, val_precision: 0.7491 val_recall: 0.7258, val_f1: 0.7297\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 08:15:35\n",
            "loss: 0.2452, acc: 0.9072\n",
            "E2E-ABSA >>> 2024-06-03 08:16:11\n",
            "loss: 0.2428, acc: 0.9096\n",
            "E2E-ABSA >>> 2024-06-03 08:16:35\n",
            ">>> val_acc: 0.7560, val_precision: 0.7494 val_recall: 0.7560, val_f1: 0.7521\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 08:17:08\n",
            "loss: 0.1719, acc: 0.9361\n",
            "E2E-ABSA >>> 2024-06-03 08:17:59\n",
            ">>> val_acc: 0.7385, val_precision: 0.7396 val_recall: 0.7385, val_f1: 0.7356\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 08:18:05\n",
            "loss: 0.1601, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 08:18:41\n",
            "loss: 0.1644, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 08:19:24\n",
            ">>> val_acc: 0.7393, val_precision: 0.7381 val_recall: 0.7393, val_f1: 0.7358\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 08:19:39\n",
            "loss: 0.1369, acc: 0.9484\n",
            "E2E-ABSA >>> 2024-06-03 08:20:15\n",
            "loss: 0.1788, acc: 0.9362\n",
            "E2E-ABSA >>> 2024-06-03 08:20:49\n",
            ">>> val_acc: 0.7393, val_precision: 0.7386 val_recall: 0.7393, val_f1: 0.7389\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 08:21:12\n",
            "loss: 0.1418, acc: 0.9473\n",
            "E2E-ABSA >>> 2024-06-03 08:21:49\n",
            "loss: 0.1997, acc: 0.9238\n",
            "E2E-ABSA >>> 2024-06-03 08:22:14\n",
            ">>> val_acc: 0.7314, val_precision: 0.7279 val_recall: 0.7314, val_f1: 0.7286\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 08:22:46\n",
            "loss: 0.1325, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-03 08:23:39\n",
            ">>> val_acc: 0.7407, val_precision: 0.7272 val_recall: 0.7407, val_f1: 0.7188\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 08:23:43\n",
            "loss: 0.1441, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-03 08:24:19\n",
            "loss: 0.1723, acc: 0.9347\n",
            "E2E-ABSA >>> 2024-06-03 08:25:04\n",
            ">>> val_acc: 0.7204, val_precision: 0.7310 val_recall: 0.7204, val_f1: 0.7244\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 08:25:17\n",
            "loss: 0.0863, acc: 0.9653\n",
            "E2E-ABSA >>> 2024-06-03 08:25:53\n",
            "loss: 0.1432, acc: 0.9416\n",
            "E2E-ABSA >>> 2024-06-03 08:26:29\n",
            ">>> val_acc: 0.7300, val_precision: 0.7288 val_recall: 0.7300, val_f1: 0.7290\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 08:26:50\n",
            "loss: 0.1380, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-03 08:27:27\n",
            "loss: 0.1398, acc: 0.9539\n",
            "E2E-ABSA >>> 2024-06-03 08:27:54\n",
            ">>> val_acc: 0.7211, val_precision: 0.7272 val_recall: 0.7211, val_f1: 0.7239\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 08:28:24\n",
            "loss: 0.1450, acc: 0.9405\n",
            "E2E-ABSA >>> 2024-06-03 08:29:18\n",
            ">>> val_acc: 0.7055, val_precision: 0.7313 val_recall: 0.7055, val_f1: 0.7084\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 08:29:21\n",
            "loss: 0.1676, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-03 08:29:58\n",
            "loss: 0.1723, acc: 0.9392\n",
            "E2E-ABSA >>> 2024-06-03 08:30:43\n",
            ">>> val_acc: 0.7293, val_precision: 0.7112 val_recall: 0.7293, val_f1: 0.7171\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 08:30:55\n",
            "loss: 0.0998, acc: 0.9824\n",
            "E2E-ABSA >>> 2024-06-03 08:31:31\n",
            "loss: 0.1046, acc: 0.9697\n",
            "E2E-ABSA >>> 2024-06-03 08:32:08\n",
            ">>> val_acc: 0.7020, val_precision: 0.7158 val_recall: 0.7020, val_f1: 0.7079\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 08:32:29\n",
            "loss: 0.1248, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-06-03 08:33:05\n",
            "loss: 0.1331, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-03 08:33:33\n",
            ">>> val_acc: 0.7226, val_precision: 0.7229 val_recall: 0.7226, val_f1: 0.7225\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 08:34:02\n",
            "loss: 0.1037, acc: 0.9656\n",
            "E2E-ABSA >>> 2024-06-03 08:34:58\n",
            ">>> val_acc: 0.7325, val_precision: 0.7099 val_recall: 0.7325, val_f1: 0.7155\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 08:34:59\n",
            "loss: 0.0325, acc: 1.0000\n",
            "E2E-ABSA >>> 2024-06-03 08:35:35\n",
            "loss: 0.1400, acc: 0.9501\n",
            "E2E-ABSA >>> 2024-06-03 08:36:23\n",
            ">>> val_acc: 0.7155, val_precision: 0.7165 val_recall: 0.7155, val_f1: 0.7160\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 08:36:33\n",
            "loss: 0.1001, acc: 0.9665\n",
            "E2E-ABSA >>> 2024-06-03 08:37:09\n",
            "loss: 0.1058, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-03 08:37:48\n",
            ">>> val_acc: 0.7158, val_precision: 0.7147 val_recall: 0.7158, val_f1: 0.7152\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 08:38:06\n",
            "loss: 0.0988, acc: 0.9700\n",
            "E2E-ABSA >>> 2024-06-03 08:38:43\n",
            "loss: 0.1075, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-03 08:39:12\n",
            ">>> val_acc: 0.7279, val_precision: 0.7074 val_recall: 0.7279, val_f1: 0.7135\n",
            "E2E-ABSA >>> 2024-06-03 08:39:12\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7655, val_precision: 0.7671 val_recall: 0.7655, val_f1: 0.7663\n",
            "you can download the best model from state_dict/bert_spc_combined_ori_val_f1_0.7655\n",
            ">>> test_acc: 0.7445, test_precision: 0.7424, test_recall: 0.7445, test_f1: 0.7431\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_ori --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## indobenchmark/indobert-base-p1 Concatenation"
      ],
      "metadata": {
        "id": "Y5GtT4vyLkb0"
      },
      "id": "Y5GtT4vyLkb0"
    },
    {
      "cell_type": "markdown",
      "id": "243488f2-d0c3-41ed-8055-c7c76fa12bb4",
      "metadata": {
        "id": "243488f2-d0c3-41ed-8055-c7c76fa12bb4"
      },
      "source": [
        "### **indobenchmark/indobert-base-p1** s1 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-mWKgJxc_PI7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-mWKgJxc_PI7",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8411c3c6-5087-45f1-d023-ac0dc7665ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 2.00/2.00 [00:00<00:00, 11.8kB/s]\n",
            "vocab.txt: 100% 229k/229k [00:00<00:00, 2.00MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 678kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.53k/1.53k [00:00<00:00, 8.97MB/s]\n",
            "pytorch_model.bin: 100% 498M/498M [00:01<00:00, 286MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f8d142123b0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/a_raw_know/train.tsv', 'test': './datasets/ulasan_combined/a_raw_know/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-03 07:28:47\n",
            "loss: 0.8448, acc: 0.6338\n",
            "E2E-ABSA >>> 2024-06-03 07:29:36\n",
            ">>> val_acc: 0.7126, val_precision: 0.7111 val_recall: 0.7126, val_f1: 0.6894\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7126\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 07:29:46\n",
            "loss: 0.6965, acc: 0.6875\n",
            "E2E-ABSA >>> 2024-06-03 07:30:22\n",
            "loss: 0.6487, acc: 0.7238\n",
            "E2E-ABSA >>> 2024-06-03 07:31:02\n",
            ">>> val_acc: 0.7137, val_precision: 0.7335 val_recall: 0.7137, val_f1: 0.7080\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7137\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 07:31:25\n",
            "loss: 0.4566, acc: 0.8112\n",
            "E2E-ABSA >>> 2024-06-03 07:32:01\n",
            "loss: 0.5073, acc: 0.7965\n",
            "E2E-ABSA >>> 2024-06-03 07:32:32\n",
            ">>> val_acc: 0.7375, val_precision: 0.7107 val_recall: 0.7375, val_f1: 0.6897\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 07:32:58\n",
            "loss: 0.3961, acc: 0.8290\n",
            "E2E-ABSA >>> 2024-06-03 07:33:35\n",
            "loss: 0.4302, acc: 0.8172\n",
            "E2E-ABSA >>> 2024-06-03 07:33:57\n",
            ">>> val_acc: 0.7421, val_precision: 0.7488 val_recall: 0.7421, val_f1: 0.7451\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7421\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 07:34:37\n",
            "loss: 0.3038, acc: 0.8763\n",
            "E2E-ABSA >>> 2024-06-03 07:35:26\n",
            ">>> val_acc: 0.7155, val_precision: 0.7429 val_recall: 0.7155, val_f1: 0.7256\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 07:35:34\n",
            "loss: 0.2446, acc: 0.9125\n",
            "E2E-ABSA >>> 2024-06-03 07:36:10\n",
            "loss: 0.2849, acc: 0.8891\n",
            "E2E-ABSA >>> 2024-06-03 07:36:52\n",
            ">>> val_acc: 0.6789, val_precision: 0.7543 val_recall: 0.6789, val_f1: 0.6987\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 07:37:08\n",
            "loss: 0.2412, acc: 0.9048\n",
            "E2E-ABSA >>> 2024-06-03 07:37:44\n",
            "loss: 0.2589, acc: 0.9015\n",
            "E2E-ABSA >>> 2024-06-03 07:38:17\n",
            ">>> val_acc: 0.7279, val_precision: 0.7284 val_recall: 0.7279, val_f1: 0.7275\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 07:38:41\n",
            "loss: 0.2898, acc: 0.8833\n",
            "E2E-ABSA >>> 2024-06-03 07:39:18\n",
            "loss: 0.2731, acc: 0.8895\n",
            "E2E-ABSA >>> 2024-06-03 07:39:42\n",
            ">>> val_acc: 0.7233, val_precision: 0.7285 val_recall: 0.7233, val_f1: 0.7222\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 07:40:15\n",
            "loss: 0.1895, acc: 0.9246\n",
            "E2E-ABSA >>> 2024-06-03 07:41:06\n",
            ">>> val_acc: 0.7147, val_precision: 0.7278 val_recall: 0.7147, val_f1: 0.7190\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 07:41:12\n",
            "loss: 0.1845, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 07:41:49\n",
            "loss: 0.1668, acc: 0.9359\n",
            "E2E-ABSA >>> 2024-06-03 07:42:31\n",
            ">>> val_acc: 0.7272, val_precision: 0.7347 val_recall: 0.7272, val_f1: 0.7265\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 07:42:46\n",
            "loss: 0.1332, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-03 07:43:22\n",
            "loss: 0.2027, acc: 0.9210\n",
            "E2E-ABSA >>> 2024-06-03 07:43:56\n",
            ">>> val_acc: 0.7275, val_precision: 0.7156 val_recall: 0.7275, val_f1: 0.7198\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 07:44:20\n",
            "loss: 0.1340, acc: 0.9521\n",
            "E2E-ABSA >>> 2024-06-03 07:44:56\n",
            "loss: 0.1989, acc: 0.9234\n",
            "E2E-ABSA >>> 2024-06-03 07:45:22\n",
            ">>> val_acc: 0.7027, val_precision: 0.7297 val_recall: 0.7027, val_f1: 0.7115\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 07:45:54\n",
            "loss: 0.1854, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-03 07:46:47\n",
            ">>> val_acc: 0.7140, val_precision: 0.7199 val_recall: 0.7140, val_f1: 0.7167\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 07:46:51\n",
            "loss: 0.0774, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-03 07:47:28\n",
            "loss: 0.1394, acc: 0.9481\n",
            "E2E-ABSA >>> 2024-06-03 07:48:12\n",
            ">>> val_acc: 0.7108, val_precision: 0.7197 val_recall: 0.7108, val_f1: 0.7128\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 07:48:25\n",
            "loss: 0.0917, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 07:49:01\n",
            "loss: 0.1413, acc: 0.9485\n",
            "E2E-ABSA >>> 2024-06-03 07:49:37\n",
            ">>> val_acc: 0.7130, val_precision: 0.7036 val_recall: 0.7130, val_f1: 0.7066\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 07:49:58\n",
            "loss: 0.1333, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-03 07:50:35\n",
            "loss: 0.1568, acc: 0.9383\n",
            "E2E-ABSA >>> 2024-06-03 07:51:01\n",
            ">>> val_acc: 0.7261, val_precision: 0.7128 val_recall: 0.7261, val_f1: 0.7178\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 07:51:32\n",
            "loss: 0.1214, acc: 0.9501\n",
            "E2E-ABSA >>> 2024-06-03 07:52:26\n",
            ">>> val_acc: 0.6870, val_precision: 0.7092 val_recall: 0.6870, val_f1: 0.6943\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 07:52:29\n",
            "loss: 0.1224, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 07:53:06\n",
            "loss: 0.1097, acc: 0.9612\n",
            "E2E-ABSA >>> 2024-06-03 07:53:51\n",
            ">>> val_acc: 0.7229, val_precision: 0.7095 val_recall: 0.7229, val_f1: 0.7082\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 07:54:03\n",
            "loss: 0.1404, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-03 07:54:40\n",
            "loss: 0.1261, acc: 0.9508\n",
            "E2E-ABSA >>> 2024-06-03 07:55:16\n",
            ">>> val_acc: 0.6941, val_precision: 0.7062 val_recall: 0.6941, val_f1: 0.6989\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 07:55:37\n",
            "loss: 0.1013, acc: 0.9632\n",
            "E2E-ABSA >>> 2024-06-03 07:56:13\n",
            "loss: 0.1282, acc: 0.9555\n",
            "E2E-ABSA >>> 2024-06-03 07:56:41\n",
            ">>> val_acc: 0.6906, val_precision: 0.7077 val_recall: 0.6906, val_f1: 0.6958\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 07:57:10\n",
            "loss: 0.1021, acc: 0.9648\n",
            "E2E-ABSA >>> 2024-06-03 07:58:06\n",
            ">>> val_acc: 0.7151, val_precision: 0.6981 val_recall: 0.7151, val_f1: 0.7043\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 07:58:08\n",
            "loss: 0.1309, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-03 07:58:44\n",
            "loss: 0.1218, acc: 0.9591\n",
            "E2E-ABSA >>> 2024-06-03 07:59:31\n",
            ">>> val_acc: 0.6927, val_precision: 0.7099 val_recall: 0.6927, val_f1: 0.6980\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 07:59:41\n",
            "loss: 0.1241, acc: 0.9621\n",
            "E2E-ABSA >>> 2024-06-03 08:00:18\n",
            "loss: 0.1244, acc: 0.9590\n",
            "E2E-ABSA >>> 2024-06-03 08:00:56\n",
            ">>> val_acc: 0.6959, val_precision: 0.6962 val_recall: 0.6959, val_f1: 0.6953\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 08:01:15\n",
            "loss: 0.0808, acc: 0.9736\n",
            "E2E-ABSA >>> 2024-06-03 08:01:52\n",
            "loss: 0.1030, acc: 0.9601\n",
            "E2E-ABSA >>> 2024-06-03 08:02:21\n",
            ">>> val_acc: 0.7204, val_precision: 0.7040 val_recall: 0.7204, val_f1: 0.7086\n",
            "E2E-ABSA >>> 2024-06-03 08:02:21\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7421, val_precision: 0.7488 val_recall: 0.7421, val_f1: 0.7451\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7421\n",
            ">>> test_acc: 0.7140, test_precision: 0.7154, test_recall: 0.7140, test_f1: 0.7140\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 4\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OM93XXKgtGxJ",
      "metadata": {
        "id": "OM93XXKgtGxJ"
      },
      "source": [
        "### **indobenchmark/indobert-base-p1** s2 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "c8ebed27-6cd9-4997-8f78-a884e9100513",
        "scrolled": true,
        "id": "AF7r4vEwhh9g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x79f1d60164d0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/f_raw_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/f_raw_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-03 17:37:02\n",
            "loss: 0.9031, acc: 0.6375\n",
            "E2E-ABSA >>> 2024-06-03 17:37:48\n",
            ">>> val_acc: 0.6483, val_precision: 0.6915 val_recall: 0.6483, val_f1: 0.6341\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6483\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 17:38:40\n",
            "loss: 0.7394, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-03 17:39:15\n",
            "loss: 0.7037, acc: 0.7011\n",
            "E2E-ABSA >>> 2024-06-03 17:39:52\n",
            ">>> val_acc: 0.7197, val_precision: 0.7207 val_recall: 0.7197, val_f1: 0.7020\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7197\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 17:40:54\n",
            "loss: 0.5187, acc: 0.7760\n",
            "E2E-ABSA >>> 2024-06-03 17:41:29\n",
            "loss: 0.5577, acc: 0.7644\n",
            "E2E-ABSA >>> 2024-06-03 17:41:58\n",
            ">>> val_acc: 0.7414, val_precision: 0.7180 val_recall: 0.7414, val_f1: 0.7010\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 17:42:23\n",
            "loss: 0.4560, acc: 0.8082\n",
            "E2E-ABSA >>> 2024-06-03 17:42:58\n",
            "loss: 0.4724, acc: 0.8078\n",
            "E2E-ABSA >>> 2024-06-03 17:43:19\n",
            ">>> val_acc: 0.7385, val_precision: 0.7438 val_recall: 0.7385, val_f1: 0.7385\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7385\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 17:44:05\n",
            "loss: 0.3403, acc: 0.8711\n",
            "E2E-ABSA >>> 2024-06-03 17:44:52\n",
            ">>> val_acc: 0.7261, val_precision: 0.7236 val_recall: 0.7261, val_f1: 0.7229\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 17:44:59\n",
            "loss: 0.2782, acc: 0.9031\n",
            "E2E-ABSA >>> 2024-06-03 17:45:34\n",
            "loss: 0.3197, acc: 0.8781\n",
            "E2E-ABSA >>> 2024-06-03 17:46:13\n",
            ">>> val_acc: 0.7037, val_precision: 0.7546 val_recall: 0.7037, val_f1: 0.7199\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 17:46:28\n",
            "loss: 0.2796, acc: 0.8935\n",
            "E2E-ABSA >>> 2024-06-03 17:47:03\n",
            "loss: 0.2998, acc: 0.8837\n",
            "E2E-ABSA >>> 2024-06-03 17:47:34\n",
            ">>> val_acc: 0.7343, val_precision: 0.7392 val_recall: 0.7343, val_f1: 0.7332\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 17:47:58\n",
            "loss: 0.2495, acc: 0.9072\n",
            "E2E-ABSA >>> 2024-06-03 17:48:33\n",
            "loss: 0.2751, acc: 0.8880\n",
            "E2E-ABSA >>> 2024-06-03 17:48:55\n",
            ">>> val_acc: 0.7368, val_precision: 0.7377 val_recall: 0.7368, val_f1: 0.7360\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 17:49:27\n",
            "loss: 0.2041, acc: 0.9164\n",
            "E2E-ABSA >>> 2024-06-03 17:50:16\n",
            ">>> val_acc: 0.7297, val_precision: 0.7181 val_recall: 0.7297, val_f1: 0.7174\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 17:50:21\n",
            "loss: 0.2106, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-03 17:50:56\n",
            "loss: 0.2087, acc: 0.9208\n",
            "E2E-ABSA >>> 2024-06-03 17:51:37\n",
            ">>> val_acc: 0.7361, val_precision: 0.7299 val_recall: 0.7361, val_f1: 0.7294\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 17:51:51\n",
            "loss: 0.1705, acc: 0.9344\n",
            "E2E-ABSA >>> 2024-06-03 17:52:26\n",
            "loss: 0.2067, acc: 0.9214\n",
            "E2E-ABSA >>> 2024-06-03 17:52:58\n",
            ">>> val_acc: 0.7130, val_precision: 0.7318 val_recall: 0.7130, val_f1: 0.7206\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 17:53:20\n",
            "loss: 0.1500, acc: 0.9502\n",
            "E2E-ABSA >>> 2024-06-03 17:53:55\n",
            "loss: 0.2009, acc: 0.9268\n",
            "E2E-ABSA >>> 2024-06-03 17:54:18\n",
            ">>> val_acc: 0.7311, val_precision: 0.7212 val_recall: 0.7311, val_f1: 0.7248\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 17:54:49\n",
            "loss: 0.1568, acc: 0.9425\n",
            "E2E-ABSA >>> 2024-06-03 17:55:39\n",
            ">>> val_acc: 0.7282, val_precision: 0.7229 val_recall: 0.7282, val_f1: 0.7239\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 17:55:44\n",
            "loss: 0.1446, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-03 17:56:19\n",
            "loss: 0.1536, acc: 0.9431\n",
            "E2E-ABSA >>> 2024-06-03 17:57:00\n",
            ">>> val_acc: 0.7236, val_precision: 0.7150 val_recall: 0.7236, val_f1: 0.7177\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 17:57:13\n",
            "loss: 0.0990, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 17:57:48\n",
            "loss: 0.1565, acc: 0.9380\n",
            "E2E-ABSA >>> 2024-06-03 17:58:21\n",
            ">>> val_acc: 0.6991, val_precision: 0.7206 val_recall: 0.6991, val_f1: 0.7072\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 17:58:42\n",
            "loss: 0.1958, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-03 17:59:17\n",
            "loss: 0.1792, acc: 0.9316\n",
            "E2E-ABSA >>> 2024-06-03 17:59:42\n",
            ">>> val_acc: 0.7023, val_precision: 0.7173 val_recall: 0.7023, val_f1: 0.7056\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 18:00:12\n",
            "loss: 0.1181, acc: 0.9598\n",
            "E2E-ABSA >>> 2024-06-03 18:01:03\n",
            ">>> val_acc: 0.6778, val_precision: 0.7191 val_recall: 0.6778, val_f1: 0.6856\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 18:01:06\n",
            "loss: 0.1612, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-03 18:01:41\n",
            "loss: 0.1576, acc: 0.9381\n",
            "E2E-ABSA >>> 2024-06-03 18:02:24\n",
            ">>> val_acc: 0.7162, val_precision: 0.7040 val_recall: 0.7162, val_f1: 0.7089\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 18:02:35\n",
            "loss: 0.1270, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-03 18:03:10\n",
            "loss: 0.1344, acc: 0.9508\n",
            "E2E-ABSA >>> 2024-06-03 18:03:45\n",
            ">>> val_acc: 0.6931, val_precision: 0.7148 val_recall: 0.6931, val_f1: 0.7019\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 18:04:04\n",
            "loss: 0.0930, acc: 0.9621\n",
            "E2E-ABSA >>> 2024-06-03 18:04:40\n",
            "loss: 0.1314, acc: 0.9483\n",
            "E2E-ABSA >>> 2024-06-03 18:05:06\n",
            ">>> val_acc: 0.7108, val_precision: 0.7080 val_recall: 0.7108, val_f1: 0.7093\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 18:05:34\n",
            "loss: 0.1073, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-06-03 18:06:27\n",
            ">>> val_acc: 0.7197, val_precision: 0.7097 val_recall: 0.7197, val_f1: 0.7115\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 18:06:28\n",
            "loss: 0.0514, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-03 18:07:03\n",
            "loss: 0.1221, acc: 0.9537\n",
            "E2E-ABSA >>> 2024-06-03 18:07:48\n",
            ">>> val_acc: 0.7233, val_precision: 0.6990 val_recall: 0.7233, val_f1: 0.7049\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 18:07:57\n",
            "loss: 0.1460, acc: 0.9464\n",
            "E2E-ABSA >>> 2024-06-03 18:08:33\n",
            "loss: 0.1184, acc: 0.9536\n",
            "E2E-ABSA >>> 2024-06-03 18:09:08\n",
            ">>> val_acc: 0.7044, val_precision: 0.7135 val_recall: 0.7044, val_f1: 0.7066\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 18:09:27\n",
            "loss: 0.0821, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 18:10:02\n",
            "loss: 0.1086, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-03 18:10:29\n",
            ">>> val_acc: 0.7123, val_precision: 0.6933 val_recall: 0.7123, val_f1: 0.6998\n",
            "E2E-ABSA >>> 2024-06-03 18:10:29\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7385, val_precision: 0.7438 val_recall: 0.7385, val_f1: 0.7385\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.7385\n",
            ">>> test_acc: 0.7165, test_precision: 0.7227, test_recall: 0.7165, test_f1: 0.7137\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "AF7r4vEwhh9g"
    },
    {
      "cell_type": "markdown",
      "id": "47e503c6-6788-410b-9282-90dad704246f",
      "metadata": {
        "id": "47e503c6-6788-410b-9282-90dad704246f"
      },
      "source": [
        "### **indobenchmark/indobert-base-p1** s3 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00575374-641a-4fb7-8309-02de23cdeeea",
      "metadata": {
        "collapsed": true,
        "id": "00575374-641a-4fb7-8309-02de23cdeeea",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3a4b4b0f-3788-478c-b9ea-9909607b8999",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f9d1062f520>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/e_raw_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/e_raw_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-30 15:51:28\n",
            "loss: 0.8395, acc: 0.6488\n",
            "E2E-ABSA >>> 2024-05-30 15:51:39\n",
            ">>> val_acc: 0.7343, val_precision: 0.7084 val_recall: 0.7343, val_f1: 0.7072\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7343\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-30 15:51:42\n",
            "loss: 0.7060, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-05-30 15:51:50\n",
            "loss: 0.6326, acc: 0.7268\n",
            "E2E-ABSA >>> 2024-05-30 15:51:59\n",
            ">>> val_acc: 0.7442, val_precision: 0.7613 val_recall: 0.7442, val_f1: 0.7345\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7442\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-30 15:52:04\n",
            "loss: 0.4545, acc: 0.8060\n",
            "E2E-ABSA >>> 2024-05-30 15:52:12\n",
            "loss: 0.4659, acc: 0.8079\n",
            "E2E-ABSA >>> 2024-05-30 15:52:19\n",
            ">>> val_acc: 0.7478, val_precision: 0.7324 val_recall: 0.7478, val_f1: 0.7057\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-30 15:52:25\n",
            "loss: 0.3672, acc: 0.8524\n",
            "E2E-ABSA >>> 2024-05-30 15:52:34\n",
            "loss: 0.3917, acc: 0.8499\n",
            "E2E-ABSA >>> 2024-05-30 15:52:39\n",
            ">>> val_acc: 0.7492, val_precision: 0.7540 val_recall: 0.7492, val_f1: 0.7513\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7492\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-30 15:52:47\n",
            "loss: 0.2694, acc: 0.8939\n",
            "E2E-ABSA >>> 2024-05-30 15:52:59\n",
            ">>> val_acc: 0.7435, val_precision: 0.7488 val_recall: 0.7435, val_f1: 0.7437\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-30 15:53:01\n",
            "loss: 0.1989, acc: 0.9187\n",
            "E2E-ABSA >>> 2024-05-30 15:53:09\n",
            "loss: 0.2511, acc: 0.9031\n",
            "E2E-ABSA >>> 2024-05-30 15:53:18\n",
            ">>> val_acc: 0.7499, val_precision: 0.7663 val_recall: 0.7499, val_f1: 0.7561\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7499\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-30 15:53:23\n",
            "loss: 0.2223, acc: 0.9176\n",
            "E2E-ABSA >>> 2024-05-30 15:53:31\n",
            "loss: 0.2202, acc: 0.9132\n",
            "E2E-ABSA >>> 2024-05-30 15:53:38\n",
            ">>> val_acc: 0.6963, val_precision: 0.7578 val_recall: 0.6963, val_f1: 0.7123\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-30 15:53:44\n",
            "loss: 0.1855, acc: 0.9347\n",
            "E2E-ABSA >>> 2024-05-30 15:53:53\n",
            "loss: 0.2233, acc: 0.9178\n",
            "E2E-ABSA >>> 2024-05-30 15:53:58\n",
            ">>> val_acc: 0.7510, val_precision: 0.7446 val_recall: 0.7510, val_f1: 0.7468\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-30 15:54:06\n",
            "loss: 0.1897, acc: 0.9226\n",
            "E2E-ABSA >>> 2024-05-30 15:54:18\n",
            ">>> val_acc: 0.7393, val_precision: 0.7464 val_recall: 0.7393, val_f1: 0.7422\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-30 15:54:19\n",
            "loss: 0.1554, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-05-30 15:54:27\n",
            "loss: 0.1651, acc: 0.9407\n",
            "E2E-ABSA >>> 2024-05-30 15:54:37\n",
            ">>> val_acc: 0.7446, val_precision: 0.7226 val_recall: 0.7446, val_f1: 0.7275\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-30 15:54:41\n",
            "loss: 0.1506, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-05-30 15:54:49\n",
            "loss: 0.1594, acc: 0.9379\n",
            "E2E-ABSA >>> 2024-05-30 15:54:57\n",
            ">>> val_acc: 0.7208, val_precision: 0.7287 val_recall: 0.7208, val_f1: 0.7211\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-30 15:55:02\n",
            "loss: 0.1598, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-05-30 15:55:11\n",
            "loss: 0.2023, acc: 0.9253\n",
            "E2E-ABSA >>> 2024-05-30 15:55:16\n",
            ">>> val_acc: 0.7329, val_precision: 0.7289 val_recall: 0.7329, val_f1: 0.7303\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-30 15:55:24\n",
            "loss: 0.1603, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 15:55:36\n",
            ">>> val_acc: 0.7243, val_precision: 0.7160 val_recall: 0.7243, val_f1: 0.7178\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-30 15:55:37\n",
            "loss: 0.1453, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-05-30 15:55:45\n",
            "loss: 0.1406, acc: 0.9498\n",
            "E2E-ABSA >>> 2024-05-30 15:55:55\n",
            ">>> val_acc: 0.7297, val_precision: 0.7296 val_recall: 0.7297, val_f1: 0.7290\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-30 15:55:59\n",
            "loss: 0.1206, acc: 0.9514\n",
            "E2E-ABSA >>> 2024-05-30 15:56:07\n",
            "loss: 0.1636, acc: 0.9389\n",
            "E2E-ABSA >>> 2024-05-30 15:56:15\n",
            ">>> val_acc: 0.7172, val_precision: 0.7270 val_recall: 0.7172, val_f1: 0.7216\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-30 15:56:20\n",
            "loss: 0.1472, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-05-30 15:56:29\n",
            "loss: 0.1500, acc: 0.9422\n",
            "E2E-ABSA >>> 2024-05-30 15:56:35\n",
            ">>> val_acc: 0.7247, val_precision: 0.7285 val_recall: 0.7247, val_f1: 0.7253\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-30 15:56:42\n",
            "loss: 0.1122, acc: 0.9606\n",
            "E2E-ABSA >>> 2024-05-30 15:56:54\n",
            ">>> val_acc: 0.7119, val_precision: 0.7339 val_recall: 0.7119, val_f1: 0.7172\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-30 15:56:55\n",
            "loss: 0.1062, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 15:57:03\n",
            "loss: 0.1338, acc: 0.9537\n",
            "E2E-ABSA >>> 2024-05-30 15:57:14\n",
            ">>> val_acc: 0.7158, val_precision: 0.7176 val_recall: 0.7158, val_f1: 0.7148\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-30 15:57:16\n",
            "loss: 0.1077, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-05-30 15:57:25\n",
            "loss: 0.1227, acc: 0.9545\n",
            "E2E-ABSA >>> 2024-05-30 15:57:33\n",
            ">>> val_acc: 0.6938, val_precision: 0.7149 val_recall: 0.6938, val_f1: 0.7024\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-30 15:57:38\n",
            "loss: 0.1168, acc: 0.9654\n",
            "E2E-ABSA >>> 2024-05-30 15:57:47\n",
            "loss: 0.1345, acc: 0.9535\n",
            "E2E-ABSA >>> 2024-05-30 15:57:53\n",
            ">>> val_acc: 0.7158, val_precision: 0.7077 val_recall: 0.7158, val_f1: 0.7105\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-30 15:58:00\n",
            "loss: 0.1122, acc: 0.9625\n",
            "E2E-ABSA >>> 2024-05-30 15:58:12\n",
            ">>> val_acc: 0.7325, val_precision: 0.7126 val_recall: 0.7325, val_f1: 0.7183\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-30 15:58:13\n",
            "loss: 0.0716, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-30 15:58:21\n",
            "loss: 0.1164, acc: 0.9537\n",
            "E2E-ABSA >>> 2024-05-30 15:58:32\n",
            ">>> val_acc: 0.7208, val_precision: 0.7076 val_recall: 0.7208, val_f1: 0.7125\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-30 15:58:34\n",
            "loss: 0.1117, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-30 15:58:43\n",
            "loss: 0.1162, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-30 15:58:52\n",
            ">>> val_acc: 0.7069, val_precision: 0.7112 val_recall: 0.7069, val_f1: 0.7031\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-30 15:58:56\n",
            "loss: 0.1015, acc: 0.9627\n",
            "E2E-ABSA >>> 2024-05-30 15:59:04\n",
            "loss: 0.1309, acc: 0.9490\n",
            "E2E-ABSA >>> 2024-05-30 15:59:11\n",
            ">>> val_acc: 0.7194, val_precision: 0.7070 val_recall: 0.7194, val_f1: 0.7120\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-30 15:59:18\n",
            "loss: 0.1000, acc: 0.9663\n",
            "E2E-ABSA >>> 2024-05-30 15:59:26\n",
            "loss: 0.1096, acc: 0.9631\n",
            "E2E-ABSA >>> 2024-05-30 15:59:31\n",
            ">>> val_acc: 0.7151, val_precision: 0.7024 val_recall: 0.7151, val_f1: 0.7070\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-30 15:59:39\n",
            "loss: 0.0997, acc: 0.9644\n",
            "E2E-ABSA >>> 2024-05-30 15:59:50\n",
            ">>> val_acc: 0.7041, val_precision: 0.7202 val_recall: 0.7041, val_f1: 0.7109\n",
            "E2E-ABSA >>> 2024-05-30 15:59:50\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7499, val_precision: 0.7663 val_recall: 0.7499, val_f1: 0.7561\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.7499\n",
            ">>> test_acc: 0.7229, test_precision: 0.7373, test_recall: 0.7229, test_f1: 0.7289\n"
          ]
        }
      ],
      "source": [
        "# 30-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83067f58-9c4f-4d4a-be69-f7fb82f313da",
      "metadata": {
        "id": "83067f58-9c4f-4d4a-be69-f7fb82f313da"
      },
      "source": [
        "### **indobenchmark/indobert-base-p1** s4 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e29306-48b2-4125-95a9-94b367c67158",
      "metadata": {
        "collapsed": true,
        "id": "e7e29306-48b2-4125-95a9-94b367c67158",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "0fa1ff39-309b-4ae2-adb3-707186430f12",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5532.\n",
            "> testing dataset count: 2300.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f77b8227520>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/b_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/b_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-30 14:15:30\n",
            "loss: 0.8999, acc: 0.6256\n",
            "E2E-ABSA >>> 2024-05-30 14:15:41\n",
            ">>> val_acc: 0.6898, val_precision: 0.6522 val_recall: 0.6898, val_f1: 0.5937\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6898\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-30 14:15:44\n",
            "loss: 0.7252, acc: 0.6736\n",
            "E2E-ABSA >>> 2024-05-30 14:15:52\n",
            "loss: 0.6882, acc: 0.7096\n",
            "E2E-ABSA >>> 2024-05-30 14:16:01\n",
            ">>> val_acc: 0.7126, val_precision: 0.6855 val_recall: 0.7126, val_f1: 0.6557\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7126\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-30 14:16:06\n",
            "loss: 0.5954, acc: 0.7593\n",
            "E2E-ABSA >>> 2024-05-30 14:16:14\n",
            "loss: 0.5925, acc: 0.7435\n",
            "E2E-ABSA >>> 2024-05-30 14:16:20\n",
            ">>> val_acc: 0.7285, val_precision: 0.7063 val_recall: 0.7285, val_f1: 0.6978\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7285\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-30 14:16:28\n",
            "loss: 0.5132, acc: 0.7870\n",
            "E2E-ABSA >>> 2024-05-30 14:16:40\n",
            ">>> val_acc: 0.7303, val_precision: 0.7226 val_recall: 0.7303, val_f1: 0.7239\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7303\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-30 14:16:41\n",
            "loss: 0.3400, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-05-30 14:16:50\n",
            "loss: 0.4187, acc: 0.8362\n",
            "E2E-ABSA >>> 2024-05-30 14:17:00\n",
            ">>> val_acc: 0.7220, val_precision: 0.7161 val_recall: 0.7220, val_f1: 0.7187\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-30 14:17:03\n",
            "loss: 0.3451, acc: 0.8625\n",
            "E2E-ABSA >>> 2024-05-30 14:17:11\n",
            "loss: 0.4040, acc: 0.8431\n",
            "E2E-ABSA >>> 2024-05-30 14:17:19\n",
            ">>> val_acc: 0.7187, val_precision: 0.7051 val_recall: 0.7187, val_f1: 0.6859\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-30 14:17:24\n",
            "loss: 0.3628, acc: 0.8589\n",
            "E2E-ABSA >>> 2024-05-30 14:17:33\n",
            "loss: 0.3559, acc: 0.8519\n",
            "E2E-ABSA >>> 2024-05-30 14:17:38\n",
            ">>> val_acc: 0.7281, val_precision: 0.7039 val_recall: 0.7281, val_f1: 0.7068\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-30 14:17:46\n",
            "loss: 0.3249, acc: 0.8764\n",
            "E2E-ABSA >>> 2024-05-30 14:17:58\n",
            ">>> val_acc: 0.7216, val_precision: 0.7132 val_recall: 0.7216, val_f1: 0.7137\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-30 14:17:59\n",
            "loss: 0.2586, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-05-30 14:18:08\n",
            "loss: 0.2586, acc: 0.8987\n",
            "E2E-ABSA >>> 2024-05-30 14:18:17\n",
            ">>> val_acc: 0.7090, val_precision: 0.7003 val_recall: 0.7090, val_f1: 0.6969\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-30 14:18:21\n",
            "loss: 0.2364, acc: 0.9070\n",
            "E2E-ABSA >>> 2024-05-30 14:18:29\n",
            "loss: 0.2682, acc: 0.8951\n",
            "E2E-ABSA >>> 2024-05-30 14:18:36\n",
            ">>> val_acc: 0.7032, val_precision: 0.7037 val_recall: 0.7032, val_f1: 0.7013\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-30 14:18:42\n",
            "loss: 0.1937, acc: 0.9259\n",
            "E2E-ABSA >>> 2024-05-30 14:18:51\n",
            "loss: 0.2293, acc: 0.9103\n",
            "E2E-ABSA >>> 2024-05-30 14:18:56\n",
            ">>> val_acc: 0.6819, val_precision: 0.7011 val_recall: 0.6819, val_f1: 0.6881\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-30 14:19:04\n",
            "loss: 0.2102, acc: 0.9130\n",
            "E2E-ABSA >>> 2024-05-30 14:19:15\n",
            ">>> val_acc: 0.7090, val_precision: 0.6936 val_recall: 0.7090, val_f1: 0.6996\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-30 14:19:17\n",
            "loss: 0.1710, acc: 0.9271\n",
            "E2E-ABSA >>> 2024-05-30 14:19:26\n",
            "loss: 0.2093, acc: 0.9158\n",
            "E2E-ABSA >>> 2024-05-30 14:19:34\n",
            ">>> val_acc: 0.7140, val_precision: 0.6836 val_recall: 0.7140, val_f1: 0.6855\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-30 14:19:39\n",
            "loss: 0.1572, acc: 0.9350\n",
            "E2E-ABSA >>> 2024-05-30 14:19:47\n",
            "loss: 0.1942, acc: 0.9247\n",
            "E2E-ABSA >>> 2024-05-30 14:19:54\n",
            ">>> val_acc: 0.6869, val_precision: 0.6823 val_recall: 0.6869, val_f1: 0.6826\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-30 14:20:00\n",
            "loss: 0.1535, acc: 0.9399\n",
            "E2E-ABSA >>> 2024-05-30 14:20:13\n",
            ">>> val_acc: 0.6826, val_precision: 0.6851 val_recall: 0.6826, val_f1: 0.6835\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-30 14:20:13\n",
            "loss: 0.1228, acc: 0.9500\n",
            "E2E-ABSA >>> 2024-05-30 14:20:22\n",
            "loss: 0.1682, acc: 0.9315\n",
            "E2E-ABSA >>> 2024-05-30 14:20:32\n",
            ">>> val_acc: 0.6923, val_precision: 0.6911 val_recall: 0.6923, val_f1: 0.6917\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-30 14:20:35\n",
            "loss: 0.1262, acc: 0.9551\n",
            "E2E-ABSA >>> 2024-05-30 14:20:44\n",
            "loss: 0.1612, acc: 0.9408\n",
            "E2E-ABSA >>> 2024-05-30 14:20:52\n",
            ">>> val_acc: 0.6941, val_precision: 0.6848 val_recall: 0.6941, val_f1: 0.6889\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-30 14:20:57\n",
            "loss: 0.1236, acc: 0.9544\n",
            "E2E-ABSA >>> 2024-05-30 14:21:05\n",
            "loss: 0.1570, acc: 0.9359\n",
            "E2E-ABSA >>> 2024-05-30 14:21:11\n",
            ">>> val_acc: 0.6909, val_precision: 0.6951 val_recall: 0.6909, val_f1: 0.6857\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-30 14:21:18\n",
            "loss: 0.1377, acc: 0.9448\n",
            "E2E-ABSA >>> 2024-05-30 14:21:30\n",
            ">>> val_acc: 0.6764, val_precision: 0.6841 val_recall: 0.6764, val_f1: 0.6793\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-30 14:21:31\n",
            "loss: 0.1179, acc: 0.9663\n",
            "E2E-ABSA >>> 2024-05-30 14:21:40\n",
            "loss: 0.1512, acc: 0.9425\n",
            "E2E-ABSA >>> 2024-05-30 14:21:50\n",
            ">>> val_acc: 0.7007, val_precision: 0.6706 val_recall: 0.7007, val_f1: 0.6761\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-30 14:21:53\n",
            "loss: 0.1715, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-05-30 14:22:02\n",
            "loss: 0.1640, acc: 0.9362\n",
            "E2E-ABSA >>> 2024-05-30 14:22:09\n",
            ">>> val_acc: 0.7072, val_precision: 0.6732 val_recall: 0.7072, val_f1: 0.6714\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-30 14:22:15\n",
            "loss: 0.1084, acc: 0.9646\n",
            "E2E-ABSA >>> 2024-05-30 14:22:23\n",
            "loss: 0.1447, acc: 0.9472\n",
            "E2E-ABSA >>> 2024-05-30 14:22:28\n",
            ">>> val_acc: 0.6916, val_precision: 0.6731 val_recall: 0.6916, val_f1: 0.6793\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-30 14:22:36\n",
            "loss: 0.1234, acc: 0.9488\n",
            "E2E-ABSA >>> 2024-05-30 14:22:48\n",
            ">>> val_acc: 0.6663, val_precision: 0.6865 val_recall: 0.6663, val_f1: 0.6742\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-30 14:22:49\n",
            "loss: 0.0993, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-05-30 14:22:58\n",
            "loss: 0.1148, acc: 0.9556\n",
            "E2E-ABSA >>> 2024-05-30 14:23:07\n",
            ">>> val_acc: 0.6938, val_precision: 0.6671 val_recall: 0.6938, val_f1: 0.6745\n",
            "E2E-ABSA >>> 2024-05-30 14:23:07\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7303, val_precision: 0.7226 val_recall: 0.7303, val_f1: 0.7239\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7303\n",
            ">>> test_acc: 0.6991, test_precision: 0.6900, test_recall: 0.6991, test_f1: 0.6867\n"
          ]
        }
      ],
      "source": [
        "# 30-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd0ee17-26ed-4d14-bf47-e6015b03d2e2",
      "metadata": {
        "id": "2dd0ee17-26ed-4d14-bf47-e6015b03d2e2"
      },
      "source": [
        "### **indobenchmark/indobert-base-p1** s5 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a63b147-7b0f-4b0a-adec-4bfacd56cbec",
      "metadata": {
        "collapsed": true,
        "id": "3a63b147-7b0f-4b0a-adec-4bfacd56cbec",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "60277546-aaed-4ea2-df92-7ffc5595bd6b",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fc287523520>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/c_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/c_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-30 14:46:26\n",
            "loss: 0.8710, acc: 0.6631\n",
            "E2E-ABSA >>> 2024-05-30 14:46:37\n",
            ">>> val_acc: 0.6955, val_precision: 0.6174 val_recall: 0.6955, val_f1: 0.6221\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6955\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-30 14:46:40\n",
            "loss: 0.6476, acc: 0.7222\n",
            "E2E-ABSA >>> 2024-05-30 14:46:49\n",
            "loss: 0.6731, acc: 0.7156\n",
            "E2E-ABSA >>> 2024-05-30 14:46:57\n",
            ">>> val_acc: 0.7458, val_precision: 0.7327 val_recall: 0.7458, val_f1: 0.7176\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7458\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-30 14:47:02\n",
            "loss: 0.5127, acc: 0.7731\n",
            "E2E-ABSA >>> 2024-05-30 14:47:11\n",
            "loss: 0.5300, acc: 0.7768\n",
            "E2E-ABSA >>> 2024-05-30 14:47:17\n",
            ">>> val_acc: 0.7487, val_precision: 0.7337 val_recall: 0.7487, val_f1: 0.7180\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7487\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-30 14:47:24\n",
            "loss: 0.4143, acc: 0.8310\n",
            "E2E-ABSA >>> 2024-05-30 14:47:36\n",
            ">>> val_acc: 0.7433, val_precision: 0.7452 val_recall: 0.7433, val_f1: 0.7437\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7433\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-30 14:47:38\n",
            "loss: 0.2567, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-05-30 14:47:46\n",
            "loss: 0.3296, acc: 0.8657\n",
            "E2E-ABSA >>> 2024-05-30 14:47:56\n",
            ">>> val_acc: 0.7444, val_precision: 0.7388 val_recall: 0.7444, val_f1: 0.7400\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-30 14:47:59\n",
            "loss: 0.3032, acc: 0.8804\n",
            "E2E-ABSA >>> 2024-05-30 14:48:08\n",
            "loss: 0.2992, acc: 0.8861\n",
            "E2E-ABSA >>> 2024-05-30 14:48:15\n",
            ">>> val_acc: 0.7393, val_precision: 0.7322 val_recall: 0.7393, val_f1: 0.7334\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-30 14:48:21\n",
            "loss: 0.2356, acc: 0.9173\n",
            "E2E-ABSA >>> 2024-05-30 14:48:29\n",
            "loss: 0.2591, acc: 0.9020\n",
            "E2E-ABSA >>> 2024-05-30 14:48:35\n",
            ">>> val_acc: 0.6792, val_precision: 0.7461 val_recall: 0.6792, val_f1: 0.6984\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-30 14:48:42\n",
            "loss: 0.2236, acc: 0.9143\n",
            "E2E-ABSA >>> 2024-05-30 14:48:54\n",
            ">>> val_acc: 0.7136, val_precision: 0.7231 val_recall: 0.7136, val_f1: 0.7145\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-30 14:48:55\n",
            "loss: 0.1965, acc: 0.9336\n",
            "E2E-ABSA >>> 2024-05-30 14:49:04\n",
            "loss: 0.2149, acc: 0.9224\n",
            "E2E-ABSA >>> 2024-05-30 14:49:13\n",
            ">>> val_acc: 0.7129, val_precision: 0.7200 val_recall: 0.7129, val_f1: 0.7161\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-30 14:49:17\n",
            "loss: 0.1718, acc: 0.9331\n",
            "E2E-ABSA >>> 2024-05-30 14:49:25\n",
            "loss: 0.1964, acc: 0.9218\n",
            "E2E-ABSA >>> 2024-05-30 14:49:33\n",
            ">>> val_acc: 0.7263, val_precision: 0.7101 val_recall: 0.7263, val_f1: 0.7084\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-30 14:49:38\n",
            "loss: 0.1618, acc: 0.9393\n",
            "E2E-ABSA >>> 2024-05-30 14:49:47\n",
            "loss: 0.1978, acc: 0.9294\n",
            "E2E-ABSA >>> 2024-05-30 14:49:52\n",
            ">>> val_acc: 0.7118, val_precision: 0.7142 val_recall: 0.7118, val_f1: 0.7128\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-30 14:50:00\n",
            "loss: 0.1590, acc: 0.9388\n",
            "E2E-ABSA >>> 2024-05-30 14:50:11\n",
            ">>> val_acc: 0.6796, val_precision: 0.7115 val_recall: 0.6796, val_f1: 0.6896\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-30 14:50:13\n",
            "loss: 0.1744, acc: 0.9193\n",
            "E2E-ABSA >>> 2024-05-30 14:50:22\n",
            "loss: 0.1514, acc: 0.9385\n",
            "E2E-ABSA >>> 2024-05-30 14:50:30\n",
            ">>> val_acc: 0.6506, val_precision: 0.7075 val_recall: 0.6506, val_f1: 0.6663\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-30 14:50:35\n",
            "loss: 0.1461, acc: 0.9534\n",
            "E2E-ABSA >>> 2024-05-30 14:50:43\n",
            "loss: 0.1653, acc: 0.9408\n",
            "E2E-ABSA >>> 2024-05-30 14:50:50\n",
            ">>> val_acc: 0.6941, val_precision: 0.7063 val_recall: 0.6941, val_f1: 0.6989\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-30 14:50:56\n",
            "loss: 0.1691, acc: 0.9415\n",
            "E2E-ABSA >>> 2024-05-30 14:51:09\n",
            ">>> val_acc: 0.7140, val_precision: 0.7145 val_recall: 0.7140, val_f1: 0.7124\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-30 14:51:09\n",
            "loss: 0.1185, acc: 0.9625\n",
            "E2E-ABSA >>> 2024-05-30 14:51:18\n",
            "loss: 0.1339, acc: 0.9548\n",
            "E2E-ABSA >>> 2024-05-30 14:51:28\n",
            ">>> val_acc: 0.7060, val_precision: 0.7046 val_recall: 0.7060, val_f1: 0.7053\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-30 14:51:31\n",
            "loss: 0.1487, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-05-30 14:51:39\n",
            "loss: 0.1545, acc: 0.9394\n",
            "E2E-ABSA >>> 2024-05-30 14:51:47\n",
            ">>> val_acc: 0.7183, val_precision: 0.6997 val_recall: 0.7183, val_f1: 0.7050\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-30 14:51:52\n",
            "loss: 0.1818, acc: 0.9290\n",
            "E2E-ABSA >>> 2024-05-30 14:52:01\n",
            "loss: 0.1509, acc: 0.9438\n",
            "E2E-ABSA >>> 2024-05-30 14:52:07\n",
            ">>> val_acc: 0.6933, val_precision: 0.7062 val_recall: 0.6933, val_f1: 0.6962\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-30 14:52:14\n",
            "loss: 0.1479, acc: 0.9462\n",
            "E2E-ABSA >>> 2024-05-30 14:52:26\n",
            ">>> val_acc: 0.7151, val_precision: 0.6966 val_recall: 0.7151, val_f1: 0.7025\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-30 14:52:27\n",
            "loss: 0.1216, acc: 0.9567\n",
            "E2E-ABSA >>> 2024-05-30 14:52:36\n",
            "loss: 0.1267, acc: 0.9519\n",
            "E2E-ABSA >>> 2024-05-30 14:52:45\n",
            ">>> val_acc: 0.6901, val_precision: 0.7020 val_recall: 0.6901, val_f1: 0.6953\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-30 14:52:49\n",
            "loss: 0.1485, acc: 0.9422\n",
            "E2E-ABSA >>> 2024-05-30 14:52:57\n",
            "loss: 0.1348, acc: 0.9482\n",
            "E2E-ABSA >>> 2024-05-30 14:53:04\n",
            ">>> val_acc: 0.6836, val_precision: 0.7023 val_recall: 0.6836, val_f1: 0.6892\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-30 14:53:10\n",
            "loss: 0.1571, acc: 0.9412\n",
            "E2E-ABSA >>> 2024-05-30 14:53:19\n",
            "loss: 0.1444, acc: 0.9480\n",
            "E2E-ABSA >>> 2024-05-30 14:53:24\n",
            ">>> val_acc: 0.6973, val_precision: 0.7014 val_recall: 0.6973, val_f1: 0.6983\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-30 14:53:32\n",
            "loss: 0.1028, acc: 0.9608\n",
            "E2E-ABSA >>> 2024-05-30 14:53:43\n",
            ">>> val_acc: 0.7017, val_precision: 0.6903 val_recall: 0.7017, val_f1: 0.6922\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-30 14:53:45\n",
            "loss: 0.1090, acc: 0.9494\n",
            "E2E-ABSA >>> 2024-05-30 14:53:53\n",
            "loss: 0.1174, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-05-30 14:54:02\n",
            ">>> val_acc: 0.6814, val_precision: 0.6936 val_recall: 0.6814, val_f1: 0.6862\n",
            "E2E-ABSA >>> 2024-05-30 14:54:02\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7433, val_precision: 0.7452 val_recall: 0.7433, val_f1: 0.7437\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7433\n",
            ">>> test_acc: 0.7293, test_precision: 0.7249, test_recall: 0.7293, test_f1: 0.7254\n"
          ]
        }
      ],
      "source": [
        "# 30-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e6e0f13-09ff-4bb3-9c34-d9bf0c9ccc87",
      "metadata": {
        "id": "8e6e0f13-09ff-4bb3-9c34-d9bf0c9ccc87"
      },
      "source": [
        "### **indobenchmark/indobert-base-p1** s6 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24fec6f1-0b7f-4275-8a3f-7d8e8709178a",
      "metadata": {
        "collapsed": true,
        "id": "24fec6f1-0b7f-4275-8a3f-7d8e8709178a",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b36bd457-efff-487e-cd82-1eb11028ae5d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f7068233520>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/d_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/d_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-30 15:19:57\n",
            "loss: 0.8952, acc: 0.6644\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-05-30 15:20:07\n",
            ">>> val_acc: 0.6803, val_precision: 0.5704 val_recall: 0.6803, val_f1: 0.5626\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6803\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-30 15:20:10\n",
            "loss: 0.7110, acc: 0.6852\n",
            "E2E-ABSA >>> 2024-05-30 15:20:19\n",
            "loss: 0.7544, acc: 0.6713\n",
            "E2E-ABSA >>> 2024-05-30 15:20:27\n",
            ">>> val_acc: 0.7053, val_precision: 0.6664 val_recall: 0.7053, val_f1: 0.6293\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7053\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-30 15:20:32\n",
            "loss: 0.6353, acc: 0.7361\n",
            "E2E-ABSA >>> 2024-05-30 15:20:41\n",
            "loss: 0.6219, acc: 0.7321\n",
            "E2E-ABSA >>> 2024-05-30 15:20:47\n",
            ">>> val_acc: 0.7361, val_precision: 0.7212 val_recall: 0.7361, val_f1: 0.7018\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7361\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-30 15:20:54\n",
            "loss: 0.5182, acc: 0.7840\n",
            "E2E-ABSA >>> 2024-05-30 15:21:06\n",
            ">>> val_acc: 0.7343, val_precision: 0.7354 val_recall: 0.7343, val_f1: 0.7307\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7343\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-30 15:21:07\n",
            "loss: 0.4975, acc: 0.7734\n",
            "E2E-ABSA >>> 2024-05-30 15:21:16\n",
            "loss: 0.4220, acc: 0.8304\n",
            "E2E-ABSA >>> 2024-05-30 15:21:26\n",
            ">>> val_acc: 0.7328, val_precision: 0.7297 val_recall: 0.7328, val_f1: 0.7290\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-30 15:21:29\n",
            "loss: 0.3820, acc: 0.8518\n",
            "E2E-ABSA >>> 2024-05-30 15:21:38\n",
            "loss: 0.3789, acc: 0.8458\n",
            "E2E-ABSA >>> 2024-05-30 15:21:45\n",
            ">>> val_acc: 0.7295, val_precision: 0.7337 val_recall: 0.7295, val_f1: 0.7273\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-30 15:21:51\n",
            "loss: 0.2847, acc: 0.9002\n",
            "E2E-ABSA >>> 2024-05-30 15:21:59\n",
            "loss: 0.3192, acc: 0.8746\n",
            "E2E-ABSA >>> 2024-05-30 15:22:05\n",
            ">>> val_acc: 0.7136, val_precision: 0.7337 val_recall: 0.7136, val_f1: 0.7207\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-30 15:22:12\n",
            "loss: 0.2626, acc: 0.8897\n",
            "E2E-ABSA >>> 2024-05-30 15:22:24\n",
            ">>> val_acc: 0.7042, val_precision: 0.7331 val_recall: 0.7042, val_f1: 0.7123\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-30 15:22:25\n",
            "loss: 0.2509, acc: 0.8945\n",
            "E2E-ABSA >>> 2024-05-30 15:22:34\n",
            "loss: 0.2790, acc: 0.8960\n",
            "E2E-ABSA >>> 2024-05-30 15:22:43\n",
            ">>> val_acc: 0.7223, val_precision: 0.7227 val_recall: 0.7223, val_f1: 0.7211\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-30 15:22:47\n",
            "loss: 0.1911, acc: 0.9259\n",
            "E2E-ABSA >>> 2024-05-30 15:22:55\n",
            "loss: 0.2232, acc: 0.9122\n",
            "E2E-ABSA >>> 2024-05-30 15:23:02\n",
            ">>> val_acc: 0.7180, val_precision: 0.7035 val_recall: 0.7180, val_f1: 0.7066\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-30 15:23:08\n",
            "loss: 0.1902, acc: 0.9196\n",
            "E2E-ABSA >>> 2024-05-30 15:23:17\n",
            "loss: 0.2179, acc: 0.9107\n",
            "E2E-ABSA >>> 2024-05-30 15:23:22\n",
            ">>> val_acc: 0.6951, val_precision: 0.7154 val_recall: 0.6951, val_f1: 0.7034\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-30 15:23:30\n",
            "loss: 0.1734, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 15:23:41\n",
            ">>> val_acc: 0.7194, val_precision: 0.6975 val_recall: 0.7194, val_f1: 0.7001\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-30 15:23:43\n",
            "loss: 0.1490, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 15:23:52\n",
            "loss: 0.1689, acc: 0.9365\n",
            "E2E-ABSA >>> 2024-05-30 15:24:00\n",
            ">>> val_acc: 0.6651, val_precision: 0.7179 val_recall: 0.6651, val_f1: 0.6745\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-30 15:24:05\n",
            "loss: 0.1947, acc: 0.9338\n",
            "E2E-ABSA >>> 2024-05-30 15:24:13\n",
            "loss: 0.1861, acc: 0.9313\n",
            "E2E-ABSA >>> 2024-05-30 15:24:20\n",
            ">>> val_acc: 0.6890, val_precision: 0.7171 val_recall: 0.6890, val_f1: 0.6981\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-30 15:24:26\n",
            "loss: 0.1457, acc: 0.9415\n",
            "E2E-ABSA >>> 2024-05-30 15:24:39\n",
            ">>> val_acc: 0.6937, val_precision: 0.7101 val_recall: 0.6937, val_f1: 0.6984\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-30 15:24:40\n",
            "loss: 0.1814, acc: 0.9500\n",
            "E2E-ABSA >>> 2024-05-30 15:24:48\n",
            "loss: 0.1424, acc: 0.9494\n",
            "E2E-ABSA >>> 2024-05-30 15:24:58\n",
            ">>> val_acc: 0.7129, val_precision: 0.6896 val_recall: 0.7129, val_f1: 0.6953\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-30 15:25:01\n",
            "loss: 0.1387, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-05-30 15:25:10\n",
            "loss: 0.1464, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-05-30 15:25:18\n",
            ">>> val_acc: 0.7028, val_precision: 0.7052 val_recall: 0.7028, val_f1: 0.7039\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-30 15:25:23\n",
            "loss: 0.1290, acc: 0.9481\n",
            "E2E-ABSA >>> 2024-05-30 15:25:31\n",
            "loss: 0.1311, acc: 0.9501\n",
            "E2E-ABSA >>> 2024-05-30 15:25:37\n",
            ">>> val_acc: 0.6687, val_precision: 0.6924 val_recall: 0.6687, val_f1: 0.6784\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-30 15:25:44\n",
            "loss: 0.1338, acc: 0.9513\n",
            "E2E-ABSA >>> 2024-05-30 15:25:56\n",
            ">>> val_acc: 0.7136, val_precision: 0.6876 val_recall: 0.7136, val_f1: 0.6934\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-30 15:25:57\n",
            "loss: 0.1476, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 15:26:06\n",
            "loss: 0.1358, acc: 0.9513\n",
            "E2E-ABSA >>> 2024-05-30 15:26:16\n",
            ">>> val_acc: 0.6687, val_precision: 0.6967 val_recall: 0.6687, val_f1: 0.6795\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-30 15:26:19\n",
            "loss: 0.1301, acc: 0.9563\n",
            "E2E-ABSA >>> 2024-05-30 15:26:28\n",
            "loss: 0.1533, acc: 0.9455\n",
            "E2E-ABSA >>> 2024-05-30 15:26:35\n",
            ">>> val_acc: 0.6951, val_precision: 0.6868 val_recall: 0.6951, val_f1: 0.6905\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-30 15:26:41\n",
            "loss: 0.1367, acc: 0.9496\n",
            "E2E-ABSA >>> 2024-05-30 15:26:49\n",
            "loss: 0.1324, acc: 0.9517\n",
            "E2E-ABSA >>> 2024-05-30 15:26:54\n",
            ">>> val_acc: 0.6933, val_precision: 0.6989 val_recall: 0.6933, val_f1: 0.6916\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-30 15:27:02\n",
            "loss: 0.1245, acc: 0.9508\n",
            "E2E-ABSA >>> 2024-05-30 15:27:14\n",
            ">>> val_acc: 0.6908, val_precision: 0.7013 val_recall: 0.6908, val_f1: 0.6871\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-30 15:27:15\n",
            "loss: 0.0874, acc: 0.9643\n",
            "E2E-ABSA >>> 2024-05-30 15:27:24\n",
            "loss: 0.1131, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-05-30 15:27:33\n",
            ">>> val_acc: 0.6781, val_precision: 0.6880 val_recall: 0.6781, val_f1: 0.6826\n",
            "E2E-ABSA >>> 2024-05-30 15:27:33\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7343, val_precision: 0.7354 val_recall: 0.7343, val_f1: 0.7307\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7343\n",
            ">>> test_acc: 0.7206, test_precision: 0.7180, test_recall: 0.7206, test_f1: 0.7134\n"
          ]
        }
      ],
      "source": [
        "# 30-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM3ES7E2ZWfY"
      },
      "source": [
        "## indobenchmark/indobert-base-p1 Insertion"
      ],
      "id": "cM3ES7E2ZWfY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-THgj03Ks4Pd"
      },
      "source": [
        "### indobenchmark/indobert-base-p1 s1 insert"
      ],
      "id": "-THgj03Ks4Pd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xav9IjAxs4Pj",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "1cb3ca6c-8d97-42e6-a67c-a18ed82c3f36",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 2.00/2.00 [00:00<00:00, 12.0kB/s]\n",
            "vocab.txt: 100% 229k/229k [00:00<00:00, 31.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 711kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.53k/1.53k [00:00<00:00, 10.5MB/s]\n",
            "pytorch_model.bin: 100% 498M/498M [00:01<00:00, 315MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f52b340a5f0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-03 16:50:20\n",
            "loss: 0.8501, acc: 0.6294\n",
            "E2E-ABSA >>> 2024-06-03 16:51:03\n",
            ">>> val_acc: 0.7130, val_precision: 0.7137 val_recall: 0.7130, val_f1: 0.6797\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.713\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 16:51:12\n",
            "loss: 0.7089, acc: 0.6875\n",
            "E2E-ABSA >>> 2024-06-03 16:51:47\n",
            "loss: 0.6360, acc: 0.7308\n",
            "E2E-ABSA >>> 2024-06-03 16:52:23\n",
            ">>> val_acc: 0.7435, val_precision: 0.7470 val_recall: 0.7435, val_f1: 0.7325\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7435\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 16:52:52\n",
            "loss: 0.4514, acc: 0.8203\n",
            "E2E-ABSA >>> 2024-06-03 16:53:28\n",
            "loss: 0.4854, acc: 0.7990\n",
            "E2E-ABSA >>> 2024-06-03 16:53:57\n",
            ">>> val_acc: 0.7375, val_precision: 0.7147 val_recall: 0.7375, val_f1: 0.6936\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 16:54:22\n",
            "loss: 0.3656, acc: 0.8368\n",
            "E2E-ABSA >>> 2024-06-03 16:54:57\n",
            "loss: 0.3957, acc: 0.8289\n",
            "E2E-ABSA >>> 2024-06-03 16:55:17\n",
            ">>> val_acc: 0.7599, val_precision: 0.7633 val_recall: 0.7599, val_f1: 0.7613\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7599\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 16:56:04\n",
            "loss: 0.2783, acc: 0.8945\n",
            "E2E-ABSA >>> 2024-06-03 16:56:51\n",
            ">>> val_acc: 0.7147, val_precision: 0.7677 val_recall: 0.7147, val_f1: 0.7261\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 16:56:58\n",
            "loss: 0.2187, acc: 0.9156\n",
            "E2E-ABSA >>> 2024-06-03 16:57:33\n",
            "loss: 0.2451, acc: 0.9016\n",
            "E2E-ABSA >>> 2024-06-03 16:58:12\n",
            ">>> val_acc: 0.7087, val_precision: 0.7571 val_recall: 0.7087, val_f1: 0.7229\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 16:58:27\n",
            "loss: 0.2081, acc: 0.9290\n",
            "E2E-ABSA >>> 2024-06-03 16:59:02\n",
            "loss: 0.2346, acc: 0.9162\n",
            "E2E-ABSA >>> 2024-06-03 16:59:33\n",
            ">>> val_acc: 0.7403, val_precision: 0.7416 val_recall: 0.7403, val_f1: 0.7341\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 16:59:56\n",
            "loss: 0.1763, acc: 0.9412\n",
            "E2E-ABSA >>> 2024-06-03 17:00:32\n",
            "loss: 0.2070, acc: 0.9275\n",
            "E2E-ABSA >>> 2024-06-03 17:00:54\n",
            ">>> val_acc: 0.7496, val_precision: 0.7565 val_recall: 0.7496, val_f1: 0.7527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 17:01:26\n",
            "loss: 0.1546, acc: 0.9368\n",
            "E2E-ABSA >>> 2024-06-03 17:02:14\n",
            ">>> val_acc: 0.7531, val_precision: 0.7500 val_recall: 0.7531, val_f1: 0.7500\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 17:02:20\n",
            "loss: 0.1536, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-03 17:02:55\n",
            "loss: 0.1586, acc: 0.9380\n",
            "E2E-ABSA >>> 2024-06-03 17:03:35\n",
            ">>> val_acc: 0.7464, val_precision: 0.7467 val_recall: 0.7464, val_f1: 0.7414\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 17:03:49\n",
            "loss: 0.1007, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-06-03 17:04:24\n",
            "loss: 0.1582, acc: 0.9411\n",
            "E2E-ABSA >>> 2024-06-03 17:04:56\n",
            ">>> val_acc: 0.6789, val_precision: 0.7346 val_recall: 0.6789, val_f1: 0.6927\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 17:05:19\n",
            "loss: 0.1372, acc: 0.9521\n",
            "E2E-ABSA >>> 2024-06-03 17:05:54\n",
            "loss: 0.1806, acc: 0.9367\n",
            "E2E-ABSA >>> 2024-06-03 17:06:17\n",
            ">>> val_acc: 0.7371, val_precision: 0.7358 val_recall: 0.7371, val_f1: 0.7356\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 17:06:48\n",
            "loss: 0.1318, acc: 0.9567\n",
            "E2E-ABSA >>> 2024-06-03 17:07:38\n",
            ">>> val_acc: 0.7307, val_precision: 0.7223 val_recall: 0.7307, val_f1: 0.7259\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 17:07:42\n",
            "loss: 0.0554, acc: 0.9948\n",
            "E2E-ABSA >>> 2024-06-03 17:08:17\n",
            "loss: 0.1170, acc: 0.9581\n",
            "E2E-ABSA >>> 2024-06-03 17:08:59\n",
            ">>> val_acc: 0.7293, val_precision: 0.7276 val_recall: 0.7293, val_f1: 0.7275\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 17:09:12\n",
            "loss: 0.0611, acc: 0.9792\n",
            "E2E-ABSA >>> 2024-06-03 17:09:47\n",
            "loss: 0.1274, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-06-03 17:10:20\n",
            ">>> val_acc: 0.7201, val_precision: 0.7332 val_recall: 0.7201, val_f1: 0.7257\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 17:10:41\n",
            "loss: 0.1103, acc: 0.9646\n",
            "E2E-ABSA >>> 2024-06-03 17:11:16\n",
            "loss: 0.1147, acc: 0.9625\n",
            "E2E-ABSA >>> 2024-06-03 17:11:41\n",
            ">>> val_acc: 0.6956, val_precision: 0.7074 val_recall: 0.6956, val_f1: 0.6982\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 17:12:10\n",
            "loss: 0.1081, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-06-03 17:13:01\n",
            ">>> val_acc: 0.7336, val_precision: 0.7235 val_recall: 0.7336, val_f1: 0.7258\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 17:13:04\n",
            "loss: 0.0979, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-03 17:13:39\n",
            "loss: 0.0981, acc: 0.9624\n",
            "E2E-ABSA >>> 2024-06-03 17:14:22\n",
            ">>> val_acc: 0.6963, val_precision: 0.7046 val_recall: 0.6963, val_f1: 0.6992\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 17:14:34\n",
            "loss: 0.1150, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-03 17:15:09\n",
            "loss: 0.1315, acc: 0.9560\n",
            "E2E-ABSA >>> 2024-06-03 17:15:43\n",
            ">>> val_acc: 0.7183, val_precision: 0.7111 val_recall: 0.7183, val_f1: 0.7141\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 17:16:03\n",
            "loss: 0.0839, acc: 0.9777\n",
            "E2E-ABSA >>> 2024-06-03 17:16:38\n",
            "loss: 0.1075, acc: 0.9655\n",
            "E2E-ABSA >>> 2024-06-03 17:17:04\n",
            ">>> val_acc: 0.7304, val_precision: 0.7222 val_recall: 0.7304, val_f1: 0.7255\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 17:17:33\n",
            "loss: 0.0748, acc: 0.9719\n",
            "E2E-ABSA >>> 2024-06-03 17:18:25\n",
            ">>> val_acc: 0.7101, val_precision: 0.6997 val_recall: 0.7101, val_f1: 0.7022\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 17:18:27\n",
            "loss: 0.0457, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-03 17:19:02\n",
            "loss: 0.1125, acc: 0.9621\n",
            "E2E-ABSA >>> 2024-06-03 17:19:46\n",
            ">>> val_acc: 0.6931, val_precision: 0.6971 val_recall: 0.6931, val_f1: 0.6882\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 17:19:56\n",
            "loss: 0.0862, acc: 0.9732\n",
            "E2E-ABSA >>> 2024-06-03 17:20:31\n",
            "loss: 0.1115, acc: 0.9629\n",
            "E2E-ABSA >>> 2024-06-03 17:21:07\n",
            ">>> val_acc: 0.7215, val_precision: 0.7004 val_recall: 0.7215, val_f1: 0.7065\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 17:21:25\n",
            "loss: 0.0913, acc: 0.9784\n",
            "E2E-ABSA >>> 2024-06-03 17:22:00\n",
            "loss: 0.1042, acc: 0.9671\n",
            "E2E-ABSA >>> 2024-06-03 17:22:28\n",
            ">>> val_acc: 0.7169, val_precision: 0.6966 val_recall: 0.7169, val_f1: 0.7021\n",
            "E2E-ABSA >>> 2024-06-03 17:22:28\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7599, val_precision: 0.7633 val_recall: 0.7599, val_f1: 0.7613\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7599\n",
            ">>> test_acc: 0.7326, test_precision: 0.7345, test_recall: 0.7326, test_f1: 0.7326\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "Xav9IjAxs4Pj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFm2oYwPZd6B"
      },
      "source": [
        "### indobenchmark/indobert-base-p1 s2 insert"
      ],
      "id": "JFm2oYwPZd6B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s7tsJtu8ZXez",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100% 2.00/2.00 [00:00<00:00, 10.2kB/s]\n",
            "vocab.txt: 100% 229k/229k [00:00<00:00, 11.1MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 761kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.53k/1.53k [00:00<00:00, 9.55MB/s]\n",
            "pytorch_model.bin: 100% 498M/498M [00:01<00:00, 269MB/s]\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7d61e9616290>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-29 22:11:22\n",
            "loss: 0.8886, acc: 0.6369\n",
            "E2E-ABSA >>> 2024-05-29 22:12:09\n",
            ">>> val_acc: 0.6472, val_precision: 0.7288 val_recall: 0.6472, val_f1: 0.6512\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6472\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-29 22:12:23\n",
            "loss: 0.7352, acc: 0.6615\n",
            "E2E-ABSA >>> 2024-05-29 22:12:59\n",
            "loss: 0.6515, acc: 0.7228\n",
            "E2E-ABSA >>> 2024-05-29 22:13:38\n",
            ">>> val_acc: 0.7364, val_precision: 0.7633 val_recall: 0.7364, val_f1: 0.7338\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7364\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-29 22:14:01\n",
            "loss: 0.4599, acc: 0.8138\n",
            "E2E-ABSA >>> 2024-05-29 22:14:37\n",
            "loss: 0.4797, acc: 0.7969\n",
            "E2E-ABSA >>> 2024-05-29 22:15:07\n",
            ">>> val_acc: 0.7336, val_precision: 0.7278 val_recall: 0.7336, val_f1: 0.6748\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-29 22:15:34\n",
            "loss: 0.3896, acc: 0.8299\n",
            "E2E-ABSA >>> 2024-05-29 22:16:10\n",
            "loss: 0.4094, acc: 0.8303\n",
            "E2E-ABSA >>> 2024-05-29 22:16:32\n",
            ">>> val_acc: 0.7627, val_precision: 0.7656 val_recall: 0.7627, val_f1: 0.7628\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7627\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-29 22:17:13\n",
            "loss: 0.2773, acc: 0.8867\n",
            "E2E-ABSA >>> 2024-05-29 22:18:02\n",
            ">>> val_acc: 0.7318, val_precision: 0.7797 val_recall: 0.7318, val_f1: 0.7427\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-29 22:18:09\n",
            "loss: 0.2210, acc: 0.9125\n",
            "E2E-ABSA >>> 2024-05-29 22:18:45\n",
            "loss: 0.2568, acc: 0.8911\n",
            "E2E-ABSA >>> 2024-05-29 22:19:26\n",
            ">>> val_acc: 0.7048, val_precision: 0.7736 val_recall: 0.7048, val_f1: 0.7237\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-29 22:19:42\n",
            "loss: 0.2247, acc: 0.9134\n",
            "E2E-ABSA >>> 2024-05-29 22:20:18\n",
            "loss: 0.2320, acc: 0.9097\n",
            "E2E-ABSA >>> 2024-05-29 22:20:50\n",
            ">>> val_acc: 0.7325, val_precision: 0.7518 val_recall: 0.7325, val_f1: 0.7358\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-29 22:21:14\n",
            "loss: 0.2105, acc: 0.9191\n",
            "E2E-ABSA >>> 2024-05-29 22:21:50\n",
            "loss: 0.2161, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-05-29 22:22:13\n",
            ">>> val_acc: 0.7442, val_precision: 0.7629 val_recall: 0.7442, val_f1: 0.7517\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-29 22:22:47\n",
            "loss: 0.1493, acc: 0.9490\n",
            "E2E-ABSA >>> 2024-05-29 22:23:38\n",
            ">>> val_acc: 0.7517, val_precision: 0.7381 val_recall: 0.7517, val_f1: 0.7414\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-29 22:23:43\n",
            "loss: 0.1651, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-05-29 22:24:20\n",
            "loss: 0.1455, acc: 0.9499\n",
            "E2E-ABSA >>> 2024-05-29 22:25:01\n",
            ">>> val_acc: 0.7364, val_precision: 0.7546 val_recall: 0.7364, val_f1: 0.7368\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-29 22:25:16\n",
            "loss: 0.1061, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-29 22:25:52\n",
            "loss: 0.1233, acc: 0.9571\n",
            "E2E-ABSA >>> 2024-05-29 22:26:25\n",
            ">>> val_acc: 0.7240, val_precision: 0.7240 val_recall: 0.7240, val_f1: 0.7239\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-29 22:26:48\n",
            "loss: 0.1433, acc: 0.9580\n",
            "E2E-ABSA >>> 2024-05-29 22:27:25\n",
            "loss: 0.1571, acc: 0.9455\n",
            "E2E-ABSA >>> 2024-05-29 22:27:49\n",
            ">>> val_acc: 0.7293, val_precision: 0.7278 val_recall: 0.7293, val_f1: 0.7264\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-29 22:28:21\n",
            "loss: 0.1540, acc: 0.9432\n",
            "E2E-ABSA >>> 2024-05-29 22:29:13\n",
            ">>> val_acc: 0.7506, val_precision: 0.7392 val_recall: 0.7506, val_f1: 0.7430\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-29 22:29:17\n",
            "loss: 0.0978, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-29 22:29:54\n",
            "loss: 0.1397, acc: 0.9470\n",
            "E2E-ABSA >>> 2024-05-29 22:30:37\n",
            ">>> val_acc: 0.7432, val_precision: 0.7359 val_recall: 0.7432, val_f1: 0.7367\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-29 22:30:50\n",
            "loss: 0.0477, acc: 0.9809\n",
            "E2E-ABSA >>> 2024-05-29 22:31:26\n",
            "loss: 0.0858, acc: 0.9669\n",
            "E2E-ABSA >>> 2024-05-29 22:32:01\n",
            ">>> val_acc: 0.7368, val_precision: 0.7287 val_recall: 0.7368, val_f1: 0.7322\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-29 22:32:23\n",
            "loss: 0.0850, acc: 0.9708\n",
            "E2E-ABSA >>> 2024-05-29 22:32:59\n",
            "loss: 0.1263, acc: 0.9551\n",
            "E2E-ABSA >>> 2024-05-29 22:33:25\n",
            ">>> val_acc: 0.7410, val_precision: 0.7270 val_recall: 0.7410, val_f1: 0.7310\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-29 22:33:55\n",
            "loss: 0.1215, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-05-29 22:34:49\n",
            ">>> val_acc: 0.7144, val_precision: 0.7340 val_recall: 0.7144, val_f1: 0.7179\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-29 22:34:52\n",
            "loss: 0.1316, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-29 22:35:28\n",
            "loss: 0.1294, acc: 0.9549\n",
            "E2E-ABSA >>> 2024-05-29 22:36:13\n",
            ">>> val_acc: 0.7339, val_precision: 0.7262 val_recall: 0.7339, val_f1: 0.7293\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-29 22:36:25\n",
            "loss: 0.0899, acc: 0.9668\n",
            "E2E-ABSA >>> 2024-05-29 22:37:01\n",
            "loss: 0.1013, acc: 0.9612\n",
            "E2E-ABSA >>> 2024-05-29 22:37:37\n",
            ">>> val_acc: 0.7403, val_precision: 0.7262 val_recall: 0.7403, val_f1: 0.7288\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-29 22:37:57\n",
            "loss: 0.0722, acc: 0.9766\n",
            "E2E-ABSA >>> 2024-05-29 22:38:34\n",
            "loss: 0.1071, acc: 0.9623\n",
            "E2E-ABSA >>> 2024-05-29 22:39:01\n",
            ">>> val_acc: 0.7126, val_precision: 0.7369 val_recall: 0.7126, val_f1: 0.7220\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-29 22:39:30\n",
            "loss: 0.0850, acc: 0.9734\n",
            "E2E-ABSA >>> 2024-05-29 22:40:25\n",
            ">>> val_acc: 0.7172, val_precision: 0.7163 val_recall: 0.7172, val_f1: 0.7142\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-29 22:40:27\n",
            "loss: 0.0159, acc: 1.0000\n",
            "E2E-ABSA >>> 2024-05-29 22:41:03\n",
            "loss: 0.1013, acc: 0.9663\n",
            "E2E-ABSA >>> 2024-05-29 22:41:49\n",
            ">>> val_acc: 0.7069, val_precision: 0.7225 val_recall: 0.7069, val_f1: 0.7125\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-29 22:42:00\n",
            "loss: 0.0686, acc: 0.9777\n",
            "E2E-ABSA >>> 2024-05-29 22:42:36\n",
            "loss: 0.0927, acc: 0.9668\n",
            "E2E-ABSA >>> 2024-05-29 22:43:14\n",
            ">>> val_acc: 0.7229, val_precision: 0.7141 val_recall: 0.7229, val_f1: 0.7177\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-29 22:43:32\n",
            "loss: 0.0726, acc: 0.9736\n",
            "E2E-ABSA >>> 2024-05-29 22:44:09\n",
            "loss: 0.0855, acc: 0.9712\n",
            "E2E-ABSA >>> 2024-05-29 22:44:38\n",
            ">>> val_acc: 0.7293, val_precision: 0.7010 val_recall: 0.7293, val_f1: 0.7020\n",
            "E2E-ABSA >>> 2024-05-29 22:44:38\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7627, val_precision: 0.7656 val_recall: 0.7627, val_f1: 0.7628\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7627\n",
            ">>> test_acc: 0.7364, test_precision: 0.7390, test_recall: 0.7364, test_f1: 0.7332\n"
          ]
        }
      ],
      "source": [
        "# 29-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "s7tsJtu8ZXez"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3734cb39-a204-4298-9a96-a74e8495b310"
      },
      "source": [
        "### indobenchmark/indobert-base-p1 s3 insert"
      ],
      "id": "3734cb39-a204-4298-9a96-a74e8495b310"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ccd70176-45c3-42d6-8a2c-881025c783ef",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fa14200f400>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/z_insert_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/z_insert_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-30 15:38:31\n",
            "loss: 0.8312, acc: 0.6450\n",
            "E2E-ABSA >>> 2024-05-30 15:38:42\n",
            ">>> val_acc: 0.7385, val_precision: 0.7245 val_recall: 0.7385, val_f1: 0.7162\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7385\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-30 15:38:44\n",
            "loss: 0.6916, acc: 0.6901\n",
            "E2E-ABSA >>> 2024-05-30 15:38:53\n",
            "loss: 0.6238, acc: 0.7344\n",
            "E2E-ABSA >>> 2024-05-30 15:39:02\n",
            ">>> val_acc: 0.7375, val_precision: 0.7416 val_recall: 0.7375, val_f1: 0.7267\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7375\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-30 15:39:07\n",
            "loss: 0.4536, acc: 0.8203\n",
            "E2E-ABSA >>> 2024-05-30 15:39:15\n",
            "loss: 0.4703, acc: 0.8087\n",
            "E2E-ABSA >>> 2024-05-30 15:39:22\n",
            ">>> val_acc: 0.7471, val_precision: 0.7246 val_recall: 0.7471, val_f1: 0.7105\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-30 15:39:28\n",
            "loss: 0.3795, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-05-30 15:39:37\n",
            "loss: 0.3988, acc: 0.8412\n",
            "E2E-ABSA >>> 2024-05-30 15:39:42\n",
            ">>> val_acc: 0.7382, val_precision: 0.7473 val_recall: 0.7382, val_f1: 0.7422\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7382\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-30 15:39:50\n",
            "loss: 0.2699, acc: 0.8978\n",
            "E2E-ABSA >>> 2024-05-30 15:40:02\n",
            ">>> val_acc: 0.7279, val_precision: 0.7372 val_recall: 0.7279, val_f1: 0.7303\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-30 15:40:03\n",
            "loss: 0.2010, acc: 0.9313\n",
            "E2E-ABSA >>> 2024-05-30 15:40:12\n",
            "loss: 0.2806, acc: 0.8948\n",
            "E2E-ABSA >>> 2024-05-30 15:40:21\n",
            ">>> val_acc: 0.7520, val_precision: 0.7668 val_recall: 0.7520, val_f1: 0.7575\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.752\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-30 15:40:25\n",
            "loss: 0.2281, acc: 0.9048\n",
            "E2E-ABSA >>> 2024-05-30 15:40:34\n",
            "loss: 0.2434, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-05-30 15:40:41\n",
            ">>> val_acc: 0.7119, val_precision: 0.7546 val_recall: 0.7119, val_f1: 0.7238\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-30 15:40:47\n",
            "loss: 0.1968, acc: 0.9301\n",
            "E2E-ABSA >>> 2024-05-30 15:40:56\n",
            "loss: 0.2094, acc: 0.9170\n",
            "E2E-ABSA >>> 2024-05-30 15:41:01\n",
            ">>> val_acc: 0.7428, val_precision: 0.7330 val_recall: 0.7428, val_f1: 0.7351\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-30 15:41:09\n",
            "loss: 0.1990, acc: 0.9300\n",
            "E2E-ABSA >>> 2024-05-30 15:41:20\n",
            ">>> val_acc: 0.7488, val_precision: 0.7284 val_recall: 0.7488, val_f1: 0.7311\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-30 15:41:22\n",
            "loss: 0.1976, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 15:41:30\n",
            "loss: 0.1788, acc: 0.9305\n",
            "E2E-ABSA >>> 2024-05-30 15:41:40\n",
            ">>> val_acc: 0.7318, val_precision: 0.7354 val_recall: 0.7318, val_f1: 0.7304\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-30 15:41:43\n",
            "loss: 0.1268, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-30 15:41:52\n",
            "loss: 0.1627, acc: 0.9411\n",
            "E2E-ABSA >>> 2024-05-30 15:42:00\n",
            ">>> val_acc: 0.7201, val_precision: 0.7278 val_recall: 0.7201, val_f1: 0.7218\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-30 15:42:05\n",
            "loss: 0.1362, acc: 0.9502\n",
            "E2E-ABSA >>> 2024-05-30 15:42:14\n",
            "loss: 0.1831, acc: 0.9352\n",
            "E2E-ABSA >>> 2024-05-30 15:42:19\n",
            ">>> val_acc: 0.7176, val_precision: 0.7283 val_recall: 0.7176, val_f1: 0.7207\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-30 15:42:27\n",
            "loss: 0.1911, acc: 0.9240\n",
            "E2E-ABSA >>> 2024-05-30 15:42:39\n",
            ">>> val_acc: 0.7222, val_precision: 0.7034 val_recall: 0.7222, val_f1: 0.7074\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-30 15:42:40\n",
            "loss: 0.1731, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-05-30 15:42:48\n",
            "loss: 0.1652, acc: 0.9342\n",
            "E2E-ABSA >>> 2024-05-30 15:42:58\n",
            ">>> val_acc: 0.7215, val_precision: 0.7239 val_recall: 0.7215, val_f1: 0.7222\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-30 15:43:01\n",
            "loss: 0.1321, acc: 0.9497\n",
            "E2E-ABSA >>> 2024-05-30 15:43:10\n",
            "loss: 0.1565, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-05-30 15:43:18\n",
            ">>> val_acc: 0.7027, val_precision: 0.7356 val_recall: 0.7027, val_f1: 0.7145\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-30 15:43:23\n",
            "loss: 0.1205, acc: 0.9573\n",
            "E2E-ABSA >>> 2024-05-30 15:43:32\n",
            "loss: 0.1435, acc: 0.9496\n",
            "E2E-ABSA >>> 2024-05-30 15:43:38\n",
            ">>> val_acc: 0.7243, val_precision: 0.7167 val_recall: 0.7243, val_f1: 0.7190\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-30 15:43:45\n",
            "loss: 0.1148, acc: 0.9598\n",
            "E2E-ABSA >>> 2024-05-30 15:43:57\n",
            ">>> val_acc: 0.7101, val_precision: 0.7270 val_recall: 0.7101, val_f1: 0.7096\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-30 15:43:58\n",
            "loss: 0.0976, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-30 15:44:06\n",
            "loss: 0.1311, acc: 0.9566\n",
            "E2E-ABSA >>> 2024-05-30 15:44:17\n",
            ">>> val_acc: 0.7211, val_precision: 0.7177 val_recall: 0.7211, val_f1: 0.7117\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-30 15:44:19\n",
            "loss: 0.1318, acc: 0.9551\n",
            "E2E-ABSA >>> 2024-05-30 15:44:28\n",
            "loss: 0.1318, acc: 0.9522\n",
            "E2E-ABSA >>> 2024-05-30 15:44:36\n",
            ">>> val_acc: 0.7094, val_precision: 0.7172 val_recall: 0.7094, val_f1: 0.7123\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-30 15:44:41\n",
            "loss: 0.0836, acc: 0.9699\n",
            "E2E-ABSA >>> 2024-05-30 15:44:50\n",
            "loss: 0.1240, acc: 0.9571\n",
            "E2E-ABSA >>> 2024-05-30 15:44:56\n",
            ">>> val_acc: 0.7094, val_precision: 0.7134 val_recall: 0.7094, val_f1: 0.7096\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-30 15:45:03\n",
            "loss: 0.1073, acc: 0.9633\n",
            "E2E-ABSA >>> 2024-05-30 15:45:15\n",
            ">>> val_acc: 0.7172, val_precision: 0.7084 val_recall: 0.7172, val_f1: 0.7122\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-30 15:45:16\n",
            "loss: 0.0353, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-05-30 15:45:24\n",
            "loss: 0.1238, acc: 0.9555\n",
            "E2E-ABSA >>> 2024-05-30 15:45:35\n",
            ">>> val_acc: 0.7261, val_precision: 0.7120 val_recall: 0.7261, val_f1: 0.7168\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-30 15:45:37\n",
            "loss: 0.0951, acc: 0.9576\n",
            "E2E-ABSA >>> 2024-05-30 15:45:46\n",
            "loss: 0.1086, acc: 0.9590\n",
            "E2E-ABSA >>> 2024-05-30 15:45:55\n",
            ">>> val_acc: 0.6963, val_precision: 0.7116 val_recall: 0.6963, val_f1: 0.6959\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-30 15:45:59\n",
            "loss: 0.1016, acc: 0.9663\n",
            "E2E-ABSA >>> 2024-05-30 15:46:08\n",
            "loss: 0.1267, acc: 0.9556\n",
            "E2E-ABSA >>> 2024-05-30 15:46:14\n",
            ">>> val_acc: 0.7226, val_precision: 0.6987 val_recall: 0.7226, val_f1: 0.6979\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-05-30 15:46:21\n",
            "loss: 0.1248, acc: 0.9548\n",
            "E2E-ABSA >>> 2024-05-30 15:46:29\n",
            "loss: 0.1185, acc: 0.9567\n",
            "E2E-ABSA >>> 2024-05-30 15:46:34\n",
            ">>> val_acc: 0.7258, val_precision: 0.7010 val_recall: 0.7258, val_f1: 0.7049\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-05-30 15:46:42\n",
            "loss: 0.1021, acc: 0.9694\n",
            "E2E-ABSA >>> 2024-05-30 15:46:53\n",
            ">>> val_acc: 0.7009, val_precision: 0.7169 val_recall: 0.7009, val_f1: 0.7077\n",
            "E2E-ABSA >>> 2024-05-30 15:46:53\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7520, val_precision: 0.7668 val_recall: 0.7520, val_f1: 0.7575\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.752\n",
            ">>> test_acc: 0.7208, test_precision: 0.7413, test_recall: 0.7208, test_f1: 0.7288\n"
          ]
        }
      ],
      "source": [
        "# 30-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "ccd70176-45c3-42d6-8a2c-881025c783ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be48146d-0ae0-4309-bfbc-440c1b7d2617"
      },
      "source": [
        "### indobenchmark/indobert-base-p1 s4 insert"
      ],
      "id": "be48146d-0ae0-4309-bfbc-440c1b7d2617"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "2cb9779d-04a9-479a-8bc1-1f07b95101ae",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100%|█████████████████| 2.00/2.00 [00:00<00:00, 13.8kB/s]\n",
            "vocab.txt: 100%|█████████████████████████████| 229k/229k [00:00<00:00, 3.71MB/s]\n",
            "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 873kB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████| 1.53k/1.53k [00:00<00:00, 12.5MB/s]\n",
            "pytorch_model.bin: 100%|█████████████████████| 498M/498M [00:06<00:00, 80.6MB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fc18b40f760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/j_insert_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/j_insert_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 09:04:02\n",
            "loss: 0.8424, acc: 0.6381\n",
            "E2E-ABSA >>> 2024-06-04 09:04:13\n",
            ">>> val_acc: 0.7378, val_precision: 0.7166 val_recall: 0.7378, val_f1: 0.6974\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7378\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 09:04:15\n",
            "loss: 0.6946, acc: 0.7005\n",
            "E2E-ABSA >>> 2024-06-04 09:04:24\n",
            "loss: 0.6463, acc: 0.7339\n",
            "E2E-ABSA >>> 2024-06-04 09:04:33\n",
            ">>> val_acc: 0.7691, val_precision: 0.7652 val_recall: 0.7691, val_f1: 0.7556\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7691\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 09:04:38\n",
            "loss: 0.4199, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-04 09:04:46\n",
            "loss: 0.4660, acc: 0.8087\n",
            "E2E-ABSA >>> 2024-06-04 09:04:53\n",
            ">>> val_acc: 0.7570, val_precision: 0.7434 val_recall: 0.7570, val_f1: 0.7219\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 09:04:59\n",
            "loss: 0.3505, acc: 0.8611\n",
            "E2E-ABSA >>> 2024-06-04 09:05:08\n",
            "loss: 0.3748, acc: 0.8514\n",
            "E2E-ABSA >>> 2024-06-04 09:05:13\n",
            ">>> val_acc: 0.7719, val_precision: 0.7757 val_recall: 0.7719, val_f1: 0.7704\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7719\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 09:05:21\n",
            "loss: 0.2285, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-04 09:05:33\n",
            ">>> val_acc: 0.7201, val_precision: 0.7820 val_recall: 0.7201, val_f1: 0.7319\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 09:05:34\n",
            "loss: 0.2512, acc: 0.9000\n",
            "E2E-ABSA >>> 2024-06-04 09:05:43\n",
            "loss: 0.2435, acc: 0.9104\n",
            "E2E-ABSA >>> 2024-06-04 09:05:52\n",
            ">>> val_acc: 0.7382, val_precision: 0.7787 val_recall: 0.7382, val_f1: 0.7506\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 09:05:56\n",
            "loss: 0.1759, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-06-04 09:06:05\n",
            "loss: 0.1741, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-06-04 09:06:12\n",
            ">>> val_acc: 0.7698, val_precision: 0.7628 val_recall: 0.7698, val_f1: 0.7563\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 09:06:18\n",
            "loss: 0.1220, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-06-04 09:06:26\n",
            "loss: 0.1662, acc: 0.9371\n",
            "E2E-ABSA >>> 2024-06-04 09:06:31\n",
            ">>> val_acc: 0.7531, val_precision: 0.7373 val_recall: 0.7531, val_f1: 0.7327\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 09:06:39\n",
            "loss: 0.1459, acc: 0.9409\n",
            "E2E-ABSA >>> 2024-06-04 09:06:51\n",
            ">>> val_acc: 0.7609, val_precision: 0.7476 val_recall: 0.7609, val_f1: 0.7521\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 09:06:52\n",
            "loss: 0.0911, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 09:07:01\n",
            "loss: 0.1455, acc: 0.9456\n",
            "E2E-ABSA >>> 2024-06-04 09:07:10\n",
            ">>> val_acc: 0.7531, val_precision: 0.7379 val_recall: 0.7531, val_f1: 0.7420\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 09:07:14\n",
            "loss: 0.1346, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 09:07:22\n",
            "loss: 0.1317, acc: 0.9549\n",
            "E2E-ABSA >>> 2024-06-04 09:07:30\n",
            ">>> val_acc: 0.7474, val_precision: 0.7582 val_recall: 0.7474, val_f1: 0.7506\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 09:07:35\n",
            "loss: 0.0854, acc: 0.9717\n",
            "E2E-ABSA >>> 2024-06-04 09:07:44\n",
            "loss: 0.1245, acc: 0.9588\n",
            "E2E-ABSA >>> 2024-06-04 09:07:50\n",
            ">>> val_acc: 0.7368, val_precision: 0.7505 val_recall: 0.7368, val_f1: 0.7419\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 09:07:57\n",
            "loss: 0.1217, acc: 0.9574\n",
            "E2E-ABSA >>> 2024-06-04 09:08:09\n",
            ">>> val_acc: 0.7393, val_precision: 0.7174 val_recall: 0.7393, val_f1: 0.7211\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 09:08:10\n",
            "loss: 0.0672, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 09:08:19\n",
            "loss: 0.0962, acc: 0.9676\n",
            "E2E-ABSA >>> 2024-06-04 09:08:29\n",
            ">>> val_acc: 0.7343, val_precision: 0.7427 val_recall: 0.7343, val_f1: 0.7347\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 09:08:32\n",
            "loss: 0.0857, acc: 0.9653\n",
            "E2E-ABSA >>> 2024-06-04 09:08:40\n",
            "loss: 0.1063, acc: 0.9655\n",
            "E2E-ABSA >>> 2024-06-04 09:08:48\n",
            ">>> val_acc: 0.7439, val_precision: 0.7380 val_recall: 0.7439, val_f1: 0.7388\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 09:08:53\n",
            "loss: 0.0922, acc: 0.9708\n",
            "E2E-ABSA >>> 2024-06-04 09:09:02\n",
            "loss: 0.1057, acc: 0.9641\n",
            "E2E-ABSA >>> 2024-06-04 09:09:08\n",
            ">>> val_acc: 0.6970, val_precision: 0.7467 val_recall: 0.6970, val_f1: 0.7117\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 09:09:15\n",
            "loss: 0.1334, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 09:09:27\n",
            ">>> val_acc: 0.7364, val_precision: 0.7332 val_recall: 0.7364, val_f1: 0.7328\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 09:09:28\n",
            "loss: 0.0859, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 09:09:36\n",
            "loss: 0.0639, acc: 0.9797\n",
            "E2E-ABSA >>> 2024-06-04 09:09:47\n",
            ">>> val_acc: 0.7361, val_precision: 0.7267 val_recall: 0.7361, val_f1: 0.7282\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 09:09:49\n",
            "loss: 0.1093, acc: 0.9629\n",
            "E2E-ABSA >>> 2024-06-04 09:09:58\n",
            "loss: 0.0996, acc: 0.9669\n",
            "E2E-ABSA >>> 2024-06-04 09:10:06\n",
            ">>> val_acc: 0.7499, val_precision: 0.7332 val_recall: 0.7499, val_f1: 0.7377\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 09:10:11\n",
            "loss: 0.0867, acc: 0.9654\n",
            "E2E-ABSA >>> 2024-06-04 09:10:20\n",
            "loss: 0.1204, acc: 0.9595\n",
            "E2E-ABSA >>> 2024-06-04 09:10:26\n",
            ">>> val_acc: 0.7385, val_precision: 0.7277 val_recall: 0.7385, val_f1: 0.7261\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 09:10:33\n",
            "loss: 0.0579, acc: 0.9836\n",
            "E2E-ABSA >>> 2024-06-04 09:10:45\n",
            ">>> val_acc: 0.7282, val_precision: 0.7232 val_recall: 0.7282, val_f1: 0.7157\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 09:10:46\n",
            "loss: 0.0812, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 09:10:54\n",
            "loss: 0.0972, acc: 0.9645\n",
            "E2E-ABSA >>> 2024-06-04 09:11:05\n",
            ">>> val_acc: 0.7300, val_precision: 0.7105 val_recall: 0.7300, val_f1: 0.7162\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 09:11:07\n",
            "loss: 0.0468, acc: 0.9911\n",
            "E2E-ABSA >>> 2024-06-04 09:11:16\n",
            "loss: 0.0724, acc: 0.9795\n",
            "E2E-ABSA >>> 2024-06-04 09:11:24\n",
            ">>> val_acc: 0.7268, val_precision: 0.7243 val_recall: 0.7268, val_f1: 0.7249\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 09:11:29\n",
            "loss: 0.0826, acc: 0.9712\n",
            "E2E-ABSA >>> 2024-06-04 09:11:37\n",
            "loss: 0.0974, acc: 0.9704\n",
            "E2E-ABSA >>> 2024-06-04 09:11:44\n",
            ">>> val_acc: 0.7428, val_precision: 0.7219 val_recall: 0.7428, val_f1: 0.7237\n",
            "E2E-ABSA >>> 2024-06-04 09:11:44\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7719, val_precision: 0.7757 val_recall: 0.7719, val_f1: 0.7704\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7719\n",
            ">>> test_acc: 0.7458, test_precision: 0.7430, test_recall: 0.7458, test_f1: 0.7396\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "2cb9779d-04a9-479a-8bc1-1f07b95101ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "874c3402-b340-4746-bcb6-12481d3709db"
      },
      "source": [
        "### indobenchmark/indobert-base-p1 s5 insert"
      ],
      "id": "874c3402-b340-4746-bcb6-12481d3709db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "d99748cd-8ad2-4e31-a119-7818327124ca",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fc47c127760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 09:18:17\n",
            "loss: 0.8580, acc: 0.6331\n",
            "E2E-ABSA >>> 2024-06-04 09:18:28\n",
            ">>> val_acc: 0.7272, val_precision: 0.7075 val_recall: 0.7272, val_f1: 0.6976\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7272\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 09:18:30\n",
            "loss: 0.6840, acc: 0.6875\n",
            "E2E-ABSA >>> 2024-06-04 09:18:39\n",
            "loss: 0.6430, acc: 0.7278\n",
            "E2E-ABSA >>> 2024-06-04 09:18:48\n",
            ">>> val_acc: 0.7560, val_precision: 0.7731 val_recall: 0.7560, val_f1: 0.7508\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.756\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 09:18:53\n",
            "loss: 0.4300, acc: 0.8177\n",
            "E2E-ABSA >>> 2024-06-04 09:19:01\n",
            "loss: 0.4673, acc: 0.7998\n",
            "E2E-ABSA >>> 2024-06-04 09:19:08\n",
            ">>> val_acc: 0.7712, val_precision: 0.7635 val_recall: 0.7712, val_f1: 0.7388\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 09:19:14\n",
            "loss: 0.3540, acc: 0.8576\n",
            "E2E-ABSA >>> 2024-06-04 09:19:23\n",
            "loss: 0.3840, acc: 0.8398\n",
            "E2E-ABSA >>> 2024-06-04 09:19:28\n",
            ">>> val_acc: 0.7769, val_precision: 0.7767 val_recall: 0.7769, val_f1: 0.7726\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7769\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 09:19:37\n",
            "loss: 0.2520, acc: 0.9030\n",
            "E2E-ABSA >>> 2024-06-04 09:19:48\n",
            ">>> val_acc: 0.7737, val_precision: 0.7839 val_recall: 0.7737, val_f1: 0.7742\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7737\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 09:19:50\n",
            "loss: 0.2017, acc: 0.9156\n",
            "E2E-ABSA >>> 2024-06-04 09:19:59\n",
            "loss: 0.2326, acc: 0.9073\n",
            "E2E-ABSA >>> 2024-06-04 09:20:08\n",
            ">>> val_acc: 0.7460, val_precision: 0.7859 val_recall: 0.7460, val_f1: 0.7586\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 09:20:12\n",
            "loss: 0.1975, acc: 0.9190\n",
            "E2E-ABSA >>> 2024-06-04 09:20:21\n",
            "loss: 0.1761, acc: 0.9349\n",
            "E2E-ABSA >>> 2024-06-04 09:20:28\n",
            ">>> val_acc: 0.7719, val_precision: 0.7714 val_recall: 0.7719, val_f1: 0.7622\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 09:20:34\n",
            "loss: 0.1439, acc: 0.9476\n",
            "E2E-ABSA >>> 2024-06-04 09:20:42\n",
            "loss: 0.1701, acc: 0.9349\n",
            "E2E-ABSA >>> 2024-06-04 09:20:48\n",
            ">>> val_acc: 0.7503, val_precision: 0.7711 val_recall: 0.7503, val_f1: 0.7576\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 09:20:55\n",
            "loss: 0.1422, acc: 0.9457\n",
            "E2E-ABSA >>> 2024-06-04 09:21:07\n",
            ">>> val_acc: 0.7506, val_precision: 0.7663 val_recall: 0.7506, val_f1: 0.7553\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 09:21:09\n",
            "loss: 0.1237, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-04 09:21:17\n",
            "loss: 0.1335, acc: 0.9510\n",
            "E2E-ABSA >>> 2024-06-04 09:21:27\n",
            ">>> val_acc: 0.7609, val_precision: 0.7572 val_recall: 0.7609, val_f1: 0.7576\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 09:21:30\n",
            "loss: 0.0959, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 09:21:39\n",
            "loss: 0.1289, acc: 0.9496\n",
            "E2E-ABSA >>> 2024-06-04 09:21:47\n",
            ">>> val_acc: 0.7446, val_precision: 0.7593 val_recall: 0.7446, val_f1: 0.7506\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 09:21:52\n",
            "loss: 0.0816, acc: 0.9717\n",
            "E2E-ABSA >>> 2024-06-04 09:22:01\n",
            "loss: 0.1148, acc: 0.9581\n",
            "E2E-ABSA >>> 2024-06-04 09:22:06\n",
            ">>> val_acc: 0.7538, val_precision: 0.7677 val_recall: 0.7538, val_f1: 0.7595\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 09:22:14\n",
            "loss: 0.1049, acc: 0.9624\n",
            "E2E-ABSA >>> 2024-06-04 09:22:26\n",
            ">>> val_acc: 0.7599, val_precision: 0.7430 val_recall: 0.7599, val_f1: 0.7436\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 09:22:27\n",
            "loss: 0.0931, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 09:22:35\n",
            "loss: 0.1101, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 09:22:46\n",
            ">>> val_acc: 0.7570, val_precision: 0.7399 val_recall: 0.7570, val_f1: 0.7433\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 09:22:49\n",
            "loss: 0.0935, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-06-04 09:22:57\n",
            "loss: 0.1049, acc: 0.9605\n",
            "E2E-ABSA >>> 2024-06-04 09:23:05\n",
            ">>> val_acc: 0.7304, val_precision: 0.7530 val_recall: 0.7304, val_f1: 0.7391\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 09:23:10\n",
            "loss: 0.0936, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 09:23:19\n",
            "loss: 0.1166, acc: 0.9613\n",
            "E2E-ABSA >>> 2024-06-04 09:23:25\n",
            ">>> val_acc: 0.7265, val_precision: 0.7668 val_recall: 0.7265, val_f1: 0.7376\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 09:23:32\n",
            "loss: 0.0755, acc: 0.9702\n",
            "E2E-ABSA >>> 2024-06-04 09:23:45\n",
            ">>> val_acc: 0.7375, val_precision: 0.7440 val_recall: 0.7375, val_f1: 0.7326\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 09:23:45\n",
            "loss: 0.0911, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 09:23:54\n",
            "loss: 0.0930, acc: 0.9664\n",
            "E2E-ABSA >>> 2024-06-04 09:24:04\n",
            ">>> val_acc: 0.7389, val_precision: 0.7456 val_recall: 0.7389, val_f1: 0.7418\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 09:24:07\n",
            "loss: 0.0606, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 09:24:16\n",
            "loss: 0.0718, acc: 0.9801\n",
            "E2E-ABSA >>> 2024-06-04 09:24:24\n",
            ">>> val_acc: 0.7492, val_precision: 0.7367 val_recall: 0.7492, val_f1: 0.7402\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 09:24:29\n",
            "loss: 0.0882, acc: 0.9721\n",
            "E2E-ABSA >>> 2024-06-04 09:24:37\n",
            "loss: 0.0876, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 09:24:44\n",
            ">>> val_acc: 0.7382, val_precision: 0.7214 val_recall: 0.7382, val_f1: 0.7265\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 09:24:50\n",
            "loss: 0.0632, acc: 0.9789\n",
            "E2E-ABSA >>> 2024-06-04 09:25:03\n",
            ">>> val_acc: 0.7428, val_precision: 0.7200 val_recall: 0.7428, val_f1: 0.7208\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 09:25:04\n",
            "loss: 0.0693, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 09:25:12\n",
            "loss: 0.0866, acc: 0.9675\n",
            "E2E-ABSA >>> 2024-06-04 09:25:23\n",
            ">>> val_acc: 0.7314, val_precision: 0.7413 val_recall: 0.7314, val_f1: 0.7328\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 09:25:25\n",
            "loss: 0.0537, acc: 0.9888\n",
            "E2E-ABSA >>> 2024-06-04 09:25:34\n",
            "loss: 0.0777, acc: 0.9771\n",
            "E2E-ABSA >>> 2024-06-04 09:25:43\n",
            ">>> val_acc: 0.7432, val_precision: 0.7276 val_recall: 0.7432, val_f1: 0.7311\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 09:25:47\n",
            "loss: 0.0455, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 09:25:55\n",
            "loss: 0.0628, acc: 0.9790\n",
            "E2E-ABSA >>> 2024-06-04 09:26:02\n",
            ">>> val_acc: 0.7385, val_precision: 0.7268 val_recall: 0.7385, val_f1: 0.7302\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 09:26:09\n",
            "loss: 0.0743, acc: 0.9729\n",
            "E2E-ABSA >>> 2024-06-04 09:26:17\n",
            "loss: 0.0724, acc: 0.9751\n",
            "E2E-ABSA >>> 2024-06-04 09:26:22\n",
            ">>> val_acc: 0.7396, val_precision: 0.7332 val_recall: 0.7396, val_f1: 0.7349\n",
            "E2E-ABSA >>> 2024-06-04 09:26:22\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7737, val_precision: 0.7839 val_recall: 0.7737, val_f1: 0.7742\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7737\n",
            ">>> test_acc: 0.7555, test_precision: 0.7674, test_recall: 0.7555, test_f1: 0.7555\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "d99748cd-8ad2-4e31-a119-7818327124ca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbb59289-e7a6-4d9f-a70f-66f60a0722c3"
      },
      "source": [
        "### indobenchmark/indobert-base-p1 s6 insert"
      ],
      "id": "fbb59289-e7a6-4d9f-a70f-66f60a0722c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "df75ea36-1c3a-400c-aff4-2acc02cfbf99",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f179f91b760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p1\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 10:35:21\n",
            "loss: 0.8456, acc: 0.6362\n",
            "E2E-ABSA >>> 2024-06-04 10:35:32\n",
            ">>> val_acc: 0.7414, val_precision: 0.7252 val_recall: 0.7414, val_f1: 0.7225\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7414\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 10:35:34\n",
            "loss: 0.7146, acc: 0.6771\n",
            "E2E-ABSA >>> 2024-06-04 10:35:43\n",
            "loss: 0.6401, acc: 0.7329\n",
            "E2E-ABSA >>> 2024-06-04 10:35:52\n",
            ">>> val_acc: 0.7375, val_precision: 0.7476 val_recall: 0.7375, val_f1: 0.7284\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7375\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 10:35:57\n",
            "loss: 0.4820, acc: 0.8060\n",
            "E2E-ABSA >>> 2024-06-04 10:36:05\n",
            "loss: 0.5096, acc: 0.7973\n",
            "E2E-ABSA >>> 2024-06-04 10:36:12\n",
            ">>> val_acc: 0.7517, val_precision: 0.7308 val_recall: 0.7517, val_f1: 0.7187\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 10:36:18\n",
            "loss: 0.3830, acc: 0.8325\n",
            "E2E-ABSA >>> 2024-06-04 10:36:27\n",
            "loss: 0.4190, acc: 0.8201\n",
            "E2E-ABSA >>> 2024-06-04 10:36:32\n",
            ">>> val_acc: 0.7456, val_precision: 0.7496 val_recall: 0.7456, val_f1: 0.7470\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7456\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 10:36:41\n",
            "loss: 0.2907, acc: 0.8841\n",
            "E2E-ABSA >>> 2024-06-04 10:36:52\n",
            ">>> val_acc: 0.7393, val_precision: 0.7437 val_recall: 0.7393, val_f1: 0.7406\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 10:36:54\n",
            "loss: 0.2089, acc: 0.9156\n",
            "E2E-ABSA >>> 2024-06-04 10:37:02\n",
            "loss: 0.2856, acc: 0.8885\n",
            "E2E-ABSA >>> 2024-06-04 10:37:12\n",
            ">>> val_acc: 0.7300, val_precision: 0.7663 val_recall: 0.7300, val_f1: 0.7424\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 10:37:15\n",
            "loss: 0.1935, acc: 0.9304\n",
            "E2E-ABSA >>> 2024-06-04 10:37:24\n",
            "loss: 0.2076, acc: 0.9240\n",
            "E2E-ABSA >>> 2024-06-04 10:37:31\n",
            ">>> val_acc: 0.7414, val_precision: 0.7499 val_recall: 0.7414, val_f1: 0.7433\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 10:37:37\n",
            "loss: 0.1782, acc: 0.9320\n",
            "E2E-ABSA >>> 2024-06-04 10:37:46\n",
            "loss: 0.2007, acc: 0.9211\n",
            "E2E-ABSA >>> 2024-06-04 10:37:51\n",
            ">>> val_acc: 0.7375, val_precision: 0.7318 val_recall: 0.7375, val_f1: 0.7341\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 10:37:59\n",
            "loss: 0.1742, acc: 0.9321\n",
            "E2E-ABSA >>> 2024-06-04 10:38:11\n",
            ">>> val_acc: 0.7435, val_precision: 0.7380 val_recall: 0.7435, val_f1: 0.7397\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 10:38:12\n",
            "loss: 0.1820, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-04 10:38:21\n",
            "loss: 0.1624, acc: 0.9353\n",
            "E2E-ABSA >>> 2024-06-04 10:38:30\n",
            ">>> val_acc: 0.7265, val_precision: 0.7269 val_recall: 0.7265, val_f1: 0.7237\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 10:38:34\n",
            "loss: 0.1426, acc: 0.9500\n",
            "E2E-ABSA >>> 2024-06-04 10:38:42\n",
            "loss: 0.1673, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 10:38:50\n",
            ">>> val_acc: 0.7371, val_precision: 0.7213 val_recall: 0.7371, val_f1: 0.7260\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 10:38:55\n",
            "loss: 0.1580, acc: 0.9502\n",
            "E2E-ABSA >>> 2024-06-04 10:39:04\n",
            "loss: 0.1956, acc: 0.9318\n",
            "E2E-ABSA >>> 2024-06-04 10:39:10\n",
            ">>> val_acc: 0.7183, val_precision: 0.7194 val_recall: 0.7183, val_f1: 0.7184\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 10:39:17\n",
            "loss: 0.1426, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-04 10:39:29\n",
            ">>> val_acc: 0.7101, val_precision: 0.7303 val_recall: 0.7101, val_f1: 0.7174\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 10:39:30\n",
            "loss: 0.1191, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-04 10:39:39\n",
            "loss: 0.1248, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 10:39:49\n",
            ">>> val_acc: 0.7240, val_precision: 0.7201 val_recall: 0.7240, val_f1: 0.7192\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 10:39:52\n",
            "loss: 0.1024, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 10:40:01\n",
            "loss: 0.1504, acc: 0.9499\n",
            "E2E-ABSA >>> 2024-06-04 10:40:09\n",
            ">>> val_acc: 0.6909, val_precision: 0.7204 val_recall: 0.6909, val_f1: 0.7013\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 10:40:14\n",
            "loss: 0.1223, acc: 0.9521\n",
            "E2E-ABSA >>> 2024-06-04 10:40:22\n",
            "loss: 0.1365, acc: 0.9488\n",
            "E2E-ABSA >>> 2024-06-04 10:40:28\n",
            ">>> val_acc: 0.7162, val_precision: 0.7050 val_recall: 0.7162, val_f1: 0.7082\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 10:40:35\n",
            "loss: 0.1109, acc: 0.9621\n",
            "E2E-ABSA >>> 2024-06-04 10:40:48\n",
            ">>> val_acc: 0.7069, val_precision: 0.7248 val_recall: 0.7069, val_f1: 0.7139\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 10:40:49\n",
            "loss: 0.0705, acc: 0.9766\n",
            "E2E-ABSA >>> 2024-06-04 10:40:57\n",
            "loss: 0.1089, acc: 0.9612\n",
            "E2E-ABSA >>> 2024-06-04 10:41:08\n",
            ">>> val_acc: 0.7179, val_precision: 0.7077 val_recall: 0.7179, val_f1: 0.7114\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 10:41:10\n",
            "loss: 0.1180, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 10:41:19\n",
            "loss: 0.1376, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-04 10:41:27\n",
            ">>> val_acc: 0.6988, val_precision: 0.7138 val_recall: 0.6988, val_f1: 0.7050\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 10:41:32\n",
            "loss: 0.1221, acc: 0.9576\n",
            "E2E-ABSA >>> 2024-06-04 10:41:41\n",
            "loss: 0.1257, acc: 0.9563\n",
            "E2E-ABSA >>> 2024-06-04 10:41:47\n",
            ">>> val_acc: 0.7133, val_precision: 0.7046 val_recall: 0.7133, val_f1: 0.7074\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 10:41:54\n",
            "loss: 0.0978, acc: 0.9680\n",
            "E2E-ABSA >>> 2024-06-04 10:42:07\n",
            ">>> val_acc: 0.7133, val_precision: 0.6948 val_recall: 0.7133, val_f1: 0.7009\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 10:42:07\n",
            "loss: 0.1313, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 10:42:16\n",
            "loss: 0.1414, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 10:42:26\n",
            ">>> val_acc: 0.6838, val_precision: 0.7077 val_recall: 0.6838, val_f1: 0.6923\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 10:42:29\n",
            "loss: 0.1182, acc: 0.9643\n",
            "E2E-ABSA >>> 2024-06-04 10:42:37\n",
            "loss: 0.0990, acc: 0.9639\n",
            "E2E-ABSA >>> 2024-06-04 10:42:46\n",
            ">>> val_acc: 0.6948, val_precision: 0.7012 val_recall: 0.6948, val_f1: 0.6960\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 10:42:50\n",
            "loss: 0.0996, acc: 0.9639\n",
            "E2E-ABSA >>> 2024-06-04 10:42:59\n",
            "loss: 0.0950, acc: 0.9646\n",
            "E2E-ABSA >>> 2024-06-04 10:43:06\n",
            ">>> val_acc: 0.7091, val_precision: 0.6965 val_recall: 0.7091, val_f1: 0.7009\n",
            "E2E-ABSA >>> 2024-06-04 10:43:06\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7456, val_precision: 0.7496 val_recall: 0.7456, val_f1: 0.7470\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7456\n",
            ">>> test_acc: 0.7331, test_precision: 0.7345, test_recall: 0.7331, test_f1: 0.7317\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indobenchmark/indobert-base-p1 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "df75ea36-1c3a-400c-aff4-2acc02cfbf99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with indobenchmark/indobert-base-p2"
      ],
      "metadata": {
        "id": "iiozdtyLL2zu"
      },
      "id": "iiozdtyLL2zu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "u70HiP8ENbYj"
      },
      "outputs": [],
      "source": [
        "#  menyesuaikan tokenizer BERT untuk indobenchmark\n",
        "path = 'ta-dictabsa/data_utils.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[100] = \"        self.tokenizer = BertTokenizer.from_pretrained(pretrained_bert_name)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "id": "u70HiP8ENbYj"
    },
    {
      "cell_type": "markdown",
      "id": "Yr-A9dFmFa3d",
      "metadata": {
        "id": "Yr-A9dFmFa3d"
      },
      "source": [
        "## **indobenchmark/indobert-base-p2** Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WdQqxinbFa3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WdQqxinbFa3e",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e4c23cc0-df28-456f-ef69-376a6d75ff30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_ori\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7e97de4263b0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/train.tsv', 'test': './datasets/ulasan_combined/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-03 09:32:41\n",
            "loss: 0.9168, acc: 0.6456\n",
            "E2E-ABSA >>> 2024-06-03 09:33:31\n",
            ">>> val_acc: 0.6892, val_precision: 0.6772 val_recall: 0.6892, val_f1: 0.5972\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6892\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 09:33:48\n",
            "loss: 0.8242, acc: 0.6536\n",
            "E2E-ABSA >>> 2024-06-03 09:34:25\n",
            "loss: 0.8048, acc: 0.6608\n",
            "E2E-ABSA >>> 2024-06-03 09:35:04\n",
            ">>> val_acc: 0.7002, val_precision: 0.7166 val_recall: 0.7002, val_f1: 0.6948\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.7002\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 09:35:29\n",
            "loss: 0.6240, acc: 0.7344\n",
            "E2E-ABSA >>> 2024-06-03 09:36:06\n",
            "loss: 0.6328, acc: 0.7318\n",
            "E2E-ABSA >>> 2024-06-03 09:36:37\n",
            ">>> val_acc: 0.7187, val_precision: 0.6911 val_recall: 0.7187, val_f1: 0.6482\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 09:37:03\n",
            "loss: 0.5309, acc: 0.7700\n",
            "E2E-ABSA >>> 2024-06-03 09:37:39\n",
            "loss: 0.5318, acc: 0.7733\n",
            "E2E-ABSA >>> 2024-06-03 09:38:02\n",
            ">>> val_acc: 0.7531, val_precision: 0.7496 val_recall: 0.7531, val_f1: 0.7512\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.7531\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 09:38:49\n",
            "loss: 0.3947, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-03 09:39:39\n",
            ">>> val_acc: 0.7375, val_precision: 0.7227 val_recall: 0.7375, val_f1: 0.7262\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 09:39:46\n",
            "loss: 0.3484, acc: 0.8656\n",
            "E2E-ABSA >>> 2024-06-03 09:40:23\n",
            "loss: 0.3713, acc: 0.8557\n",
            "E2E-ABSA >>> 2024-06-03 09:41:04\n",
            ">>> val_acc: 0.7204, val_precision: 0.7564 val_recall: 0.7204, val_f1: 0.7330\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 09:41:20\n",
            "loss: 0.2926, acc: 0.8835\n",
            "E2E-ABSA >>> 2024-06-03 09:41:56\n",
            "loss: 0.3237, acc: 0.8720\n",
            "E2E-ABSA >>> 2024-06-03 09:42:29\n",
            ">>> val_acc: 0.7364, val_precision: 0.7263 val_recall: 0.7364, val_f1: 0.7287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 09:42:54\n",
            "loss: 0.2792, acc: 0.8851\n",
            "E2E-ABSA >>> 2024-06-03 09:43:30\n",
            "loss: 0.2874, acc: 0.8858\n",
            "E2E-ABSA >>> 2024-06-03 09:43:54\n",
            ">>> val_acc: 0.7290, val_precision: 0.7357 val_recall: 0.7290, val_f1: 0.7319\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 09:44:27\n",
            "loss: 0.2269, acc: 0.9110\n",
            "E2E-ABSA >>> 2024-06-03 09:45:18\n",
            ">>> val_acc: 0.7272, val_precision: 0.7099 val_recall: 0.7272, val_f1: 0.7145\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 09:45:24\n",
            "loss: 0.2264, acc: 0.9102\n",
            "E2E-ABSA >>> 2024-06-03 09:46:01\n",
            "loss: 0.2349, acc: 0.9095\n",
            "E2E-ABSA >>> 2024-06-03 09:46:44\n",
            ">>> val_acc: 0.7325, val_precision: 0.7275 val_recall: 0.7325, val_f1: 0.7272\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 09:46:58\n",
            "loss: 0.1601, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-03 09:47:35\n",
            "loss: 0.2025, acc: 0.9214\n",
            "E2E-ABSA >>> 2024-06-03 09:48:09\n",
            ">>> val_acc: 0.7226, val_precision: 0.7213 val_recall: 0.7226, val_f1: 0.7219\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 09:48:32\n",
            "loss: 0.1549, acc: 0.9424\n",
            "E2E-ABSA >>> 2024-06-03 09:49:08\n",
            "loss: 0.2081, acc: 0.9223\n",
            "E2E-ABSA >>> 2024-06-03 09:49:34\n",
            ">>> val_acc: 0.7218, val_precision: 0.7165 val_recall: 0.7218, val_f1: 0.7190\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 09:50:06\n",
            "loss: 0.1376, acc: 0.9524\n",
            "E2E-ABSA >>> 2024-06-03 09:50:59\n",
            ">>> val_acc: 0.7297, val_precision: 0.7210 val_recall: 0.7297, val_f1: 0.7244\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 09:51:03\n",
            "loss: 0.0874, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 09:51:39\n",
            "loss: 0.1766, acc: 0.9291\n",
            "E2E-ABSA >>> 2024-06-03 09:52:24\n",
            ">>> val_acc: 0.7194, val_precision: 0.7117 val_recall: 0.7194, val_f1: 0.7150\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 09:52:37\n",
            "loss: 0.1070, acc: 0.9566\n",
            "E2E-ABSA >>> 2024-06-03 09:53:13\n",
            "loss: 0.1451, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-06-03 09:53:49\n",
            ">>> val_acc: 0.7133, val_precision: 0.7202 val_recall: 0.7133, val_f1: 0.7163\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 09:54:11\n",
            "loss: 0.1343, acc: 0.9500\n",
            "E2E-ABSA >>> 2024-06-03 09:54:47\n",
            "loss: 0.1667, acc: 0.9379\n",
            "E2E-ABSA >>> 2024-06-03 09:55:14\n",
            ">>> val_acc: 0.7361, val_precision: 0.7137 val_recall: 0.7361, val_f1: 0.7141\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 09:55:45\n",
            "loss: 0.1045, acc: 0.9680\n",
            "E2E-ABSA >>> 2024-06-03 09:56:39\n",
            ">>> val_acc: 0.6867, val_precision: 0.7124 val_recall: 0.6867, val_f1: 0.6860\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 09:56:42\n",
            "loss: 0.2337, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-03 09:57:18\n",
            "loss: 0.1620, acc: 0.9392\n",
            "E2E-ABSA >>> 2024-06-03 09:58:04\n",
            ">>> val_acc: 0.7162, val_precision: 0.7072 val_recall: 0.7162, val_f1: 0.7111\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 09:58:16\n",
            "loss: 0.1166, acc: 0.9629\n",
            "E2E-ABSA >>> 2024-06-03 09:58:52\n",
            "loss: 0.1253, acc: 0.9560\n",
            "E2E-ABSA >>> 2024-06-03 09:59:29\n",
            ">>> val_acc: 0.7073, val_precision: 0.7162 val_recall: 0.7073, val_f1: 0.7111\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 09:59:49\n",
            "loss: 0.1374, acc: 0.9475\n",
            "E2E-ABSA >>> 2024-06-03 10:00:26\n",
            "loss: 0.1426, acc: 0.9423\n",
            "E2E-ABSA >>> 2024-06-03 10:00:54\n",
            ">>> val_acc: 0.7101, val_precision: 0.7017 val_recall: 0.7101, val_f1: 0.7045\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 10:01:23\n",
            "loss: 0.0976, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-03 10:02:19\n",
            ">>> val_acc: 0.7151, val_precision: 0.7055 val_recall: 0.7151, val_f1: 0.7090\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 10:02:20\n",
            "loss: 0.0506, acc: 1.0000\n",
            "E2E-ABSA >>> 2024-06-03 10:02:57\n",
            "loss: 0.1327, acc: 0.9507\n",
            "E2E-ABSA >>> 2024-06-03 10:03:44\n",
            ">>> val_acc: 0.7158, val_precision: 0.7005 val_recall: 0.7158, val_f1: 0.7063\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 10:03:54\n",
            "loss: 0.1003, acc: 0.9732\n",
            "E2E-ABSA >>> 2024-06-03 10:04:31\n",
            "loss: 0.1189, acc: 0.9585\n",
            "E2E-ABSA >>> 2024-06-03 10:05:09\n",
            ">>> val_acc: 0.6973, val_precision: 0.7020 val_recall: 0.6973, val_f1: 0.6970\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 10:05:28\n",
            "loss: 0.1068, acc: 0.9591\n",
            "E2E-ABSA >>> 2024-06-03 10:06:05\n",
            "loss: 0.1175, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-03 10:06:34\n",
            ">>> val_acc: 0.7176, val_precision: 0.6923 val_recall: 0.7176, val_f1: 0.6962\n",
            "E2E-ABSA >>> 2024-06-03 10:06:34\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7531, val_precision: 0.7496 val_recall: 0.7531, val_f1: 0.7512\n",
            "you can download the best model from state_dict/bert_spc_combined_ori_val_f1_0.7531\n",
            ">>> test_acc: 0.7254, test_precision: 0.7173, test_recall: 0.7254, test_f1: 0.7203\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_ori --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cgMezYFUFcQk",
      "metadata": {
        "id": "cgMezYFUFcQk"
      },
      "source": [
        "## indobenchmark/indobert-base-p2 Concatenation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QE3GNHfJFpft",
      "metadata": {
        "id": "QE3GNHfJFpft"
      },
      "source": [
        "### **indobenchmark/indobert-base-p2** s1 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wDpkpdnqFpSy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wDpkpdnqFpSy",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "57af4e7d-16d8-4be9-cd8f-88acbca20330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7ce3b080e3b0>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/a_raw_know/train.tsv', 'test': './datasets/ulasan_combined/a_raw_know/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-03 10:09:51\n",
            "loss: 0.9032, acc: 0.6369\n",
            "E2E-ABSA >>> 2024-06-03 10:10:36\n",
            ">>> val_acc: 0.6991, val_precision: 0.6507 val_recall: 0.6991, val_f1: 0.6606\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6991\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-03 10:11:28\n",
            "loss: 0.7671, acc: 0.6615\n",
            "E2E-ABSA >>> 2024-06-03 10:12:02\n",
            "loss: 0.7126, acc: 0.6941\n",
            "E2E-ABSA >>> 2024-06-03 10:12:40\n",
            ">>> val_acc: 0.7229, val_precision: 0.7099 val_recall: 0.7229, val_f1: 0.7016\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7229\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-03 10:12:58\n",
            "loss: 0.5180, acc: 0.7852\n",
            "E2E-ABSA >>> 2024-06-03 10:13:34\n",
            "loss: 0.5602, acc: 0.7635\n",
            "E2E-ABSA >>> 2024-06-03 10:14:04\n",
            ">>> val_acc: 0.7339, val_precision: 0.7153 val_recall: 0.7339, val_f1: 0.6814\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-03 10:14:30\n",
            "loss: 0.4590, acc: 0.8047\n",
            "E2E-ABSA >>> 2024-06-03 10:15:05\n",
            "loss: 0.4794, acc: 0.7965\n",
            "E2E-ABSA >>> 2024-06-03 10:15:27\n",
            ">>> val_acc: 0.7535, val_precision: 0.7442 val_recall: 0.7535, val_f1: 0.7479\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7535\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-03 10:16:09\n",
            "loss: 0.3462, acc: 0.8665\n",
            "E2E-ABSA >>> 2024-06-03 10:17:00\n",
            ">>> val_acc: 0.6931, val_precision: 0.7315 val_recall: 0.6931, val_f1: 0.7049\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-03 10:17:07\n",
            "loss: 0.3227, acc: 0.8719\n",
            "E2E-ABSA >>> 2024-06-03 10:17:43\n",
            "loss: 0.3333, acc: 0.8646\n",
            "E2E-ABSA >>> 2024-06-03 10:18:25\n",
            ">>> val_acc: 0.7005, val_precision: 0.7471 val_recall: 0.7005, val_f1: 0.7156\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-03 10:18:41\n",
            "loss: 0.2530, acc: 0.9006\n",
            "E2E-ABSA >>> 2024-06-03 10:19:17\n",
            "loss: 0.2867, acc: 0.8880\n",
            "E2E-ABSA >>> 2024-06-03 10:19:50\n",
            ">>> val_acc: 0.7112, val_precision: 0.7303 val_recall: 0.7112, val_f1: 0.7178\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-03 10:20:15\n",
            "loss: 0.2908, acc: 0.8695\n",
            "E2E-ABSA >>> 2024-06-03 10:20:51\n",
            "loss: 0.2743, acc: 0.8847\n",
            "E2E-ABSA >>> 2024-06-03 10:21:15\n",
            ">>> val_acc: 0.7254, val_precision: 0.7177 val_recall: 0.7254, val_f1: 0.7149\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-03 10:21:49\n",
            "loss: 0.1846, acc: 0.9355\n",
            "E2E-ABSA >>> 2024-06-03 10:22:40\n",
            ">>> val_acc: 0.7055, val_precision: 0.7270 val_recall: 0.7055, val_f1: 0.7115\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-03 10:22:46\n",
            "loss: 0.1743, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-03 10:23:23\n",
            "loss: 0.1831, acc: 0.9343\n",
            "E2E-ABSA >>> 2024-06-03 10:24:05\n",
            ">>> val_acc: 0.6998, val_precision: 0.7340 val_recall: 0.6998, val_f1: 0.7078\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-03 10:24:20\n",
            "loss: 0.1698, acc: 0.9391\n",
            "E2E-ABSA >>> 2024-06-03 10:24:56\n",
            "loss: 0.1933, acc: 0.9254\n",
            "E2E-ABSA >>> 2024-06-03 10:25:30\n",
            ">>> val_acc: 0.7009, val_precision: 0.6969 val_recall: 0.7009, val_f1: 0.6937\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-03 10:25:54\n",
            "loss: 0.1501, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-03 10:26:30\n",
            "loss: 0.1983, acc: 0.9261\n",
            "E2E-ABSA >>> 2024-06-03 10:26:55\n",
            ">>> val_acc: 0.7076, val_precision: 0.7147 val_recall: 0.7076, val_f1: 0.7094\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-03 10:27:27\n",
            "loss: 0.1430, acc: 0.9510\n",
            "E2E-ABSA >>> 2024-06-03 10:28:20\n",
            ">>> val_acc: 0.7151, val_precision: 0.7091 val_recall: 0.7151, val_f1: 0.7099\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-03 10:28:25\n",
            "loss: 0.1142, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-03 10:29:01\n",
            "loss: 0.1454, acc: 0.9470\n",
            "E2E-ABSA >>> 2024-06-03 10:29:46\n",
            ">>> val_acc: 0.6995, val_precision: 0.6919 val_recall: 0.6995, val_f1: 0.6953\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-03 10:29:59\n",
            "loss: 0.1066, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-03 10:30:36\n",
            "loss: 0.1621, acc: 0.9361\n",
            "E2E-ABSA >>> 2024-06-03 10:31:11\n",
            ">>> val_acc: 0.6821, val_precision: 0.7122 val_recall: 0.6821, val_f1: 0.6936\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-03 10:31:33\n",
            "loss: 0.1524, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-03 10:32:10\n",
            "loss: 0.1596, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-06-03 10:32:36\n",
            ">>> val_acc: 0.7147, val_precision: 0.7184 val_recall: 0.7147, val_f1: 0.7163\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-03 10:33:07\n",
            "loss: 0.1324, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-03 10:34:02\n",
            ">>> val_acc: 0.6977, val_precision: 0.7029 val_recall: 0.6977, val_f1: 0.6985\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-03 10:34:04\n",
            "loss: 0.0992, acc: 0.9766\n",
            "E2E-ABSA >>> 2024-06-03 10:34:41\n",
            "loss: 0.1342, acc: 0.9439\n",
            "E2E-ABSA >>> 2024-06-03 10:35:27\n",
            ">>> val_acc: 0.7172, val_precision: 0.6918 val_recall: 0.7172, val_f1: 0.6982\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-03 10:35:38\n",
            "loss: 0.1433, acc: 0.9512\n",
            "E2E-ABSA >>> 2024-06-03 10:36:15\n",
            "loss: 0.1265, acc: 0.9579\n",
            "E2E-ABSA >>> 2024-06-03 10:36:52\n",
            ">>> val_acc: 0.6991, val_precision: 0.6971 val_recall: 0.6991, val_f1: 0.6979\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-03 10:37:12\n",
            "loss: 0.0939, acc: 0.9699\n",
            "E2E-ABSA >>> 2024-06-03 10:37:49\n",
            "loss: 0.1330, acc: 0.9499\n",
            "E2E-ABSA >>> 2024-06-03 10:38:17\n",
            ">>> val_acc: 0.6970, val_precision: 0.6989 val_recall: 0.6970, val_f1: 0.6977\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-03 10:38:46\n",
            "loss: 0.0931, acc: 0.9656\n",
            "E2E-ABSA >>> 2024-06-03 10:39:42\n",
            ">>> val_acc: 0.7027, val_precision: 0.6787 val_recall: 0.7027, val_f1: 0.6859\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-03 10:39:44\n",
            "loss: 0.1097, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-03 10:40:20\n",
            "loss: 0.1285, acc: 0.9567\n",
            "E2E-ABSA >>> 2024-06-03 10:41:07\n",
            ">>> val_acc: 0.6746, val_precision: 0.6929 val_recall: 0.6746, val_f1: 0.6824\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-03 10:41:17\n",
            "loss: 0.1349, acc: 0.9598\n",
            "E2E-ABSA >>> 2024-06-03 10:41:54\n",
            "loss: 0.1365, acc: 0.9497\n",
            "E2E-ABSA >>> 2024-06-03 10:42:32\n",
            ">>> val_acc: 0.6924, val_precision: 0.6862 val_recall: 0.6924, val_f1: 0.6887\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-03 10:42:51\n",
            "loss: 0.0913, acc: 0.9651\n",
            "E2E-ABSA >>> 2024-06-03 10:43:28\n",
            "loss: 0.1100, acc: 0.9589\n",
            "E2E-ABSA >>> 2024-06-03 10:43:57\n",
            ">>> val_acc: 0.7087, val_precision: 0.6794 val_recall: 0.7087, val_f1: 0.6822\n",
            "E2E-ABSA >>> 2024-06-03 10:43:57\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7535, val_precision: 0.7442 val_recall: 0.7535, val_f1: 0.7479\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7535\n",
            ">>> test_acc: 0.7258, test_precision: 0.7149, test_recall: 0.7258, test_f1: 0.7175\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lxZaPdywuDAr",
      "metadata": {
        "id": "lxZaPdywuDAr"
      },
      "source": [
        "### **indobenchmark/indobert-base-p2** s2 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EMtfkkLOuDAr",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "EMtfkkLOuDAr",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5872d30d-d923-4d6d-b135-1724693adae6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f626c923640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/f_raw_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/f_raw_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 02:26:14\n",
            "loss: 0.9012, acc: 0.6244\n",
            "E2E-ABSA >>> 2024-06-04 02:26:25\n",
            ">>> val_acc: 0.6988, val_precision: 0.7282 val_recall: 0.6988, val_f1: 0.6618\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6988\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 02:26:28\n",
            "loss: 0.7534, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-04 02:26:36\n",
            "loss: 0.6929, acc: 0.7082\n",
            "E2E-ABSA >>> 2024-06-04 02:26:45\n",
            ">>> val_acc: 0.7357, val_precision: 0.7340 val_recall: 0.7357, val_f1: 0.7246\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7357\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 02:26:50\n",
            "loss: 0.5041, acc: 0.7799\n",
            "E2E-ABSA >>> 2024-06-04 02:26:58\n",
            "loss: 0.5146, acc: 0.7817\n",
            "E2E-ABSA >>> 2024-06-04 02:27:05\n",
            ">>> val_acc: 0.7393, val_precision: 0.7192 val_recall: 0.7393, val_f1: 0.6913\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 02:27:11\n",
            "loss: 0.4020, acc: 0.8333\n",
            "E2E-ABSA >>> 2024-06-04 02:27:20\n",
            "loss: 0.4277, acc: 0.8267\n",
            "E2E-ABSA >>> 2024-06-04 02:27:25\n",
            ">>> val_acc: 0.7410, val_precision: 0.7458 val_recall: 0.7410, val_f1: 0.7422\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.741\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 02:27:33\n",
            "loss: 0.2658, acc: 0.8926\n",
            "E2E-ABSA >>> 2024-06-04 02:27:45\n",
            ">>> val_acc: 0.7471, val_precision: 0.7339 val_recall: 0.7471, val_f1: 0.7385\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 02:27:46\n",
            "loss: 0.1845, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-06-04 02:27:55\n",
            "loss: 0.2848, acc: 0.8917\n",
            "E2E-ABSA >>> 2024-06-04 02:28:04\n",
            ">>> val_acc: 0.7279, val_precision: 0.7499 val_recall: 0.7279, val_f1: 0.7350\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 02:28:08\n",
            "loss: 0.2305, acc: 0.9176\n",
            "E2E-ABSA >>> 2024-06-04 02:28:17\n",
            "loss: 0.2429, acc: 0.9115\n",
            "E2E-ABSA >>> 2024-06-04 02:28:24\n",
            ">>> val_acc: 0.7094, val_precision: 0.7570 val_recall: 0.7094, val_f1: 0.7187\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 02:28:30\n",
            "loss: 0.2426, acc: 0.9044\n",
            "E2E-ABSA >>> 2024-06-04 02:28:38\n",
            "loss: 0.2464, acc: 0.9022\n",
            "E2E-ABSA >>> 2024-06-04 02:28:43\n",
            ">>> val_acc: 0.7343, val_precision: 0.7260 val_recall: 0.7343, val_f1: 0.7291\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 02:28:51\n",
            "loss: 0.1997, acc: 0.9253\n",
            "E2E-ABSA >>> 2024-06-04 02:29:03\n",
            ">>> val_acc: 0.7332, val_precision: 0.7164 val_recall: 0.7332, val_f1: 0.7221\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 02:29:04\n",
            "loss: 0.1678, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-04 02:29:13\n",
            "loss: 0.1874, acc: 0.9300\n",
            "E2E-ABSA >>> 2024-06-04 02:29:23\n",
            ">>> val_acc: 0.7286, val_precision: 0.7252 val_recall: 0.7286, val_f1: 0.7266\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 02:29:26\n",
            "loss: 0.1511, acc: 0.9547\n",
            "E2E-ABSA >>> 2024-06-04 02:29:35\n",
            "loss: 0.1772, acc: 0.9330\n",
            "E2E-ABSA >>> 2024-06-04 02:29:42\n",
            ">>> val_acc: 0.7250, val_precision: 0.7191 val_recall: 0.7250, val_f1: 0.7214\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 02:29:48\n",
            "loss: 0.1507, acc: 0.9395\n",
            "E2E-ABSA >>> 2024-06-04 02:29:56\n",
            "loss: 0.2010, acc: 0.9242\n",
            "E2E-ABSA >>> 2024-06-04 02:30:02\n",
            ">>> val_acc: 0.7233, val_precision: 0.7143 val_recall: 0.7233, val_f1: 0.7178\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 02:30:09\n",
            "loss: 0.1775, acc: 0.9361\n",
            "E2E-ABSA >>> 2024-06-04 02:30:21\n",
            ">>> val_acc: 0.7279, val_precision: 0.7141 val_recall: 0.7279, val_f1: 0.7178\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 02:30:22\n",
            "loss: 0.1306, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 02:30:31\n",
            "loss: 0.1518, acc: 0.9464\n",
            "E2E-ABSA >>> 2024-06-04 02:30:41\n",
            ">>> val_acc: 0.7261, val_precision: 0.7215 val_recall: 0.7261, val_f1: 0.7210\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 02:30:44\n",
            "loss: 0.0763, acc: 0.9757\n",
            "E2E-ABSA >>> 2024-06-04 02:30:53\n",
            "loss: 0.1584, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-06-04 02:31:01\n",
            ">>> val_acc: 0.6966, val_precision: 0.7183 val_recall: 0.6966, val_f1: 0.7055\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 02:31:06\n",
            "loss: 0.1474, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-06-04 02:31:14\n",
            "loss: 0.1567, acc: 0.9395\n",
            "E2E-ABSA >>> 2024-06-04 02:31:20\n",
            ">>> val_acc: 0.7236, val_precision: 0.7234 val_recall: 0.7236, val_f1: 0.7222\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 02:31:28\n",
            "loss: 0.1060, acc: 0.9665\n",
            "E2E-ABSA >>> 2024-06-04 02:31:40\n",
            ">>> val_acc: 0.7112, val_precision: 0.7155 val_recall: 0.7112, val_f1: 0.7132\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 02:31:41\n",
            "loss: 0.1142, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 02:31:49\n",
            "loss: 0.1316, acc: 0.9537\n",
            "E2E-ABSA >>> 2024-06-04 02:32:00\n",
            ">>> val_acc: 0.7258, val_precision: 0.7081 val_recall: 0.7258, val_f1: 0.7105\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 02:32:03\n",
            "loss: 0.1298, acc: 0.9629\n",
            "E2E-ABSA >>> 2024-06-04 02:32:11\n",
            "loss: 0.1491, acc: 0.9474\n",
            "E2E-ABSA >>> 2024-06-04 02:32:19\n",
            ">>> val_acc: 0.6998, val_precision: 0.7152 val_recall: 0.6998, val_f1: 0.7058\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 02:32:24\n",
            "loss: 0.1111, acc: 0.9632\n",
            "E2E-ABSA >>> 2024-06-04 02:32:33\n",
            "loss: 0.1459, acc: 0.9447\n",
            "E2E-ABSA >>> 2024-06-04 02:32:39\n",
            ">>> val_acc: 0.6764, val_precision: 0.7090 val_recall: 0.6764, val_f1: 0.6864\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 02:32:46\n",
            "loss: 0.1272, acc: 0.9484\n",
            "E2E-ABSA >>> 2024-06-04 02:32:59\n",
            ">>> val_acc: 0.7140, val_precision: 0.7018 val_recall: 0.7140, val_f1: 0.7068\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 02:32:59\n",
            "loss: 0.0747, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 02:33:08\n",
            "loss: 0.1235, acc: 0.9567\n",
            "E2E-ABSA >>> 2024-06-04 02:33:19\n",
            ">>> val_acc: 0.7087, val_precision: 0.7061 val_recall: 0.7087, val_f1: 0.7069\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 02:33:21\n",
            "loss: 0.1035, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 02:33:30\n",
            "loss: 0.1166, acc: 0.9546\n",
            "E2E-ABSA >>> 2024-06-04 02:33:38\n",
            ">>> val_acc: 0.6885, val_precision: 0.7017 val_recall: 0.6885, val_f1: 0.6911\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 02:33:43\n",
            "loss: 0.0867, acc: 0.9700\n",
            "E2E-ABSA >>> 2024-06-04 02:33:51\n",
            "loss: 0.1181, acc: 0.9593\n",
            "E2E-ABSA >>> 2024-06-04 02:33:58\n",
            ">>> val_acc: 0.7101, val_precision: 0.7047 val_recall: 0.7101, val_f1: 0.7069\n",
            "E2E-ABSA >>> 2024-06-04 02:33:58\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7410, val_precision: 0.7458 val_recall: 0.7410, val_f1: 0.7422\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.741\n",
            ">>> test_acc: 0.7195, test_precision: 0.7273, test_recall: 0.7195, test_f1: 0.7210\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa239464-3344-40e3-afc8-d0b2e3c941e8",
      "metadata": {
        "id": "fa239464-3344-40e3-afc8-d0b2e3c941e8"
      },
      "source": [
        "### **indobenchmark/indobert-base-p2** s3 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e9d4c3-df87-4cc2-af18-5e6b0f731899",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "d1e9d4c3-df87-4cc2-af18-5e6b0f731899",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5872d30d-d923-4d6d-b135-1724693adae6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fd9de737640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/e_raw_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/e_raw_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 11:44:40\n",
            "loss: 0.9136, acc: 0.6362\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 11:44:51\n",
            ">>> val_acc: 0.6963, val_precision: 0.6000 val_recall: 0.6963, val_f1: 0.6000\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6963\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 11:44:53\n",
            "loss: 0.7844, acc: 0.6380\n",
            "E2E-ABSA >>> 2024-06-04 11:45:02\n",
            "loss: 0.7684, acc: 0.6714\n",
            "E2E-ABSA >>> 2024-06-04 11:45:11\n",
            ">>> val_acc: 0.7140, val_precision: 0.7201 val_recall: 0.7140, val_f1: 0.6978\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.714\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 11:45:16\n",
            "loss: 0.5970, acc: 0.7435\n",
            "E2E-ABSA >>> 2024-06-04 11:45:24\n",
            "loss: 0.5977, acc: 0.7411\n",
            "E2E-ABSA >>> 2024-06-04 11:45:31\n",
            ">>> val_acc: 0.7261, val_precision: 0.6844 val_recall: 0.7261, val_f1: 0.6704\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 11:45:37\n",
            "loss: 0.5074, acc: 0.7865\n",
            "E2E-ABSA >>> 2024-06-04 11:45:46\n",
            "loss: 0.5179, acc: 0.7874\n",
            "E2E-ABSA >>> 2024-06-04 11:45:51\n",
            ">>> val_acc: 0.7378, val_precision: 0.7326 val_recall: 0.7378, val_f1: 0.7345\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7378\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 11:46:00\n",
            "loss: 0.3793, acc: 0.8509\n",
            "E2E-ABSA >>> 2024-06-04 11:46:11\n",
            ">>> val_acc: 0.7336, val_precision: 0.7065 val_recall: 0.7336, val_f1: 0.7080\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 11:46:13\n",
            "loss: 0.2997, acc: 0.8875\n",
            "E2E-ABSA >>> 2024-06-04 11:46:21\n",
            "loss: 0.3528, acc: 0.8599\n",
            "E2E-ABSA >>> 2024-06-04 11:46:31\n",
            ">>> val_acc: 0.7130, val_precision: 0.7550 val_recall: 0.7130, val_f1: 0.7272\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 11:46:35\n",
            "loss: 0.2655, acc: 0.8977\n",
            "E2E-ABSA >>> 2024-06-04 11:46:43\n",
            "loss: 0.3095, acc: 0.8793\n",
            "E2E-ABSA >>> 2024-06-04 11:46:51\n",
            ">>> val_acc: 0.7023, val_precision: 0.7390 val_recall: 0.7023, val_f1: 0.7135\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 11:46:56\n",
            "loss: 0.2820, acc: 0.8888\n",
            "E2E-ABSA >>> 2024-06-04 11:47:05\n",
            "loss: 0.3022, acc: 0.8765\n",
            "E2E-ABSA >>> 2024-06-04 11:47:10\n",
            ">>> val_acc: 0.7343, val_precision: 0.7251 val_recall: 0.7343, val_f1: 0.7194\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 11:47:18\n",
            "loss: 0.2377, acc: 0.9076\n",
            "E2E-ABSA >>> 2024-06-04 11:47:30\n",
            ">>> val_acc: 0.7279, val_precision: 0.7309 val_recall: 0.7279, val_f1: 0.7289\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 11:47:31\n",
            "loss: 0.2034, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 11:47:40\n",
            "loss: 0.2212, acc: 0.9154\n",
            "E2E-ABSA >>> 2024-06-04 11:47:50\n",
            ">>> val_acc: 0.7318, val_precision: 0.7201 val_recall: 0.7318, val_f1: 0.7212\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 11:47:53\n",
            "loss: 0.1846, acc: 0.9281\n",
            "E2E-ABSA >>> 2024-06-04 11:48:02\n",
            "loss: 0.2126, acc: 0.9138\n",
            "E2E-ABSA >>> 2024-06-04 11:48:09\n",
            ">>> val_acc: 0.7290, val_precision: 0.7273 val_recall: 0.7290, val_f1: 0.7280\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 11:48:15\n",
            "loss: 0.1363, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-04 11:48:23\n",
            "loss: 0.1973, acc: 0.9238\n",
            "E2E-ABSA >>> 2024-06-04 11:48:29\n",
            ">>> val_acc: 0.7023, val_precision: 0.7200 val_recall: 0.7023, val_f1: 0.7095\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 11:48:37\n",
            "loss: 0.1759, acc: 0.9347\n",
            "E2E-ABSA >>> 2024-06-04 11:48:49\n",
            ">>> val_acc: 0.7290, val_precision: 0.7125 val_recall: 0.7290, val_f1: 0.7149\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 11:48:50\n",
            "loss: 0.1098, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-04 11:48:58\n",
            "loss: 0.1765, acc: 0.9302\n",
            "E2E-ABSA >>> 2024-06-04 11:49:08\n",
            ">>> val_acc: 0.7187, val_precision: 0.7157 val_recall: 0.7187, val_f1: 0.7150\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 11:49:11\n",
            "loss: 0.1372, acc: 0.9462\n",
            "E2E-ABSA >>> 2024-06-04 11:49:20\n",
            "loss: 0.1853, acc: 0.9278\n",
            "E2E-ABSA >>> 2024-06-04 11:49:28\n",
            ">>> val_acc: 0.7098, val_precision: 0.7090 val_recall: 0.7098, val_f1: 0.7089\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 11:49:33\n",
            "loss: 0.1918, acc: 0.9302\n",
            "E2E-ABSA >>> 2024-06-04 11:49:42\n",
            "loss: 0.1681, acc: 0.9367\n",
            "E2E-ABSA >>> 2024-06-04 11:49:48\n",
            ">>> val_acc: 0.6995, val_precision: 0.7077 val_recall: 0.6995, val_f1: 0.7026\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 11:49:55\n",
            "loss: 0.1304, acc: 0.9494\n",
            "E2E-ABSA >>> 2024-06-04 11:50:07\n",
            ">>> val_acc: 0.6892, val_precision: 0.7158 val_recall: 0.6892, val_f1: 0.6956\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 11:50:08\n",
            "loss: 0.1769, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-04 11:50:17\n",
            "loss: 0.1505, acc: 0.9456\n",
            "E2E-ABSA >>> 2024-06-04 11:50:27\n",
            ">>> val_acc: 0.7261, val_precision: 0.7024 val_recall: 0.7261, val_f1: 0.6997\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 11:50:30\n",
            "loss: 0.1013, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 11:50:38\n",
            "loss: 0.1224, acc: 0.9545\n",
            "E2E-ABSA >>> 2024-06-04 11:50:47\n",
            ">>> val_acc: 0.6938, val_precision: 0.7168 val_recall: 0.6938, val_f1: 0.7026\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 11:50:52\n",
            "loss: 0.1068, acc: 0.9632\n",
            "E2E-ABSA >>> 2024-06-04 11:51:00\n",
            "loss: 0.1239, acc: 0.9571\n",
            "E2E-ABSA >>> 2024-06-04 11:51:06\n",
            ">>> val_acc: 0.6952, val_precision: 0.7075 val_recall: 0.6952, val_f1: 0.7002\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 11:51:13\n",
            "loss: 0.1131, acc: 0.9570\n",
            "E2E-ABSA >>> 2024-06-04 11:51:26\n",
            ">>> val_acc: 0.7250, val_precision: 0.7058 val_recall: 0.7250, val_f1: 0.7121\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 11:51:27\n",
            "loss: 0.1302, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 11:51:35\n",
            "loss: 0.1197, acc: 0.9555\n",
            "E2E-ABSA >>> 2024-06-04 11:51:46\n",
            ">>> val_acc: 0.6813, val_precision: 0.7034 val_recall: 0.6813, val_f1: 0.6904\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 11:51:48\n",
            "loss: 0.1079, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-06-04 11:51:57\n",
            "loss: 0.1114, acc: 0.9590\n",
            "E2E-ABSA >>> 2024-06-04 11:52:06\n",
            ">>> val_acc: 0.6956, val_precision: 0.7027 val_recall: 0.6956, val_f1: 0.6960\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 11:52:10\n",
            "loss: 0.0890, acc: 0.9639\n",
            "E2E-ABSA >>> 2024-06-04 11:52:19\n",
            "loss: 0.1110, acc: 0.9601\n",
            "E2E-ABSA >>> 2024-06-04 11:52:25\n",
            ">>> val_acc: 0.7076, val_precision: 0.7005 val_recall: 0.7076, val_f1: 0.7001\n",
            "E2E-ABSA >>> 2024-06-04 11:52:25\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7378, val_precision: 0.7326 val_recall: 0.7378, val_f1: 0.7345\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.7378\n",
            ">>> test_acc: 0.7148, test_precision: 0.7074, test_recall: 0.7148, test_f1: 0.7100\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f514246-fcb1-4626-b682-7e2e3926678c",
      "metadata": {
        "id": "0f514246-fcb1-4626-b682-7e2e3926678c"
      },
      "source": [
        "### **indobenchmark/indobert-base-p2** s4 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc0eedc-d93e-4730-a6e3-d28af30c61ba",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "dfc0eedc-d93e-4730-a6e3-d28af30c61ba",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5872d30d-d923-4d6d-b135-1724693adae6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5532.\n",
            "> testing dataset count: 2300.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f0e6922f640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/b_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/b_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 11:56:41\n",
            "loss: 0.8818, acc: 0.6238\n",
            "E2E-ABSA >>> 2024-06-04 11:56:52\n",
            ">>> val_acc: 0.6829, val_precision: 0.7310 val_recall: 0.6829, val_f1: 0.5652\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6829\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 11:56:55\n",
            "loss: 0.7220, acc: 0.6690\n",
            "E2E-ABSA >>> 2024-06-04 11:57:03\n",
            "loss: 0.6665, acc: 0.7215\n",
            "E2E-ABSA >>> 2024-06-04 11:57:12\n",
            ">>> val_acc: 0.7129, val_precision: 0.6843 val_recall: 0.7129, val_f1: 0.6584\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7129\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 11:57:17\n",
            "loss: 0.5642, acc: 0.7731\n",
            "E2E-ABSA >>> 2024-06-04 11:57:25\n",
            "loss: 0.5616, acc: 0.7650\n",
            "E2E-ABSA >>> 2024-06-04 11:57:32\n",
            ">>> val_acc: 0.7299, val_precision: 0.7107 val_recall: 0.7299, val_f1: 0.7049\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7299\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 11:57:39\n",
            "loss: 0.4830, acc: 0.7940\n",
            "E2E-ABSA >>> 2024-06-04 11:57:52\n",
            ">>> val_acc: 0.7267, val_precision: 0.7191 val_recall: 0.7267, val_f1: 0.7130\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7267\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 11:57:53\n",
            "loss: 0.2954, acc: 0.8828\n",
            "E2E-ABSA >>> 2024-06-04 11:58:01\n",
            "loss: 0.3750, acc: 0.8513\n",
            "E2E-ABSA >>> 2024-06-04 11:58:11\n",
            ">>> val_acc: 0.7372, val_precision: 0.7312 val_recall: 0.7372, val_f1: 0.7335\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7372\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 11:58:15\n",
            "loss: 0.3090, acc: 0.8554\n",
            "E2E-ABSA >>> 2024-06-04 11:58:24\n",
            "loss: 0.3535, acc: 0.8514\n",
            "E2E-ABSA >>> 2024-06-04 11:58:31\n",
            ">>> val_acc: 0.7137, val_precision: 0.7095 val_recall: 0.7137, val_f1: 0.6970\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 11:58:37\n",
            "loss: 0.3285, acc: 0.8690\n",
            "E2E-ABSA >>> 2024-06-04 11:58:45\n",
            "loss: 0.3260, acc: 0.8681\n",
            "E2E-ABSA >>> 2024-06-04 11:58:51\n",
            ">>> val_acc: 0.7216, val_precision: 0.7375 val_recall: 0.7216, val_f1: 0.7280\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 11:58:58\n",
            "loss: 0.2722, acc: 0.8975\n",
            "E2E-ABSA >>> 2024-06-04 11:59:10\n",
            ">>> val_acc: 0.7314, val_precision: 0.7130 val_recall: 0.7314, val_f1: 0.7176\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 11:59:11\n",
            "loss: 0.2296, acc: 0.9180\n",
            "E2E-ABSA >>> 2024-06-04 11:59:20\n",
            "loss: 0.2334, acc: 0.9122\n",
            "E2E-ABSA >>> 2024-06-04 11:59:29\n",
            ">>> val_acc: 0.7173, val_precision: 0.7019 val_recall: 0.7173, val_f1: 0.7047\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 11:59:33\n",
            "loss: 0.2189, acc: 0.9128\n",
            "E2E-ABSA >>> 2024-06-04 11:59:42\n",
            "loss: 0.2319, acc: 0.9100\n",
            "E2E-ABSA >>> 2024-06-04 11:59:49\n",
            ">>> val_acc: 0.7242, val_precision: 0.7161 val_recall: 0.7242, val_f1: 0.7190\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 11:59:55\n",
            "loss: 0.1865, acc: 0.9348\n",
            "E2E-ABSA >>> 2024-06-04 12:00:03\n",
            "loss: 0.2193, acc: 0.9165\n",
            "E2E-ABSA >>> 2024-06-04 12:00:08\n",
            ">>> val_acc: 0.6873, val_precision: 0.7197 val_recall: 0.6873, val_f1: 0.6988\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 12:00:16\n",
            "loss: 0.1785, acc: 0.9336\n",
            "E2E-ABSA >>> 2024-06-04 12:00:27\n",
            ">>> val_acc: 0.7166, val_precision: 0.7030 val_recall: 0.7166, val_f1: 0.7074\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 12:00:29\n",
            "loss: 0.2043, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-04 12:00:38\n",
            "loss: 0.2174, acc: 0.9143\n",
            "E2E-ABSA >>> 2024-06-04 12:00:47\n",
            ">>> val_acc: 0.7155, val_precision: 0.6872 val_recall: 0.7155, val_f1: 0.6861\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 12:00:51\n",
            "loss: 0.1892, acc: 0.9240\n",
            "E2E-ABSA >>> 2024-06-04 12:01:00\n",
            "loss: 0.1885, acc: 0.9292\n",
            "E2E-ABSA >>> 2024-06-04 12:01:06\n",
            ">>> val_acc: 0.7115, val_precision: 0.7019 val_recall: 0.7115, val_f1: 0.7052\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 12:01:13\n",
            "loss: 0.1544, acc: 0.9383\n",
            "E2E-ABSA >>> 2024-06-04 12:01:26\n",
            ">>> val_acc: 0.6829, val_precision: 0.6943 val_recall: 0.6829, val_f1: 0.6876\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 12:01:26\n",
            "loss: 0.0952, acc: 0.9625\n",
            "E2E-ABSA >>> 2024-06-04 12:01:34\n",
            "loss: 0.1540, acc: 0.9369\n",
            "E2E-ABSA >>> 2024-06-04 12:01:45\n",
            ">>> val_acc: 0.7050, val_precision: 0.6959 val_recall: 0.7050, val_f1: 0.6998\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 12:01:48\n",
            "loss: 0.1274, acc: 0.9453\n",
            "E2E-ABSA >>> 2024-06-04 12:01:56\n",
            "loss: 0.1682, acc: 0.9370\n",
            "E2E-ABSA >>> 2024-06-04 12:02:04\n",
            ">>> val_acc: 0.7054, val_precision: 0.6859 val_recall: 0.7054, val_f1: 0.6896\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 12:02:09\n",
            "loss: 0.1585, acc: 0.9354\n",
            "E2E-ABSA >>> 2024-06-04 12:02:18\n",
            "loss: 0.1631, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 12:02:24\n",
            ">>> val_acc: 0.7014, val_precision: 0.6860 val_recall: 0.7014, val_f1: 0.6887\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 12:02:31\n",
            "loss: 0.1542, acc: 0.9469\n",
            "E2E-ABSA >>> 2024-06-04 12:02:43\n",
            ">>> val_acc: 0.6652, val_precision: 0.6928 val_recall: 0.6652, val_f1: 0.6757\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 12:02:44\n",
            "loss: 0.1860, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 12:02:53\n",
            "loss: 0.1618, acc: 0.9336\n",
            "E2E-ABSA >>> 2024-06-04 12:03:02\n",
            ">>> val_acc: 0.7035, val_precision: 0.6801 val_recall: 0.7035, val_f1: 0.6873\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 12:03:06\n",
            "loss: 0.1326, acc: 0.9437\n",
            "E2E-ABSA >>> 2024-06-04 12:03:14\n",
            "loss: 0.1306, acc: 0.9509\n",
            "E2E-ABSA >>> 2024-06-04 12:03:22\n",
            ">>> val_acc: 0.7151, val_precision: 0.6855 val_recall: 0.7151, val_f1: 0.6864\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 12:03:27\n",
            "loss: 0.1194, acc: 0.9543\n",
            "E2E-ABSA >>> 2024-06-04 12:03:36\n",
            "loss: 0.1389, acc: 0.9465\n",
            "E2E-ABSA >>> 2024-06-04 12:03:41\n",
            ">>> val_acc: 0.6819, val_precision: 0.6876 val_recall: 0.6819, val_f1: 0.6836\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 12:03:49\n",
            "loss: 0.1461, acc: 0.9435\n",
            "E2E-ABSA >>> 2024-06-04 12:04:00\n",
            ">>> val_acc: 0.6562, val_precision: 0.6777 val_recall: 0.6562, val_f1: 0.6649\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 12:04:02\n",
            "loss: 0.1090, acc: 0.9524\n",
            "E2E-ABSA >>> 2024-06-04 12:04:11\n",
            "loss: 0.1102, acc: 0.9571\n",
            "E2E-ABSA >>> 2024-06-04 12:04:20\n",
            ">>> val_acc: 0.6974, val_precision: 0.6735 val_recall: 0.6974, val_f1: 0.6807\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 12:04:24\n",
            "loss: 0.0937, acc: 0.9648\n",
            "E2E-ABSA >>> 2024-06-04 12:04:32\n",
            "loss: 0.1139, acc: 0.9557\n",
            "E2E-ABSA >>> 2024-06-04 12:04:39\n",
            ">>> val_acc: 0.6833, val_precision: 0.6796 val_recall: 0.6833, val_f1: 0.6813\n",
            "E2E-ABSA >>> 2024-06-04 12:04:39\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7372, val_precision: 0.7312 val_recall: 0.7372, val_f1: 0.7335\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7372\n",
            ">>> test_acc: 0.7104, test_precision: 0.6952, test_recall: 0.7104, test_f1: 0.7008\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb83e078-4462-4287-aaa4-2b9c5e753517",
      "metadata": {
        "id": "bb83e078-4462-4287-aaa4-2b9c5e753517"
      },
      "source": [
        "### **indobenchmark/indobert-base-p2** s5 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a47a1787-4954-4b21-8f23-072b1945c96c",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "a47a1787-4954-4b21-8f23-072b1945c96c",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5872d30d-d923-4d6d-b135-1724693adae6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.6846\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 12:43:59\n",
            "loss: 0.6979, acc: 0.6713\n",
            "E2E-ABSA >>> 2024-06-04 12:44:08\n",
            "loss: 0.7203, acc: 0.6865\n",
            "E2E-ABSA >>> 2024-06-04 12:44:16\n",
            ">>> val_acc: 0.7292, val_precision: 0.7037 val_recall: 0.7292, val_f1: 0.6977\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7292\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 12:44:21\n",
            "loss: 0.5671, acc: 0.7581\n",
            "E2E-ABSA >>> 2024-06-04 12:44:30\n",
            "loss: 0.5849, acc: 0.7480\n",
            "E2E-ABSA >>> 2024-06-04 12:44:36\n",
            ">>> val_acc: 0.7440, val_precision: 0.7245 val_recall: 0.7440, val_f1: 0.7086\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.744\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 12:44:44\n",
            "loss: 0.4898, acc: 0.7978\n",
            "E2E-ABSA >>> 2024-06-04 12:44:56\n",
            ">>> val_acc: 0.7205, val_precision: 0.7441 val_recall: 0.7205, val_f1: 0.7273\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7205\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 12:44:57\n",
            "loss: 0.4320, acc: 0.8047\n",
            "E2E-ABSA >>> 2024-06-04 12:45:06\n",
            "loss: 0.4194, acc: 0.8229\n",
            "E2E-ABSA >>> 2024-06-04 12:45:16\n",
            ">>> val_acc: 0.7368, val_precision: 0.7353 val_recall: 0.7368, val_f1: 0.7338\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7368\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 12:45:19\n",
            "loss: 0.3450, acc: 0.8679\n",
            "E2E-ABSA >>> 2024-06-04 12:45:28\n",
            "loss: 0.3505, acc: 0.8620\n",
            "E2E-ABSA >>> 2024-06-04 12:45:36\n",
            ">>> val_acc: 0.7118, val_precision: 0.7239 val_recall: 0.7118, val_f1: 0.7168\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 12:45:41\n",
            "loss: 0.2650, acc: 0.9042\n",
            "E2E-ABSA >>> 2024-06-04 12:45:50\n",
            "loss: 0.2908, acc: 0.8885\n",
            "E2E-ABSA >>> 2024-06-04 12:45:55\n",
            ">>> val_acc: 0.6991, val_precision: 0.7404 val_recall: 0.6991, val_f1: 0.7127\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 12:46:03\n",
            "loss: 0.2302, acc: 0.9143\n",
            "E2E-ABSA >>> 2024-06-04 12:46:14\n",
            ">>> val_acc: 0.6727, val_precision: 0.7298 val_recall: 0.6727, val_f1: 0.6822\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 12:46:16\n",
            "loss: 0.2907, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-04 12:46:24\n",
            "loss: 0.2753, acc: 0.8890\n",
            "E2E-ABSA >>> 2024-06-04 12:46:34\n",
            ">>> val_acc: 0.7111, val_precision: 0.7125 val_recall: 0.7111, val_f1: 0.7099\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 12:46:37\n",
            "loss: 0.1868, acc: 0.9360\n",
            "E2E-ABSA >>> 2024-06-04 12:46:46\n",
            "loss: 0.1956, acc: 0.9279\n",
            "E2E-ABSA >>> 2024-06-04 12:46:53\n",
            ">>> val_acc: 0.7201, val_precision: 0.6997 val_recall: 0.7201, val_f1: 0.7052\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 12:46:59\n",
            "loss: 0.1793, acc: 0.9357\n",
            "E2E-ABSA >>> 2024-06-04 12:47:07\n",
            "loss: 0.1938, acc: 0.9268\n",
            "E2E-ABSA >>> 2024-06-04 12:47:12\n",
            ">>> val_acc: 0.6763, val_precision: 0.7145 val_recall: 0.6763, val_f1: 0.6891\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 12:47:21\n",
            "loss: 0.1737, acc: 0.9317\n",
            "E2E-ABSA >>> 2024-06-04 12:47:32\n",
            ">>> val_acc: 0.7078, val_precision: 0.7083 val_recall: 0.7078, val_f1: 0.7073\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 12:47:34\n",
            "loss: 0.1568, acc: 0.9271\n",
            "E2E-ABSA >>> 2024-06-04 12:47:42\n",
            "loss: 0.1608, acc: 0.9415\n",
            "E2E-ABSA >>> 2024-06-04 12:47:51\n",
            ">>> val_acc: 0.6564, val_precision: 0.7074 val_recall: 0.6564, val_f1: 0.6683\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 12:47:55\n",
            "loss: 0.1872, acc: 0.9154\n",
            "E2E-ABSA >>> 2024-06-04 12:48:04\n",
            "loss: 0.1830, acc: 0.9296\n",
            "E2E-ABSA >>> 2024-06-04 12:48:10\n",
            ">>> val_acc: 0.6941, val_precision: 0.7042 val_recall: 0.6941, val_f1: 0.6952\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 12:48:17\n",
            "loss: 0.1700, acc: 0.9383\n",
            "E2E-ABSA >>> 2024-06-04 12:48:30\n",
            ">>> val_acc: 0.6919, val_precision: 0.6953 val_recall: 0.6919, val_f1: 0.6891\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 12:48:39\n",
            "loss: 0.1273, acc: 0.9548\n",
            "E2E-ABSA >>> 2024-06-04 12:48:49\n",
            ">>> val_acc: 0.7067, val_precision: 0.6967 val_recall: 0.7067, val_f1: 0.7006\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 12:48:52\n",
            "loss: 0.1076, acc: 0.9668\n",
            "E2E-ABSA >>> 2024-06-04 12:49:00\n",
            "loss: 0.1382, acc: 0.9503\n",
            "E2E-ABSA >>> 2024-06-04 12:49:08\n",
            ">>> val_acc: 0.7104, val_precision: 0.7016 val_recall: 0.7104, val_f1: 0.7054\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 12:49:13\n",
            "loss: 0.1534, acc: 0.9417\n",
            "E2E-ABSA >>> 2024-06-04 12:49:22\n",
            "loss: 0.1404, acc: 0.9489\n",
            "E2E-ABSA >>> 2024-06-04 12:49:28\n",
            ">>> val_acc: 0.6778, val_precision: 0.7021 val_recall: 0.6778, val_f1: 0.6875\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 12:49:35\n",
            "loss: 0.1207, acc: 0.9520\n",
            "E2E-ABSA >>> 2024-06-04 12:49:47\n",
            ">>> val_acc: 0.7071, val_precision: 0.6804 val_recall: 0.7071, val_f1: 0.6830\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 12:49:48\n",
            "loss: 0.1359, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 12:49:57\n",
            "loss: 0.1245, acc: 0.9519\n",
            "E2E-ABSA >>> 2024-06-04 12:50:06\n",
            ">>> val_acc: 0.6933, val_precision: 0.6915 val_recall: 0.6933, val_f1: 0.6923\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 12:50:10\n",
            "loss: 0.1293, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 12:50:18\n",
            "loss: 0.1316, acc: 0.9536\n",
            "E2E-ABSA >>> 2024-06-04 12:50:25\n",
            ">>> val_acc: 0.6846, val_precision: 0.6879 val_recall: 0.6846, val_f1: 0.6834\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 12:50:31\n",
            "loss: 0.1298, acc: 0.9552\n",
            "E2E-ABSA >>> 2024-06-04 12:50:40\n",
            "loss: 0.1300, acc: 0.9525\n",
            "E2E-ABSA >>> 2024-06-04 12:50:45\n",
            ">>> val_acc: 0.6883, val_precision: 0.6906 val_recall: 0.6883, val_f1: 0.6871\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 12:50:53\n",
            "loss: 0.1099, acc: 0.9528\n",
            "E2E-ABSA >>> 2024-06-04 12:51:04\n",
            ">>> val_acc: 0.6767, val_precision: 0.6890 val_recall: 0.6767, val_f1: 0.6788\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 12:51:06\n",
            "loss: 0.1015, acc: 0.9613\n",
            "E2E-ABSA >>> 2024-06-04 12:51:14\n",
            "loss: 0.1205, acc: 0.9551\n",
            "E2E-ABSA >>> 2024-06-04 12:51:23\n",
            ">>> val_acc: 0.7006, val_precision: 0.6885 val_recall: 0.7006, val_f1: 0.6934\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 12:51:28\n",
            "loss: 0.0919, acc: 0.9661\n",
            "E2E-ABSA >>> 2024-06-04 12:51:36\n",
            "loss: 0.1090, acc: 0.9595\n",
            "E2E-ABSA >>> 2024-06-04 12:51:43\n",
            ">>> val_acc: 0.7060, val_precision: 0.6936 val_recall: 0.7060, val_f1: 0.6942\n",
            "E2E-ABSA >>> 2024-06-04 12:51:43\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7368, val_precision: 0.7353 val_recall: 0.7368, val_f1: 0.7338\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7368\n",
            ">>> test_acc: 0.7263, test_precision: 0.7137, test_recall: 0.7263, test_f1: 0.7173\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93af8e56-4b8c-4e83-b915-cddf2aa6aee0",
      "metadata": {
        "id": "93af8e56-4b8c-4e83-b915-cddf2aa6aee0"
      },
      "source": [
        "### **indobenchmark/indobert-base-p2** s6 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174e35b6-fd9d-4cf6-9908-1052bfcfa925",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "174e35b6-fd9d-4cf6-9908-1052bfcfa925",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "5872d30d-d923-4d6d-b135-1724693adae6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f6407323640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/d_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/d_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 13:22:22\n",
            "loss: 0.8937, acc: 0.6631\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 13:22:32\n",
            ">>> val_acc: 0.6770, val_precision: 0.5198 val_recall: 0.6770, val_f1: 0.5494\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.677\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 13:22:35\n",
            "loss: 0.7224, acc: 0.7130\n",
            "E2E-ABSA >>> 2024-06-04 13:22:44\n",
            "loss: 0.7536, acc: 0.6801\n",
            "E2E-ABSA >>> 2024-06-04 13:22:52\n",
            ">>> val_acc: 0.7107, val_precision: 0.6735 val_recall: 0.7107, val_f1: 0.6596\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7107\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 13:22:58\n",
            "loss: 0.6254, acc: 0.7431\n",
            "E2E-ABSA >>> 2024-06-04 13:23:06\n",
            "loss: 0.6227, acc: 0.7399\n",
            "E2E-ABSA >>> 2024-06-04 13:23:12\n",
            ">>> val_acc: 0.7397, val_precision: 0.7203 val_recall: 0.7397, val_f1: 0.7153\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7397\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 13:23:20\n",
            "loss: 0.5165, acc: 0.7855\n",
            "E2E-ABSA >>> 2024-06-04 13:23:32\n",
            ">>> val_acc: 0.7274, val_precision: 0.7143 val_recall: 0.7274, val_f1: 0.7179\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 13:23:33\n",
            "loss: 0.5495, acc: 0.7812\n",
            "E2E-ABSA >>> 2024-06-04 13:23:42\n",
            "loss: 0.4502, acc: 0.8154\n",
            "E2E-ABSA >>> 2024-06-04 13:23:52\n",
            ">>> val_acc: 0.7285, val_precision: 0.7138 val_recall: 0.7285, val_f1: 0.7178\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 13:23:55\n",
            "loss: 0.4039, acc: 0.8321\n",
            "E2E-ABSA >>> 2024-06-04 13:24:04\n",
            "loss: 0.3929, acc: 0.8417\n",
            "E2E-ABSA >>> 2024-06-04 13:24:11\n",
            ">>> val_acc: 0.7165, val_precision: 0.7133 val_recall: 0.7165, val_f1: 0.7130\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 13:24:17\n",
            "loss: 0.3173, acc: 0.8831\n",
            "E2E-ABSA >>> 2024-06-04 13:24:25\n",
            "loss: 0.3578, acc: 0.8584\n",
            "E2E-ABSA >>> 2024-06-04 13:24:31\n",
            ">>> val_acc: 0.6995, val_precision: 0.7260 val_recall: 0.6995, val_f1: 0.7088\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 13:24:38\n",
            "loss: 0.2966, acc: 0.8785\n",
            "E2E-ABSA >>> 2024-06-04 13:24:50\n",
            ">>> val_acc: 0.6774, val_precision: 0.7237 val_recall: 0.6774, val_f1: 0.6922\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 13:24:51\n",
            "loss: 0.2706, acc: 0.8945\n",
            "E2E-ABSA >>> 2024-06-04 13:25:00\n",
            "loss: 0.3189, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-04 13:25:09\n",
            ">>> val_acc: 0.6890, val_precision: 0.7071 val_recall: 0.6890, val_f1: 0.6917\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 13:25:13\n",
            "loss: 0.2539, acc: 0.8997\n",
            "E2E-ABSA >>> 2024-06-04 13:25:21\n",
            "loss: 0.2717, acc: 0.8990\n",
            "E2E-ABSA >>> 2024-06-04 13:25:29\n",
            ">>> val_acc: 0.7183, val_precision: 0.6996 val_recall: 0.7183, val_f1: 0.7028\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 13:25:35\n",
            "loss: 0.2438, acc: 0.8973\n",
            "E2E-ABSA >>> 2024-06-04 13:25:43\n",
            "loss: 0.2576, acc: 0.8960\n",
            "E2E-ABSA >>> 2024-06-04 13:25:48\n",
            ">>> val_acc: 0.6814, val_precision: 0.7099 val_recall: 0.6814, val_f1: 0.6911\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 13:25:56\n",
            "loss: 0.2065, acc: 0.9214\n",
            "E2E-ABSA >>> 2024-06-04 13:26:07\n",
            ">>> val_acc: 0.7002, val_precision: 0.6874 val_recall: 0.7002, val_f1: 0.6898\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 13:26:09\n",
            "loss: 0.1603, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-04 13:26:18\n",
            "loss: 0.2003, acc: 0.9244\n",
            "E2E-ABSA >>> 2024-06-04 13:26:27\n",
            ">>> val_acc: 0.6636, val_precision: 0.6957 val_recall: 0.6636, val_f1: 0.6703\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 13:26:31\n",
            "loss: 0.2027, acc: 0.9228\n",
            "E2E-ABSA >>> 2024-06-04 13:26:39\n",
            "loss: 0.1981, acc: 0.9218\n",
            "E2E-ABSA >>> 2024-06-04 13:26:46\n",
            ">>> val_acc: 0.6542, val_precision: 0.7019 val_recall: 0.6542, val_f1: 0.6695\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 13:26:53\n",
            "loss: 0.1682, acc: 0.9391\n",
            "E2E-ABSA >>> 2024-06-04 13:27:05\n",
            ">>> val_acc: 0.6984, val_precision: 0.6962 val_recall: 0.6984, val_f1: 0.6968\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 13:27:06\n",
            "loss: 0.1927, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 13:27:14\n",
            "loss: 0.1549, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 13:27:24\n",
            ">>> val_acc: 0.7100, val_precision: 0.6794 val_recall: 0.7100, val_f1: 0.6781\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 13:27:27\n",
            "loss: 0.1759, acc: 0.9277\n",
            "E2E-ABSA >>> 2024-06-04 13:27:36\n",
            "loss: 0.1748, acc: 0.9332\n",
            "E2E-ABSA >>> 2024-06-04 13:27:44\n",
            ">>> val_acc: 0.7035, val_precision: 0.6800 val_recall: 0.7035, val_f1: 0.6865\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 13:27:49\n",
            "loss: 0.1397, acc: 0.9523\n",
            "E2E-ABSA >>> 2024-06-04 13:27:57\n",
            "loss: 0.1425, acc: 0.9438\n",
            "E2E-ABSA >>> 2024-06-04 13:28:03\n",
            ">>> val_acc: 0.6810, val_precision: 0.6865 val_recall: 0.6810, val_f1: 0.6826\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 13:28:10\n",
            "loss: 0.1153, acc: 0.9528\n",
            "E2E-ABSA >>> 2024-06-04 13:28:22\n",
            ">>> val_acc: 0.7028, val_precision: 0.6682 val_recall: 0.7028, val_f1: 0.6711\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 13:28:23\n",
            "loss: 0.1451, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 13:28:32\n",
            "loss: 0.1399, acc: 0.9447\n",
            "E2E-ABSA >>> 2024-06-04 13:28:42\n",
            ">>> val_acc: 0.6890, val_precision: 0.6841 val_recall: 0.6890, val_f1: 0.6862\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 13:28:45\n",
            "loss: 0.0991, acc: 0.9641\n",
            "E2E-ABSA >>> 2024-06-04 13:28:54\n",
            "loss: 0.1176, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-04 13:29:01\n",
            ">>> val_acc: 0.6774, val_precision: 0.6854 val_recall: 0.6774, val_f1: 0.6811\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 13:29:07\n",
            "loss: 0.1515, acc: 0.9496\n",
            "E2E-ABSA >>> 2024-06-04 13:29:15\n",
            "loss: 0.1527, acc: 0.9476\n",
            "E2E-ABSA >>> 2024-06-04 13:29:20\n",
            ">>> val_acc: 0.6694, val_precision: 0.6885 val_recall: 0.6694, val_f1: 0.6770\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 13:29:28\n",
            "loss: 0.1357, acc: 0.9475\n",
            "E2E-ABSA >>> 2024-06-04 13:29:40\n",
            ">>> val_acc: 0.6901, val_precision: 0.6773 val_recall: 0.6901, val_f1: 0.6800\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 13:29:41\n",
            "loss: 0.0830, acc: 0.9732\n",
            "E2E-ABSA >>> 2024-06-04 13:29:50\n",
            "loss: 0.1166, acc: 0.9597\n",
            "E2E-ABSA >>> 2024-06-04 13:29:59\n",
            ">>> val_acc: 0.6676, val_precision: 0.6777 val_recall: 0.6676, val_f1: 0.6723\n",
            "E2E-ABSA >>> 2024-06-04 13:29:59\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7274, val_precision: 0.7143 val_recall: 0.7274, val_f1: 0.7179\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7274\n",
            ">>> test_acc: 0.7054, test_precision: 0.6877, test_recall: 0.7054, test_f1: 0.6928\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb9xFOubKmQg"
      },
      "source": [
        "## indobenchmark/indobert-base-p2 Insertion"
      ],
      "id": "mb9xFOubKmQg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hVNXHyFt2xP"
      },
      "source": [
        "### indobenchmark/indobert-base-p2 s1 insert"
      ],
      "id": "0hVNXHyFt2xP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KPf6V0ait2xV",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100%|█████████████████| 2.00/2.00 [00:00<00:00, 14.4kB/s]\n",
            "vocab.txt: 100%|█████████████████████████████| 229k/229k [00:00<00:00, 3.60MB/s]\n",
            "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 930kB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████| 1.53k/1.53k [00:00<00:00, 12.5MB/s]\n",
            "pytorch_model.bin: 100%|█████████████████████| 498M/498M [00:05<00:00, 92.0MB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f1837633760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 02:11:27\n",
            "loss: 0.8947, acc: 0.6306\n",
            "E2E-ABSA >>> 2024-06-04 02:11:38\n",
            ">>> val_acc: 0.6956, val_precision: 0.6664 val_recall: 0.6956, val_f1: 0.6708\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6956\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 02:11:41\n",
            "loss: 0.7311, acc: 0.6693\n",
            "E2E-ABSA >>> 2024-06-04 02:11:49\n",
            "loss: 0.7050, acc: 0.6895\n",
            "E2E-ABSA >>> 2024-06-04 02:11:58\n",
            ">>> val_acc: 0.7410, val_precision: 0.7299 val_recall: 0.7410, val_f1: 0.7222\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.741\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 02:12:03\n",
            "loss: 0.4564, acc: 0.8034\n",
            "E2E-ABSA >>> 2024-06-04 02:12:12\n",
            "loss: 0.4992, acc: 0.7969\n",
            "E2E-ABSA >>> 2024-06-04 02:12:19\n",
            ">>> val_acc: 0.7272, val_precision: 0.7153 val_recall: 0.7272, val_f1: 0.6694\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 02:12:25\n",
            "loss: 0.3943, acc: 0.8403\n",
            "E2E-ABSA >>> 2024-06-04 02:12:33\n",
            "loss: 0.4255, acc: 0.8296\n",
            "E2E-ABSA >>> 2024-06-04 02:12:38\n",
            ">>> val_acc: 0.7552, val_precision: 0.7414 val_recall: 0.7552, val_f1: 0.7449\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7552\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 02:12:47\n",
            "loss: 0.2909, acc: 0.8848\n",
            "E2E-ABSA >>> 2024-06-04 02:12:59\n",
            ">>> val_acc: 0.7378, val_precision: 0.7565 val_recall: 0.7378, val_f1: 0.7414\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 02:13:00\n",
            "loss: 0.2397, acc: 0.9187\n",
            "E2E-ABSA >>> 2024-06-04 02:13:09\n",
            "loss: 0.2690, acc: 0.8964\n",
            "E2E-ABSA >>> 2024-06-04 02:13:18\n",
            ">>> val_acc: 0.7304, val_precision: 0.7660 val_recall: 0.7304, val_f1: 0.7423\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 02:13:22\n",
            "loss: 0.2194, acc: 0.9190\n",
            "E2E-ABSA >>> 2024-06-04 02:13:31\n",
            "loss: 0.2291, acc: 0.9089\n",
            "E2E-ABSA >>> 2024-06-04 02:13:38\n",
            ">>> val_acc: 0.7304, val_precision: 0.7340 val_recall: 0.7304, val_f1: 0.7278\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 02:13:44\n",
            "loss: 0.1984, acc: 0.9228\n",
            "E2E-ABSA >>> 2024-06-04 02:13:52\n",
            "loss: 0.2178, acc: 0.9159\n",
            "E2E-ABSA >>> 2024-06-04 02:13:58\n",
            ">>> val_acc: 0.7396, val_precision: 0.7322 val_recall: 0.7396, val_f1: 0.7277\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 02:14:06\n",
            "loss: 0.1405, acc: 0.9484\n",
            "E2E-ABSA >>> 2024-06-04 02:14:17\n",
            ">>> val_acc: 0.7318, val_precision: 0.7259 val_recall: 0.7318, val_f1: 0.7285\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 02:14:19\n",
            "loss: 0.1456, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 02:14:27\n",
            "loss: 0.1691, acc: 0.9364\n",
            "E2E-ABSA >>> 2024-06-04 02:14:37\n",
            ">>> val_acc: 0.7318, val_precision: 0.7206 val_recall: 0.7318, val_f1: 0.7219\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 02:14:41\n",
            "loss: 0.1318, acc: 0.9484\n",
            "E2E-ABSA >>> 2024-06-04 02:14:49\n",
            "loss: 0.1401, acc: 0.9522\n",
            "E2E-ABSA >>> 2024-06-04 02:14:57\n",
            ">>> val_acc: 0.7304, val_precision: 0.7195 val_recall: 0.7304, val_f1: 0.7239\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 02:15:02\n",
            "loss: 0.1538, acc: 0.9482\n",
            "E2E-ABSA >>> 2024-06-04 02:15:11\n",
            "loss: 0.1615, acc: 0.9455\n",
            "E2E-ABSA >>> 2024-06-04 02:15:16\n",
            ">>> val_acc: 0.7233, val_precision: 0.7332 val_recall: 0.7233, val_f1: 0.7276\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 02:15:24\n",
            "loss: 0.1643, acc: 0.9389\n",
            "E2E-ABSA >>> 2024-06-04 02:15:36\n",
            ">>> val_acc: 0.7176, val_precision: 0.7171 val_recall: 0.7176, val_f1: 0.7018\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 02:15:37\n",
            "loss: 0.1442, acc: 0.9427\n",
            "E2E-ABSA >>> 2024-06-04 02:15:46\n",
            "loss: 0.1358, acc: 0.9526\n",
            "E2E-ABSA >>> 2024-06-04 02:15:56\n",
            ">>> val_acc: 0.6998, val_precision: 0.7246 val_recall: 0.6998, val_f1: 0.7016\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 02:15:59\n",
            "loss: 0.1142, acc: 0.9618\n",
            "E2E-ABSA >>> 2024-06-04 02:16:08\n",
            "loss: 0.1385, acc: 0.9540\n",
            "E2E-ABSA >>> 2024-06-04 02:16:16\n",
            ">>> val_acc: 0.7364, val_precision: 0.7288 val_recall: 0.7364, val_f1: 0.7320\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 02:16:21\n",
            "loss: 0.1182, acc: 0.9656\n",
            "E2E-ABSA >>> 2024-06-04 02:16:29\n",
            "loss: 0.1119, acc: 0.9602\n",
            "E2E-ABSA >>> 2024-06-04 02:16:35\n",
            ">>> val_acc: 0.7009, val_precision: 0.7249 val_recall: 0.7009, val_f1: 0.7058\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 02:16:42\n",
            "loss: 0.0860, acc: 0.9732\n",
            "E2E-ABSA >>> 2024-06-04 02:16:55\n",
            ">>> val_acc: 0.6888, val_precision: 0.7201 val_recall: 0.6888, val_f1: 0.7006\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 02:16:56\n",
            "loss: 0.1149, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 02:17:04\n",
            "loss: 0.1006, acc: 0.9647\n",
            "E2E-ABSA >>> 2024-06-04 02:17:15\n",
            ">>> val_acc: 0.7208, val_precision: 0.7162 val_recall: 0.7208, val_f1: 0.7182\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 02:17:17\n",
            "loss: 0.1258, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 02:17:26\n",
            "loss: 0.1202, acc: 0.9588\n",
            "E2E-ABSA >>> 2024-06-04 02:17:34\n",
            ">>> val_acc: 0.7208, val_precision: 0.7039 val_recall: 0.7208, val_f1: 0.7090\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 02:17:39\n",
            "loss: 0.0824, acc: 0.9721\n",
            "E2E-ABSA >>> 2024-06-04 02:17:48\n",
            "loss: 0.0993, acc: 0.9655\n",
            "E2E-ABSA >>> 2024-06-04 02:17:54\n",
            ">>> val_acc: 0.7169, val_precision: 0.7028 val_recall: 0.7169, val_f1: 0.7082\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 02:18:01\n",
            "loss: 0.1203, acc: 0.9625\n",
            "E2E-ABSA >>> 2024-06-04 02:18:14\n",
            ">>> val_acc: 0.6988, val_precision: 0.6964 val_recall: 0.6988, val_f1: 0.6955\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 02:18:14\n",
            "loss: 0.0074, acc: 1.0000\n",
            "E2E-ABSA >>> 2024-06-04 02:18:23\n",
            "loss: 0.1060, acc: 0.9681\n",
            "E2E-ABSA >>> 2024-06-04 02:18:33\n",
            ">>> val_acc: 0.7123, val_precision: 0.7121 val_recall: 0.7123, val_f1: 0.7117\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 02:18:36\n",
            "loss: 0.0471, acc: 0.9911\n",
            "E2E-ABSA >>> 2024-06-04 02:18:44\n",
            "loss: 0.0973, acc: 0.9722\n",
            "E2E-ABSA >>> 2024-06-04 02:18:53\n",
            ">>> val_acc: 0.6941, val_precision: 0.6916 val_recall: 0.6941, val_f1: 0.6865\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 02:18:57\n",
            "loss: 0.0989, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 02:19:06\n",
            "loss: 0.1017, acc: 0.9663\n",
            "E2E-ABSA >>> 2024-06-04 02:19:13\n",
            ">>> val_acc: 0.7094, val_precision: 0.6953 val_recall: 0.7094, val_f1: 0.6967\n",
            "E2E-ABSA >>> 2024-06-04 02:19:13\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7552, val_precision: 0.7414 val_recall: 0.7552, val_f1: 0.7449\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7552\n",
            ">>> test_acc: 0.7233, test_precision: 0.7051, test_recall: 0.7233, test_f1: 0.7105\n"
          ]
        }
      ],
      "source": [
        "# 3-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "KPf6V0ait2xV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b88182e7-b832-43af-b972-5dccecd7d6ea"
      },
      "source": [
        "### indobenchmark/indobert-base-p2 s2 insert"
      ],
      "id": "b88182e7-b832-43af-b972-5dccecd7d6ea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "67733009-a6ae-4921-b8c4-f8540037df8f",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100%|█████████████████| 2.00/2.00 [00:00<00:00, 15.0kB/s]\n",
            "vocab.txt: 100%|██████████████████████████████| 229k/229k [00:00<00:00, 430kB/s]\n",
            "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 953kB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████| 1.53k/1.53k [00:00<00:00, 12.9MB/s]\n",
            "pytorch_model.bin: 100%|█████████████████████| 498M/498M [00:06<00:00, 82.1MB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f4ae6d27400>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-05-30 16:27:56\n",
            "loss: 0.9159, acc: 0.6338\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-05-30 16:28:07\n",
            ">>> val_acc: 0.6895, val_precision: 0.6190 val_recall: 0.6895, val_f1: 0.5676\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6895\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-05-30 16:28:10\n",
            "loss: 0.7737, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-05-30 16:28:18\n",
            "loss: 0.7697, acc: 0.6683\n",
            "E2E-ABSA >>> 2024-05-30 16:28:28\n",
            ">>> val_acc: 0.7229, val_precision: 0.7186 val_recall: 0.7229, val_f1: 0.7103\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7229\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-05-30 16:28:32\n",
            "loss: 0.6037, acc: 0.7331\n",
            "E2E-ABSA >>> 2024-05-30 16:28:41\n",
            "loss: 0.5995, acc: 0.7428\n",
            "E2E-ABSA >>> 2024-05-30 16:28:48\n",
            ">>> val_acc: 0.7343, val_precision: 0.7160 val_recall: 0.7343, val_f1: 0.6903\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-05-30 16:28:54\n",
            "loss: 0.5120, acc: 0.7821\n",
            "E2E-ABSA >>> 2024-05-30 16:29:02\n",
            "loss: 0.5173, acc: 0.7827\n",
            "E2E-ABSA >>> 2024-05-30 16:29:07\n",
            ">>> val_acc: 0.7488, val_precision: 0.7374 val_recall: 0.7488, val_f1: 0.7419\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7488\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-05-30 16:29:16\n",
            "loss: 0.3572, acc: 0.8561\n",
            "E2E-ABSA >>> 2024-05-30 16:29:27\n",
            ">>> val_acc: 0.7321, val_precision: 0.7419 val_recall: 0.7321, val_f1: 0.7208\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-05-30 16:29:29\n",
            "loss: 0.3516, acc: 0.8625\n",
            "E2E-ABSA >>> 2024-05-30 16:29:38\n",
            "loss: 0.3619, acc: 0.8609\n",
            "E2E-ABSA >>> 2024-05-30 16:29:47\n",
            ">>> val_acc: 0.6995, val_precision: 0.7520 val_recall: 0.6995, val_f1: 0.7154\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-05-30 16:29:51\n",
            "loss: 0.2361, acc: 0.9134\n",
            "E2E-ABSA >>> 2024-05-30 16:29:59\n",
            "loss: 0.2686, acc: 0.8971\n",
            "E2E-ABSA >>> 2024-05-30 16:30:07\n",
            ">>> val_acc: 0.7218, val_precision: 0.7275 val_recall: 0.7218, val_f1: 0.7197\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-05-30 16:30:13\n",
            "loss: 0.2488, acc: 0.9053\n",
            "E2E-ABSA >>> 2024-05-30 16:30:21\n",
            "loss: 0.2672, acc: 0.8925\n",
            "E2E-ABSA >>> 2024-05-30 16:30:26\n",
            ">>> val_acc: 0.7407, val_precision: 0.7252 val_recall: 0.7407, val_f1: 0.7263\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-05-30 16:30:34\n",
            "loss: 0.1853, acc: 0.9280\n",
            "E2E-ABSA >>> 2024-05-30 16:30:46\n",
            ">>> val_acc: 0.7279, val_precision: 0.7277 val_recall: 0.7279, val_f1: 0.7278\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-05-30 16:30:47\n",
            "loss: 0.1516, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-05-30 16:30:56\n",
            "loss: 0.1572, acc: 0.9418\n",
            "E2E-ABSA >>> 2024-05-30 16:31:06\n",
            ">>> val_acc: 0.7265, val_precision: 0.7184 val_recall: 0.7265, val_f1: 0.7204\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-05-30 16:31:09\n",
            "loss: 0.1173, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-05-30 16:31:18\n",
            "loss: 0.1708, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 16:31:25\n",
            ">>> val_acc: 0.7250, val_precision: 0.7159 val_recall: 0.7250, val_f1: 0.7170\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-05-30 16:31:31\n",
            "loss: 0.1569, acc: 0.9463\n",
            "E2E-ABSA >>> 2024-05-30 16:31:39\n",
            "loss: 0.1831, acc: 0.9310\n",
            "E2E-ABSA >>> 2024-05-30 16:31:45\n",
            ">>> val_acc: 0.7190, val_precision: 0.7147 val_recall: 0.7190, val_f1: 0.7134\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-05-30 16:31:53\n",
            "loss: 0.1247, acc: 0.9510\n",
            "E2E-ABSA >>> 2024-05-30 16:32:05\n",
            ">>> val_acc: 0.7272, val_precision: 0.7000 val_recall: 0.7272, val_f1: 0.7048\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-05-30 16:32:06\n",
            "loss: 0.0799, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-05-30 16:32:14\n",
            "loss: 0.1553, acc: 0.9420\n",
            "E2E-ABSA >>> 2024-05-30 16:32:24\n",
            ">>> val_acc: 0.7094, val_precision: 0.7231 val_recall: 0.7094, val_f1: 0.7120\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-05-30 16:32:28\n",
            "loss: 0.0834, acc: 0.9792\n",
            "E2E-ABSA >>> 2024-05-30 16:32:36\n",
            "loss: 0.1091, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-30 16:32:44\n",
            ">>> val_acc: 0.7002, val_precision: 0.7225 val_recall: 0.7002, val_f1: 0.7091\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-05-30 16:32:49\n",
            "loss: 0.0945, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-05-30 16:32:58\n",
            "loss: 0.1061, acc: 0.9602\n",
            "E2E-ABSA >>> 2024-05-30 16:33:04\n",
            ">>> val_acc: 0.7073, val_precision: 0.7154 val_recall: 0.7073, val_f1: 0.7103\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-05-30 16:33:11\n",
            "loss: 0.0954, acc: 0.9621\n",
            "E2E-ABSA >>> 2024-05-30 16:33:23\n",
            ">>> val_acc: 0.7005, val_precision: 0.7044 val_recall: 0.7005, val_f1: 0.6970\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-05-30 16:33:24\n",
            "loss: 0.1158, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-05-30 16:33:33\n",
            "loss: 0.0931, acc: 0.9676\n",
            "E2E-ABSA >>> 2024-05-30 16:33:43\n",
            ">>> val_acc: 0.7158, val_precision: 0.7114 val_recall: 0.7158, val_f1: 0.7115\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-05-30 16:33:46\n",
            "loss: 0.0633, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-05-30 16:33:54\n",
            "loss: 0.0850, acc: 0.9721\n",
            "E2E-ABSA >>> 2024-05-30 16:34:03\n",
            ">>> val_acc: 0.7105, val_precision: 0.7097 val_recall: 0.7105, val_f1: 0.7095\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-05-30 16:34:07\n",
            "loss: 0.0569, acc: 0.9799\n",
            "E2E-ABSA >>> 2024-05-30 16:34:16\n",
            "loss: 0.0843, acc: 0.9712\n",
            "E2E-ABSA >>> 2024-05-30 16:34:22\n",
            ">>> val_acc: 0.7151, val_precision: 0.6859 val_recall: 0.7151, val_f1: 0.6908\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-05-30 16:34:29\n",
            "loss: 0.1019, acc: 0.9664\n",
            "E2E-ABSA >>> 2024-05-30 16:34:42\n",
            ">>> val_acc: 0.7048, val_precision: 0.6946 val_recall: 0.7048, val_f1: 0.6955\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-05-30 16:34:42\n",
            "loss: 0.0329, acc: 1.0000\n",
            "E2E-ABSA >>> 2024-05-30 16:34:51\n",
            "loss: 0.0849, acc: 0.9700\n",
            "E2E-ABSA >>> 2024-05-30 16:35:01\n",
            ">>> val_acc: 0.7183, val_precision: 0.6938 val_recall: 0.7183, val_f1: 0.6999\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-05-30 16:35:04\n",
            "loss: 0.0529, acc: 0.9866\n",
            "E2E-ABSA >>> 2024-05-30 16:35:12\n",
            "loss: 0.1024, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-05-30 16:35:21\n",
            ">>> val_acc: 0.6792, val_precision: 0.7062 val_recall: 0.6792, val_f1: 0.6876\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-05-30 16:35:25\n",
            "loss: 0.0787, acc: 0.9760\n",
            "E2E-ABSA >>> 2024-05-30 16:35:34\n",
            "loss: 0.0849, acc: 0.9712\n",
            "E2E-ABSA >>> 2024-05-30 16:35:41\n",
            ">>> val_acc: 0.7204, val_precision: 0.7067 val_recall: 0.7204, val_f1: 0.7109\n",
            "E2E-ABSA >>> 2024-05-30 16:35:41\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7488, val_precision: 0.7374 val_recall: 0.7488, val_f1: 0.7419\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7488\n",
            ">>> test_acc: 0.7212, test_precision: 0.7061, test_recall: 0.7212, test_f1: 0.7114\n"
          ]
        }
      ],
      "source": [
        "# 29-5 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "67733009-a6ae-4921-b8c4-f8540037df8f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05b7fcd9-724d-4f1d-bb65-4f79a761a1f6"
      },
      "source": [
        "### indobenchmark/indobert-base-p2 s3 insert"
      ],
      "id": "05b7fcd9-724d-4f1d-bb65-4f79a761a1f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a9af24b3-2e0b-44f3-a24f-e487ed3d390f",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fd33cc13760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/z_insert_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/z_insert_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 13:37:59\n",
            "loss: 0.9193, acc: 0.6306\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-04 13:38:10\n",
            ">>> val_acc: 0.6863, val_precision: 0.4710 val_recall: 0.6863, val_f1: 0.5587\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6863\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 13:38:13\n",
            "loss: 0.7788, acc: 0.6589\n",
            "E2E-ABSA >>> 2024-06-04 13:38:22\n",
            "loss: 0.7777, acc: 0.6704\n",
            "E2E-ABSA >>> 2024-06-04 13:38:31\n",
            ">>> val_acc: 0.7204, val_precision: 0.7094 val_recall: 0.7204, val_f1: 0.7005\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7204\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 13:38:35\n",
            "loss: 0.5756, acc: 0.7552\n",
            "E2E-ABSA >>> 2024-06-04 13:38:44\n",
            "loss: 0.5951, acc: 0.7534\n",
            "E2E-ABSA >>> 2024-06-04 13:38:51\n",
            ">>> val_acc: 0.7229, val_precision: 0.7075 val_recall: 0.7229, val_f1: 0.6659\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 13:38:57\n",
            "loss: 0.5330, acc: 0.7665\n",
            "E2E-ABSA >>> 2024-06-04 13:39:06\n",
            "loss: 0.5304, acc: 0.7783\n",
            "E2E-ABSA >>> 2024-06-04 13:39:10\n",
            ">>> val_acc: 0.7229, val_precision: 0.7144 val_recall: 0.7229, val_f1: 0.7181\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7229\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 13:39:19\n",
            "loss: 0.4185, acc: 0.8366\n",
            "E2E-ABSA >>> 2024-06-04 13:39:31\n",
            ">>> val_acc: 0.7226, val_precision: 0.6909 val_recall: 0.7226, val_f1: 0.6903\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 13:39:32\n",
            "loss: 0.3171, acc: 0.8812\n",
            "E2E-ABSA >>> 2024-06-04 13:39:41\n",
            "loss: 0.3936, acc: 0.8417\n",
            "E2E-ABSA >>> 2024-06-04 13:39:50\n",
            ">>> val_acc: 0.6625, val_precision: 0.7378 val_recall: 0.6625, val_f1: 0.6840\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 13:39:54\n",
            "loss: 0.3159, acc: 0.8665\n",
            "E2E-ABSA >>> 2024-06-04 13:40:03\n",
            "loss: 0.3355, acc: 0.8620\n",
            "E2E-ABSA >>> 2024-06-04 13:40:10\n",
            ">>> val_acc: 0.6988, val_precision: 0.7124 val_recall: 0.6988, val_f1: 0.7015\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 13:40:16\n",
            "loss: 0.3462, acc: 0.8631\n",
            "E2E-ABSA >>> 2024-06-04 13:40:24\n",
            "loss: 0.3584, acc: 0.8478\n",
            "E2E-ABSA >>> 2024-06-04 13:40:30\n",
            ">>> val_acc: 0.7123, val_precision: 0.7070 val_recall: 0.7123, val_f1: 0.6948\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 13:40:38\n",
            "loss: 0.2705, acc: 0.8886\n",
            "E2E-ABSA >>> 2024-06-04 13:40:49\n",
            ">>> val_acc: 0.7162, val_precision: 0.7124 val_recall: 0.7162, val_f1: 0.7133\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 13:40:51\n",
            "loss: 0.2754, acc: 0.8945\n",
            "E2E-ABSA >>> 2024-06-04 13:40:59\n",
            "loss: 0.2528, acc: 0.9009\n",
            "E2E-ABSA >>> 2024-06-04 13:41:09\n",
            ">>> val_acc: 0.7165, val_precision: 0.7080 val_recall: 0.7165, val_f1: 0.7065\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 13:41:12\n",
            "loss: 0.2241, acc: 0.9031\n",
            "E2E-ABSA >>> 2024-06-04 13:41:21\n",
            "loss: 0.2572, acc: 0.8955\n",
            "E2E-ABSA >>> 2024-06-04 13:41:29\n",
            ">>> val_acc: 0.7144, val_precision: 0.6906 val_recall: 0.7144, val_f1: 0.6910\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 13:41:34\n",
            "loss: 0.2314, acc: 0.9199\n",
            "E2E-ABSA >>> 2024-06-04 13:41:43\n",
            "loss: 0.2680, acc: 0.8944\n",
            "E2E-ABSA >>> 2024-06-04 13:41:48\n",
            ">>> val_acc: 0.6945, val_precision: 0.7050 val_recall: 0.6945, val_f1: 0.6987\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 13:41:56\n",
            "loss: 0.2000, acc: 0.9197\n",
            "E2E-ABSA >>> 2024-06-04 13:42:08\n",
            ">>> val_acc: 0.7115, val_precision: 0.7027 val_recall: 0.7115, val_f1: 0.7056\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 13:42:09\n",
            "loss: 0.1225, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-04 13:42:18\n",
            "loss: 0.1975, acc: 0.9185\n",
            "E2E-ABSA >>> 2024-06-04 13:42:28\n",
            ">>> val_acc: 0.7162, val_precision: 0.6853 val_recall: 0.7162, val_f1: 0.6926\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 13:42:31\n",
            "loss: 0.1650, acc: 0.9392\n",
            "E2E-ABSA >>> 2024-06-04 13:42:39\n",
            "loss: 0.1882, acc: 0.9210\n",
            "E2E-ABSA >>> 2024-06-04 13:42:47\n",
            ">>> val_acc: 0.6938, val_precision: 0.6917 val_recall: 0.6938, val_f1: 0.6922\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 13:42:52\n",
            "loss: 0.1703, acc: 0.9302\n",
            "E2E-ABSA >>> 2024-06-04 13:43:01\n",
            "loss: 0.1845, acc: 0.9289\n",
            "E2E-ABSA >>> 2024-06-04 13:43:07\n",
            ">>> val_acc: 0.6938, val_precision: 0.7011 val_recall: 0.6938, val_f1: 0.6971\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 13:43:14\n",
            "loss: 0.1493, acc: 0.9449\n",
            "E2E-ABSA >>> 2024-06-04 13:43:27\n",
            ">>> val_acc: 0.6785, val_precision: 0.6908 val_recall: 0.6785, val_f1: 0.6785\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 13:43:27\n",
            "loss: 0.1797, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-04 13:43:36\n",
            "loss: 0.1543, acc: 0.9387\n",
            "E2E-ABSA >>> 2024-06-04 13:43:46\n",
            ">>> val_acc: 0.7162, val_precision: 0.6845 val_recall: 0.7162, val_f1: 0.6856\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 13:43:49\n",
            "loss: 0.1438, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-04 13:43:58\n",
            "loss: 0.1338, acc: 0.9498\n",
            "E2E-ABSA >>> 2024-06-04 13:44:06\n",
            ">>> val_acc: 0.6796, val_precision: 0.6997 val_recall: 0.6796, val_f1: 0.6880\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 13:44:11\n",
            "loss: 0.1396, acc: 0.9442\n",
            "E2E-ABSA >>> 2024-06-04 13:44:19\n",
            "loss: 0.1629, acc: 0.9363\n",
            "E2E-ABSA >>> 2024-06-04 13:44:26\n",
            ">>> val_acc: 0.7091, val_precision: 0.6809 val_recall: 0.7091, val_f1: 0.6895\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 13:44:32\n",
            "loss: 0.1184, acc: 0.9539\n",
            "E2E-ABSA >>> 2024-06-04 13:44:45\n",
            ">>> val_acc: 0.6842, val_precision: 0.6843 val_recall: 0.6842, val_f1: 0.6842\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 13:44:46\n",
            "loss: 0.0813, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 13:44:54\n",
            "loss: 0.1676, acc: 0.9417\n",
            "E2E-ABSA >>> 2024-06-04 13:45:05\n",
            ">>> val_acc: 0.6995, val_precision: 0.6890 val_recall: 0.6995, val_f1: 0.6933\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 13:45:07\n",
            "loss: 0.0980, acc: 0.9710\n",
            "E2E-ABSA >>> 2024-06-04 13:45:16\n",
            "loss: 0.1252, acc: 0.9521\n",
            "E2E-ABSA >>> 2024-06-04 13:45:25\n",
            ">>> val_acc: 0.7087, val_precision: 0.6845 val_recall: 0.7087, val_f1: 0.6914\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 13:45:29\n",
            "loss: 0.1012, acc: 0.9651\n",
            "E2E-ABSA >>> 2024-06-04 13:45:38\n",
            "loss: 0.1100, acc: 0.9597\n",
            "E2E-ABSA >>> 2024-06-04 13:45:44\n",
            ">>> val_acc: 0.7055, val_precision: 0.6816 val_recall: 0.7055, val_f1: 0.6896\n",
            "E2E-ABSA >>> 2024-06-04 13:45:44\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7229, val_precision: 0.7144 val_recall: 0.7229, val_f1: 0.7181\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.7229\n",
            ">>> test_acc: 0.7042, test_precision: 0.6890, test_recall: 0.7042, test_f1: 0.6951\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "a9af24b3-2e0b-44f3-a24f-e487ed3d390f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bd46a3c-729e-467e-a5ef-710f670d5fa0"
      },
      "source": [
        "### indobenchmark/indobert-base-p2 s4 insert"
      ],
      "id": "2bd46a3c-729e-467e-a5ef-710f670d5fa0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f50d8911-78ac-4be7-8d27-01ceae1b8832",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f12cdd17760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/j_insert_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/j_insert_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 13:49:10\n",
            "loss: 0.8438, acc: 0.6306\n",
            "E2E-ABSA >>> 2024-06-04 13:49:22\n",
            ">>> val_acc: 0.7268, val_precision: 0.7000 val_recall: 0.7268, val_f1: 0.6759\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7268\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 13:49:24\n",
            "loss: 0.6971, acc: 0.6953\n",
            "E2E-ABSA >>> 2024-06-04 13:49:33\n",
            "loss: 0.6612, acc: 0.7283\n",
            "E2E-ABSA >>> 2024-06-04 13:49:42\n",
            ">>> val_acc: 0.7716, val_precision: 0.7643 val_recall: 0.7716, val_f1: 0.7622\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7716\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 13:49:46\n",
            "loss: 0.4334, acc: 0.8242\n",
            "E2E-ABSA >>> 2024-06-04 13:49:55\n",
            "loss: 0.4799, acc: 0.8070\n",
            "E2E-ABSA >>> 2024-06-04 13:50:02\n",
            ">>> val_acc: 0.7499, val_precision: 0.7297 val_recall: 0.7499, val_f1: 0.7150\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 13:50:08\n",
            "loss: 0.3631, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-04 13:50:17\n",
            "loss: 0.3949, acc: 0.8416\n",
            "E2E-ABSA >>> 2024-06-04 13:50:22\n",
            ">>> val_acc: 0.7783, val_precision: 0.7666 val_recall: 0.7783, val_f1: 0.7699\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7783\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 13:50:30\n",
            "loss: 0.2397, acc: 0.9128\n",
            "E2E-ABSA >>> 2024-06-04 13:50:42\n",
            ">>> val_acc: 0.7307, val_precision: 0.7657 val_recall: 0.7307, val_f1: 0.7398\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 13:50:44\n",
            "loss: 0.1797, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-04 13:50:52\n",
            "loss: 0.2470, acc: 0.9073\n",
            "E2E-ABSA >>> 2024-06-04 13:51:02\n",
            ">>> val_acc: 0.7517, val_precision: 0.7556 val_recall: 0.7517, val_f1: 0.7528\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 13:51:05\n",
            "loss: 0.1600, acc: 0.9432\n",
            "E2E-ABSA >>> 2024-06-04 13:51:14\n",
            "loss: 0.1800, acc: 0.9310\n",
            "E2E-ABSA >>> 2024-06-04 13:51:21\n",
            ">>> val_acc: 0.7659, val_precision: 0.7548 val_recall: 0.7659, val_f1: 0.7577\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 13:51:27\n",
            "loss: 0.1135, acc: 0.9678\n",
            "E2E-ABSA >>> 2024-06-04 13:51:36\n",
            "loss: 0.1786, acc: 0.9435\n",
            "E2E-ABSA >>> 2024-06-04 13:51:41\n",
            ">>> val_acc: 0.7563, val_precision: 0.7545 val_recall: 0.7563, val_f1: 0.7536\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 13:51:49\n",
            "loss: 0.1422, acc: 0.9504\n",
            "E2E-ABSA >>> 2024-06-04 13:52:01\n",
            ">>> val_acc: 0.7560, val_precision: 0.7512 val_recall: 0.7560, val_f1: 0.7534\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 13:52:02\n",
            "loss: 0.1269, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 13:52:11\n",
            "loss: 0.1507, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-06-04 13:52:20\n",
            ">>> val_acc: 0.7453, val_precision: 0.7292 val_recall: 0.7453, val_f1: 0.7346\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 13:52:24\n",
            "loss: 0.1481, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 13:52:32\n",
            "loss: 0.1408, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-04 13:52:40\n",
            ">>> val_acc: 0.7403, val_precision: 0.7398 val_recall: 0.7403, val_f1: 0.7365\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 13:52:46\n",
            "loss: 0.1338, acc: 0.9629\n",
            "E2E-ABSA >>> 2024-06-04 13:52:54\n",
            "loss: 0.1385, acc: 0.9539\n",
            "E2E-ABSA >>> 2024-06-04 13:53:00\n",
            ">>> val_acc: 0.7368, val_precision: 0.7551 val_recall: 0.7368, val_f1: 0.7399\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 13:53:07\n",
            "loss: 0.0878, acc: 0.9709\n",
            "E2E-ABSA >>> 2024-06-04 13:53:20\n",
            ">>> val_acc: 0.7400, val_precision: 0.7247 val_recall: 0.7400, val_f1: 0.7266\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 13:53:21\n",
            "loss: 0.0758, acc: 0.9792\n",
            "E2E-ABSA >>> 2024-06-04 13:53:29\n",
            "loss: 0.1269, acc: 0.9576\n",
            "E2E-ABSA >>> 2024-06-04 13:53:39\n",
            ">>> val_acc: 0.7332, val_precision: 0.7305 val_recall: 0.7332, val_f1: 0.7287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 13:53:42\n",
            "loss: 0.0761, acc: 0.9774\n",
            "E2E-ABSA >>> 2024-06-04 13:53:51\n",
            "loss: 0.1004, acc: 0.9697\n",
            "E2E-ABSA >>> 2024-06-04 13:53:59\n",
            ">>> val_acc: 0.7275, val_precision: 0.7374 val_recall: 0.7275, val_f1: 0.7287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 13:54:04\n",
            "loss: 0.0979, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 13:54:13\n",
            "loss: 0.1222, acc: 0.9602\n",
            "E2E-ABSA >>> 2024-06-04 13:54:19\n",
            ">>> val_acc: 0.7385, val_precision: 0.7328 val_recall: 0.7385, val_f1: 0.7354\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 13:54:26\n",
            "loss: 0.0623, acc: 0.9821\n",
            "E2E-ABSA >>> 2024-06-04 13:54:38\n",
            ">>> val_acc: 0.7375, val_precision: 0.7165 val_recall: 0.7375, val_f1: 0.7200\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 13:54:39\n",
            "loss: 0.0858, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 13:54:48\n",
            "loss: 0.0779, acc: 0.9734\n",
            "E2E-ABSA >>> 2024-06-04 13:54:58\n",
            ">>> val_acc: 0.7158, val_precision: 0.7079 val_recall: 0.7158, val_f1: 0.7105\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 13:55:01\n",
            "loss: 0.1428, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 13:55:09\n",
            "loss: 0.1077, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-06-04 13:55:18\n",
            ">>> val_acc: 0.7293, val_precision: 0.7259 val_recall: 0.7293, val_f1: 0.7271\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 13:55:23\n",
            "loss: 0.0606, acc: 0.9799\n",
            "E2E-ABSA >>> 2024-06-04 13:55:31\n",
            "loss: 0.0985, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 13:55:38\n",
            ">>> val_acc: 0.7346, val_precision: 0.7189 val_recall: 0.7346, val_f1: 0.7229\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 13:55:44\n",
            "loss: 0.0717, acc: 0.9773\n",
            "E2E-ABSA >>> 2024-06-04 13:55:57\n",
            ">>> val_acc: 0.7172, val_precision: 0.6971 val_recall: 0.7172, val_f1: 0.7002\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 13:55:58\n",
            "loss: 0.1002, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 13:56:06\n",
            "loss: 0.1146, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 13:56:17\n",
            ">>> val_acc: 0.7325, val_precision: 0.7241 val_recall: 0.7325, val_f1: 0.7274\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 13:56:19\n",
            "loss: 0.0777, acc: 0.9732\n",
            "E2E-ABSA >>> 2024-06-04 13:56:28\n",
            "loss: 0.0983, acc: 0.9707\n",
            "E2E-ABSA >>> 2024-06-04 13:56:37\n",
            ">>> val_acc: 0.7187, val_precision: 0.7006 val_recall: 0.7187, val_f1: 0.7065\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 13:56:41\n",
            "loss: 0.0679, acc: 0.9820\n",
            "E2E-ABSA >>> 2024-06-04 13:56:50\n",
            "loss: 0.0911, acc: 0.9716\n",
            "E2E-ABSA >>> 2024-06-04 13:56:56\n",
            ">>> val_acc: 0.7204, val_precision: 0.7007 val_recall: 0.7204, val_f1: 0.7049\n",
            "E2E-ABSA >>> 2024-06-04 13:56:56\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7783, val_precision: 0.7666 val_recall: 0.7783, val_f1: 0.7699\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7783\n",
            ">>> test_acc: 0.7602, test_precision: 0.7456, test_recall: 0.7602, test_f1: 0.7479\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "f50d8911-78ac-4be7-8d27-01ceae1b8832"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbd9c5b5-0545-4a35-a1f5-58d2463cefec"
      },
      "source": [
        "### indobenchmark/indobert-base-p2 s5 insert"
      ],
      "id": "fbd9c5b5-0545-4a35-a1f5-58d2463cefec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "612ef11b-07bd-43c5-b724-7b30d3e06396",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fcf98e2f760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 14:08:13\n",
            "loss: 0.8852, acc: 0.6412\n",
            "E2E-ABSA >>> 2024-06-04 14:08:24\n",
            ">>> val_acc: 0.7112, val_precision: 0.6951 val_recall: 0.7112, val_f1: 0.6756\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7112\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 14:08:27\n",
            "loss: 0.7319, acc: 0.6823\n",
            "E2E-ABSA >>> 2024-06-04 14:08:35\n",
            "loss: 0.6873, acc: 0.7152\n",
            "E2E-ABSA >>> 2024-06-04 14:08:44\n",
            ">>> val_acc: 0.7513, val_precision: 0.7605 val_recall: 0.7513, val_f1: 0.7433\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7513\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 14:08:49\n",
            "loss: 0.4747, acc: 0.7956\n",
            "E2E-ABSA >>> 2024-06-04 14:08:57\n",
            "loss: 0.5041, acc: 0.7817\n",
            "E2E-ABSA >>> 2024-06-04 14:09:04\n",
            ">>> val_acc: 0.7638, val_precision: 0.7501 val_recall: 0.7638, val_f1: 0.7288\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 14:09:10\n",
            "loss: 0.3586, acc: 0.8611\n",
            "E2E-ABSA >>> 2024-06-04 14:09:19\n",
            "loss: 0.3964, acc: 0.8383\n",
            "E2E-ABSA >>> 2024-06-04 14:09:24\n",
            ">>> val_acc: 0.7815, val_precision: 0.7706 val_recall: 0.7815, val_f1: 0.7728\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7815\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 14:09:32\n",
            "loss: 0.2573, acc: 0.9004\n",
            "E2E-ABSA >>> 2024-06-04 14:09:44\n",
            ">>> val_acc: 0.7787, val_precision: 0.7836 val_recall: 0.7787, val_f1: 0.7792\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7787\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 14:09:46\n",
            "loss: 0.2193, acc: 0.9125\n",
            "E2E-ABSA >>> 2024-06-04 14:09:54\n",
            "loss: 0.2505, acc: 0.8984\n",
            "E2E-ABSA >>> 2024-06-04 14:10:04\n",
            ">>> val_acc: 0.7478, val_precision: 0.7806 val_recall: 0.7478, val_f1: 0.7580\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 14:10:08\n",
            "loss: 0.1783, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-06-04 14:10:16\n",
            "loss: 0.1890, acc: 0.9306\n",
            "E2E-ABSA >>> 2024-06-04 14:10:24\n",
            ">>> val_acc: 0.7623, val_precision: 0.7619 val_recall: 0.7623, val_f1: 0.7534\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 14:10:29\n",
            "loss: 0.1482, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 14:10:38\n",
            "loss: 0.1687, acc: 0.9397\n",
            "E2E-ABSA >>> 2024-06-04 14:10:43\n",
            ">>> val_acc: 0.7531, val_precision: 0.7552 val_recall: 0.7531, val_f1: 0.7485\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 14:10:51\n",
            "loss: 0.1282, acc: 0.9511\n",
            "E2E-ABSA >>> 2024-06-04 14:11:03\n",
            ">>> val_acc: 0.7460, val_precision: 0.7615 val_recall: 0.7460, val_f1: 0.7493\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 14:11:04\n",
            "loss: 0.1463, acc: 0.9414\n",
            "E2E-ABSA >>> 2024-06-04 14:11:13\n",
            "loss: 0.1456, acc: 0.9429\n",
            "E2E-ABSA >>> 2024-06-04 14:11:22\n",
            ">>> val_acc: 0.7428, val_precision: 0.7566 val_recall: 0.7428, val_f1: 0.7446\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 14:11:26\n",
            "loss: 0.1076, acc: 0.9563\n",
            "E2E-ABSA >>> 2024-06-04 14:11:34\n",
            "loss: 0.1123, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 14:11:42\n",
            ">>> val_acc: 0.7314, val_precision: 0.7648 val_recall: 0.7314, val_f1: 0.7403\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 14:11:47\n",
            "loss: 0.0990, acc: 0.9639\n",
            "E2E-ABSA >>> 2024-06-04 14:11:56\n",
            "loss: 0.1294, acc: 0.9512\n",
            "E2E-ABSA >>> 2024-06-04 14:12:02\n",
            ">>> val_acc: 0.7620, val_precision: 0.7643 val_recall: 0.7620, val_f1: 0.7631\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 14:12:09\n",
            "loss: 0.1060, acc: 0.9638\n",
            "E2E-ABSA >>> 2024-06-04 14:12:21\n",
            ">>> val_acc: 0.7524, val_precision: 0.7329 val_recall: 0.7524, val_f1: 0.7363\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 14:12:22\n",
            "loss: 0.0850, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-04 14:12:31\n",
            "loss: 0.1252, acc: 0.9520\n",
            "E2E-ABSA >>> 2024-06-04 14:12:41\n",
            ">>> val_acc: 0.7606, val_precision: 0.7481 val_recall: 0.7606, val_f1: 0.7497\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 14:12:44\n",
            "loss: 0.0700, acc: 0.9757\n",
            "E2E-ABSA >>> 2024-06-04 14:12:52\n",
            "loss: 0.0997, acc: 0.9623\n",
            "E2E-ABSA >>> 2024-06-04 14:13:00\n",
            ">>> val_acc: 0.7492, val_precision: 0.7409 val_recall: 0.7492, val_f1: 0.7430\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 14:13:06\n",
            "loss: 0.0784, acc: 0.9760\n",
            "E2E-ABSA >>> 2024-06-04 14:13:14\n",
            "loss: 0.0937, acc: 0.9668\n",
            "E2E-ABSA >>> 2024-06-04 14:13:20\n",
            ">>> val_acc: 0.7321, val_precision: 0.7419 val_recall: 0.7321, val_f1: 0.7321\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 14:13:27\n",
            "loss: 0.0911, acc: 0.9710\n",
            "E2E-ABSA >>> 2024-06-04 14:13:40\n",
            ">>> val_acc: 0.7385, val_precision: 0.7261 val_recall: 0.7385, val_f1: 0.7302\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 14:13:40\n",
            "loss: 0.0472, acc: 0.9922\n",
            "E2E-ABSA >>> 2024-06-04 14:13:49\n",
            "loss: 0.0819, acc: 0.9676\n",
            "E2E-ABSA >>> 2024-06-04 14:13:59\n",
            ">>> val_acc: 0.7304, val_precision: 0.7360 val_recall: 0.7304, val_f1: 0.7329\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 14:14:02\n",
            "loss: 0.0657, acc: 0.9727\n",
            "E2E-ABSA >>> 2024-06-04 14:14:11\n",
            "loss: 0.0702, acc: 0.9711\n",
            "E2E-ABSA >>> 2024-06-04 14:14:19\n",
            ">>> val_acc: 0.7456, val_precision: 0.7497 val_recall: 0.7456, val_f1: 0.7469\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 14:14:24\n",
            "loss: 0.0578, acc: 0.9777\n",
            "E2E-ABSA >>> 2024-06-04 14:14:32\n",
            "loss: 0.0861, acc: 0.9679\n",
            "E2E-ABSA >>> 2024-06-04 14:14:39\n",
            ">>> val_acc: 0.7336, val_precision: 0.7315 val_recall: 0.7336, val_f1: 0.7275\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 14:14:45\n",
            "loss: 0.0651, acc: 0.9781\n",
            "E2E-ABSA >>> 2024-06-04 14:14:58\n",
            ">>> val_acc: 0.7293, val_precision: 0.7209 val_recall: 0.7293, val_f1: 0.7211\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 14:14:58\n",
            "loss: 0.0558, acc: 0.9844\n",
            "E2E-ABSA >>> 2024-06-04 14:15:07\n",
            "loss: 0.0767, acc: 0.9754\n",
            "E2E-ABSA >>> 2024-06-04 14:15:18\n",
            ">>> val_acc: 0.7417, val_precision: 0.7266 val_recall: 0.7417, val_f1: 0.7296\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 14:15:20\n",
            "loss: 0.0365, acc: 0.9911\n",
            "E2E-ABSA >>> 2024-06-04 14:15:29\n",
            "loss: 0.0631, acc: 0.9800\n",
            "E2E-ABSA >>> 2024-06-04 14:15:37\n",
            ">>> val_acc: 0.7229, val_precision: 0.7420 val_recall: 0.7229, val_f1: 0.7282\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 14:15:42\n",
            "loss: 0.0516, acc: 0.9832\n",
            "E2E-ABSA >>> 2024-06-04 14:15:50\n",
            "loss: 0.0786, acc: 0.9745\n",
            "E2E-ABSA >>> 2024-06-04 14:15:57\n",
            ">>> val_acc: 0.7346, val_precision: 0.7065 val_recall: 0.7346, val_f1: 0.7055\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-04 14:16:04\n",
            "loss: 0.0958, acc: 0.9638\n",
            "E2E-ABSA >>> 2024-06-04 14:16:12\n",
            "loss: 0.0756, acc: 0.9726\n",
            "E2E-ABSA >>> 2024-06-04 14:16:17\n",
            ">>> val_acc: 0.7268, val_precision: 0.7326 val_recall: 0.7268, val_f1: 0.7239\n",
            "E2E-ABSA >>> 2024-06-04 14:16:17\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7787, val_precision: 0.7836 val_recall: 0.7787, val_f1: 0.7792\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7787\n",
            ">>> test_acc: 0.7462, test_precision: 0.7536, test_recall: 0.7462, test_f1: 0.7470\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "612ef11b-07bd-43c5-b724-7b30d3e06396"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e6f5e28-aebb-43a4-b3ec-f18c01ba8f1d"
      },
      "source": [
        "### indobenchmark/indobert-base-p2 s6 insert"
      ],
      "id": "9e6f5e28-aebb-43a4-b3ec-f18c01ba8f1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0d6970e1-8884-48d2-bd60-217e72e15915",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "3ab07adb-6e32-4498-9028-18053ad0e76f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 497799680\n",
            "> n_trainable_params: 124443651, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f53f1333760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-base-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-04 14:24:42\n",
            "loss: 0.9085, acc: 0.6344\n",
            "E2E-ABSA >>> 2024-06-04 14:24:53\n",
            ">>> val_acc: 0.6984, val_precision: 0.6862 val_recall: 0.6984, val_f1: 0.5953\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6984\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-04 14:24:56\n",
            "loss: 0.7897, acc: 0.6536\n",
            "E2E-ABSA >>> 2024-06-04 14:25:04\n",
            "loss: 0.7697, acc: 0.6749\n",
            "E2E-ABSA >>> 2024-06-04 14:25:13\n",
            ">>> val_acc: 0.7130, val_precision: 0.7099 val_recall: 0.7130, val_f1: 0.7018\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.713\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-04 14:25:18\n",
            "loss: 0.6227, acc: 0.7396\n",
            "E2E-ABSA >>> 2024-06-04 14:25:26\n",
            "loss: 0.6132, acc: 0.7407\n",
            "E2E-ABSA >>> 2024-06-04 14:25:33\n",
            ">>> val_acc: 0.7336, val_precision: 0.7091 val_recall: 0.7336, val_f1: 0.6870\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-04 14:25:39\n",
            "loss: 0.5442, acc: 0.7622\n",
            "E2E-ABSA >>> 2024-06-04 14:25:48\n",
            "loss: 0.5435, acc: 0.7722\n",
            "E2E-ABSA >>> 2024-06-04 14:25:53\n",
            ">>> val_acc: 0.7403, val_precision: 0.7280 val_recall: 0.7403, val_f1: 0.7323\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7403\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-04 14:26:01\n",
            "loss: 0.4138, acc: 0.8294\n",
            "E2E-ABSA >>> 2024-06-04 14:26:13\n",
            ">>> val_acc: 0.7350, val_precision: 0.7270 val_recall: 0.7350, val_f1: 0.7278\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-04 14:26:15\n",
            "loss: 0.3430, acc: 0.8688\n",
            "E2E-ABSA >>> 2024-06-04 14:26:23\n",
            "loss: 0.3779, acc: 0.8495\n",
            "E2E-ABSA >>> 2024-06-04 14:26:32\n",
            ">>> val_acc: 0.6760, val_precision: 0.7540 val_recall: 0.6760, val_f1: 0.6983\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-04 14:26:36\n",
            "loss: 0.2955, acc: 0.8935\n",
            "E2E-ABSA >>> 2024-06-04 14:26:45\n",
            "loss: 0.3223, acc: 0.8759\n",
            "E2E-ABSA >>> 2024-06-04 14:26:52\n",
            ">>> val_acc: 0.7343, val_precision: 0.7297 val_recall: 0.7343, val_f1: 0.7287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-04 14:26:58\n",
            "loss: 0.3095, acc: 0.8796\n",
            "E2E-ABSA >>> 2024-06-04 14:27:06\n",
            "loss: 0.3184, acc: 0.8717\n",
            "E2E-ABSA >>> 2024-06-04 14:27:12\n",
            ">>> val_acc: 0.7371, val_precision: 0.7231 val_recall: 0.7371, val_f1: 0.7161\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-04 14:27:19\n",
            "loss: 0.2306, acc: 0.9164\n",
            "E2E-ABSA >>> 2024-06-04 14:27:31\n",
            ">>> val_acc: 0.6892, val_precision: 0.7065 val_recall: 0.6892, val_f1: 0.6964\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-04 14:27:32\n",
            "loss: 0.2042, acc: 0.9219\n",
            "E2E-ABSA >>> 2024-06-04 14:27:41\n",
            "loss: 0.2174, acc: 0.9213\n",
            "E2E-ABSA >>> 2024-06-04 14:27:51\n",
            ">>> val_acc: 0.7204, val_precision: 0.7206 val_recall: 0.7204, val_f1: 0.7201\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-04 14:27:54\n",
            "loss: 0.1645, acc: 0.9437\n",
            "E2E-ABSA >>> 2024-06-04 14:28:02\n",
            "loss: 0.1913, acc: 0.9308\n",
            "E2E-ABSA >>> 2024-06-04 14:28:10\n",
            ">>> val_acc: 0.7201, val_precision: 0.7115 val_recall: 0.7201, val_f1: 0.7145\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-04 14:28:16\n",
            "loss: 0.1612, acc: 0.9395\n",
            "E2E-ABSA >>> 2024-06-04 14:28:24\n",
            "loss: 0.2166, acc: 0.9184\n",
            "E2E-ABSA >>> 2024-06-04 14:28:30\n",
            ">>> val_acc: 0.7179, val_precision: 0.7184 val_recall: 0.7179, val_f1: 0.7181\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-04 14:28:37\n",
            "loss: 0.1379, acc: 0.9432\n",
            "E2E-ABSA >>> 2024-06-04 14:28:49\n",
            ">>> val_acc: 0.7123, val_precision: 0.7054 val_recall: 0.7123, val_f1: 0.7086\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-04 14:28:50\n",
            "loss: 0.0947, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-04 14:28:59\n",
            "loss: 0.1406, acc: 0.9448\n",
            "E2E-ABSA >>> 2024-06-04 14:29:09\n",
            ">>> val_acc: 0.7087, val_precision: 0.7089 val_recall: 0.7087, val_f1: 0.7065\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-04 14:29:12\n",
            "loss: 0.1034, acc: 0.9635\n",
            "E2E-ABSA >>> 2024-06-04 14:29:20\n",
            "loss: 0.1354, acc: 0.9508\n",
            "E2E-ABSA >>> 2024-06-04 14:29:28\n",
            ">>> val_acc: 0.7144, val_precision: 0.6987 val_recall: 0.7144, val_f1: 0.7023\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-04 14:29:33\n",
            "loss: 0.1242, acc: 0.9604\n",
            "E2E-ABSA >>> 2024-06-04 14:29:42\n",
            "loss: 0.1445, acc: 0.9484\n",
            "E2E-ABSA >>> 2024-06-04 14:29:48\n",
            ">>> val_acc: 0.6959, val_precision: 0.7187 val_recall: 0.6959, val_f1: 0.7046\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-04 14:29:55\n",
            "loss: 0.1179, acc: 0.9568\n",
            "E2E-ABSA >>> 2024-06-04 14:30:07\n",
            ">>> val_acc: 0.6803, val_precision: 0.7061 val_recall: 0.6803, val_f1: 0.6859\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-04 14:30:08\n",
            "loss: 0.1116, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 14:30:17\n",
            "loss: 0.1051, acc: 0.9606\n",
            "E2E-ABSA >>> 2024-06-04 14:30:27\n",
            ">>> val_acc: 0.7044, val_precision: 0.7035 val_recall: 0.7044, val_f1: 0.7037\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-04 14:30:30\n",
            "loss: 0.0790, acc: 0.9629\n",
            "E2E-ABSA >>> 2024-06-04 14:30:38\n",
            "loss: 0.1191, acc: 0.9550\n",
            "E2E-ABSA >>> 2024-06-04 14:30:47\n",
            ">>> val_acc: 0.6778, val_precision: 0.7081 val_recall: 0.6778, val_f1: 0.6891\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-04 14:30:51\n",
            "loss: 0.1131, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-04 14:31:00\n",
            "loss: 0.1280, acc: 0.9515\n",
            "E2E-ABSA >>> 2024-06-04 14:31:06\n",
            ">>> val_acc: 0.7119, val_precision: 0.6998 val_recall: 0.7119, val_f1: 0.7029\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-04 14:31:13\n",
            "loss: 0.0919, acc: 0.9641\n",
            "E2E-ABSA >>> 2024-06-04 14:31:26\n",
            ">>> val_acc: 0.7176, val_precision: 0.6953 val_recall: 0.7176, val_f1: 0.7023\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-04 14:31:26\n",
            "loss: 0.1299, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-04 14:31:35\n",
            "loss: 0.1291, acc: 0.9549\n",
            "E2E-ABSA >>> 2024-06-04 14:31:45\n",
            ">>> val_acc: 0.6924, val_precision: 0.6908 val_recall: 0.6924, val_f1: 0.6908\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-04 14:31:48\n",
            "loss: 0.1250, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-06-04 14:31:56\n",
            "loss: 0.1047, acc: 0.9614\n",
            "E2E-ABSA >>> 2024-06-04 14:32:05\n",
            ">>> val_acc: 0.7083, val_precision: 0.6880 val_recall: 0.7083, val_f1: 0.6953\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-04 14:32:09\n",
            "loss: 0.1043, acc: 0.9639\n",
            "E2E-ABSA >>> 2024-06-04 14:32:18\n",
            "loss: 0.1050, acc: 0.9634\n",
            "E2E-ABSA >>> 2024-06-04 14:32:24\n",
            ">>> val_acc: 0.6998, val_precision: 0.6972 val_recall: 0.6998, val_f1: 0.6982\n",
            "E2E-ABSA >>> 2024-06-04 14:32:24\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7403, val_precision: 0.7280 val_recall: 0.7403, val_f1: 0.7323\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7403\n",
            ">>> test_acc: 0.7131, test_precision: 0.6943, test_recall: 0.7131, test_f1: 0.6997\n"
          ]
        }
      ],
      "source": [
        "# 4-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indobenchmark/indobert-base-p2 --valset_ratio 0.5 --log_step 100"
      ],
      "id": "0d6970e1-8884-48d2-bd60-217e72e15915"
    },
    {
      "cell_type": "markdown",
      "id": "Z3XDC8PBDtfs",
      "metadata": {
        "id": "Z3XDC8PBDtfs"
      },
      "source": [
        "# Training with indobenchmark/indobert-large-p2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "HA8kkamPNb-F"
      },
      "outputs": [],
      "source": [
        "#  menyesuaikan tokenizer BERT untuk indobenchmark\n",
        "path = 'ta-dictabsa/data_utils.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[100] = \"        self.tokenizer = BertTokenizer.from_pretrained(pretrained_bert_name)\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "id": "HA8kkamPNb-F"
    },
    {
      "cell_type": "markdown",
      "id": "meO51jA3Dtft",
      "metadata": {
        "editable": true,
        "id": "meO51jA3Dtft",
        "tags": []
      },
      "source": [
        "## indobenchmark/indobert-large-p2 Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cz42T10kDtft",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "cz42T10kDtft",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8bf675ec-aafb-42b8-85d9-8c9ba5ccee97",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "tokenizer_config.json: 100%|█████████████████| 2.00/2.00 [00:00<00:00, 14.6kB/s]\n",
            "vocab.txt: 100%|█████████████████████████████| 229k/229k [00:00<00:00, 3.36MB/s]\n",
            "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 907kB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100%|█████████████████████████| 1.53k/1.53k [00:00<00:00, 10.5MB/s]\n",
            "pytorch_model.bin: 100%|███████████████████| 1.34G/1.34G [00:17<00:00, 75.9MB/s]\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_ori\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fce63d33640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/train.tsv', 'test': './datasets/ulasan_combined/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 14:57:25\n",
            "loss: 0.8815, acc: 0.6462\n",
            "E2E-ABSA >>> 2024-06-10 14:58:28\n",
            ">>> val_acc: 0.6831, val_precision: 0.6774 val_recall: 0.6831, val_f1: 0.6737\n",
            ">> saved: state_dict/bert_spc_combined_ori_val_f1_0.6831\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 14:58:41\n",
            "loss: 0.6927, acc: 0.7109\n",
            "E2E-ABSA >>> 2024-06-10 14:59:29\n",
            "loss: 0.7526, acc: 0.6890\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:00:21\n",
            ">>> val_acc: 0.2146, val_precision: 0.0460 val_recall: 0.2146, val_f1: 0.0758\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 15:00:44\n",
            "loss: 0.9276, acc: 0.6458\n",
            "E2E-ABSA >>> 2024-06-10 15:01:32\n",
            "loss: 0.9215, acc: 0.6461\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:02:12\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 15:02:47\n",
            "loss: 0.8657, acc: 0.6806\n",
            "E2E-ABSA >>> 2024-06-10 15:03:35\n",
            "loss: 0.8745, acc: 0.6726\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:04:03\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 15:04:49\n",
            "loss: 0.8840, acc: 0.6595\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:05:55\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 15:06:04\n",
            "loss: 0.9532, acc: 0.6156\n",
            "E2E-ABSA >>> 2024-06-10 15:06:52\n",
            "loss: 0.8905, acc: 0.6578\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:07:46\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 15:08:07\n",
            "loss: 0.8939, acc: 0.6264\n",
            "E2E-ABSA >>> 2024-06-10 15:08:55\n",
            "loss: 0.8633, acc: 0.6593\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:09:37\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 15:10:10\n",
            "loss: 0.8487, acc: 0.6728\n",
            "E2E-ABSA >>> 2024-06-10 15:10:58\n",
            "loss: 0.8778, acc: 0.6592\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:11:28\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 15:12:12\n",
            "loss: 0.8867, acc: 0.6630\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:13:20\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 15:13:27\n",
            "loss: 0.8491, acc: 0.6953\n",
            "E2E-ABSA >>> 2024-06-10 15:14:15\n",
            "loss: 0.8862, acc: 0.6514\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:15:11\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 15:15:30\n",
            "loss: 0.8672, acc: 0.6609\n",
            "E2E-ABSA >>> 2024-06-10 15:16:18\n",
            "loss: 0.8773, acc: 0.6656\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:17:02\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 15:17:33\n",
            "loss: 0.8497, acc: 0.6748\n",
            "E2E-ABSA >>> 2024-06-10 15:18:21\n",
            "loss: 0.8712, acc: 0.6574\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:18:53\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-10 15:19:36\n",
            "loss: 0.8651, acc: 0.6804\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:20:45\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-10 15:20:51\n",
            "loss: 0.8003, acc: 0.6875\n",
            "E2E-ABSA >>> 2024-06-10 15:21:39\n",
            "loss: 0.8671, acc: 0.6747\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:22:36\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-10 15:22:53\n",
            "loss: 0.7929, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-10 15:23:41\n",
            "loss: 0.8573, acc: 0.6765\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:24:27\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-10 15:24:56\n",
            "loss: 0.8928, acc: 0.6625\n",
            "E2E-ABSA >>> 2024-06-10 15:25:44\n",
            "loss: 0.8767, acc: 0.6680\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:26:19\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-10 15:26:59\n",
            "loss: 0.8574, acc: 0.6749\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:28:10\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-10 15:28:14\n",
            "loss: 0.7399, acc: 0.7500\n",
            "E2E-ABSA >>> 2024-06-10 15:29:02\n",
            "loss: 0.8707, acc: 0.6580\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:30:01\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-10 15:30:17\n",
            "loss: 0.8579, acc: 0.6621\n",
            "E2E-ABSA >>> 2024-06-10 15:31:05\n",
            "loss: 0.8625, acc: 0.6723\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:31:53\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-10 15:32:19\n",
            "loss: 0.8408, acc: 0.6819\n",
            "E2E-ABSA >>> 2024-06-10 15:33:08\n",
            "loss: 0.8568, acc: 0.6687\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:33:44\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-10 15:34:22\n",
            "loss: 0.8327, acc: 0.6867\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 15:35:35\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            "E2E-ABSA >>> 2024-06-10 15:35:35\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6831, val_precision: 0.6774 val_recall: 0.6831, val_f1: 0.6737\n",
            "you can download the best model from state_dict/bert_spc_combined_ori_val_f1_0.6831\n",
            ">>> test_acc: 0.6631, test_precision: 0.6490, test_recall: 0.6631, test_f1: 0.6483\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_ori --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## indobenchmark/indobert-large-p2 Concatenation"
      ],
      "metadata": {
        "id": "XXzxg7D5MRNU"
      },
      "id": "XXzxg7D5MRNU"
    },
    {
      "cell_type": "markdown",
      "id": "PrWvKmo3Dtft",
      "metadata": {
        "editable": true,
        "id": "PrWvKmo3Dtft",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s1 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vA78jYdvDtft",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "vA78jYdvDtft",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "604a9e51-29e8-4c3c-bdf9-cf4a032572cf",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f6e5402b640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/a_raw_know/train.tsv', 'test': './datasets/ulasan_combined/a_raw_know/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 16:05:48\n",
            "loss: 0.8993, acc: 0.6462\n",
            "E2E-ABSA >>> 2024-06-10 16:06:51\n",
            ">>> val_acc: 0.6369, val_precision: 0.6371 val_recall: 0.6369, val_f1: 0.6316\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.6369\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 16:07:03\n",
            "loss: 0.8649, acc: 0.6589\n",
            "E2E-ABSA >>> 2024-06-10 16:07:52\n",
            "loss: 0.8766, acc: 0.6608\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:08:43\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 16:09:06\n",
            "loss: 0.8750, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-10 16:09:54\n",
            "loss: 0.8814, acc: 0.6592\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:10:35\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 16:11:09\n",
            "loss: 0.8460, acc: 0.6823\n",
            "E2E-ABSA >>> 2024-06-10 16:11:57\n",
            "loss: 0.8693, acc: 0.6686\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:12:26\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 16:13:12\n",
            "loss: 0.8754, acc: 0.6686\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:14:17\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 16:14:27\n",
            "loss: 0.9278, acc: 0.6250\n",
            "E2E-ABSA >>> 2024-06-10 16:15:15\n",
            "loss: 0.8771, acc: 0.6557\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:16:09\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 16:16:30\n",
            "loss: 0.9222, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-06-10 16:17:18\n",
            "loss: 0.8741, acc: 0.6662\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:18:00\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 16:18:33\n",
            "loss: 0.8542, acc: 0.6792\n",
            "E2E-ABSA >>> 2024-06-10 16:19:21\n",
            "loss: 0.8722, acc: 0.6644\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:19:51\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 16:20:35\n",
            "loss: 0.8824, acc: 0.6610\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:21:42\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 16:21:50\n",
            "loss: 0.8311, acc: 0.7070\n",
            "E2E-ABSA >>> 2024-06-10 16:22:38\n",
            "loss: 0.8831, acc: 0.6573\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:23:34\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 16:23:53\n",
            "loss: 0.8582, acc: 0.6516\n",
            "E2E-ABSA >>> 2024-06-10 16:24:41\n",
            "loss: 0.8740, acc: 0.6638\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:25:25\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 16:25:56\n",
            "loss: 0.8797, acc: 0.6748\n",
            "E2E-ABSA >>> 2024-06-10 16:26:44\n",
            "loss: 0.8827, acc: 0.6616\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:27:16\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-10 16:27:59\n",
            "loss: 0.8751, acc: 0.6747\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:29:08\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-10 16:29:13\n",
            "loss: 0.7931, acc: 0.6823\n",
            "E2E-ABSA >>> 2024-06-10 16:30:01\n",
            "loss: 0.8707, acc: 0.6724\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:30:59\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-10 16:31:16\n",
            "loss: 0.8076, acc: 0.7118\n",
            "E2E-ABSA >>> 2024-06-10 16:32:04\n",
            "loss: 0.8658, acc: 0.6733\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:32:50\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-10 16:33:19\n",
            "loss: 0.8821, acc: 0.6542\n",
            "E2E-ABSA >>> 2024-06-10 16:34:07\n",
            "loss: 0.8799, acc: 0.6637\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:34:41\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-10 16:35:22\n",
            "loss: 0.8655, acc: 0.6644\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:36:33\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-10 16:36:36\n",
            "loss: 0.7934, acc: 0.7109\n",
            "E2E-ABSA >>> 2024-06-10 16:37:25\n",
            "loss: 0.8819, acc: 0.6586\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:38:24\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-10 16:38:39\n",
            "loss: 0.8548, acc: 0.6660\n",
            "E2E-ABSA >>> 2024-06-10 16:39:27\n",
            "loss: 0.8698, acc: 0.6705\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:40:15\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-10 16:40:42\n",
            "loss: 0.8620, acc: 0.6663\n",
            "E2E-ABSA >>> 2024-06-10 16:41:30\n",
            "loss: 0.8666, acc: 0.6623\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:42:06\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-10 16:42:45\n",
            "loss: 0.8426, acc: 0.6789\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 16:43:58\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            "E2E-ABSA >>> 2024-06-10 16:43:58\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6369, val_precision: 0.6371 val_recall: 0.6369, val_f1: 0.6316\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.6369\n",
            ">>> test_acc: 0.6123, test_precision: 0.5999, test_recall: 0.6123, test_f1: 0.5974\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ePn-N2eiDtfu",
      "metadata": {
        "editable": true,
        "id": "ePn-N2eiDtfu",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s2 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G-yrfF-FDtfu",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "G-yrfF-FDtfu",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e4a1c68d-945e-4284-982c-af959fd39637",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fb67ff1f640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/f_raw_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/f_raw_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 17:52:53\n",
            "loss: 0.8791, acc: 0.6494\n",
            "E2E-ABSA >>> 2024-06-10 17:53:56\n",
            ">>> val_acc: 0.6551, val_precision: 0.6510 val_recall: 0.6551, val_f1: 0.6441\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6551\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 17:54:09\n",
            "loss: 0.8800, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-10 17:54:57\n",
            "loss: 0.8659, acc: 0.6623\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:55:49\n",
            ">>> val_acc: 0.6789, val_precision: 0.5499 val_recall: 0.6789, val_f1: 0.5728\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 17:56:12\n",
            "loss: 0.8589, acc: 0.6654\n",
            "E2E-ABSA >>> 2024-06-10 17:57:00\n",
            "loss: 0.8760, acc: 0.6617\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:57:40\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 17:58:14\n",
            "loss: 0.8440, acc: 0.6849\n",
            "E2E-ABSA >>> 2024-06-10 17:59:03\n",
            "loss: 0.8701, acc: 0.6704\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:59:31\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 18:00:17\n",
            "loss: 0.8754, acc: 0.6667\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:01:23\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 18:01:32\n",
            "loss: 0.9270, acc: 0.6219\n",
            "E2E-ABSA >>> 2024-06-10 18:02:20\n",
            "loss: 0.8810, acc: 0.6562\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:03:14\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 18:03:35\n",
            "loss: 0.9281, acc: 0.6364\n",
            "E2E-ABSA >>> 2024-06-10 18:04:23\n",
            "loss: 0.8776, acc: 0.6610\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:05:05\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 18:05:38\n",
            "loss: 0.8574, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-10 18:06:26\n",
            "loss: 0.8702, acc: 0.6629\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:06:56\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 18:07:41\n",
            "loss: 0.8738, acc: 0.6630\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:08:48\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 18:08:55\n",
            "loss: 0.8117, acc: 0.6953\n",
            "E2E-ABSA >>> 2024-06-10 18:09:43\n",
            "loss: 0.8773, acc: 0.6546\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:10:39\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 18:10:58\n",
            "loss: 0.8532, acc: 0.6531\n",
            "E2E-ABSA >>> 2024-06-10 18:11:46\n",
            "loss: 0.8703, acc: 0.6638\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:12:30\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 18:13:01\n",
            "loss: 0.8719, acc: 0.6768\n",
            "E2E-ABSA >>> 2024-06-10 18:13:49\n",
            "loss: 0.8776, acc: 0.6585\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:14:21\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-10 18:15:04\n",
            "loss: 0.8591, acc: 0.6804\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:16:13\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-10 18:16:18\n",
            "loss: 0.7989, acc: 0.6979\n",
            "E2E-ABSA >>> 2024-06-10 18:17:06\n",
            "loss: 0.8653, acc: 0.6702\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:18:04\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-10 18:18:21\n",
            "loss: 0.7945, acc: 0.7118\n",
            "E2E-ABSA >>> 2024-06-10 18:19:09\n",
            "loss: 0.8642, acc: 0.6719\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:19:55\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-10 18:20:24\n",
            "loss: 0.8885, acc: 0.6521\n",
            "E2E-ABSA >>> 2024-06-10 18:21:12\n",
            "loss: 0.8804, acc: 0.6629\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:21:46\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-10 18:22:27\n",
            "loss: 0.8604, acc: 0.6696\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:23:37\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-10 18:23:41\n",
            "loss: 0.7833, acc: 0.7344\n",
            "E2E-ABSA >>> 2024-06-10 18:24:29\n",
            "loss: 0.8751, acc: 0.6597\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:25:29\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-10 18:25:44\n",
            "loss: 0.8578, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-10 18:26:32\n",
            "loss: 0.8685, acc: 0.6700\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:27:20\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-10 18:27:47\n",
            "loss: 0.8548, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-10 18:28:35\n",
            "loss: 0.8601, acc: 0.6683\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:29:11\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-10 18:29:50\n",
            "loss: 0.8410, acc: 0.6781\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:31:02\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            "E2E-ABSA >>> 2024-06-10 18:31:02\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.6551, val_precision: 0.6510 val_recall: 0.6551, val_f1: 0.6441\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.6551\n",
            ">>> test_acc: 0.6314, test_precision: 0.6241, test_recall: 0.6314, test_f1: 0.6172\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vObxa6H8Dtfu",
      "metadata": {
        "editable": true,
        "id": "vObxa6H8Dtfu",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s3 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ThFXbkJtDtfu",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "ThFXbkJtDtfu",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f5fd935c-2938-4a05-8881-1a2caf2db5dc",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f7d47b1b640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/e_raw_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/e_raw_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 19:44:22\n",
            "loss: 0.8722, acc: 0.6450\n",
            "E2E-ABSA >>> 2024-06-10 19:45:25\n",
            ">>> val_acc: 0.6988, val_precision: 0.6817 val_recall: 0.6988, val_f1: 0.6815\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6988\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 19:45:38\n",
            "loss: 0.6838, acc: 0.7109\n",
            "E2E-ABSA >>> 2024-06-10 19:46:26\n",
            "loss: 0.6953, acc: 0.7046\n",
            "E2E-ABSA >>> 2024-06-10 19:47:18\n",
            ">>> val_acc: 0.7076, val_precision: 0.6847 val_recall: 0.7076, val_f1: 0.6372\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 19:47:41\n",
            "loss: 0.6371, acc: 0.7318\n",
            "E2E-ABSA >>> 2024-06-10 19:48:29\n",
            "loss: 0.6305, acc: 0.7318\n",
            "E2E-ABSA >>> 2024-06-10 19:49:09\n",
            ">>> val_acc: 0.7201, val_precision: 0.6898 val_recall: 0.7201, val_f1: 0.6842\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7201\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 19:49:45\n",
            "loss: 0.5729, acc: 0.7578\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 19:52:53\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 19:53:02\n",
            "loss: 0.9084, acc: 0.6375\n",
            "E2E-ABSA >>> 2024-06-10 19:53:50\n",
            "loss: 0.8800, acc: 0.6609\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 19:54:44\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 19:55:05\n",
            "loss: 0.9124, acc: 0.6335\n",
            "E2E-ABSA >>> 2024-06-10 19:55:53\n",
            "loss: 0.8776, acc: 0.6584\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 19:56:35\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 19:57:08\n",
            "loss: 0.8462, acc: 0.6756\n",
            "E2E-ABSA >>> 2024-06-10 19:57:56\n",
            "loss: 0.8686, acc: 0.6652\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 19:58:27\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 19:59:11\n",
            "loss: 0.8681, acc: 0.6617\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 20:00:18\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 20:00:26\n",
            "loss: 0.8180, acc: 0.7031\n",
            "E2E-ABSA >>> 2024-06-10 20:01:14\n",
            "loss: 0.8844, acc: 0.6579\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 20:02:09\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 20:02:29\n",
            "loss: 0.8534, acc: 0.6687\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YFvdvgI_Dtfv",
      "metadata": {
        "editable": true,
        "id": "YFvdvgI_Dtfv",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s4 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9fee06c-8f98-41dc-9114-7e13fe5314de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9fee06c-8f98-41dc-9114-7e13fe5314de",
        "outputId": "45927ee5-1cf2-4ffc-f130-382adf0a7b86",
        "scrolled": true,
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5532.\n",
            "> testing dataset count: 2300.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f474002b760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 10\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/b_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/b_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-13 21:35:05\n",
            "loss: 0.8823, acc: 0.6344\n",
            "E2E-ABSA >>> 2024-06-13 21:35:42\n",
            ">>> val_acc: 0.6772, val_precision: 0.6202 val_recall: 0.6772, val_f1: 0.6230\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6772\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-13 21:35:50\n",
            "loss: 0.8011, acc: 0.6806\n",
            "E2E-ABSA >>> 2024-06-13 21:36:19\n",
            "loss: 0.7665, acc: 0.6885\n",
            "E2E-ABSA >>> 2024-06-13 21:36:48\n",
            ">>> val_acc: 0.7082, val_precision: 0.6843 val_recall: 0.7082, val_f1: 0.6528\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7082\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-13 21:37:04\n",
            "loss: 0.7265, acc: 0.6829\n",
            "E2E-ABSA >>> 2024-06-13 21:37:32\n",
            "loss: 0.6913, acc: 0.7041\n",
            "E2E-ABSA >>> 2024-06-13 21:37:54\n",
            ">>> val_acc: 0.7129, val_precision: 0.6812 val_recall: 0.7129, val_f1: 0.6717\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7129\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-13 21:38:18\n",
            "loss: 0.6381, acc: 0.7307\n",
            "E2E-ABSA >>> 2024-06-13 21:39:00\n",
            ">>> val_acc: 0.6992, val_precision: 0.6795 val_recall: 0.6992, val_f1: 0.6720\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6992\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-13 21:39:03\n",
            "loss: 0.5096, acc: 0.8125\n",
            "E2E-ABSA >>> 2024-06-13 21:39:31\n",
            "loss: 0.6541, acc: 0.7367\n",
            "E2E-ABSA >>> 2024-06-13 21:40:06\n",
            ">>> val_acc: 0.7014, val_precision: 0.6787 val_recall: 0.7014, val_f1: 0.6856\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7014\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-13 21:40:16\n",
            "loss: 0.5926, acc: 0.7750\n",
            "E2E-ABSA >>> 2024-06-13 21:40:45\n",
            "loss: 0.6269, acc: 0.7481\n",
            "E2E-ABSA >>> 2024-06-13 21:41:11\n",
            ">>> val_acc: 0.7072, val_precision: 0.6848 val_recall: 0.7072, val_f1: 0.6654\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-13 21:41:29\n",
            "loss: 0.5897, acc: 0.7510\n",
            "E2E-ABSA >>> 2024-06-13 21:41:57\n",
            "loss: 0.5960, acc: 0.7593\n",
            "E2E-ABSA >>> 2024-06-13 21:42:16\n",
            ">>> val_acc: 0.7072, val_precision: 0.6758 val_recall: 0.7072, val_f1: 0.6736\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-13 21:42:42\n",
            "loss: 0.8700, acc: 0.6706\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:43:21\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-13 21:43:26\n",
            "loss: 0.8466, acc: 0.7070\n",
            "E2E-ABSA >>> 2024-06-13 21:43:54\n",
            "loss: 0.8804, acc: 0.6751\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:44:26\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-13 21:44:38\n",
            "loss: 0.9059, acc: 0.6468\n",
            "E2E-ABSA >>> 2024-06-13 21:45:07\n",
            "loss: 0.8837, acc: 0.6648\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:45:31\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-13 21:45:51\n",
            "loss: 0.8592, acc: 0.6741\n",
            "E2E-ABSA >>> 2024-06-13 21:46:19\n",
            "loss: 0.8616, acc: 0.6724\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:46:36\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-13 21:47:04\n",
            "loss: 0.8607, acc: 0.6746\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:47:41\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-13 21:47:48\n",
            "loss: 0.9184, acc: 0.6328\n",
            "E2E-ABSA >>> 2024-06-13 21:48:16\n",
            "loss: 0.8583, acc: 0.6804\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:48:46\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-13 21:49:01\n",
            "loss: 0.8822, acc: 0.6593\n",
            "E2E-ABSA >>> 2024-06-13 21:49:29\n",
            "loss: 0.8861, acc: 0.6685\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:49:51\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-13 21:50:13\n",
            "loss: 0.8632, acc: 0.6907\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 21:50:56\n",
            ">>> val_acc: 0.6750, val_precision: 0.4556 val_recall: 0.6750, val_f1: 0.5440\n",
            "E2E-ABSA >>> 2024-06-13 21:50:56\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7014, val_precision: 0.6787 val_recall: 0.7014, val_f1: 0.6856\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7014\n",
            ">>> test_acc: 0.6861, test_precision: 0.6663, test_recall: 0.6861, test_f1: 0.6706\n"
          ]
        }
      ],
      "source": [
        "# 13-6 experiment 6\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indobenchmark/indobert-large-p2 --valset_ratio 0.5 --log_step 100 --bert_dim 1024 --patience 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709kKZUnDtfw",
      "metadata": {
        "editable": true,
        "id": "709kKZUnDtfw",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s5 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bx7FQguqDtfw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "Bx7FQguqDtfw",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "b297d793-7f50-486b-ba3f-38a35d06be77",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f273892f640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 10\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/c_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/c_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 22:35:28\n",
            "loss: 0.8458, acc: 0.6556\n",
            "E2E-ABSA >>> 2024-06-10 22:37:32\n",
            "loss: 0.6765, acc: 0.7067\n",
            "E2E-ABSA >>> 2024-06-10 22:38:20\n",
            ">>> val_acc: 0.7343, val_precision: 0.7205 val_recall: 0.7343, val_f1: 0.7248\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7343\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 22:38:47\n",
            "loss: 0.5681, acc: 0.7650\n",
            "E2E-ABSA >>> 2024-06-10 22:39:35\n",
            "loss: 0.5680, acc: 0.7545\n",
            "E2E-ABSA >>> 2024-06-10 22:40:10\n",
            ">>> val_acc: 0.6343, val_precision: 0.7091 val_recall: 0.6343, val_f1: 0.6287\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 22:40:49\n",
            "loss: 0.9192, acc: 0.6404\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:42:00\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 22:42:03\n",
            "loss: 0.9427, acc: 0.6484\n",
            "E2E-ABSA >>> 2024-06-10 22:42:51\n",
            "loss: 0.8909, acc: 0.6638\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:43:49\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 22:44:06\n",
            "loss: 0.9112, acc: 0.6464\n",
            "E2E-ABSA >>> 2024-06-10 22:44:54\n",
            "loss: 0.8849, acc: 0.6556\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:45:39\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 22:46:08\n",
            "loss: 0.8571, acc: 0.6724\n",
            "E2E-ABSA >>> 2024-06-10 22:46:57\n",
            "loss: 0.8868, acc: 0.6647\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:47:28\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 22:48:11\n",
            "loss: 0.8835, acc: 0.6580\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:49:18\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 22:49:26\n",
            "loss: 0.8921, acc: 0.6680\n",
            "E2E-ABSA >>> 2024-06-10 22:50:14\n",
            "loss: 0.8739, acc: 0.6589\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:51:08\n",
            ">>> val_acc: 0.6716, val_precision: 0.5427 val_recall: 0.6716, val_f1: 0.5632\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 22:51:28\n",
            "loss: 0.8438, acc: 0.6991\n",
            "E2E-ABSA >>> 2024-06-10 22:52:17\n",
            "loss: 0.8741, acc: 0.6613\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:52:57\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 22:53:31\n",
            "loss: 0.8410, acc: 0.6946\n",
            "E2E-ABSA >>> 2024-06-10 22:54:19\n",
            "loss: 0.8655, acc: 0.6676\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:54:47\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 22:55:34\n",
            "loss: 0.8672, acc: 0.6662\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 22:56:36\n",
            ">>> val_acc: 0.6760, val_precision: 0.4569 val_recall: 0.6760, val_f1: 0.5453\n",
            "E2E-ABSA >>> 2024-06-10 22:56:36\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7343, val_precision: 0.7205 val_recall: 0.7343, val_f1: 0.7248\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7343\n",
            ">>> test_acc: 0.7272, test_precision: 0.7110, test_recall: 0.7272, test_f1: 0.7155\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indobenchmark/indobert-large-p2 --valset_ratio 0.5 --log_step 100 --bert_dim 1024 --patience 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7JhvOg-aDtfw",
      "metadata": {
        "editable": true,
        "id": "7JhvOg-aDtfw",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s6 concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SwktYKZxDtfw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "SwktYKZxDtfw",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "91a43b13-2452-4a08-e39d-cd99d7f9c55a",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5525.\n",
            "> testing dataset count: 2298.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f3ad7a1f640>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 10\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/d_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/d_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-11 00:13:24\n",
            "loss: 0.9195, acc: 0.6525\n",
            "E2E-ABSA >>> 2024-06-11 00:14:35\n",
            ">>> val_acc: 0.6756, val_precision: 0.5296 val_recall: 0.6756, val_f1: 0.5466\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6756\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-11 00:14:53\n",
            "loss: 0.8677, acc: 0.6505\n",
            "E2E-ABSA >>> 2024-06-11 00:15:55\n",
            "loss: 0.8866, acc: 0.6516\n",
            "E2E-ABSA >>> 2024-06-11 00:16:54\n",
            ">>> val_acc: 0.6792, val_precision: 0.6539 val_recall: 0.6792, val_f1: 0.5672\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6792\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-11 00:17:27\n",
            "loss: 0.8386, acc: 0.6910\n",
            "E2E-ABSA >>> 2024-06-11 00:18:25\n",
            "loss: 0.8690, acc: 0.6684\n",
            "E2E-ABSA >>> 2024-06-11 00:19:07\n",
            ">>> val_acc: 0.6651, val_precision: 0.5393 val_recall: 0.6651, val_f1: 0.5735\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.6651\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-11 00:19:58\n",
            "loss: 0.8404, acc: 0.6852\n",
            "E2E-ABSA >>> 2024-06-11 00:21:28\n",
            ">>> val_acc: 0.6778, val_precision: 0.5612 val_recall: 0.6778, val_f1: 0.5643\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-11 00:21:33\n",
            "loss: 0.9512, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-11 00:22:32\n",
            "loss: 0.8566, acc: 0.6719\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-11 00:23:41\n",
            ">>> val_acc: 0.6810, val_precision: 0.5854 val_recall: 0.6810, val_f1: 0.5684\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-11 00:24:01\n",
            "loss: 0.8787, acc: 0.6375\n",
            "E2E-ABSA >>> 2024-06-11 00:24:59\n",
            "loss: 0.8481, acc: 0.6630\n",
            "E2E-ABSA >>> 2024-06-11 00:25:55\n",
            ">>> val_acc: 0.7031, val_precision: 0.6719 val_recall: 0.7031, val_f1: 0.6397\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7031\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-11 00:26:34\n",
            "loss: 0.7196, acc: 0.7087\n",
            "E2E-ABSA >>> 2024-06-11 00:27:36\n",
            "loss: 0.7461, acc: 0.6906\n",
            "E2E-ABSA >>> 2024-06-11 00:28:14\n",
            ">>> val_acc: 0.7122, val_precision: 0.6763 val_recall: 0.7122, val_f1: 0.6671\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7122\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-11 00:29:07\n",
            "loss: 0.6582, acc: 0.7254\n",
            "E2E-ABSA >>> 2024-06-11 00:30:27\n",
            ">>> val_acc: 0.7288, val_precision: 0.7137 val_recall: 0.7288, val_f1: 0.7188\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7288\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-11 00:30:38\n",
            "loss: 0.6286, acc: 0.7500\n",
            "E2E-ABSA >>> 2024-06-11 00:31:39\n",
            "loss: 0.6569, acc: 0.7263\n",
            "E2E-ABSA >>> 2024-06-11 00:32:49\n",
            ">>> val_acc: 0.7375, val_precision: 0.7158 val_recall: 0.7375, val_f1: 0.7162\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-11 00:33:14\n",
            "loss: 0.5827, acc: 0.7573\n",
            "E2E-ABSA >>> 2024-06-11 00:34:12\n",
            "loss: 0.5991, acc: 0.7526\n",
            "E2E-ABSA >>> 2024-06-11 00:35:01\n",
            ">>> val_acc: 0.7285, val_precision: 0.7220 val_recall: 0.7285, val_f1: 0.7223\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7285\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-11 00:35:43\n",
            "loss: 0.5199, acc: 0.7830\n",
            "E2E-ABSA >>> 2024-06-11 00:36:43\n",
            "loss: 0.5447, acc: 0.7768\n",
            "E2E-ABSA >>> 2024-06-11 00:39:36\n",
            ">>> val_acc: 0.7256, val_precision: 0.7084 val_recall: 0.7256, val_f1: 0.6680\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-11 00:39:50\n",
            "loss: 0.4271, acc: 0.8099\n",
            "E2E-ABSA >>> 2024-06-11 00:40:48\n",
            "loss: 0.4979, acc: 0.7888\n",
            "E2E-ABSA >>> 2024-06-11 00:41:48\n",
            ">>> val_acc: 0.7382, val_precision: 0.7228 val_recall: 0.7382, val_f1: 0.7277\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7382\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-11 00:42:21\n",
            "loss: 0.4510, acc: 0.8088\n",
            "E2E-ABSA >>> 2024-06-11 00:43:23\n",
            "loss: 0.4657, acc: 0.8071\n",
            "E2E-ABSA >>> 2024-06-11 00:44:11\n",
            ">>> val_acc: 0.6901, val_precision: 0.7177 val_recall: 0.6901, val_f1: 0.6644\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-11 00:44:56\n",
            "loss: 0.4236, acc: 0.8349\n",
            "E2E-ABSA >>> 2024-06-11 00:46:23\n",
            ">>> val_acc: 0.7234, val_precision: 0.7093 val_recall: 0.7234, val_f1: 0.6871\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-11 00:46:26\n",
            "loss: 0.3426, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-11 00:47:23\n",
            "loss: 0.3961, acc: 0.8393\n",
            "E2E-ABSA >>> 2024-06-11 00:48:37\n",
            ">>> val_acc: 0.7350, val_precision: 0.7114 val_recall: 0.7350, val_f1: 0.7003\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-11 00:48:57\n",
            "loss: 0.4175, acc: 0.8379\n",
            "E2E-ABSA >>> 2024-06-11 00:49:59\n",
            "loss: 0.4014, acc: 0.8438\n",
            "E2E-ABSA >>> 2024-06-11 00:50:56\n",
            ">>> val_acc: 0.7009, val_precision: 0.7100 val_recall: 0.7009, val_f1: 0.7051\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-11 00:51:30\n",
            "loss: 0.3226, acc: 0.8697\n",
            "E2E-ABSA >>> 2024-06-11 00:52:28\n",
            "loss: 0.3599, acc: 0.8514\n",
            "E2E-ABSA >>> 2024-06-11 00:53:07\n",
            ">>> val_acc: 0.7310, val_precision: 0.7073 val_recall: 0.7310, val_f1: 0.7096\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-11 00:53:57\n",
            "loss: 0.3240, acc: 0.8474\n",
            "E2E-ABSA >>> 2024-06-11 00:55:24\n",
            ">>> val_acc: 0.7067, val_precision: 0.7114 val_recall: 0.7067, val_f1: 0.7084\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-11 00:55:32\n",
            "loss: 0.2686, acc: 0.8846\n",
            "E2E-ABSA >>> 2024-06-11 00:56:34\n",
            "loss: 0.3497, acc: 0.8606\n",
            "E2E-ABSA >>> 2024-06-11 00:57:40\n",
            ">>> val_acc: 0.6901, val_precision: 0.7073 val_recall: 0.6901, val_f1: 0.6958\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-11 00:58:04\n",
            "loss: 0.3718, acc: 0.8531\n",
            "E2E-ABSA >>> 2024-06-11 00:59:01\n",
            "loss: 0.3628, acc: 0.8580\n",
            "E2E-ABSA >>> 2024-06-11 00:59:52\n",
            ">>> val_acc: 0.7147, val_precision: 0.7057 val_recall: 0.7147, val_f1: 0.7095\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-11 01:00:31\n",
            "loss: 0.3422, acc: 0.8638\n",
            "E2E-ABSA >>> 2024-06-11 01:01:33\n",
            "loss: 0.3507, acc: 0.8563\n",
            "E2E-ABSA >>> 2024-06-11 01:02:11\n",
            ">>> val_acc: 0.7046, val_precision: 0.7131 val_recall: 0.7046, val_f1: 0.7048\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-11 01:03:08\n",
            "loss: 0.2455, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-11 01:04:25\n",
            ">>> val_acc: 0.6524, val_precision: 0.7114 val_recall: 0.6524, val_f1: 0.6695\n",
            "E2E-ABSA >>> 2024-06-11 01:04:25\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7382, val_precision: 0.7228 val_recall: 0.7382, val_f1: 0.7277\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7382\n",
            ">>> test_acc: 0.7119, test_precision: 0.6867, test_recall: 0.7119, test_f1: 0.6931\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024 --patience 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## indobenchmark/indobert-large-p2 Insertion"
      ],
      "metadata": {
        "id": "xygiGKGsMfS1"
      },
      "id": "xygiGKGsMfS1"
    },
    {
      "cell_type": "markdown",
      "id": "qC5eBizEDtft",
      "metadata": {
        "editable": true,
        "id": "qC5eBizEDtft",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s1 insert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hl6BriKADtfu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "editable": true,
        "id": "hl6BriKADtfu",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "be090bb9-e2f2-4789-ffca-f260fd6e091a",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_raw_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f0e9251b760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/x_insert_raw_knowledge/train.tsv', 'test': './datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 16:47:16\n",
            "loss: 0.9503, acc: 0.6375\n",
            "E2E-ABSA >>> 2024-06-10 16:48:19\n",
            ">>> val_acc: 0.6490, val_precision: 0.6481 val_recall: 0.6490, val_f1: 0.6449\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.649\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 16:48:32\n",
            "loss: 0.7452, acc: 0.7005\n",
            "E2E-ABSA >>> 2024-06-10 16:49:20\n",
            "loss: 0.7517, acc: 0.6946\n",
            "E2E-ABSA >>> 2024-06-10 16:50:12\n",
            ">>> val_acc: 0.6998, val_precision: 0.6832 val_recall: 0.6998, val_f1: 0.6271\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 16:50:35\n",
            "loss: 0.7071, acc: 0.7044\n",
            "E2E-ABSA >>> 2024-06-10 16:51:23\n",
            "loss: 0.7070, acc: 0.7019\n",
            "E2E-ABSA >>> 2024-06-10 16:52:03\n",
            ">>> val_acc: 0.7233, val_precision: 0.7042 val_recall: 0.7233, val_f1: 0.7008\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7233\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 16:52:39\n",
            "loss: 0.6311, acc: 0.7465\n",
            "E2E-ABSA >>> 2024-06-10 16:53:27\n",
            "loss: 0.6353, acc: 0.7416\n",
            "E2E-ABSA >>> 2024-06-10 16:53:55\n",
            ">>> val_acc: 0.6796, val_precision: 0.7291 val_recall: 0.6796, val_f1: 0.6850\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 16:54:42\n",
            "loss: 0.6573, acc: 0.7266\n",
            "E2E-ABSA >>> 2024-06-10 16:55:47\n",
            ">>> val_acc: 0.6849, val_precision: 0.7041 val_recall: 0.6849, val_f1: 0.6890\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 16:55:56\n",
            "loss: 0.6838, acc: 0.7063\n",
            "E2E-ABSA >>> 2024-06-10 16:56:44\n",
            "loss: 0.6438, acc: 0.7240\n",
            "E2E-ABSA >>> 2024-06-10 16:57:38\n",
            ">>> val_acc: 0.7545, val_precision: 0.7334 val_recall: 0.7545, val_f1: 0.7299\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7545\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 16:58:00\n",
            "loss: 0.4962, acc: 0.8182\n",
            "E2E-ABSA >>> 2024-06-10 16:58:48\n",
            "loss: 0.5280, acc: 0.7982\n",
            "E2E-ABSA >>> 2024-06-10 16:59:31\n",
            ">>> val_acc: 0.7343, val_precision: 0.7370 val_recall: 0.7343, val_f1: 0.7334\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7343\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 17:00:04\n",
            "loss: 0.4463, acc: 0.8392\n",
            "E2E-ABSA >>> 2024-06-10 17:00:52\n",
            "loss: 0.4699, acc: 0.8147\n",
            "E2E-ABSA >>> 2024-06-10 17:01:23\n",
            ">>> val_acc: 0.7446, val_precision: 0.7323 val_recall: 0.7446, val_f1: 0.6958\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 17:02:07\n",
            "loss: 0.6497, acc: 0.7391\n",
            "E2E-ABSA >>> 2024-06-10 17:03:14\n",
            ">>> val_acc: 0.7027, val_precision: 0.6609 val_recall: 0.7027, val_f1: 0.6362\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 17:03:22\n",
            "loss: 0.6888, acc: 0.7539\n",
            "E2E-ABSA >>> 2024-06-10 17:04:10\n",
            "loss: 0.6019, acc: 0.7667\n",
            "E2E-ABSA >>> 2024-06-10 17:05:06\n",
            ">>> val_acc: 0.7464, val_precision: 0.7274 val_recall: 0.7464, val_f1: 0.7312\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 17:05:25\n",
            "loss: 0.4794, acc: 0.8187\n",
            "E2E-ABSA >>> 2024-06-10 17:06:13\n",
            "loss: 0.4544, acc: 0.8250\n",
            "E2E-ABSA >>> 2024-06-10 17:06:57\n",
            ">>> val_acc: 0.7602, val_precision: 0.7454 val_recall: 0.7602, val_f1: 0.7431\n",
            ">> saved: state_dict/bert_spc_combined_raw_know_val_f1_0.7602\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 17:07:29\n",
            "loss: 0.4526, acc: 0.8203\n",
            "E2E-ABSA >>> 2024-06-10 17:08:17\n",
            "loss: 0.4650, acc: 0.8163\n",
            "E2E-ABSA >>> 2024-06-10 17:08:49\n",
            ">>> val_acc: 0.6984, val_precision: 0.7151 val_recall: 0.6984, val_f1: 0.7053\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-10 17:09:32\n",
            "loss: 0.4480, acc: 0.8388\n",
            "E2E-ABSA >>> 2024-06-10 17:10:41\n",
            ">>> val_acc: 0.7247, val_precision: 0.7371 val_recall: 0.7247, val_f1: 0.7273\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-10 17:10:47\n",
            "loss: 0.2900, acc: 0.8802\n",
            "E2E-ABSA >>> 2024-06-10 17:11:35\n",
            "loss: 0.3500, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-10 17:12:32\n",
            ">>> val_acc: 0.7211, val_precision: 0.7228 val_recall: 0.7211, val_f1: 0.7206\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-10 17:12:49\n",
            "loss: 0.3345, acc: 0.8802\n",
            "E2E-ABSA >>> 2024-06-10 17:13:37\n",
            "loss: 0.3804, acc: 0.8552\n",
            "E2E-ABSA >>> 2024-06-10 17:14:23\n",
            ">>> val_acc: 0.7361, val_precision: 0.7414 val_recall: 0.7361, val_f1: 0.7347\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-10 17:14:52\n",
            "loss: 0.2732, acc: 0.9042\n",
            "E2E-ABSA >>> 2024-06-10 17:15:40\n",
            "loss: 0.3290, acc: 0.8859\n",
            "E2E-ABSA >>> 2024-06-10 17:16:15\n",
            ">>> val_acc: 0.7453, val_precision: 0.7337 val_recall: 0.7453, val_f1: 0.7377\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-10 17:16:55\n",
            "loss: 0.3117, acc: 0.8810\n",
            "E2E-ABSA >>> 2024-06-10 17:18:06\n",
            ">>> val_acc: 0.7432, val_precision: 0.7229 val_recall: 0.7432, val_f1: 0.7251\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-10 17:18:10\n",
            "loss: 0.2243, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-10 17:18:58\n",
            "loss: 0.3075, acc: 0.8947\n",
            "E2E-ABSA >>> 2024-06-10 17:19:57\n",
            ">>> val_acc: 0.7371, val_precision: 0.7179 val_recall: 0.7371, val_f1: 0.7168\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-10 17:20:13\n",
            "loss: 0.3079, acc: 0.8848\n",
            "E2E-ABSA >>> 2024-06-10 17:21:01\n",
            "loss: 0.6706, acc: 0.7538\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:21:49\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-10 17:22:16\n",
            "loss: 0.8588, acc: 0.6741\n",
            "E2E-ABSA >>> 2024-06-10 17:23:04\n",
            "loss: 0.8626, acc: 0.6679\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:23:40\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-10 17:24:18\n",
            "loss: 0.8466, acc: 0.6750\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:25:31\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-10 17:25:33\n",
            "loss: 0.9283, acc: 0.6562\n",
            "E2E-ABSA >>> 2024-06-10 17:26:21\n",
            "loss: 0.8788, acc: 0.6593\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:27:22\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-10 17:27:36\n",
            "loss: 0.8983, acc: 0.6384\n",
            "E2E-ABSA >>> 2024-06-10 17:28:24\n",
            "loss: 0.8812, acc: 0.6519\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:29:14\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-10 17:29:39\n",
            "loss: 0.8694, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-10 17:30:27\n",
            "loss: 0.8720, acc: 0.6665\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:31:05\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-10 17:31:41\n",
            "loss: 0.8536, acc: 0.6678\n",
            "E2E-ABSA >>> 2024-06-10 17:32:29\n",
            "loss: 0.8639, acc: 0.6686\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:32:56\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-10 17:33:44\n",
            "loss: 0.8619, acc: 0.6656\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:34:47\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-10 17:34:59\n",
            "loss: 0.8228, acc: 0.6927\n",
            "E2E-ABSA >>> 2024-06-10 17:35:47\n",
            "loss: 0.8615, acc: 0.6704\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:36:39\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-10 17:37:02\n",
            "loss: 0.8531, acc: 0.6641\n",
            "E2E-ABSA >>> 2024-06-10 17:39:53\n",
            "loss: 0.8824, acc: 0.6664\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:40:21\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-10 17:41:07\n",
            "loss: 0.8557, acc: 0.6732\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:42:12\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-10 17:42:22\n",
            "loss: 0.8708, acc: 0.6438\n",
            "E2E-ABSA >>> 2024-06-10 17:43:10\n",
            "loss: 0.8582, acc: 0.6745\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 17:44:04\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            "E2E-ABSA >>> 2024-06-10 17:44:04\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7602, val_precision: 0.7454 val_recall: 0.7602, val_f1: 0.7431\n",
            "you can download the best model from state_dict/bert_spc_combined_raw_know_val_f1_0.7602\n",
            ">>> test_acc: 0.7377, test_precision: 0.7170, test_recall: 0.7377, test_f1: 0.7089\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_raw_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "azVTRILuDtfu",
      "metadata": {
        "editable": true,
        "id": "azVTRILuDtfu",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s2 insert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kkdPQjyfDtfu",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "kkdPQjyfDtfu",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "c5e6436d-df73-4a75-f0f6-6401bb405b38",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_trim_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7feb92427760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/y_insert_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/y_insert_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 18:34:35\n",
            "loss: 0.8749, acc: 0.6594\n",
            "E2E-ABSA >>> 2024-06-10 18:35:39\n",
            ">>> val_acc: 0.6906, val_precision: 0.6769 val_recall: 0.6906, val_f1: 0.6804\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.6906\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 18:35:51\n",
            "loss: 0.6573, acc: 0.7188\n",
            "E2E-ABSA >>> 2024-06-10 18:36:39\n",
            "loss: 0.6778, acc: 0.7142\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 18:37:31\n",
            ">>> val_acc: 0.6970, val_precision: 0.5981 val_recall: 0.6970, val_f1: 0.6209\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 18:37:54\n",
            "loss: 0.6839, acc: 0.6966\n",
            "E2E-ABSA >>> 2024-06-10 18:38:42\n",
            "loss: 0.6453, acc: 0.7137\n",
            "E2E-ABSA >>> 2024-06-10 18:39:22\n",
            ">>> val_acc: 0.7453, val_precision: 0.7289 val_recall: 0.7453, val_f1: 0.7095\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7453\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 18:39:58\n",
            "loss: 0.5222, acc: 0.7908\n",
            "E2E-ABSA >>> 2024-06-10 18:41:15\n",
            ">>> val_acc: 0.7304, val_precision: 0.7663 val_recall: 0.7304, val_f1: 0.7387\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7304\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 18:42:02\n",
            "loss: 0.4599, acc: 0.8027\n",
            "E2E-ABSA >>> 2024-06-10 18:43:07\n",
            ">>> val_acc: 0.7329, val_precision: 0.7655 val_recall: 0.7329, val_f1: 0.7438\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7329\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 18:43:18\n",
            "loss: 0.4591, acc: 0.7844\n",
            "E2E-ABSA >>> 2024-06-10 18:44:06\n",
            "loss: 0.4018, acc: 0.8307\n",
            "E2E-ABSA >>> 2024-06-10 18:45:00\n",
            ">>> val_acc: 0.7702, val_precision: 0.7562 val_recall: 0.7702, val_f1: 0.7565\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7702\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 18:45:22\n",
            "loss: 0.3405, acc: 0.8622\n",
            "E2E-ABSA >>> 2024-06-10 18:46:10\n",
            "loss: 0.3470, acc: 0.8563\n",
            "E2E-ABSA >>> 2024-06-10 18:46:52\n",
            ">>> val_acc: 0.7677, val_precision: 0.7692 val_recall: 0.7677, val_f1: 0.7682\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7677\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 18:47:26\n",
            "loss: 0.2771, acc: 0.8814\n",
            "E2E-ABSA >>> 2024-06-10 18:48:14\n",
            "loss: 0.3100, acc: 0.8739\n",
            "E2E-ABSA >>> 2024-06-10 18:48:44\n",
            ">>> val_acc: 0.7709, val_precision: 0.7648 val_recall: 0.7709, val_f1: 0.7626\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 18:49:29\n",
            "loss: 0.2207, acc: 0.9171\n",
            "E2E-ABSA >>> 2024-06-10 18:50:36\n",
            ">>> val_acc: 0.7712, val_precision: 0.7555 val_recall: 0.7712, val_f1: 0.7541\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 18:50:43\n",
            "loss: 0.1974, acc: 0.9297\n",
            "E2E-ABSA >>> 2024-06-10 18:51:31\n",
            "loss: 0.2417, acc: 0.9079\n",
            "E2E-ABSA >>> 2024-06-10 18:52:27\n",
            ">>> val_acc: 0.7744, val_precision: 0.7672 val_recall: 0.7744, val_f1: 0.7687\n",
            ">> saved: state_dict/bert_spc_combined_trim_know_val_f1_0.7744\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 18:52:47\n",
            "loss: 0.2084, acc: 0.9203\n",
            "E2E-ABSA >>> 2024-06-10 18:53:35\n",
            "loss: 0.2363, acc: 0.9103\n",
            "E2E-ABSA >>> 2024-06-10 18:54:19\n",
            ">>> val_acc: 0.7773, val_precision: 0.7628 val_recall: 0.7773, val_f1: 0.7646\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 18:54:50\n",
            "loss: 0.1813, acc: 0.9326\n",
            "E2E-ABSA >>> 2024-06-10 18:55:38\n",
            "loss: 0.2209, acc: 0.9165\n",
            "E2E-ABSA >>> 2024-06-10 18:56:11\n",
            ">>> val_acc: 0.7712, val_precision: 0.7709 val_recall: 0.7712, val_f1: 0.7513\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-10 18:56:53\n",
            "loss: 0.2103, acc: 0.9226\n",
            "E2E-ABSA >>> 2024-06-10 18:58:02\n",
            ">>> val_acc: 0.7655, val_precision: 0.7743 val_recall: 0.7655, val_f1: 0.7646\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-10 18:58:08\n",
            "loss: 0.1978, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-10 18:58:56\n",
            "loss: 0.2184, acc: 0.9196\n",
            "E2E-ABSA >>> 2024-06-10 18:59:53\n",
            ">>> val_acc: 0.7666, val_precision: 0.7604 val_recall: 0.7666, val_f1: 0.7604\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-10 19:00:11\n",
            "loss: 0.1729, acc: 0.9288\n",
            "E2E-ABSA >>> 2024-06-10 19:00:59\n",
            "loss: 0.1998, acc: 0.9265\n",
            "E2E-ABSA >>> 2024-06-10 19:01:45\n",
            ">>> val_acc: 0.7307, val_precision: 0.7738 val_recall: 0.7307, val_f1: 0.7432\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-10 19:02:13\n",
            "loss: 0.2010, acc: 0.9250\n",
            "E2E-ABSA >>> 2024-06-10 19:03:02\n",
            "loss: 0.2365, acc: 0.9109\n",
            "E2E-ABSA >>> 2024-06-10 19:03:36\n",
            ">>> val_acc: 0.7648, val_precision: 0.7666 val_recall: 0.7648, val_f1: 0.7624\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-10 19:04:16\n",
            "loss: 0.1699, acc: 0.9390\n",
            "E2E-ABSA >>> 2024-06-10 19:05:27\n",
            ">>> val_acc: 0.7435, val_precision: 0.7712 val_recall: 0.7435, val_f1: 0.7470\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-10 19:05:31\n",
            "loss: 0.1761, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-10 19:06:19\n",
            "loss: 0.2350, acc: 0.9184\n",
            "E2E-ABSA >>> 2024-06-10 19:07:19\n",
            ">>> val_acc: 0.7666, val_precision: 0.7526 val_recall: 0.7666, val_f1: 0.7560\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-10 19:07:34\n",
            "loss: 0.1623, acc: 0.9355\n",
            "E2E-ABSA >>> 2024-06-10 19:08:22\n",
            "loss: 0.2072, acc: 0.9280\n",
            "E2E-ABSA >>> 2024-06-10 19:09:10\n",
            ">>> val_acc: 0.7602, val_precision: 0.7654 val_recall: 0.7602, val_f1: 0.7602\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-10 19:09:37\n",
            "loss: 0.1288, acc: 0.9464\n",
            "E2E-ABSA >>> 2024-06-10 19:10:25\n",
            "loss: 0.1787, acc: 0.9403\n",
            "E2E-ABSA >>> 2024-06-10 19:11:01\n",
            ">>> val_acc: 0.7488, val_precision: 0.7645 val_recall: 0.7488, val_f1: 0.7535\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-10 19:11:40\n",
            "loss: 0.1205, acc: 0.9563\n",
            "E2E-ABSA >>> 2024-06-10 19:12:53\n",
            ">>> val_acc: 0.7488, val_precision: 0.7429 val_recall: 0.7488, val_f1: 0.7452\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-10 19:12:54\n",
            "loss: 0.1821, acc: 0.8906\n",
            "E2E-ABSA >>> 2024-06-10 19:13:43\n",
            "loss: 0.1378, acc: 0.9495\n",
            "E2E-ABSA >>> 2024-06-10 19:14:44\n",
            ">>> val_acc: 0.6480, val_precision: 0.7530 val_recall: 0.6480, val_f1: 0.6703\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-10 19:14:57\n",
            "loss: 0.2225, acc: 0.9129\n",
            "E2E-ABSA >>> 2024-06-10 19:15:45\n",
            "loss: 0.1887, acc: 0.9292\n",
            "E2E-ABSA >>> 2024-06-10 19:16:35\n",
            ">>> val_acc: 0.7385, val_precision: 0.7401 val_recall: 0.7385, val_f1: 0.7353\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-10 19:17:00\n",
            "loss: 0.1078, acc: 0.9651\n",
            "E2E-ABSA >>> 2024-06-10 19:17:48\n",
            "loss: 0.1357, acc: 0.9535\n",
            "E2E-ABSA >>> 2024-06-10 19:18:27\n",
            ">>> val_acc: 0.7510, val_precision: 0.7347 val_recall: 0.7510, val_f1: 0.7365\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-10 19:19:03\n",
            "loss: 0.1683, acc: 0.9433\n",
            "E2E-ABSA >>> 2024-06-10 19:19:51\n",
            "loss: 0.1892, acc: 0.9329\n",
            "E2E-ABSA >>> 2024-06-10 19:20:18\n",
            ">>> val_acc: 0.7357, val_precision: 0.7220 val_recall: 0.7357, val_f1: 0.7193\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-10 19:21:06\n",
            "loss: 0.1702, acc: 0.9356\n",
            "E2E-ABSA >>> 2024-06-10 19:22:09\n",
            ">>> val_acc: 0.7339, val_precision: 0.7394 val_recall: 0.7339, val_f1: 0.7336\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-10 19:22:21\n",
            "loss: 0.0977, acc: 0.9583\n",
            "E2E-ABSA >>> 2024-06-10 19:23:09\n",
            "loss: 0.1308, acc: 0.9536\n",
            "E2E-ABSA >>> 2024-06-10 19:24:01\n",
            ">>> val_acc: 0.7478, val_precision: 0.7389 val_recall: 0.7478, val_f1: 0.7423\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-10 19:24:24\n",
            "loss: 0.0854, acc: 0.9701\n",
            "E2E-ABSA >>> 2024-06-10 19:25:12\n",
            "loss: 0.1516, acc: 0.9434\n",
            "E2E-ABSA >>> 2024-06-10 19:25:52\n",
            ">>> val_acc: 0.7425, val_precision: 0.7352 val_recall: 0.7425, val_f1: 0.7371\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-10 19:26:26\n",
            "loss: 0.1236, acc: 0.9566\n",
            "E2E-ABSA >>> 2024-06-10 19:27:15\n",
            "loss: 0.1581, acc: 0.9444\n",
            "E2E-ABSA >>> 2024-06-10 19:27:43\n",
            ">>> val_acc: 0.7364, val_precision: 0.7127 val_recall: 0.7364, val_f1: 0.7133\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-10 19:28:29\n",
            "loss: 0.1466, acc: 0.9505\n",
            "E2E-ABSA >>> 2024-06-10 19:29:35\n",
            ">>> val_acc: 0.7261, val_precision: 0.7296 val_recall: 0.7261, val_f1: 0.7227\n",
            "E2E-ABSA >>> 2024-06-10 19:29:35\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7744, val_precision: 0.7672 val_recall: 0.7744, val_f1: 0.7687\n",
            "you can download the best model from state_dict/bert_spc_combined_trim_know_val_f1_0.7744\n",
            ">>> test_acc: 0.7525, test_precision: 0.7438, test_recall: 0.7525, test_f1: 0.7428\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_trim_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OpnRU2-bDtfv",
      "metadata": {
        "editable": true,
        "id": "OpnRU2-bDtfv",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s3 insert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-692qF0cDtfv",
      "metadata": {
        "collapsed": true,
        "editable": true,
        "id": "-692qF0cDtfv",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a9125e10-f101-41c1-9bc3-d18ceb2ad3f5",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_select_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f6d05b23760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 10\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/z_insert_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/z_insert_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-10 20:41:36\n",
            "loss: 0.9557, acc: 0.6244\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 20:42:39\n",
            ">>> val_acc: 0.6757, val_precision: 0.5579 val_recall: 0.6757, val_f1: 0.5857\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6757\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-10 20:42:52\n",
            "loss: 0.8309, acc: 0.6927\n",
            "E2E-ABSA >>> 2024-06-10 20:43:40\n",
            "loss: 0.8288, acc: 0.6759\n",
            "E2E-ABSA >>> 2024-06-10 20:44:32\n",
            ">>> val_acc: 0.6966, val_precision: 0.7018 val_recall: 0.6966, val_f1: 0.6103\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.6966\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-10 20:44:56\n",
            "loss: 0.7302, acc: 0.6966\n",
            "E2E-ABSA >>> 2024-06-10 20:45:44\n",
            "loss: 0.7089, acc: 0.6959\n",
            "E2E-ABSA >>> 2024-06-10 20:46:24\n",
            ">>> val_acc: 0.7069, val_precision: 0.6940 val_recall: 0.7069, val_f1: 0.6810\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7069\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-10 20:47:00\n",
            "loss: 0.6588, acc: 0.7335\n",
            "E2E-ABSA >>> 2024-06-10 20:47:48\n",
            "loss: 0.6590, acc: 0.7173\n",
            "E2E-ABSA >>> 2024-06-10 20:48:17\n",
            ">>> val_acc: 0.7321, val_precision: 0.7123 val_recall: 0.7321, val_f1: 0.7114\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7321\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-10 20:49:04\n",
            "loss: 0.6171, acc: 0.7305\n",
            "E2E-ABSA >>> 2024-06-10 20:50:09\n",
            ">>> val_acc: 0.6710, val_precision: 0.7187 val_recall: 0.6710, val_f1: 0.6868\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-10 20:50:19\n",
            "loss: 0.7944, acc: 0.6500\n",
            "E2E-ABSA >>> 2024-06-10 20:51:07\n",
            "loss: 0.6916, acc: 0.7089\n",
            "E2E-ABSA >>> 2024-06-10 20:52:00\n",
            ">>> val_acc: 0.7176, val_precision: 0.7109 val_recall: 0.7176, val_f1: 0.7138\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7176\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-10 20:52:23\n",
            "loss: 0.5126, acc: 0.7670\n",
            "E2E-ABSA >>> 2024-06-10 20:53:11\n",
            "loss: 0.5317, acc: 0.7648\n",
            "E2E-ABSA >>> 2024-06-10 20:53:53\n",
            ">>> val_acc: 0.7265, val_precision: 0.7111 val_recall: 0.7265, val_f1: 0.7154\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7265\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-10 20:54:27\n",
            "loss: 0.5220, acc: 0.7831\n",
            "E2E-ABSA >>> 2024-06-10 20:55:15\n",
            "loss: 0.5203, acc: 0.7753\n",
            "E2E-ABSA >>> 2024-06-10 20:55:45\n",
            ">>> val_acc: 0.7318, val_precision: 0.7062 val_recall: 0.7318, val_f1: 0.7067\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-10 20:56:29\n",
            "loss: 0.4480, acc: 0.8057\n",
            "E2E-ABSA >>> 2024-06-10 20:57:37\n",
            ">>> val_acc: 0.7300, val_precision: 0.7087 val_recall: 0.7300, val_f1: 0.7117\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-10 20:57:44\n",
            "loss: 0.3582, acc: 0.8555\n",
            "E2E-ABSA >>> 2024-06-10 20:58:32\n",
            "loss: 0.4276, acc: 0.8168\n",
            "E2E-ABSA >>> 2024-06-10 20:59:28\n",
            ">>> val_acc: 0.7329, val_precision: 0.7090 val_recall: 0.7329, val_f1: 0.6970\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-10 20:59:47\n",
            "loss: 0.4165, acc: 0.8297\n",
            "E2E-ABSA >>> 2024-06-10 21:00:35\n",
            "loss: 0.4481, acc: 0.8152\n",
            "E2E-ABSA >>> 2024-06-10 21:01:19\n",
            ">>> val_acc: 0.7179, val_precision: 0.6968 val_recall: 0.7179, val_f1: 0.7028\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-10 21:01:50\n",
            "loss: 0.3847, acc: 0.8477\n",
            "E2E-ABSA >>> 2024-06-10 21:02:38\n",
            "loss: 0.4471, acc: 0.8186\n",
            "E2E-ABSA >>> 2024-06-10 21:03:10\n",
            ">>> val_acc: 0.7240, val_precision: 0.6954 val_recall: 0.7240, val_f1: 0.6810\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-10 21:03:53\n",
            "loss: 0.4568, acc: 0.8139\n",
            "E2E-ABSA >>> 2024-06-10 21:05:02\n",
            ">>> val_acc: 0.7155, val_precision: 0.7113 val_recall: 0.7155, val_f1: 0.7110\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-10 21:05:08\n",
            "loss: 0.3085, acc: 0.8542\n",
            "E2E-ABSA >>> 2024-06-10 21:05:56\n",
            "loss: 0.3591, acc: 0.8583\n",
            "E2E-ABSA >>> 2024-06-10 21:06:53\n",
            ">>> val_acc: 0.6998, val_precision: 0.7232 val_recall: 0.6998, val_f1: 0.7027\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-10 21:07:10\n",
            "loss: 0.3410, acc: 0.8576\n",
            "E2E-ABSA >>> 2024-06-10 21:07:58\n",
            "loss: 0.3874, acc: 0.8346\n",
            "E2E-ABSA >>> 2024-06-10 21:08:44\n",
            ">>> val_acc: 0.7293, val_precision: 0.7131 val_recall: 0.7293, val_f1: 0.7154\n",
            ">> saved: state_dict/bert_spc_combined_select_know_val_f1_0.7293\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-10 21:09:14\n",
            "loss: 0.3412, acc: 0.8594\n",
            "E2E-ABSA >>> 2024-06-10 21:10:02\n",
            "loss: 0.3748, acc: 0.8441\n",
            "E2E-ABSA >>> 2024-06-10 21:10:37\n",
            ">>> val_acc: 0.7187, val_precision: 0.7126 val_recall: 0.7187, val_f1: 0.7151\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-10 21:11:17\n",
            "loss: 0.2846, acc: 0.8884\n",
            "E2E-ABSA >>> 2024-06-10 21:12:28\n",
            ">>> val_acc: 0.6988, val_precision: 0.7091 val_recall: 0.6988, val_f1: 0.7006\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-10 21:12:32\n",
            "loss: 0.3239, acc: 0.8516\n",
            "E2E-ABSA >>> 2024-06-10 21:13:20\n",
            "loss: 0.3064, acc: 0.8808\n",
            "E2E-ABSA >>> 2024-06-10 21:14:19\n",
            ">>> val_acc: 0.7204, val_precision: 0.7135 val_recall: 0.7204, val_f1: 0.7104\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-10 21:14:35\n",
            "loss: 0.2913, acc: 0.8848\n",
            "E2E-ABSA >>> 2024-06-10 21:15:23\n",
            "loss: 0.3089, acc: 0.8745\n",
            "E2E-ABSA >>> 2024-06-10 21:16:11\n",
            ">>> val_acc: 0.7236, val_precision: 0.7014 val_recall: 0.7236, val_f1: 0.7068\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-10 21:16:38\n",
            "loss: 0.3328, acc: 0.8616\n",
            "E2E-ABSA >>> 2024-06-10 21:17:26\n",
            "loss: 0.3226, acc: 0.8662\n",
            "E2E-ABSA >>> 2024-06-10 21:18:02\n",
            ">>> val_acc: 0.7204, val_precision: 0.6938 val_recall: 0.7204, val_f1: 0.6923\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-10 21:18:41\n",
            "loss: 0.2390, acc: 0.9078\n",
            "E2E-ABSA >>> 2024-06-10 21:19:53\n",
            ">>> val_acc: 0.7226, val_precision: 0.7025 val_recall: 0.7226, val_f1: 0.6935\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-10 21:19:55\n",
            "loss: 0.1820, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-10 21:20:43\n",
            "loss: 0.2319, acc: 0.9087\n",
            "E2E-ABSA >>> 2024-06-10 21:21:45\n",
            ">>> val_acc: 0.6906, val_precision: 0.7151 val_recall: 0.6906, val_f1: 0.7001\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-10 21:21:58\n",
            "loss: 0.2390, acc: 0.8996\n",
            "E2E-ABSA >>> 2024-06-10 21:22:46\n",
            "loss: 0.2730, acc: 0.8882\n",
            "E2E-ABSA >>> 2024-06-10 21:23:36\n",
            ">>> val_acc: 0.7147, val_precision: 0.6905 val_recall: 0.7147, val_f1: 0.6964\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-10 21:24:01\n",
            "loss: 0.6307, acc: 0.7476\n",
            "E2E-ABSA >>> 2024-06-10 21:24:49\n",
            "loss: 0.7280, acc: 0.7183\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 21:25:27\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-10 21:26:04\n",
            "loss: 0.8395, acc: 0.6817\n",
            "E2E-ABSA >>> 2024-06-10 21:26:52\n",
            "loss: 0.8523, acc: 0.6767\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-10 21:27:19\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            "E2E-ABSA >>> 2024-06-10 21:27:19\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7293, val_precision: 0.7131 val_recall: 0.7293, val_f1: 0.7154\n",
            "you can download the best model from state_dict/bert_spc_combined_select_know_val_f1_0.7293\n",
            ">>> test_acc: 0.7199, test_precision: 0.6896, test_recall: 0.7199, test_f1: 0.6904\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_select_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024 --patience 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7oAyZNS2Dtfv",
      "metadata": {
        "editable": true,
        "id": "7oAyZNS2Dtfv",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s4 insert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a47296-0f26-4cac-aba4-790d6894f861",
      "metadata": {
        "id": "c0a47296-0f26-4cac-aba4-790d6894f861",
        "outputId": "8c337bd1-9118-40db-9960-46974547508a",
        "scrolled": true,
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_know\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f07e971b880>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/j_insert_padanan_knowledge/train.tsv', 'test': './datasets/ulasan_combined/j_insert_padanan_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-13 19:58:20\n",
            "loss: 0.9248, acc: 0.6350\n",
            "E2E-ABSA >>> 2024-06-13 19:58:57\n",
            ">>> val_acc: 0.6789, val_precision: 0.5618 val_recall: 0.6789, val_f1: 0.5841\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.6789\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-13 19:59:05\n",
            "loss: 0.8678, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-13 19:59:34\n",
            "loss: 0.8220, acc: 0.6638\n",
            "E2E-ABSA >>> 2024-06-13 20:00:05\n",
            ">>> val_acc: 0.7037, val_precision: 0.6848 val_recall: 0.7037, val_f1: 0.6202\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7037\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-13 20:00:19\n",
            "loss: 0.7487, acc: 0.6940\n",
            "E2E-ABSA >>> 2024-06-13 20:00:48\n",
            "loss: 0.7348, acc: 0.6993\n",
            "E2E-ABSA >>> 2024-06-13 20:01:12\n",
            ">>> val_acc: 0.7325, val_precision: 0.7116 val_recall: 0.7325, val_f1: 0.7156\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7325\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-13 20:01:33\n",
            "loss: 0.6236, acc: 0.7517\n",
            "E2E-ABSA >>> 2024-06-13 20:02:02\n",
            "loss: 0.6416, acc: 0.7456\n",
            "E2E-ABSA >>> 2024-06-13 20:02:19\n",
            ">>> val_acc: 0.7041, val_precision: 0.7103 val_recall: 0.7041, val_f1: 0.6369\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-13 20:02:46\n",
            "loss: 0.6472, acc: 0.7298\n",
            "E2E-ABSA >>> 2024-06-13 20:03:25\n",
            ">>> val_acc: 0.7513, val_precision: 0.7424 val_recall: 0.7513, val_f1: 0.7459\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7513\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-13 20:03:32\n",
            "loss: 0.5458, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-06-13 20:04:00\n",
            "loss: 0.5387, acc: 0.7870\n",
            "E2E-ABSA >>> 2024-06-13 20:04:32\n",
            ">>> val_acc: 0.7581, val_precision: 0.7456 val_recall: 0.7581, val_f1: 0.7191\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-13 20:04:45\n",
            "loss: 0.4374, acc: 0.8253\n",
            "E2E-ABSA >>> 2024-06-13 20:05:13\n",
            "loss: 0.4575, acc: 0.8242\n",
            "E2E-ABSA >>> 2024-06-13 20:05:38\n",
            ">>> val_acc: 0.7307, val_precision: 0.7395 val_recall: 0.7307, val_f1: 0.7324\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-13 20:05:58\n",
            "loss: 0.4125, acc: 0.8373\n",
            "E2E-ABSA >>> 2024-06-13 20:06:26\n",
            "loss: 0.4544, acc: 0.8207\n",
            "E2E-ABSA >>> 2024-06-13 20:06:44\n",
            ">>> val_acc: 0.7030, val_precision: 0.6763 val_recall: 0.7030, val_f1: 0.6566\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-13 20:07:10\n",
            "loss: 0.4575, acc: 0.8274\n",
            "E2E-ABSA >>> 2024-06-13 20:07:50\n",
            ">>> val_acc: 0.7545, val_precision: 0.7465 val_recall: 0.7545, val_f1: 0.7132\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-13 20:07:55\n",
            "loss: 0.3457, acc: 0.8711\n",
            "E2E-ABSA >>> 2024-06-13 20:08:23\n",
            "loss: 0.4156, acc: 0.8491\n",
            "E2E-ABSA >>> 2024-06-13 20:08:57\n",
            ">>> val_acc: 0.7531, val_precision: 0.7382 val_recall: 0.7531, val_f1: 0.7162\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-13 20:09:08\n",
            "loss: 0.3468, acc: 0.8766\n",
            "E2E-ABSA >>> 2024-06-13 20:09:36\n",
            "loss: 0.3713, acc: 0.8643\n",
            "E2E-ABSA >>> 2024-06-13 20:10:03\n",
            ">>> val_acc: 0.7488, val_precision: 0.7282 val_recall: 0.7488, val_f1: 0.7228\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-13 20:10:21\n",
            "loss: 0.3447, acc: 0.8789\n",
            "E2E-ABSA >>> 2024-06-13 20:10:49\n",
            "loss: 0.3688, acc: 0.8609\n",
            "E2E-ABSA >>> 2024-06-13 20:11:09\n",
            ">>> val_acc: 0.7588, val_precision: 0.7406 val_recall: 0.7588, val_f1: 0.7373\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-13 20:11:34\n",
            "loss: 0.3010, acc: 0.8956\n",
            "E2E-ABSA >>> 2024-06-13 20:12:15\n",
            ">>> val_acc: 0.7229, val_precision: 0.7606 val_recall: 0.7229, val_f1: 0.7353\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-13 20:12:18\n",
            "loss: 0.3230, acc: 0.8646\n",
            "E2E-ABSA >>> 2024-06-13 20:12:47\n",
            "loss: 0.3426, acc: 0.8806\n",
            "E2E-ABSA >>> 2024-06-13 20:13:21\n",
            ">>> val_acc: 0.7560, val_precision: 0.7401 val_recall: 0.7560, val_f1: 0.7425\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-13 20:13:31\n",
            "loss: 0.2521, acc: 0.9062\n",
            "E2E-ABSA >>> 2024-06-13 20:13:59\n",
            "loss: 0.3806, acc: 0.8635\n",
            "E2E-ABSA >>> 2024-06-13 20:14:27\n",
            ">>> val_acc: 0.6899, val_precision: 0.7608 val_recall: 0.6899, val_f1: 0.7075\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-13 20:14:44\n",
            "loss: 0.2794, acc: 0.8979\n",
            "E2E-ABSA >>> 2024-06-13 20:15:12\n",
            "loss: 0.2953, acc: 0.8895\n",
            "E2E-ABSA >>> 2024-06-13 20:15:33\n",
            ">>> val_acc: 0.7645, val_precision: 0.7492 val_recall: 0.7645, val_f1: 0.7499\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7645\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-13 20:15:58\n",
            "loss: 0.2814, acc: 0.8981\n",
            "E2E-ABSA >>> 2024-06-13 20:16:40\n",
            ">>> val_acc: 0.7552, val_precision: 0.7685 val_recall: 0.7552, val_f1: 0.7573\n",
            ">> saved: state_dict/bert_spc_combined_padanan_know_val_f1_0.7552\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-13 20:16:44\n",
            "loss: 0.1984, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-13 20:17:12\n",
            "loss: 0.2609, acc: 0.9086\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:17:47\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-13 20:17:56\n",
            "loss: 0.9223, acc: 0.6367\n",
            "E2E-ABSA >>> 2024-06-13 20:18:25\n",
            "loss: 0.8882, acc: 0.6615\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:18:53\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-13 20:19:09\n",
            "loss: 0.8567, acc: 0.6752\n",
            "E2E-ABSA >>> 2024-06-13 20:19:38\n",
            "loss: 0.8732, acc: 0.6623\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:20:00\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-13 20:20:22\n",
            "loss: 0.8578, acc: 0.6773\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:21:06\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-13 20:21:07\n",
            "loss: 0.9457, acc: 0.6094\n",
            "E2E-ABSA >>> 2024-06-13 20:21:35\n",
            "loss: 0.8928, acc: 0.6562\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:22:12\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-13 20:22:20\n",
            "loss: 0.9213, acc: 0.6406\n",
            "E2E-ABSA >>> 2024-06-13 20:22:48\n",
            "loss: 0.8867, acc: 0.6572\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:23:18\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-13 20:23:32\n",
            "loss: 0.8836, acc: 0.6647\n",
            "E2E-ABSA >>> 2024-06-13 20:24:01\n",
            "loss: 0.8732, acc: 0.6682\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:24:24\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-13 20:24:45\n",
            "loss: 0.8540, acc: 0.6686\n",
            "E2E-ABSA >>> 2024-06-13 20:25:14\n",
            "loss: 0.8640, acc: 0.6650\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:25:30\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-13 20:25:58\n",
            "loss: 0.8600, acc: 0.6756\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:26:36\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-13 20:26:43\n",
            "loss: 0.8256, acc: 0.6849\n",
            "E2E-ABSA >>> 2024-06-13 20:27:11\n",
            "loss: 0.8530, acc: 0.6739\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:27:42\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-13 20:27:55\n",
            "loss: 0.8420, acc: 0.6654\n",
            "E2E-ABSA >>> 2024-06-13 20:28:24\n",
            "loss: 0.8655, acc: 0.6622\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:28:48\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 28.\n",
            "E2E-ABSA >>> 2024-06-13 20:29:08\n",
            "loss: 0.8620, acc: 0.6788\n",
            "E2E-ABSA >>> 2024-06-13 20:29:37\n",
            "loss: 0.8709, acc: 0.6693\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:29:54\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 29.\n",
            "E2E-ABSA >>> 2024-06-13 20:30:21\n",
            "loss: 0.8450, acc: 0.6712\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:31:00\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 30.\n",
            "E2E-ABSA >>> 2024-06-13 20:31:06\n",
            "loss: 0.9031, acc: 0.6156\n",
            "E2E-ABSA >>> 2024-06-13 20:31:34\n",
            "loss: 0.8665, acc: 0.6672\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:32:06\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 31.\n",
            "E2E-ABSA >>> 2024-06-13 20:32:18\n",
            "loss: 0.8393, acc: 0.6918\n",
            "E2E-ABSA >>> 2024-06-13 20:32:47\n",
            "loss: 0.8621, acc: 0.6727\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:33:12\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 32.\n",
            "E2E-ABSA >>> 2024-06-13 20:33:31\n",
            "loss: 0.8740, acc: 0.6719\n",
            "E2E-ABSA >>> 2024-06-13 20:34:00\n",
            "loss: 0.8576, acc: 0.6767\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:34:18\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 33.\n",
            "E2E-ABSA >>> 2024-06-13 20:34:44\n",
            "loss: 0.8672, acc: 0.6692\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:35:24\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 34.\n",
            "E2E-ABSA >>> 2024-06-13 20:35:29\n",
            "loss: 0.8341, acc: 0.6797\n",
            "E2E-ABSA >>> 2024-06-13 20:35:57\n",
            "loss: 0.8419, acc: 0.6853\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:36:30\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 35.\n",
            "E2E-ABSA >>> 2024-06-13 20:36:41\n",
            "loss: 0.8985, acc: 0.6609\n",
            "E2E-ABSA >>> 2024-06-13 20:37:10\n",
            "loss: 0.8685, acc: 0.6674\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:37:36\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 36.\n",
            "E2E-ABSA >>> 2024-06-13 20:37:54\n",
            "loss: 0.8386, acc: 0.6836\n",
            "E2E-ABSA >>> 2024-06-13 20:38:23\n",
            "loss: 0.8531, acc: 0.6757\n",
            "/home/riset/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "E2E-ABSA >>> 2024-06-13 20:38:42\n",
            ">>> val_acc: 0.6817, val_precision: 0.4647 val_recall: 0.6817, val_f1: 0.5527\n",
            "E2E-ABSA >>> 2024-06-13 20:38:42\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7552, val_precision: 0.7685 val_recall: 0.7552, val_f1: 0.7573\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_know_val_f1_0.7552\n",
            ">>> test_acc: 0.7271, test_precision: 0.7359, test_recall: 0.7271, test_f1: 0.7241\n"
          ]
        }
      ],
      "source": [
        "# 13-6 experiment 6\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_know --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024 --patience 20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yiIAnJyDDtfw",
      "metadata": {
        "editable": true,
        "id": "yiIAnJyDDtfw",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s5 insert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d126e438-fb75-4159-9aaa-84d6a06359da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "d126e438-fb75-4159-9aaa-84d6a06359da",
        "outputId": "62e1e674-5f91-4050-bd99-1f4599955b27",
        "scrolled": true,
        "tags": [],
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_trim\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7f964861f880>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 20\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/train.tsv', 'test': './datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-13 20:41:33\n",
            "loss: 0.8636, acc: 0.6425\n",
            "E2E-ABSA >>> 2024-06-13 20:42:11\n",
            ">>> val_acc: 0.7204, val_precision: 0.7375 val_recall: 0.7204, val_f1: 0.7267\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7204\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-13 20:42:19\n",
            "loss: 0.5731, acc: 0.7708\n",
            "E2E-ABSA >>> 2024-06-13 20:42:47\n",
            "loss: 0.5856, acc: 0.7515\n",
            "E2E-ABSA >>> 2024-06-13 20:43:18\n",
            ">>> val_acc: 0.7712, val_precision: 0.7619 val_recall: 0.7712, val_f1: 0.7509\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7712\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-13 20:43:33\n",
            "loss: 0.4102, acc: 0.8099\n",
            "E2E-ABSA >>> 2024-06-13 20:44:01\n",
            "loss: 0.4410, acc: 0.8074\n",
            "E2E-ABSA >>> 2024-06-13 20:44:25\n",
            ">>> val_acc: 0.7648, val_precision: 0.7525 val_recall: 0.7648, val_f1: 0.7268\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-13 20:44:46\n",
            "loss: 0.3024, acc: 0.8828\n",
            "E2E-ABSA >>> 2024-06-13 20:45:14\n",
            "loss: 0.3339, acc: 0.8677\n",
            "E2E-ABSA >>> 2024-06-13 20:45:31\n",
            ">>> val_acc: 0.7911, val_precision: 0.7855 val_recall: 0.7911, val_f1: 0.7864\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7911\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-13 20:46:00\n",
            "loss: 0.2522, acc: 0.8971\n",
            "E2E-ABSA >>> 2024-06-13 20:46:38\n",
            ">>> val_acc: 0.7794, val_precision: 0.7953 val_recall: 0.7794, val_f1: 0.7855\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-13 20:46:44\n",
            "loss: 0.2032, acc: 0.9313\n",
            "E2E-ABSA >>> 2024-06-13 20:47:12\n",
            "loss: 0.2271, acc: 0.9141\n",
            "E2E-ABSA >>> 2024-06-13 20:47:45\n",
            ">>> val_acc: 0.7847, val_precision: 0.7768 val_recall: 0.7847, val_f1: 0.7766\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-13 20:47:57\n",
            "loss: 0.2093, acc: 0.9233\n",
            "E2E-ABSA >>> 2024-06-13 20:48:25\n",
            "loss: 0.2239, acc: 0.9128\n",
            "E2E-ABSA >>> 2024-06-13 20:48:51\n",
            ">>> val_acc: 0.7524, val_precision: 0.7803 val_recall: 0.7524, val_f1: 0.7615\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-13 20:49:10\n",
            "loss: 0.2345, acc: 0.9026\n",
            "E2E-ABSA >>> 2024-06-13 20:49:38\n",
            "loss: 0.2306, acc: 0.9118\n",
            "E2E-ABSA >>> 2024-06-13 20:49:57\n",
            ">>> val_acc: 0.7908, val_precision: 0.7887 val_recall: 0.7908, val_f1: 0.7867\n",
            ">> saved: state_dict/bert_spc_combined_padanan_trim_val_f1_0.7908\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-13 20:50:24\n",
            "loss: 0.1367, acc: 0.9524\n",
            "E2E-ABSA >>> 2024-06-13 20:51:04\n",
            ">>> val_acc: 0.7904, val_precision: 0.7861 val_recall: 0.7904, val_f1: 0.7803\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-13 20:51:08\n",
            "loss: 0.0868, acc: 0.9766\n",
            "E2E-ABSA >>> 2024-06-13 20:51:37\n",
            "loss: 0.1403, acc: 0.9499\n",
            "E2E-ABSA >>> 2024-06-13 20:52:10\n",
            ">>> val_acc: 0.7829, val_precision: 0.7740 val_recall: 0.7829, val_f1: 0.7716\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-13 20:52:21\n",
            "loss: 0.1396, acc: 0.9406\n",
            "E2E-ABSA >>> 2024-06-13 20:52:50\n",
            "loss: 0.1983, acc: 0.9272\n",
            "E2E-ABSA >>> 2024-06-13 20:53:16\n",
            ">>> val_acc: 0.7758, val_precision: 0.7762 val_recall: 0.7758, val_f1: 0.7746\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-13 20:53:34\n",
            "loss: 0.1406, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-13 20:54:03\n",
            "loss: 0.1827, acc: 0.9364\n",
            "E2E-ABSA >>> 2024-06-13 20:54:22\n",
            ">>> val_acc: 0.7670, val_precision: 0.7559 val_recall: 0.7670, val_f1: 0.7452\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-13 20:54:47\n",
            "loss: 0.1780, acc: 0.9361\n",
            "E2E-ABSA >>> 2024-06-13 20:55:28\n",
            ">>> val_acc: 0.7787, val_precision: 0.7871 val_recall: 0.7787, val_f1: 0.7823\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-13 20:55:32\n",
            "loss: 0.0802, acc: 0.9740\n",
            "E2E-ABSA >>> 2024-06-13 20:56:00\n",
            "loss: 0.1584, acc: 0.9481\n",
            "E2E-ABSA >>> 2024-06-13 20:56:34\n",
            ">>> val_acc: 0.7591, val_precision: 0.7418 val_recall: 0.7591, val_f1: 0.7370\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-13 20:56:45\n",
            "loss: 0.1754, acc: 0.9375\n",
            "E2E-ABSA >>> 2024-06-13 20:57:13\n",
            "loss: 0.2125, acc: 0.9256\n",
            "E2E-ABSA >>> 2024-06-13 20:57:40\n",
            ">>> val_acc: 0.7883, val_precision: 0.7838 val_recall: 0.7883, val_f1: 0.7844\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 15.\n",
            "E2E-ABSA >>> 2024-06-13 20:57:58\n",
            "loss: 0.1082, acc: 0.9615\n",
            "E2E-ABSA >>> 2024-06-13 20:58:26\n",
            "loss: 0.1640, acc: 0.9445\n",
            "E2E-ABSA >>> 2024-06-13 20:58:47\n",
            ">>> val_acc: 0.7766, val_precision: 0.7647 val_recall: 0.7766, val_f1: 0.7632\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 16.\n",
            "E2E-ABSA >>> 2024-06-13 20:59:10\n",
            "loss: 0.1286, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-13 20:59:53\n",
            ">>> val_acc: 0.7524, val_precision: 0.7672 val_recall: 0.7524, val_f1: 0.7538\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 17.\n",
            "E2E-ABSA >>> 2024-06-13 20:59:55\n",
            "loss: 0.1244, acc: 0.9609\n",
            "E2E-ABSA >>> 2024-06-13 21:00:23\n",
            "loss: 0.1884, acc: 0.9259\n",
            "E2E-ABSA >>> 2024-06-13 21:00:59\n",
            ">>> val_acc: 0.7634, val_precision: 0.7713 val_recall: 0.7634, val_f1: 0.7668\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 18.\n",
            "E2E-ABSA >>> 2024-06-13 21:01:08\n",
            "loss: 0.1082, acc: 0.9648\n",
            "E2E-ABSA >>> 2024-06-13 21:01:36\n",
            "loss: 0.1546, acc: 0.9418\n",
            "E2E-ABSA >>> 2024-06-13 21:02:05\n",
            ">>> val_acc: 0.7652, val_precision: 0.7527 val_recall: 0.7652, val_f1: 0.7487\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 19.\n",
            "E2E-ABSA >>> 2024-06-13 21:02:21\n",
            "loss: 0.1232, acc: 0.9531\n",
            "E2E-ABSA >>> 2024-06-13 21:02:49\n",
            "loss: 0.1363, acc: 0.9499\n",
            "E2E-ABSA >>> 2024-06-13 21:03:11\n",
            ">>> val_acc: 0.7496, val_precision: 0.7480 val_recall: 0.7496, val_f1: 0.7425\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 20.\n",
            "E2E-ABSA >>> 2024-06-13 21:03:34\n",
            "loss: 0.2128, acc: 0.9125\n",
            "E2E-ABSA >>> 2024-06-13 21:04:17\n",
            ">>> val_acc: 0.7467, val_precision: 0.7524 val_recall: 0.7467, val_f1: 0.7493\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 21.\n",
            "E2E-ABSA >>> 2024-06-13 21:04:18\n",
            "loss: 0.0988, acc: 0.9688\n",
            "E2E-ABSA >>> 2024-06-13 21:04:47\n",
            "loss: 0.1537, acc: 0.9447\n",
            "E2E-ABSA >>> 2024-06-13 21:05:23\n",
            ">>> val_acc: 0.7449, val_precision: 0.7513 val_recall: 0.7449, val_f1: 0.7367\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 22.\n",
            "E2E-ABSA >>> 2024-06-13 21:05:31\n",
            "loss: 0.1108, acc: 0.9554\n",
            "E2E-ABSA >>> 2024-06-13 21:05:59\n",
            "loss: 0.1542, acc: 0.9448\n",
            "E2E-ABSA >>> 2024-06-13 21:06:29\n",
            ">>> val_acc: 0.7702, val_precision: 0.7631 val_recall: 0.7702, val_f1: 0.7659\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 23.\n",
            "E2E-ABSA >>> 2024-06-13 21:06:44\n",
            "loss: 0.1029, acc: 0.9663\n",
            "E2E-ABSA >>> 2024-06-13 21:07:12\n",
            "loss: 0.1447, acc: 0.9502\n",
            "E2E-ABSA >>> 2024-06-13 21:07:35\n",
            ">>> val_acc: 0.7421, val_precision: 0.7612 val_recall: 0.7421, val_f1: 0.7425\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 24.\n",
            "E2E-ABSA >>> 2024-06-13 21:07:57\n",
            "loss: 0.1397, acc: 0.9482\n",
            "E2E-ABSA >>> 2024-06-13 21:08:25\n",
            "loss: 0.1687, acc: 0.9357\n",
            "E2E-ABSA >>> 2024-06-13 21:08:41\n",
            ">>> val_acc: 0.7101, val_precision: 0.7644 val_recall: 0.7101, val_f1: 0.7191\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 25.\n",
            "E2E-ABSA >>> 2024-06-13 21:09:10\n",
            "loss: 0.1123, acc: 0.9594\n",
            "E2E-ABSA >>> 2024-06-13 21:09:47\n",
            ">>> val_acc: 0.7513, val_precision: 0.7392 val_recall: 0.7513, val_f1: 0.7387\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 26.\n",
            "E2E-ABSA >>> 2024-06-13 21:09:54\n",
            "loss: 0.1886, acc: 0.9349\n",
            "E2E-ABSA >>> 2024-06-13 21:10:22\n",
            "loss: 0.1574, acc: 0.9430\n",
            "E2E-ABSA >>> 2024-06-13 21:10:53\n",
            ">>> val_acc: 0.7588, val_precision: 0.7446 val_recall: 0.7588, val_f1: 0.7477\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 27.\n",
            "E2E-ABSA >>> 2024-06-13 21:11:07\n",
            "loss: 0.0759, acc: 0.9714\n",
            "E2E-ABSA >>> 2024-06-13 21:11:35\n",
            "loss: 0.1219, acc: 0.9527\n",
            "E2E-ABSA >>> 2024-06-13 21:11:59\n",
            ">>> val_acc: 0.7201, val_precision: 0.7460 val_recall: 0.7201, val_f1: 0.7179\n",
            "E2E-ABSA >>> 2024-06-13 21:11:59\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7908, val_precision: 0.7887 val_recall: 0.7908, val_f1: 0.7867\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_trim_val_f1_0.7908\n",
            ">>> test_acc: 0.7737, test_precision: 0.7698, test_recall: 0.7737, test_f1: 0.7650\n"
          ]
        }
      ],
      "source": [
        "# 13-6 experiment 2\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_trim --pretrained_bert_name indobenchmark/indobert-large-p2\t--valset_ratio 0.5 --log_step 100 --bert_dim 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hLoIkR7qDtfx",
      "metadata": {
        "editable": true,
        "id": "hLoIkR7qDtfx",
        "tags": []
      },
      "source": [
        "### indobenchmark/indobert-large-p2 s6 insert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "62a6db7b-0829-418a-b6e7-f9ab3b830105",
        "scrolled": true,
        "tags": [],
        "collapsed": true,
        "id": "yDrP2fd3KY0A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 使用设备:cuda 训练.\n",
            "加载Bert...\n",
            "/home/riset/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Bert加载完毕.\n",
            "> training dataset count: 5630.\n",
            "> testing dataset count: 2360.\n",
            "cuda memory allocated: 1341399552\n",
            "> n_trainable_params: 335144963, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: combined_padanan_select\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fbad3b33760>\n",
            ">>> lr: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 100\n",
            ">>> batch_size: 16\n",
            ">>> log_step: 100\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 1024\n",
            ">>> pretrained_bert_name: indobenchmark/indobert-large-p2\n",
            ">>> max_seq_len: 125\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> patience: 10\n",
            ">>> device: cuda\n",
            ">>> seed: 1234\n",
            ">>> valset_ratio: 0.5\n",
            ">>> local_context_focus: cdm\n",
            ">>> SRD: 3\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/train.tsv', 'test': './datasets/ulasan_combined/l_insert_padanan_selected_knowledge/dev.tsv'}\n",
            ">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 0.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "E2E-ABSA >>> 2024-06-11 01:13:45\n",
            "loss: 0.8539, acc: 0.6550\n",
            "E2E-ABSA >>> 2024-06-11 01:14:48\n",
            ">>> val_acc: 0.7105, val_precision: 0.7031 val_recall: 0.7105, val_f1: 0.7041\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7105\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 1.\n",
            "E2E-ABSA >>> 2024-06-11 01:15:01\n",
            "loss: 0.5931, acc: 0.7656\n",
            "E2E-ABSA >>> 2024-06-11 01:15:49\n",
            "loss: 0.5899, acc: 0.7545\n",
            "E2E-ABSA >>> 2024-06-11 01:16:41\n",
            ">>> val_acc: 0.7403, val_precision: 0.7257 val_recall: 0.7403, val_f1: 0.7190\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7403\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 2.\n",
            "E2E-ABSA >>> 2024-06-11 01:17:05\n",
            "loss: 0.4775, acc: 0.7956\n",
            "E2E-ABSA >>> 2024-06-11 01:17:53\n",
            "loss: 0.4973, acc: 0.7918\n",
            "E2E-ABSA >>> 2024-06-11 01:18:33\n",
            ">>> val_acc: 0.7609, val_precision: 0.7448 val_recall: 0.7609, val_f1: 0.7342\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7609\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 3.\n",
            "E2E-ABSA >>> 2024-06-11 01:19:08\n",
            "loss: 0.4009, acc: 0.8385\n",
            "E2E-ABSA >>> 2024-06-11 01:19:56\n",
            "loss: 0.4093, acc: 0.8321\n",
            "E2E-ABSA >>> 2024-06-11 01:20:25\n",
            ">>> val_acc: 0.7666, val_precision: 0.7664 val_recall: 0.7666, val_f1: 0.7651\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7666\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 4.\n",
            "E2E-ABSA >>> 2024-06-11 01:21:12\n",
            "loss: 0.3068, acc: 0.8750\n",
            "E2E-ABSA >>> 2024-06-11 01:22:17\n",
            ">>> val_acc: 0.7648, val_precision: 0.7775 val_recall: 0.7648, val_f1: 0.7699\n",
            ">> saved: state_dict/bert_spc_combined_padanan_select_val_f1_0.7648\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 5.\n",
            "E2E-ABSA >>> 2024-06-11 01:22:28\n",
            "loss: 0.2741, acc: 0.8812\n",
            "E2E-ABSA >>> 2024-06-11 01:23:16\n",
            "loss: 0.4759, acc: 0.7865\n",
            "E2E-ABSA >>> 2024-06-11 01:24:10\n",
            ">>> val_acc: 0.7737, val_precision: 0.7572 val_recall: 0.7737, val_f1: 0.7590\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 6.\n",
            "E2E-ABSA >>> 2024-06-11 01:24:31\n",
            "loss: 0.3044, acc: 0.8821\n",
            "E2E-ABSA >>> 2024-06-11 01:25:19\n",
            "loss: 0.3094, acc: 0.8672\n",
            "E2E-ABSA >>> 2024-06-11 01:26:01\n",
            ">>> val_acc: 0.7574, val_precision: 0.7684 val_recall: 0.7574, val_f1: 0.7597\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 7.\n",
            "E2E-ABSA >>> 2024-06-11 01:26:34\n",
            "loss: 0.2322, acc: 0.9072\n",
            "E2E-ABSA >>> 2024-06-11 01:27:22\n",
            "loss: 0.2543, acc: 0.9003\n",
            "E2E-ABSA >>> 2024-06-11 01:27:52\n",
            ">>> val_acc: 0.7634, val_precision: 0.7540 val_recall: 0.7634, val_f1: 0.7567\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 8.\n",
            "E2E-ABSA >>> 2024-06-11 01:28:36\n",
            "loss: 0.2460, acc: 0.8974\n",
            "E2E-ABSA >>> 2024-06-11 01:29:43\n",
            ">>> val_acc: 0.7641, val_precision: 0.7478 val_recall: 0.7641, val_f1: 0.7424\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 9.\n",
            "E2E-ABSA >>> 2024-06-11 01:29:51\n",
            "loss: 0.2018, acc: 0.9180\n",
            "E2E-ABSA >>> 2024-06-11 01:30:39\n",
            "loss: 0.2208, acc: 0.9154\n",
            "E2E-ABSA >>> 2024-06-11 01:31:35\n",
            ">>> val_acc: 0.7730, val_precision: 0.7604 val_recall: 0.7730, val_f1: 0.7634\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 10.\n",
            "E2E-ABSA >>> 2024-06-11 01:31:54\n",
            "loss: 0.1559, acc: 0.9437\n",
            "E2E-ABSA >>> 2024-06-11 01:32:42\n",
            "loss: 0.2341, acc: 0.9054\n",
            "E2E-ABSA >>> 2024-06-11 01:33:26\n",
            ">>> val_acc: 0.7609, val_precision: 0.7441 val_recall: 0.7609, val_f1: 0.7396\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 11.\n",
            "E2E-ABSA >>> 2024-06-11 01:33:57\n",
            "loss: 0.2386, acc: 0.8936\n",
            "E2E-ABSA >>> 2024-06-11 01:34:45\n",
            "loss: 0.4965, acc: 0.7873\n",
            "E2E-ABSA >>> 2024-06-11 01:35:17\n",
            ">>> val_acc: 0.7552, val_precision: 0.7538 val_recall: 0.7552, val_f1: 0.7535\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 12.\n",
            "E2E-ABSA >>> 2024-06-11 01:36:00\n",
            "loss: 0.2738, acc: 0.8878\n",
            "E2E-ABSA >>> 2024-06-11 01:37:09\n",
            ">>> val_acc: 0.7599, val_precision: 0.7501 val_recall: 0.7599, val_f1: 0.7537\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 13.\n",
            "E2E-ABSA >>> 2024-06-11 01:37:15\n",
            "loss: 0.1383, acc: 0.9479\n",
            "E2E-ABSA >>> 2024-06-11 01:38:03\n",
            "loss: 0.2002, acc: 0.9163\n",
            "E2E-ABSA >>> 2024-06-11 01:39:00\n",
            ">>> val_acc: 0.7446, val_precision: 0.7420 val_recall: 0.7446, val_f1: 0.7358\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> epoch: 14.\n",
            "E2E-ABSA >>> 2024-06-11 01:39:17\n",
            "loss: 0.1993, acc: 0.9115\n",
            "E2E-ABSA >>> 2024-06-11 01:40:51\n",
            ">>> val_acc: 0.7552, val_precision: 0.7600 val_recall: 0.7552, val_f1: 0.7573\n",
            "E2E-ABSA >>> 2024-06-11 01:40:51\n",
            ">>> early stop.\n",
            "BEST PERFORMANCE(模型最佳表现): >>> val_acc: 0.7648, val_precision: 0.7775 val_recall: 0.7648, val_f1: 0.7699\n",
            "you can download the best model from state_dict/bert_spc_combined_padanan_select_val_f1_0.7648\n",
            ">>> test_acc: 0.7500, test_precision: 0.7600, test_recall: 0.7500, test_f1: 0.7542\n"
          ]
        }
      ],
      "source": [
        "# 10-6 experiment 1\n",
        "!cd ta-dictabsa && python3 train_insert.py --model_name bert_spc --dataset combined_padanan_select --pretrained_bert_name indobenchmark/indobert-large-p2 --valset_ratio 0.5 --log_step 100 --bert_dim 1024 --patience 10"
      ],
      "id": "yDrP2fd3KY0A"
    },
    {
      "cell_type": "markdown",
      "id": "a1ywJ3X2_HB4",
      "metadata": {
        "id": "a1ywJ3X2_HB4"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l1hzMQbv_H7R",
      "metadata": {
        "id": "l1hzMQbv_H7R"
      },
      "outputs": [],
      "source": [
        "# parameter for inference\n",
        "\n",
        "def infer_param(state_dict, pretrained_bert_name):\n",
        "\n",
        "  if pretrained_bert_name == 'indobenchmark/indobert-large-p2': bert_dim = 1024\n",
        "  else: bert_dim = 768\n",
        "\n",
        "  path = 'ta-dictabsa/infer_example.py'\n",
        "  with open(path, 'r') as file:\n",
        "      lines = file.readlines()\n",
        "  lines[241] = f\"    opt.state_dict_path = \\'{state_dict}\\'\\n\"\n",
        "  lines[245] = f\"    opt.bert_dim = {bert_dim}\\n\"\n",
        "  lines[246] = f\"    opt.pretrained_bert_name = \\'{pretrained_bert_name}\\'\\n\"\n",
        "  with open(path, 'w') as file:\n",
        "      file.writelines(lines)\n",
        "\n",
        "# # usage\n",
        "# state_dict = 'state_dict/bert_spc_combined_padanan_trim_val_f1_0.8080'\n",
        "# pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "# infer_param(state_dict, pretrained_bert_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32bf8ab3-1013-42bd-813c-67a96d0ee4b0",
      "metadata": {
        "id": "32bf8ab3-1013-42bd-813c-67a96d0ee4b0"
      },
      "source": [
        "## s0 state_dict/bert_spc_combined_ori_val_f1_0.784"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1086893e-7db6-4f47-ab50-65cc10333e28"
      },
      "outputs": [],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_ori_val_f1_0.784'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)"
      ],
      "id": "1086893e-7db6-4f47-ab50-65cc10333e28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc3c319d-6779-4f11-a7cc-c9ea8549650b",
        "outputId": "ee387be1-2e25-48f7-be3a-531e6127f4fc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 42.0/42.0 [00:00<00:00, 248kB/s]\n",
            "vocab.txt: 100% 234k/234k [00:00<00:00, 1.03MB/s]\n",
            "added_tokens.json: 100% 2.00/2.00 [00:00<00:00, 15.4kB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 902kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.01k/1.01k [00:00<00:00, 5.00MB/s]\n",
            "pytorch_model.bin: 100% 445M/445M [00:01<00:00, 281MB/s]\n",
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0            [[0.0012954057, 0.0030486134, 0.995656]]\n",
            "1            [[0.0015508606, 0.010761738, 0.9876874]]\n",
            "2               [[0.25351822, 0.36262363, 0.3838581]]\n",
            "3             [[0.071127474, 0.8963074, 0.032565184]]\n",
            "4           [[0.0017402305, 0.9970329, 0.0012268234]]\n",
            "5           [[0.003515265, 0.0038094248, 0.99267524]]\n",
            "6         [[0.0011619137, 4.8721686e-05, 0.99878937]]\n",
            "7             [[0.02587607, 0.004213527, 0.96991044]]\n",
            "8           [[0.002263227, 3.840766e-05, 0.99769837]]\n",
            "9          [[0.0017855595, 5.6718716e-05, 0.9981577]]\n",
            "10         [[0.001383671, 4.4482404e-05, 0.99857175]]\n",
            "11        [[0.00042099872, 1.1033434e-05, 0.9995679]]\n",
            "12        [[0.00041747573, 6.562321e-05, 0.99951684]]\n",
            "13        [[0.0005993204, 2.1555263e-05, 0.99937904]]\n",
            "14        [[0.0033555091, 0.00060401467, 0.99604046]]\n",
            "15           [[0.21216375, 0.0070407656, 0.78079545]]\n",
            "16         [[0.0007757109, 6.2056664e-05, 0.9991622]]\n",
            "17          [[0.0010571493, 0.0021971096, 0.9967457]]\n",
            "18           [[0.00080996286, 0.00055042, 0.9986395]]\n",
            "19            [[0.005219964, 0.004205879, 0.9905742]]\n",
            "20         [[0.00040862063, 0.0006160924, 0.9989754]]\n",
            "21        [[0.0058311974, 0.00019706917, 0.99397177]]\n",
            "22          [[0.002669631, 4.4144123e-05, 0.9972863]]\n",
            "23         [[0.0014915545, 1.7850121e-05, 0.9984906]]\n",
            "24           [[0.0014661934, 0.009001399, 0.9895325]]\n",
            "25         [[0.00018726887, 0.0016327832, 0.9981799]]\n",
            "26           [[0.001479953, 0.030570135, 0.96794987]]\n",
            "27           [[0.0033510115, 0.064259306, 0.9323896]]\n",
            "28            [[0.0016013517, 0.7482522, 0.25014642]]\n",
            "29       [[0.00035141813, 1.4465871e-05, 0.99963415]]\n",
            "30       [[0.00035141813, 1.4465871e-05, 0.99963415]]\n",
            "31         [[0.00053963397, 5.798313e-05, 0.9994024]]\n",
            "32              [[0.1978756, 0.14236838, 0.65975606]]\n",
            "33            [[0.007900625, 0.036522962, 0.9555764]]\n",
            "34           [[0.00074835407, 0.8982447, 0.10100695]]\n",
            "35         [[0.0008064239, 1.7220764e-05, 0.9991763]]\n",
            "36          [[0.0009144616, 5.618698e-05, 0.9990293]]\n",
            "37              [[0.15482716, 0.05948698, 0.7856859]]\n",
            "38            [[0.0056182942, 0.9572019, 0.03717982]]\n",
            "39         [[0.0008605642, 0.99133307, 0.0078063263]]\n",
            "40              [[0.116155855, 0.7555275, 0.1283167]]\n",
            "41          [[0.0009750741, 7.949246e-05, 0.9989454]]\n",
            "42         [[0.0010347796, 0.00038674928, 0.9985784]]\n",
            "43           [[0.00065280177, 1.82464e-05, 0.999329]]\n",
            "44         [[0.0010347796, 0.00038674928, 0.9985784]]\n",
            "45           [[0.0021693497, 0.46398616, 0.53384453]]\n",
            "46        [[0.00028310463, 9.700102e-06, 0.99970716]]\n",
            "47         [[8.673398e-05, 0.00022976223, 0.9996835]]\n",
            "48         [[0.0010278164, 2.4514884e-05, 0.9989477]]\n",
            "49          [[0.0014186191, 0.00020526059, 0.998376]]\n",
            "50        [[0.0014916388, 0.00037167026, 0.99813664]]\n",
            "51             [[0.8425835, 0.0032413865, 0.1541751]]\n",
            "52           [[0.0069387658, 0.022314362, 0.9707469]]\n",
            "53       [[0.00064902124, 3.8972572e-05, 0.99931204]]\n",
            "54         [[0.0010599282, 0.00068042445, 0.9982596]]\n",
            "55         [[0.00030328883, 9.22259e-06, 0.99968755]]\n",
            "56        [[0.00023423157, 0.00015453719, 0.9996112]]\n",
            "57         [[0.0028508492, 3.5906207e-05, 0.9971132]]\n",
            "58         [[0.0028508492, 3.5906207e-05, 0.9971132]]\n",
            "59       [[0.0009441749, 1.15426055e-05, 0.99904424]]\n",
            "60           [[0.9708693, 0.025412686, 0.0037180309]]\n",
            "61             [[0.0047341404, 0.06124792, 0.934018]]\n",
            "62       [[0.00043489883, 2.3337929e-05, 0.99954176]]\n",
            "63            [[0.123343796, 0.8256294, 0.051026735]]\n",
            "64               [[0.03157676, 0.933946, 0.03447723]]\n",
            "65       [[0.00043489883, 2.3337929e-05, 0.99954176]]\n",
            "66          [[0.00062077196, 0.000228095, 0.9991511]]\n",
            "67             [[0.017334638, 0.6389113, 0.34375402]]\n",
            "68        [[0.00060359674, 1.9311698e-05, 0.9993772]]\n",
            "69       [[0.00040521822, 0.00046052047, 0.99913436]]\n",
            "70         [[0.0021883606, 0.0007468742, 0.99706477]]\n",
            "71            [[0.003604749, 0.041898713, 0.9544965]]\n",
            "72             [[0.008148159, 0.08958466, 0.9022671]]\n",
            "73       [[0.00015493302, 4.8559974e-05, 0.99979657]]\n",
            "74          [[0.00052875606, 0.79683214, 0.20263912]]\n",
            "75          [[0.0021584313, 0.122307666, 0.87553394]]\n",
            "76       [[0.00015493302, 4.8559974e-05, 0.99979657]]\n",
            "77             [[0.59903103, 0.3947511, 0.006217803]]\n",
            "78            [[0.0013835903, 0.9186262, 0.07999019]]\n",
            "79              [[0.13769215, 0.045352936, 0.816955]]\n",
            "80             [[0.047968734, 0.07503669, 0.8769946]]\n",
            "81           [[0.011772965, 0.011322176, 0.97690475]]\n",
            "82         [[0.0006124557, 0.0028128587, 0.99657476]]\n",
            "83           [[0.011772965, 0.011322176, 0.97690475]]\n",
            "84            [[0.006340126, 0.11342921, 0.88023067]]\n",
            "85          [[0.0014294427, 0.018941907, 0.97962874]]\n",
            "86         [[0.0014585867, 0.0011449539, 0.99739647]]\n",
            "87         [[0.00021141797, 0.0001840731, 0.9996045]]\n",
            "88           [[0.0039883726, 0.13840239, 0.85760915]]\n",
            "89        [[0.00094337785, 8.715052e-05, 0.99896944]]\n",
            "90        [[0.0014128523, 2.1284568e-05, 0.99856585]]\n",
            "91              [[0.05048168, 0.7641179, 0.18540037]]\n",
            "92        [[0.00071068725, 4.303003e-05, 0.99924636]]\n",
            "93           [[0.0008770758, 0.007430582, 0.9916924]]\n",
            "94         [[0.0003484572, 0.00042481816, 0.9992268]]\n",
            "95             [[0.011360372, 0.08310124, 0.9055383]]\n",
            "96             [[0.06644536, 0.013906338, 0.9196483]]\n",
            "97               [[0.10258892, 0.8919147, 0.0054963]]\n",
            "98           [[0.97468704, 0.014136538, 0.011176424]]\n",
            "99         [[0.99050635, 0.00032675656, 0.009166943]]\n",
            "100        [[0.0008841981, 0.99054354, 0.0085722385]]\n",
            "101              [[0.02221265, 0.782331, 0.19545633]]\n",
            "102      [[0.00016444532, 0.00038834976, 0.99944717]]\n",
            "103         [[0.00055224396, 9.88324e-05, 0.9993488]]\n",
            "104         [[0.0020312062, 0.97728115, 0.020687608]]\n",
            "105            [[0.17897521, 0.74015903, 0.08086576]]\n",
            "106        [[0.0020763604, 0.0005841235, 0.99733955]]\n",
            "107           [[0.008115005, 0.02191509, 0.96996987]]\n",
            "108          [[0.0023615374, 0.004691612, 0.9929468]]\n",
            "109         [[0.0020572054, 0.0052580843, 0.9926847]]\n",
            "110        [[0.0006143955, 8.722271e-05, 0.99929833]]\n",
            "111       [[0.0004175302, 7.9222315e-05, 0.99950325]]\n",
            "112        [[0.0004966953, 0.00017491188, 0.9993285]]\n",
            "113         [[0.0005107094, 0.0010719439, 0.9984174]]\n",
            "114        [[0.00062373315, 0.006445866, 0.99293035]]\n",
            "115        [[0.0006910417, 1.359641e-05, 0.99929535]]\n",
            "116           [[0.006364876, 0.84221095, 0.15142415]]\n",
            "117             [[0.13617599, 0.7289777, 0.13484631]]\n",
            "118            [[0.20274873, 0.05654014, 0.74071115]]\n",
            "119        [[0.0012939754, 3.4791137e-05, 0.9986713]]\n",
            "120            [[0.7533677, 0.22812527, 0.018507013]]\n",
            "121         [[0.001443705, 0.0011321062, 0.99742424]]\n",
            "122       [[0.00046627584, 0.0004285624, 0.99910516]]\n",
            "123            [[0.2517915, 0.038663056, 0.70954543]]\n",
            "124       [[0.0014932845, 3.9466664e-05, 0.99846715]]\n",
            "125           [[0.005456411, 0.010351229, 0.9841924]]\n",
            "126           [[0.012958709, 0.49942032, 0.48762098]]\n",
            "127          [[0.002502677, 0.009344302, 0.98815304]]\n",
            "128          [[0.012705134, 0.000980259, 0.98631465]]\n",
            "129          [[0.002502677, 0.009344302, 0.98815304]]\n",
            "130       [[0.00084719347, 4.9611353e-05, 0.9991032]]\n",
            "131           [[0.0028906323, 0.17968598, 0.8174234]]\n",
            "132           [[0.0022896156, 0.14221969, 0.8554907]]\n",
            "133       [[0.00025964002, 0.00054054434, 0.9991998]]\n",
            "134           [[0.0032266416, 0.10023011, 0.8965433]]\n",
            "135      [[0.00025385362, 2.7904613e-05, 0.99971825]]\n",
            "136        [[0.00037695986, 8.285061e-06, 0.9996147]]\n",
            "137       [[0.0005076096, 1.6942222e-05, 0.99947554]]\n",
            "138        [[0.00037897547, 9.815075e-06, 0.9996113]]\n",
            "139        [[0.00045568723, 0.0015372318, 0.9980071]]\n",
            "140         [[0.0002965528, 7.905259e-05, 0.9996244]]\n",
            "141         [[0.0004577404, 0.0129633695, 0.9865789]]\n",
            "142        [[0.00018574738, 0.0006354556, 0.9991788]]\n",
            "143          [[0.0006333798, 0.9472106, 0.052155998]]\n",
            "144          [[0.0015424092, 0.0027015293, 0.995756]]\n",
            "145          [[0.0015424092, 0.0027015293, 0.995756]]\n",
            "146      [[0.00078972493, 2.1969085e-05, 0.99918836]]\n",
            "147       [[0.0007661242, 3.3766202e-05, 0.99920017]]\n",
            "148       [[0.00048913906, 3.0065456e-05, 0.9994809]]\n",
            "149         [[0.00043957945, 0.00042035888, 0.99914]]\n",
            "150           [[0.0042681373, 0.6421921, 0.35353974]]\n",
            "151          [[0.002056548, 0.90944904, 0.088494375]]\n",
            "152          [[0.0012546141, 0.9507377, 0.048007634]]\n",
            "153           [[0.001293155, 0.9659682, 0.032738663]]\n",
            "154          [[0.0017804118, 0.9836617, 0.014557839]]\n",
            "155          [[0.000846196, 0.016150067, 0.98300374]]\n",
            "156         [[0.0005579904, 0.0068396437, 0.9926023]]\n",
            "157       [[0.00016021576, 0.0013590924, 0.99848074]]\n",
            "158           [[0.0017328208, 0.7956705, 0.20259668]]\n",
            "159        [[0.0006910029, 0.0057811043, 0.99352795]]\n",
            "160             [[0.01097995, 0.021855947, 0.967164]]\n",
            "161           [[0.023989864, 0.04879472, 0.92721534]]\n",
            "162          [[0.014311604, 0.94234496, 0.043343402]]\n",
            "163          [[0.0012202293, 0.06518983, 0.93358994]]\n",
            "164           [[0.9070658, 0.033139084, 0.059795078]]\n",
            "165        [[0.0005592749, 0.000119731994, 0.999321]]\n",
            "166       [[0.00071469846, 3.6383077e-05, 0.9992489]]\n",
            "167       [[0.0019537667, 9.0731686e-05, 0.99795544]]\n",
            "168       [[0.0004969101, 0.00018664614, 0.99931645]]\n",
            "169       [[0.0008517741, 5.3407202e-05, 0.99909484]]\n",
            "170        [[0.0016396322, 0.0019959316, 0.99636453]]\n",
            "171            [[0.5000004, 0.013348128, 0.48665148]]\n",
            "172            [[0.69952005, 0.15917836, 0.14130156]]\n",
            "173            [[0.0053106747, 0.8707937, 0.1238956]]\n",
            "174            [[0.024581937, 0.25929797, 0.7161201]]\n",
            "175        [[0.00058598514, 0.0016794847, 0.9977344]]\n",
            "176          [[0.000850955, 8.695553e-05, 0.9990621]]\n",
            "177          [[0.008400662, 0.0009099694, 0.9906894]]\n",
            "178        [[0.0015864244, 0.00046079385, 0.9979528]]\n",
            "179         [[0.0020861828, 0.0012221579, 0.9966917]]\n",
            "180          [[0.0037297555, 0.022394083, 0.9738762]]\n",
            "181        [[0.0015045542, 3.1203494e-05, 0.9984642]]\n",
            "182        [[0.0003257774, 1.8714165e-05, 0.9996555]]\n",
            "183              [[0.07487058, 0.678239, 0.24689046]]\n",
            "184        [[0.0016146546, 0.0021529936, 0.99623233]]\n",
            "185               [[0.0339436, 0.91663235, 0.049424]]\n",
            "186       [[0.0012600898, 0.00014985079, 0.99859005]]\n",
            "187          [[0.011384672, 0.059246413, 0.92936885]]\n",
            "188       [[0.00065492763, 2.0669435e-05, 0.9993243]]\n",
            "189        [[0.0061521544, 0.0024590015, 0.99138886]]\n",
            "190           [[0.19746974, 0.038219444, 0.76431084]]\n",
            "191         [[0.00042141014, 0.002971769, 0.9966068]]\n",
            "192         [[0.00040840608, 0.9788109, 0.020780731]]\n",
            "193         [[0.00063643913, 0.49638012, 0.50298345]]\n",
            "194          [[0.003461655, 0.002849663, 0.99368864]]\n",
            "195      [[0.00059660897, 0.00023460196, 0.99916875]]\n",
            "196         [[0.0003520292, 0.0004648851, 0.9991831]]\n",
            "197         [[0.0004978011, 6.233481e-05, 0.9994399]]\n",
            "198             [[0.05032462, 0.5837467, 0.36592868]]\n",
            "199        [[0.00096643606, 0.9961945, 0.0028390388]]\n",
            "200       [[0.0004133572, 2.3507502e-05, 0.99956316]]\n",
            "201          [[0.017572455, 0.017252734, 0.96517485]]\n",
            "202            [[0.00061137, 0.0006726899, 0.998716]]\n",
            "203          [[0.018665178, 0.95198673, 0.029348152]]\n",
            "204        [[0.00037105032, 0.0006794213, 0.9989496]]\n",
            "205       [[0.00011461305, 0.00044803252, 0.9994374]]\n",
            "206      [[0.00021774252, 0.00084480946, 0.99893755]]\n",
            "207         [[0.0004096327, 0.0012346113, 0.9983557]]\n",
            "208           [[0.40365952, 0.55749893, 0.038841516]]\n",
            "209       [[0.0008497867, 1.5390795e-05, 0.99913484]]\n",
            "210        [[0.99426645, 0.0011909558, 0.0045426637]]\n",
            "211              [[0.06763872, 0.923456, 0.00890524]]\n",
            "212            [[0.008458158, 0.988617, 0.002924893]]\n",
            "213         [[0.0008336572, 0.000794784, 0.99837154]]\n",
            "214        [[0.006547101, 0.00011827872, 0.99333453]]\n",
            "215        [[0.0007209281, 0.0002243964, 0.99905473]]\n",
            "216           [[0.053340435, 0.17107394, 0.77558565]]\n",
            "217       [[0.0011044213, 2.1908301e-05, 0.99887365]]\n",
            "218             [[0.019543184, 0.3237571, 0.6566997]]\n",
            "219      [[0.00041897493, 2.3418965e-05, 0.99955755]]\n",
            "220             [[0.012780446, 0.532079, 0.45514062]]\n",
            "221       [[0.0010223923, 6.9497414e-06, 0.99897075]]\n",
            "222         [[0.0016083103, 9.551485e-06, 0.9983822]]\n",
            "223              [[0.08061618, 0.748109, 0.17127486]]\n",
            "224             [[0.11975573, 0.67074054, 0.2095037]]\n",
            "225             [[0.003534126, 0.2810264, 0.7154395]]\n",
            "226           [[0.0034944615, 0.7876235, 0.20888202]]\n",
            "227            [[0.007746009, 0.49500754, 0.4972465]]\n",
            "228              [[0.00640764, 0.31958038, 0.674012]]\n",
            "229        [[0.0016029958, 8.574684e-05, 0.99831116]]\n",
            "230           [[0.0027841055, 0.7807532, 0.21646275]]\n",
            "231        [[0.0011428776, 0.00053682603, 0.9983203]]\n",
            "232          [[0.023847388, 0.94427377, 0.031878836]]\n",
            "233          [[0.023847388, 0.94427377, 0.031878836]]\n",
            "234          [[0.023847388, 0.94427377, 0.031878836]]\n",
            "235          [[0.023847388, 0.94427377, 0.031878836]]\n",
            "236         [[0.0022146637, 0.004868475, 0.99291694]]\n",
            "237           [[0.0047566094, 0.8973785, 0.09786488]]\n",
            "238          [[0.007889099, 0.011564332, 0.98054653]]\n",
            "239         [[0.0049231807, 0.0023782894, 0.9926986]]\n",
            "240           [[0.011270799, 0.18220699, 0.80652225]]\n",
            "241          [[0.00058004755, 1.9947323e-05, 0.9994]]\n",
            "242        [[0.0011501595, 9.6492615e-05, 0.9987534]]\n",
            "243          [[0.0031548277, 0.012878007, 0.9839671]]\n",
            "244      [[0.00081059657, 4.9641847e-05, 0.99913967]]\n",
            "245             [[0.48992532, 0.2645293, 0.24554543]]\n",
            "246       [[0.0010957544, 2.6918024e-05, 0.99887735]]\n",
            "247            [[0.002693192, 8.2657e-05, 0.9972242]]\n",
            "248         [[0.0024052432, 0.0008420859, 0.9967527]]\n",
            "249        [[0.0009123714, 0.00015980106, 0.9989278]]\n",
            "250       [[0.00021131648, 3.4918285e-05, 0.9997538]]\n",
            "251            [[0.0030907781, 0.2072938, 0.7896155]]\n",
            "252             [[0.010536179, 0.4403094, 0.5491544]]\n",
            "253           [[0.0057930187, 0.11360928, 0.8805976]]\n",
            "254           [[0.009015343, 0.010957947, 0.9800268]]\n",
            "255           [[0.023469914, 0.84137636, 0.13515379]]\n",
            "256           [[0.016581213, 0.94040626, 0.04301249]]\n",
            "257          [[0.0117184315, 0.9375899, 0.050691742]]\n",
            "258          [[0.016775608, 0.007683207, 0.97554123]]\n",
            "259        [[0.0018119513, 5.1510066e-05, 0.9981365]]\n",
            "260      [[0.00063741556, 0.00088660355, 0.99847597]]\n",
            "261           [[0.053338386, 0.24263021, 0.70403147]]\n",
            "262           [[0.016904386, 0.14233549, 0.84076005]]\n",
            "263      [[0.00063741556, 0.00088660355, 0.99847597]]\n",
            "264          [[0.0025010647, 0.02588634, 0.97161263]]\n",
            "265         [[0.0012461044, 0.0034875444, 0.9952663]]\n",
            "266          [[0.000772129, 6.622533e-05, 0.9991616]]\n",
            "267            [[0.031126795, 0.6097581, 0.35911506]]\n",
            "268            [[0.01353139, 0.13075903, 0.85570955]]\n",
            "269           [[0.008689827, 0.85600513, 0.13530503]]\n",
            "270            [[0.036512665, 0.13128614, 0.8322012]]\n",
            "271           [[0.0027143208, 0.4781946, 0.51909107]]\n",
            "272            [[0.13220018, 0.051660486, 0.8161394]]\n",
            "273           [[0.0020740784, 0.84664124, 0.1512847]]\n",
            "274       [[0.00021344938, 1.6916803e-05, 0.9997696]]\n",
            "275       [[0.00032282007, 2.6717214e-05, 0.9996505]]\n",
            "276       [[0.00034216425, 3.1405183e-05, 0.9996264]]\n",
            "277            [[0.41906536, 0.33188933, 0.24904531]]\n",
            "278          [[0.0020153015, 0.82526994, 0.17271483]]\n",
            "279        [[0.00066838827, 0.9889044, 0.0104272105]]\n",
            "280        [[0.00066838827, 0.9889044, 0.0104272105]]\n",
            "281        [[0.0003364038, 0.99901605, 0.0006474867]]\n",
            "282           [[0.004634883, 0.40456313, 0.59080195]]\n",
            "283        [[0.00064838526, 0.0072019626, 0.9921497]]\n",
            "284            [[0.05167246, 0.90457815, 0.04374938]]\n",
            "285           [[0.029816767, 0.79944694, 0.17073627]]\n",
            "286         [[0.0046776053, 0.87413514, 0.121187255]]\n",
            "287         [[0.0036391644, 0.0022017406, 0.9941591]]\n",
            "288          [[0.003212687, 0.0022006962, 0.9945866]]\n",
            "289        [[0.0007936696, 2.4111312e-05, 0.9991823]]\n",
            "290         [[0.0005348245, 0.0006457586, 0.9988194]]\n",
            "291          [[0.0011023214, 0.051456343, 0.9474414]]\n",
            "292          [[0.0002722138, 0.035718903, 0.9640088]]\n",
            "293          [[0.0002308779, 0.9898498, 0.009919282]]\n",
            "294          [[0.00048535707, 0.8372375, 0.16227718]]\n",
            "295        [[0.00045009062, 0.055343524, 0.94420636]]\n",
            "296      [[0.00019330689, 0.00012915547, 0.99967754]]\n",
            "297       [[0.00018351266, 2.742399e-05, 0.99978906]]\n",
            "298         [[0.0012189685, 6.385439e-05, 0.9987172]]\n",
            "299       [[0.00024601657, 0.00047349307, 0.9992805]]\n",
            "300           [[0.00051159953, 0.0725541, 0.9269343]]\n",
            "301          [[0.9938235, 0.001653776, 0.0045227096]]\n",
            "302          [[0.000902685, 2.562935e-05, 0.9990717]]\n",
            "303        [[0.00027939063, 1.836227e-05, 0.9997023]]\n",
            "304           [[0.024163045, 0.81659234, 0.15924464]]\n",
            "305       [[0.0003721883, 3.3675176e-05, 0.99959415]]\n",
            "306            [[0.0246724, 0.014222256, 0.96110535]]\n",
            "307              [[0.981784, 0.0160857, 0.002130305]]\n",
            "308          [[0.008029032, 0.9892195, 0.0027515346]]\n",
            "309          [[0.09078695, 0.00022253164, 0.9089905]]\n",
            "310        [[0.99559057, 0.0035767294, 0.0008327102]]\n",
            "311           [[0.9652744, 0.03264536, 0.0020802824]]\n",
            "312          [[0.01388521, 0.00018568523, 0.9859291]]\n",
            "313            [[0.40403232, 0.33598927, 0.25997835]]\n",
            "314           [[0.10267281, 0.85032606, 0.047001105]]\n",
            "315            [[0.7327654, 0.22347976, 0.043754876]]\n",
            "316            [[0.40403232, 0.33598927, 0.25997835]]\n",
            "317              [[0.6060682, 0.3730607, 0.02087111]]\n",
            "318             [[0.850895, 0.1345225, 0.0145825865]]\n",
            "319           [[0.026598444, 0.012498227, 0.9609033]]\n",
            "320          [[0.002848649, 0.0003377052, 0.9968136]]\n",
            "321           [[0.026598444, 0.012498227, 0.9609033]]\n",
            "322       [[0.00056098687, 4.9037844e-05, 0.9993899]]\n",
            "323         [[0.0035302707, 0.96339124, 0.033078447]]\n",
            "324          [[0.0017480836, 0.98955905, 0.00869279]]\n",
            "325          [[0.0017480836, 0.98955905, 0.00869279]]\n",
            "326           [[0.28920594, 0.7037507, 0.0070433146]]\n",
            "327          [[0.011416246, 0.97416264, 0.014421127]]\n",
            "328          [[0.000542077, 6.416867e-05, 0.9993937]]\n",
            "329       [[0.00058797444, 1.3228277e-05, 0.9993988]]\n",
            "330        [[0.0004368041, 2.1331824e-05, 0.9995419]]\n",
            "331        [[0.00017912597, 3.531953e-05, 0.9997856]]\n",
            "332         [[0.001123012, 3.1177275e-05, 0.9988458]]\n",
            "333        [[0.00063799124, 1.9028426e-05, 0.999343]]\n",
            "334       [[0.00090700755, 1.340715e-05, 0.99907947]]\n",
            "335        [[0.0002173686, 1.6242975e-05, 0.9997664]]\n",
            "336           [[0.009669336, 0.054042924, 0.9362877]]\n",
            "337           [[0.004977805, 0.041709967, 0.9533122]]\n",
            "338           [[0.0017196564, 0.03559845, 0.9626819]]\n",
            "339         [[0.0032446475, 0.015981426, 0.98077387]]\n",
            "340        [[0.0005475843, 5.424552e-05, 0.99939823]]\n",
            "341          [[0.0073180837, 0.003075684, 0.9896062]]\n",
            "342           [[0.004977805, 0.041709967, 0.9533122]]\n",
            "343          [[0.0033620489, 0.20129895, 0.79533905]]\n",
            "344         [[0.004123034, 0.0002309114, 0.99564606]]\n",
            "345        [[0.0008464349, 0.00082215515, 0.9983315]]\n",
            "346       [[0.00071064575, 0.00021286834, 0.9990765]]\n",
            "347         [[0.99351007, 0.0010295403, 0.005460338]]\n",
            "348           [[0.8276784, 0.0076303775, 0.16469118]]\n",
            "349             [[0.31396165, 0.02725442, 0.6587839]]\n",
            "350            [[0.45134947, 0.13538073, 0.41326982]]\n",
            "351          [[0.003265265, 0.0011097561, 0.9956251]]\n",
            "352           [[0.17163746, 0.016237356, 0.81212515]]\n",
            "353            [[0.022522891, 0.6354482, 0.34202892]]\n",
            "354           [[0.9805103, 0.001589357, 0.017900245]]\n",
            "355         [[0.0014151594, 6.727284e-05, 0.9985176]]\n",
            "356          [[0.004999898, 0.0014739757, 0.9935262]]\n",
            "357            [[0.00495031, 0.005539486, 0.9895103]]\n",
            "358            [[0.00495031, 0.005539486, 0.9895103]]\n",
            "359        [[0.0006390809, 4.1031442e-05, 0.9993199]]\n",
            "360        [[0.0006390809, 4.1031442e-05, 0.9993199]]\n",
            "361         [[0.0023403938, 0.0015839387, 0.9960757]]\n",
            "362         [[0.0020949696, 0.032175586, 0.96572936]]\n",
            "363          [[0.0015492839, 0.001800443, 0.9966503]]\n",
            "364           [[0.84815156, 0.0009784052, 0.1508701]]\n",
            "365         [[0.9877416, 0.00019880672, 0.012059601]]\n",
            "366         [[0.9904861, 7.5508164e-05, 0.009438422]]\n",
            "367          [[0.5094872, 0.00015277002, 0.49036002]]\n",
            "368         [[0.0006819574, 1.846661e-05, 0.9992995]]\n",
            "369       [[0.0007406219, 0.00011791977, 0.99914145]]\n",
            "370       [[0.0011049795, 0.00019107106, 0.99870396]]\n",
            "371        [[0.0015778806, 0.0010077341, 0.99741435]]\n",
            "372       [[0.0011049795, 0.00019107106, 0.99870396]]\n",
            "373           [[0.0017148671, 0.3269311, 0.67135406]]\n",
            "374       [[0.00016226232, 1.400614e-05, 0.99982375]]\n",
            "375          [[0.0011187057, 0.16014709, 0.83873415]]\n",
            "376        [[0.00013642343, 3.830176e-05, 0.9998253]]\n",
            "377           [[0.29708472, 0.68002933, 0.022885915]]\n",
            "378            [[0.008751712, 0.8309211, 0.16032718]]\n",
            "379            [[0.008751712, 0.8309211, 0.16032718]]\n",
            "380      [[0.00083492836, 0.00040099458, 0.99876404]]\n",
            "381      [[0.00033301883, 1.8458193e-05, 0.99964845]]\n",
            "382        [[0.00022607681, 4.532926e-05, 0.9997286]]\n",
            "383      [[0.00033301883, 1.8458193e-05, 0.99964845]]\n",
            "384         [[0.0014251295, 0.0024810932, 0.9960937]]\n",
            "385      [[0.00019890231, 3.2083823e-05, 0.99976903]]\n",
            "386         [[0.0033421395, 0.008017784, 0.98864007]]\n",
            "387           [[0.0007708902, 0.3848084, 0.61442065]]\n",
            "388          [[0.004389264, 0.98322785, 0.012382832]]\n",
            "389           [[0.011111599, 0.98418254, 0.00470582]]\n",
            "390            [[0.008751712, 0.8309211, 0.16032718]]\n",
            "391         [[0.006492973, 0.0011110402, 0.99239606]]\n",
            "392            [[0.14281513, 0.36548495, 0.49169996]]\n",
            "393          [[0.001016032, 0.0006182963, 0.9983657]]\n",
            "394             [[0.012069442, 0.4875645, 0.5003661]]\n",
            "395               [[0.0917546, 0.6491589, 0.2590865]]\n",
            "396         [[0.00050682965, 0.99731857, 0.00217456]]\n",
            "397        [[0.00075612665, 0.9964889, 0.0027549923]]\n",
            "398          [[0.008305168, 0.97533876, 0.016356016]]\n",
            "399           [[0.0030989915, 0.08677665, 0.9101245]]\n",
            "400            [[0.055135842, 0.36159828, 0.5832659]]\n",
            "401            [[0.40199384, 0.20548476, 0.39252135]]\n",
            "402        [[0.99663216, 0.0001186346, 0.0032491838]]\n",
            "403          [[0.83331156, 0.0003797871, 0.16630869]]\n",
            "404           [[0.9660772, 0.021056417, 0.012866339]]\n",
            "405        [[0.99663216, 0.0001186346, 0.0032491838]]\n",
            "406        [[0.0015646641, 8.807188e-06, 0.99842656]]\n",
            "407       [[0.0008200867, 2.5520665e-05, 0.99915445]]\n",
            "408       [[0.0008200867, 2.5520665e-05, 0.99915445]]\n",
            "409         [[0.0002365058, 0.0004536021, 0.9993099]]\n",
            "410          [[0.0022541685, 0.021596253, 0.9761496]]\n",
            "411          [[0.0014478596, 0.9465889, 0.051963296]]\n",
            "412            [[0.006137362, 0.7886762, 0.20518643]]\n",
            "413             [[0.17033213, 0.6955092, 0.13415869]]\n",
            "414          [[0.00092346885, 9.646573e-05, 0.99898]]\n",
            "415         [[0.0047137425, 0.95014405, 0.045142267]]\n",
            "416          [[0.000536405, 0.98734295, 0.012120574]]\n",
            "417        [[0.0005420254, 0.0003242631, 0.99913377]]\n",
            "418         [[0.0021663639, 0.0034544375, 0.9943791]]\n",
            "419          [[0.0054150918, 0.019291848, 0.9752931]]\n",
            "420             [[0.866154, 0.08510613, 0.048739843]]\n",
            "421            [[0.18408975, 0.75922495, 0.05668532]]\n",
            "422          [[0.006163354, 0.0038960841, 0.9899406]]\n",
            "423         [[0.00058368954, 0.001521669, 0.9978946]]\n",
            "424          [[0.0035326288, 0.050584584, 0.9458828]]\n",
            "425            [[0.004797177, 0.6687574, 0.32644543]]\n",
            "426          [[0.0051010055, 0.83441395, 0.16048506]]\n",
            "427          [[0.0005594402, 0.98131233, 0.01812825]]\n",
            "428        [[0.00050005864, 0.98241204, 0.017087894]]\n",
            "429         [[0.00053998816, 0.9822729, 0.017187018]]\n",
            "430         [[0.028174525, 0.0045196107, 0.96730584]]\n",
            "431          [[0.0003051089, 0.96693265, 0.03276221]]\n",
            "432      [[0.00095419394, 2.6060437e-05, 0.99901974]]\n",
            "433       [[0.0009665914, 0.00013084561, 0.99890256]]\n",
            "434        [[0.0012508185, 7.7764875e-05, 0.9986714]]\n",
            "435       [[0.00036789262, 0.00013578155, 0.9994962]]\n",
            "436          [[0.9524724, 0.0068908585, 0.040636774]]\n",
            "437          [[0.95844054, 0.0023535467, 0.03920592]]\n",
            "438         [[0.95169574, 0.0005994593, 0.047704812]]\n",
            "439          [[0.9524724, 0.0068908585, 0.040636774]]\n",
            "440         [[0.0074977996, 0.0027751082, 0.9897271]]\n",
            "441        [[0.0012508185, 7.7764875e-05, 0.9986714]]\n",
            "442          [[0.011124717, 0.0005027475, 0.9883725]]\n",
            "443       [[0.00084947783, 0.00027020587, 0.9988803]]\n",
            "444          [[0.0012230694, 0.31025353, 0.68852335]]\n",
            "445            [[0.003237538, 0.010011532, 0.986751]]\n",
            "446      [[0.00026131197, 4.0587565e-05, 0.99969804]]\n",
            "447      [[0.00067915116, 2.5507863e-05, 0.99929535]]\n",
            "448         [[0.014801135, 0.00055742456, 0.9846414]]\n",
            "449         [[0.014801135, 0.00055742456, 0.9846414]]\n",
            "450           [[0.00083942, 1.310836e-05, 0.9991474]]\n",
            "451       [[0.00080574345, 1.8119892e-05, 0.9991761]]\n",
            "452         [[0.000553869, 3.283135e-05, 0.99941325]]\n",
            "453         [[0.0019916615, 0.024012286, 0.97399616]]\n",
            "454          [[0.04533447, 0.0031704025, 0.95149505]]\n",
            "455      [[0.00085832964, 0.00015385385, 0.99898785]]\n",
            "456        [[0.0033301145, 0.00015847878, 0.9965114]]\n",
            "457         [[0.0003546907, 1.66306e-05, 0.99962866]]\n",
            "458       [[0.00050678576, 4.2653908e-05, 0.9994505]]\n",
            "459        [[0.0007961386, 0.0006069809, 0.99859685]]\n",
            "460       [[0.00057140784, 0.00015745692, 0.9992711]]\n",
            "461       [[0.00028708245, 0.00082277285, 0.9988901]]\n",
            "462         [[0.00028615067, 0.020769496, 0.9789443]]\n",
            "463        [[0.0040396187, 8.9503024e-05, 0.9958709]]\n",
            "464         [[0.0045664604, 0.0019372773, 0.9934963]]\n",
            "465            [[0.6747306, 0.048234344, 0.27703506]]\n",
            "466          [[0.0063502938, 0.15888353, 0.83476627]]\n",
            "467           [[0.0012330962, 0.8818221, 0.11694481]]\n",
            "468          [[0.002824835, 3.089268e-05, 0.9971443]]\n",
            "469        [[0.0005554229, 0.0004265786, 0.99901795]]\n",
            "470           [[0.0012330962, 0.8818221, 0.11694481]]\n",
            "471            [[0.02432975, 0.046973485, 0.9286968]]\n",
            "472            [[0.010267913, 0.84803855, 0.1416936]]\n",
            "473               [[0.023394553, 0.81932, 0.1572854]]\n",
            "474        [[0.0014052651, 0.00091004744, 0.9976846]]\n",
            "475             [[0.02042163, 0.45652577, 0.5230526]]\n",
            "476          [[0.014389646, 0.005591243, 0.98001915]]\n",
            "477           [[0.0024250667, 0.011513887, 0.986061]]\n",
            "478         [[0.0016666446, 0.011728529, 0.98660475]]\n",
            "479         [[0.0040170024, 0.90440387, 0.091579124]]\n",
            "480       [[0.00014461634, 0.0012547841, 0.99860054]]\n",
            "481       [[0.00033112385, 4.588468e-05, 0.99962294]]\n",
            "482       [[0.00033112385, 4.588468e-05, 0.99962294]]\n",
            "483             [[0.08290026, 0.5776483, 0.33945152]]\n",
            "484       [[0.00041354858, 8.634679e-05, 0.99950004]]\n",
            "485            [[0.14655875, 0.80499995, 0.04844138]]\n",
            "486        [[0.0006713614, 0.00043529802, 0.9988933]]\n",
            "487         [[0.000524806, 1.8917093e-05, 0.9994562]]\n",
            "488       [[0.0002606042, 0.000104284176, 0.9996351]]\n",
            "489         [[0.0031205406, 0.009557947, 0.98732156]]\n",
            "490            [[0.002789037, 0.9343125, 0.06289849]]\n",
            "491          [[0.001244634, 0.003098411, 0.99565697]]\n",
            "492          [[0.001244634, 0.003098411, 0.99565697]]\n",
            "493         [[0.0013862746, 6.412713e-05, 0.9985495]]\n",
            "494        [[0.0016929643, 0.00017364115, 0.9981335]]\n",
            "495      [[0.00034389462, 0.00045532835, 0.99920076]]\n",
            "496             [[0.2526273, 0.015165568, 0.7322071]]\n",
            "497             [[0.2526273, 0.015165568, 0.7322071]]\n",
            "498          [[0.000721004, 7.475604e-05, 0.9992042]]\n",
            "499         [[0.0004846829, 0.0003385407, 0.9991768]]\n",
            "500              [[0.0038404, 0.06145172, 0.9347079]]\n",
            "501          [[0.0018477142, 0.96337014, 0.03478214]]\n",
            "502           [[0.010285035, 0.9577318, 0.031983223]]\n",
            "503            [[0.7708601, 0.17677839, 0.052361526]]\n",
            "504            [[0.0051095923, 0.8770107, 0.1178797]]\n",
            "505           [[0.014283786, 0.017722873, 0.9679933]]\n",
            "506         [[0.0024498005, 0.97571087, 0.021839334]]\n",
            "507              [[0.07044808, 0.4248711, 0.5046809]]\n",
            "508        [[0.00088272814, 0.000408474, 0.99870884]]\n",
            "509          [[0.011611607, 0.022681171, 0.96570724]]\n",
            "510       [[0.00080850476, 0.00028126247, 0.9989102]]\n",
            "511        [[0.00088272814, 0.000408474, 0.99870884]]\n",
            "512      [[0.00091451145, 2.3283083e-05, 0.99906224]]\n",
            "513          [[0.9654465, 0.029512612, 0.0050409106]]\n",
            "514            [[0.04231215, 0.014197226, 0.9434906]]\n",
            "515           [[0.010116417, 0.07216667, 0.91771704]]\n",
            "516           [[0.011426526, 0.9597104, 0.028863037]]\n",
            "517           [[0.012488101, 0.012570453, 0.9749415]]\n",
            "518         [[0.006463385, 0.00021093056, 0.9933257]]\n",
            "519            [[0.31532654, 0.64785963, 0.03681385]]\n",
            "520            [[0.8500481, 0.13324803, 0.016703866]]\n",
            "521       [[0.00084663497, 0.00080598315, 0.9983474]]\n",
            "522             [[0.4894847, 0.49700704, 0.01350828]]\n",
            "523        [[0.0010864345, 0.00053654256, 0.9983771]]\n",
            "524       [[0.00021869013, 2.3667462e-05, 0.9997576]]\n",
            "525             [[0.7005827, 0.07864689, 0.22077046]]\n",
            "526            [[0.001968495, 0.9239293, 0.07410225]]\n",
            "527         [[0.0003387127, 2.738811e-05, 0.9996339]]\n",
            "528         [[0.0021645655, 0.0011358206, 0.9966995]]\n",
            "529       [[0.0011974734, 0.00044772754, 0.99835473]]\n",
            "530            [[0.0076363827, 0.1176896, 0.8746741]]\n",
            "531          [[0.0018775273, 0.9741711, 0.023951309]]\n",
            "532           [[0.0022589047, 0.6255309, 0.37221017]]\n",
            "533      [[0.00015027492, 2.7837807e-05, 0.99982184]]\n",
            "534        [[0.00082039944, 0.0011200481, 0.9980596]]\n",
            "535         [[0.0022911977, 0.0032804308, 0.9944284]]\n",
            "536           [[0.0034261998, 0.8583658, 0.13820796]]\n",
            "537         [[0.0153393205, 0.94628537, 0.038375247]]\n",
            "538         [[0.0153393205, 0.94628537, 0.038375247]]\n",
            "539            [[0.8825712, 0.049024206, 0.06840461]]\n",
            "540           [[0.53732383, 0.43243846, 0.030237705]]\n",
            "541          [[0.0017841147, 0.89745885, 0.10075705]]\n",
            "542           [[0.0025039292, 0.9738184, 0.02367766]]\n",
            "543          [[0.9812464, 0.0047206287, 0.014033017]]\n",
            "544         [[0.0013268603, 0.0016022844, 0.9970709]]\n",
            "545            [[0.08465298, 0.070910715, 0.8444363]]\n",
            "546         [[0.0019647141, 7.742119e-05, 0.9979578]]\n",
            "547      [[0.00060910307, 0.00033416797, 0.99905676]]\n",
            "548         [[0.9974367, 0.00043408145, 0.002129256]]\n",
            "549              [[0.10642963, 0.3302115, 0.5633589]]\n",
            "550            [[0.0027817076, 0.6877535, 0.3094648]]\n",
            "551        [[0.002598981, 5.8817597e-05, 0.99734217]]\n",
            "552            [[0.003623875, 0.6550911, 0.34128508]]\n",
            "553         [[0.001970531, 0.00017626418, 0.9978531]]\n",
            "554           [[0.009352138, 0.055513427, 0.9351345]]\n",
            "555       [[0.00030315682, 1.6360907e-05, 0.9996805]]\n",
            "556           [[0.67488736, 0.31466138, 0.010451334]]\n",
            "557            [[0.7132127, 0.016677056, 0.27011016]]\n",
            "558      [[0.00078045845, 4.5072673e-05, 0.99917454]]\n",
            "559       [[0.0005247928, 3.1126263e-05, 0.99944407]]\n",
            "560        [[0.0032857968, 2.9674324e-05, 0.9966845]]\n",
            "561        [[0.0042009135, 0.0068424996, 0.98895663]]\n",
            "562        [[0.0042009135, 0.0068424996, 0.98895663]]\n",
            "563             [[0.23317526, 0.6829576, 0.08386713]]\n",
            "564         [[0.0021950272, 0.034329657, 0.96347535]]\n",
            "565         [[0.0001788725, 8.649217e-06, 0.9998124]]\n",
            "566      [[0.00021243673, 1.8419185e-05, 0.99976915]]\n",
            "567       [[0.00018129172, 8.0925405e-05, 0.9997378]]\n",
            "568           [[0.00041841296, 0.6863995, 0.3131821]]\n",
            "569           [[0.002963259, 0.96183443, 0.03520238]]\n",
            "570        [[0.0047878474, 0.99024594, 0.0049661687]]\n",
            "571         [[0.0018581165, 0.99221635, 0.005925489]]\n",
            "572        [[0.00027312856, 0.001984281, 0.99774265]]\n",
            "573         [[0.000332708, 1.9936815e-05, 0.9996474]]\n",
            "574       [[0.00047447678, 1.4629646e-05, 0.9995109]]\n",
            "575        [[0.0018594129, 4.7331465e-05, 0.9980932]]\n",
            "576               [[0.07634595, 0.403059, 0.5205951]]\n",
            "577         [[0.011878047, 0.0047430494, 0.98337895]]\n",
            "578        [[0.0029698454, 0.0011861648, 0.99584395]]\n",
            "579           [[0.002253989, 0.007051482, 0.9906945]]\n",
            "580         [[0.001444191, 6.0152273e-05, 0.9984957]]\n",
            "581              [[0.031480134, 0.434235, 0.5342849]]\n",
            "582           [[0.36096495, 0.62663656, 0.012398441]]\n",
            "583            [[0.23450711, 0.75616294, 0.00932996]]\n",
            "584         [[0.004102335, 0.0009193347, 0.99497825]]\n",
            "585        [[0.0034349307, 0.0044124215, 0.99215263]]\n",
            "586         [[0.005468221, 5.0523166e-05, 0.9944813]]\n",
            "587           [[0.007374512, 0.61203444, 0.38059098]]\n",
            "588           [[0.0033248002, 0.24175441, 0.7549208]]\n",
            "589           [[0.0033248002, 0.24175441, 0.7549208]]\n",
            "590          [[0.016499003, 0.021744275, 0.96175677]]\n",
            "591            [[0.05853576, 0.18509552, 0.75636864]]\n",
            "592        [[0.0018396036, 0.00015460522, 0.9980057]]\n",
            "593             [[0.024302848, 0.5679977, 0.4076994]]\n",
            "594         [[0.00020607794, 0.017987428, 0.9818064]]\n",
            "595           [[0.0041121487, 0.5268701, 0.46901783]]\n",
            "596            [[0.08197061, 0.42635772, 0.49167162]]\n",
            "597       [[0.00013383599, 0.00012330397, 0.9997428]]\n",
            "598        [[0.0001005807, 0.00024687234, 0.9996525]]\n",
            "599         [[0.00036908878, 0.9868427, 0.012788243]]\n",
            "600           [[0.0029326868, 0.11189221, 0.8851751]]\n",
            "601           [[0.9560174, 0.020951772, 0.023030847]]\n",
            "602            [[0.003277719, 0.13825093, 0.8584714]]\n",
            "603            [[0.0076211374, 0.2294419, 0.7629369]]\n",
            "604            [[0.0076211374, 0.2294419, 0.7629369]]\n",
            "605        [[0.00070311734, 0.005243362, 0.99405354]]\n",
            "606          [[0.00038881268, 0.03062171, 0.9689895]]\n",
            "607            [[0.004026003, 0.12404834, 0.8719257]]\n",
            "608            [[0.009627316, 0.8778935, 0.11247922]]\n",
            "609             [[0.1440312, 0.8311712, 0.024797557]]\n",
            "610      [[0.00093620754, 0.00051476515, 0.99854904]]\n",
            "611       [[0.00079957646, 0.00055631145, 0.9986442]]\n",
            "612           [[0.022865955, 0.43075123, 0.54638284]]\n",
            "613           [[0.014706423, 0.009961474, 0.9753321]]\n",
            "614        [[0.00036001494, 0.0010947058, 0.9985454]]\n",
            "615        [[0.0019668962, 0.00071413384, 0.9973189]]\n",
            "616           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "617           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "618           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "619           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "620           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "621           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "622           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "623           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "624           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "625           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "626           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "627           [[0.0054968395, 0.22387393, 0.7706293]]\n",
            "628       [[0.0008938927, 0.00063141534, 0.99847466]]\n",
            "629        [[0.0012559275, 7.264124e-05, 0.99867153]]\n",
            "630            [[0.051552784, 0.7554152, 0.19303204]]\n",
            "631         [[0.00092839956, 0.005619293, 0.9934523]]\n",
            "632          [[0.001031227, 0.98978674, 0.009182057]]\n",
            "633        [[0.00053839455, 0.96266514, 0.036796436]]\n",
            "634         [[0.00090261357, 0.9854204, 0.013676954]]\n",
            "635          [[0.0009353982, 0.8876217, 0.111442916]]\n",
            "636           [[0.0020990463, 0.2039411, 0.79395986]]\n",
            "637       [[0.0007349953, 6.9774156e-05, 0.99919516]]\n",
            "638          [[0.0004284202, 7.74921e-05, 0.9994941]]\n",
            "639            [[0.02855835, 0.9629906, 0.008451045]]\n",
            "640         [[0.001409343, 0.0045013763, 0.99408925]]\n",
            "641        [[0.0036150308, 0.00013536296, 0.9962496]]\n",
            "642         [[0.0004473496, 0.010041707, 0.98951095]]\n",
            "643           [[0.53595877, 0.019350378, 0.44469085]]\n",
            "644         [[0.0009843424, 1.449072e-05, 0.9990011]]\n",
            "645        [[0.0007936369, 1.5257791e-05, 0.9991911]]\n",
            "646           [[0.89878416, 0.07798068, 0.023235084]]\n",
            "647           [[0.37316394, 0.037967797, 0.58886826]]\n",
            "648           [[0.009096119, 0.028107231, 0.9627967]]\n",
            "649        [[0.0005181311, 0.00017251768, 0.9993094]]\n",
            "650            [[0.08711008, 0.016868545, 0.8960214]]\n",
            "651           [[0.035094764, 0.019738715, 0.9451665]]\n",
            "652           [[0.9771262, 0.0024512117, 0.02042256]]\n",
            "653         [[0.00091136224, 0.48996964, 0.50911903]]\n",
            "654           [[0.026094241, 0.50320566, 0.47070011]]\n",
            "655           [[0.026094241, 0.50320566, 0.47070011]]\n",
            "656           [[0.026094241, 0.50320566, 0.47070011]]\n",
            "657           [[0.035094764, 0.019738715, 0.9451665]]\n",
            "658            [[0.040981617, 0.47278616, 0.4862322]]\n",
            "659         [[0.0014894509, 8.504873e-05, 0.9984255]]\n",
            "660        [[0.0015814027, 0.000120672914, 0.998298]]\n",
            "661          [[0.0043217028, 0.004029557, 0.9916488]]\n",
            "662          [[0.009047751, 0.020893358, 0.97005886]]\n",
            "663            [[0.1816707, 0.0011634837, 0.8171658]]\n",
            "664            [[0.1816707, 0.0011634837, 0.8171658]]\n",
            "665          [[0.01046239, 0.0005415028, 0.98899615]]\n",
            "666           [[0.022340901, 0.15378171, 0.82387733]]\n",
            "667            [[0.2046991, 0.7895614, 0.0057395753]]\n",
            "668       [[0.0009354402, 3.9044233e-05, 0.99902546]]\n",
            "669        [[0.0012585035, 0.0018013354, 0.99694026]]\n",
            "670        [[0.0018951795, 5.2204094e-05, 0.9980526]]\n",
            "671        [[0.00031180316, 4.0139217e-05, 0.999648]]\n",
            "672           [[0.00420799, 0.0022426012, 0.9935495]]\n",
            "673       [[0.0025020866, 9.2484945e-05, 0.99740535]]\n",
            "674       [[0.0025020866, 9.2484945e-05, 0.99740535]]\n",
            "675             [[0.004266358, 0.0066209, 0.9891128]]\n",
            "676          [[0.004821066, 0.012342969, 0.98283595]]\n",
            "677         [[0.0016055009, 0.0027803073, 0.9956142]]\n",
            "678         [[0.0065721995, 0.009873199, 0.98355466]]\n",
            "679        [[0.0009725233, 0.00017977609, 0.9988476]]\n",
            "680        [[0.0011465579, 7.592313e-05, 0.99877745]]\n",
            "681          [[0.002942315, 6.732964e-05, 0.9969903]]\n",
            "682             [[0.107441925, 0.5480799, 0.3444782]]\n",
            "683             [[0.78677875, 0.199132, 0.014089284]]\n",
            "684            [[0.8281366, 0.001108419, 0.17075497]]\n",
            "685       [[0.00023779589, 1.3651387e-05, 0.9997485]]\n",
            "686       [[0.00027511115, 5.4498018e-05, 0.9996704]]\n",
            "687      [[0.00013232061, 0.00019025551, 0.99967754]]\n",
            "688       [[0.00023779589, 1.3651387e-05, 0.9997485]]\n",
            "689         [[0.0006154285, 0.0033017013, 0.9960828]]\n",
            "690             [[0.001017069, 0.73906994, 0.259913]]\n",
            "691      [[0.00020905223, 2.1113405e-05, 0.99976987]]\n",
            "692      [[0.00013232061, 0.00019025551, 0.99967754]]\n",
            "693            [[0.008375614, 0.12685099, 0.8647734]]\n",
            "694        [[0.00069274515, 0.95090145, 0.048405845]]\n",
            "695          [[0.00088884076, 0.7319784, 0.26713273]]\n",
            "696         [[0.0010294537, 0.99071735, 0.008253226]]\n",
            "697           [[0.01052486, 0.88654834, 0.102926835]]\n",
            "698           [[0.0023008632, 0.8577277, 0.13997145]]\n",
            "699       [[0.00087195163, 0.00017195236, 0.9989561]]\n",
            "700         [[0.0017286544, 0.0031626045, 0.9951088]]\n",
            "701         [[0.0009125177, 0.0019769955, 0.9971105]]\n",
            "702      [[0.00040938274, 2.5466321e-05, 0.99956506]]\n",
            "703       [[0.00072122336, 0.00050615065, 0.9987727]]\n",
            "704          [[0.0048055416, 0.76243806, 0.23275644]]\n",
            "705         [[0.00034465734, 3.129162e-05, 0.999624]]\n",
            "706       [[0.00047025434, 3.9125607e-05, 0.9994906]]\n",
            "707       [[0.0002874341, 1.37314255e-05, 0.9996989]]\n",
            "708       [[0.00047025434, 3.9125607e-05, 0.9994906]]\n",
            "709        [[0.0002690965, 2.9040753e-05, 0.9997018]]\n",
            "710        [[0.0006144572, 0.00031947557, 0.9990662]]\n",
            "711        [[0.0005577768, 2.9818604e-05, 0.9994124]]\n",
            "712          [[0.0031465131, 0.003253616, 0.9935999]]\n",
            "713          [[0.00131254, 0.00012577577, 0.9985617]]\n",
            "714             [[0.24132092, 0.6830616, 0.07561744]]\n",
            "715           [[0.0058884304, 0.19536008, 0.7987515]]\n",
            "716         [[0.017442118, 0.00033715394, 0.9822207]]\n",
            "717           [[0.9359437, 0.056196764, 0.007859504]]\n",
            "718              [[0.24544066, 0.6027538, 0.1518055]]\n",
            "719         [[0.0004511687, 0.0005428231, 0.9990061]]\n",
            "720           [[0.0062670936, 0.44699308, 0.5467398]]\n",
            "721       [[0.0002680616, 0.00024779706, 0.99948406]]\n",
            "722        [[0.00042712214, 5.920222e-05, 0.9995136]]\n",
            "723           [[0.020605268, 0.44037008, 0.53902465]]\n",
            "724        [[0.00024113606, 2.360738e-05, 0.9997353]]\n",
            "725          [[0.0013536641, 0.9765315, 0.022114852]]\n",
            "726             [[0.6971986, 0.2883443, 0.014457115]]\n",
            "727           [[0.023387041, 0.9716115, 0.005001463]]\n",
            "728        [[0.0137279555, 0.98009354, 0.0061784578]]\n",
            "729       [[0.0014935912, 3.8005695e-05, 0.99846846]]\n",
            "730        [[0.0006743515, 4.2904325e-05, 0.9992828]]\n",
            "731          [[0.026084598, 0.012223164, 0.96169215]]\n",
            "732          [[0.9970493, 0.002184116, 0.0007666639]]\n",
            "733        [[0.99745005, 0.0007133959, 0.0018364547]]\n",
            "734          [[0.016832028, 0.9819608, 0.0012072661]]\n",
            "735       [[0.0003091567, 0.00043558597, 0.99925524]]\n",
            "736         [[0.00014635392, 0.0002976474, 0.999556]]\n",
            "737         [[0.026557598, 0.0051543745, 0.96828806]]\n",
            "738        [[0.0007117527, 1.1125399e-05, 0.9992772]]\n",
            "739       [[0.0003762704, 1.4133412e-05, 0.99960953]]\n",
            "740          [[0.0010429409, 0.24724711, 0.75170994]]\n",
            "741          [[0.0009045716, 6.12228e-05, 0.9990343]]\n",
            "742       [[0.0005158334, 2.1704622e-05, 0.99946254]]\n",
            "743         [[0.0003766116, 8.876247e-06, 0.9996146]]\n",
            "744          [[0.0009045716, 6.12228e-05, 0.9990343]]\n",
            "745         [[0.00030490395, 0.9451089, 0.054586194]]\n",
            "746        [[0.00035977486, 0.00018917074, 0.999451]]\n",
            "747         [[0.0003766116, 8.876247e-06, 0.9996146]]\n",
            "748          [[0.0006789889, 0.018277591, 0.9810434]]\n",
            "749            [[0.014359806, 0.07886147, 0.9067787]]\n",
            "750            [[0.032604724, 0.03883355, 0.9285618]]\n",
            "751         [[0.00015569446, 0.005761212, 0.9940831]]\n",
            "752         [[7.745624e-05, 0.0008949066, 0.9990277]]\n",
            "753        [[0.00068832136, 3.140287e-05, 0.9992803]]\n",
            "754       [[0.00057666976, 2.4749235e-05, 0.9993986]]\n",
            "755       [[0.00014176931, 3.4069664e-05, 0.9998242]]\n",
            "756        [[0.0001094416, 0.00087459775, 0.9990159]]\n",
            "757       [[0.00014199552, 0.00060314813, 0.9992549]]\n",
            "758         [[0.0041590924, 0.031250335, 0.96459055]]\n",
            "759        [[0.0003070819, 0.00016588195, 0.9995271]]\n",
            "760       [[0.00014199552, 0.00060314813, 0.9992549]]\n",
            "761            [[0.6538954, 0.060181122, 0.28592348]]\n",
            "762       [[0.99263567, 0.00029464075, 0.0070697595]]\n",
            "763             [[0.16622932, 0.7743193, 0.05945138]]\n",
            "764           [[0.87687564, 0.06541106, 0.057713285]]\n",
            "765         [[0.0006466684, 3.858305e-05, 0.9993148]]\n",
            "766          [[0.0024541926, 0.17332716, 0.82421863]]\n",
            "767      [[0.00042002613, 1.3719656e-05, 0.99956626]]\n",
            "768        [[0.0005261713, 0.0018978792, 0.99757594]]\n",
            "769           [[0.018550444, 0.18588243, 0.79556715]]\n",
            "770             [[0.01318131, 0.08903997, 0.8977787]]\n",
            "771             [[0.01246459, 0.17930982, 0.8082256]]\n",
            "772         [[0.0002970015, 6.494281e-05, 0.9996381]]\n",
            "773            [[0.23993024, 0.00186144, 0.75820833]]\n",
            "774        [[0.0014667534, 3.0226991e-05, 0.9985031]]\n",
            "775        [[0.0020595132, 0.0008040878, 0.99713635]]\n",
            "776           [[0.09750546, 0.054713868, 0.84778064]]\n",
            "777          [[0.0012682859, 0.9590701, 0.039661616]]\n",
            "778         [[0.002565881, 0.0013890149, 0.99604505]]\n",
            "779          [[0.0027721194, 0.011118068, 0.9861098]]\n",
            "780             [[0.4903871, 0.060549583, 0.4490633]]\n",
            "781        [[0.0014773646, 6.203568e-05, 0.99846065]]\n",
            "782       [[0.00056888914, 8.7888955e-05, 0.9993432]]\n",
            "783     [[0.000116856456, 3.3566193e-05, 0.99984956]]\n",
            "784        [[8.085346e-05, 0.00010378493, 0.9998154]]\n",
            "785             [[0.0240579, 0.097525775, 0.8784163]]\n",
            "786           [[0.003912699, 0.71287936, 0.28320795]]\n",
            "787           [[0.15438175, 0.81496835, 0.030649845]]\n",
            "788         [[0.0055178967, 0.9942644, 0.0002177004]]\n",
            "789           [[0.0008487235, 0.5361651, 0.46298617]]\n",
            "790         [[9.06686e-05, 0.00024057126, 0.9996687]]\n",
            "791        [[0.00068182725, 0.044670083, 0.95464814]]\n",
            "792          [[0.017269002, 0.0028225158, 0.9799085]]\n",
            "793          [[0.017269002, 0.0028225158, 0.9799085]]\n",
            "794            [[0.0023868743, 0.409238, 0.58837515]]\n",
            "795            [[0.0014365163, 0.6202204, 0.3783431]]\n",
            "796          [[0.017269002, 0.0028225158, 0.9799085]]\n",
            "797           [[0.94603664, 0.03630259, 0.017660735]]\n",
            "798           [[0.002089887, 0.60145277, 0.39645734]]\n",
            "799       [[0.00087278197, 7.914592e-05, 0.99904805]]\n",
            "800         [[0.00058734964, 7.32953e-05, 0.9993394]]\n",
            "801       [[0.0007873477, 7.0721304e-05, 0.99914193]]\n",
            "802         [[0.00038239005, 3.263021e-05, 0.999585]]\n",
            "803        [[0.0036202017, 0.0007326125, 0.99564725]]\n",
            "804      [[0.00043415587, 0.00013180883, 0.99943405]]\n",
            "805            [[0.0067776074, 0.7076871, 0.2855353]]\n",
            "806        [[0.0031819062, 0.0019581527, 0.99485993]]\n",
            "807           [[0.0034085053, 0.6422555, 0.35433602]]\n",
            "808         [[0.0034717273, 0.028655557, 0.96787274]]\n",
            "809         [[0.00057203835, 0.9902024, 0.009225535]]\n",
            "810       [[0.00030906874, 0.0002968905, 0.99939406]]\n",
            "811      [[0.00044951224, 4.7772697e-05, 0.99950266]]\n",
            "812       [[0.0013592133, 2.1210555e-05, 0.99861956]]\n",
            "813         [[0.004238765, 5.1954026e-05, 0.9957092]]\n",
            "814          [[0.003456023, 0.006421198, 0.99012285]]\n",
            "815       [[0.00097351853, 0.0006074425, 0.99841905]]\n",
            "816            [[0.00627861, 0.73628044, 0.25744095]]\n",
            "817          [[0.003456023, 0.006421198, 0.99012285]]\n",
            "818           [[0.028121239, 0.052909467, 0.9189694]]\n",
            "819            [[0.06255925, 0.007140563, 0.9303002]]\n",
            "820           [[0.0064614196, 0.40862095, 0.5849176]]\n",
            "821       [[0.0013858796, 2.5345886e-05, 0.99858874]]\n",
            "822            [[0.0020156293, 0.4172212, 0.5807632]]\n",
            "823         [[0.00089321105, 0.057145227, 0.9419616]]\n",
            "824          [[0.00035631564, 0.9478713, 0.05177238]]\n",
            "825           [[0.004285879, 0.016631173, 0.9790829]]\n",
            "826            [[0.009840506, 0.7426757, 0.24748376]]\n",
            "827          [[0.0057760836, 0.19859625, 0.79562765]]\n",
            "828           [[0.0031210275, 0.03093141, 0.9659475]]\n",
            "829        [[0.0009316052, 0.00033410633, 0.9987343]]\n",
            "830          [[0.0031043903, 0.91101074, 0.08588487]]\n",
            "831          [[0.000689353, 0.998691, 0.00061967684]]\n",
            "832          [[0.0015226254, 0.9820807, 0.016396701]]\n",
            "833         [[0.0016271347, 0.9968622, 0.0015107571]]\n",
            "834         [[0.00024833798, 0.9900613, 0.009690422]]\n",
            "835         [[0.0021299433, 0.0024257305, 0.9954443]]\n",
            "836          [[0.0018718983, 0.98213285, 0.01599524]]\n",
            "837          [[0.003000836, 0.0018399414, 0.9951592]]\n",
            "838            [[0.31325865, 0.35273755, 0.33400384]]\n",
            "839          [[0.00061994925, 0.8725282, 0.12685189]]\n",
            "840        [[0.0005314809, 3.2225955e-05, 0.9994363]]\n",
            "841        [[0.0011284029, 0.0018906504, 0.99698097]]\n",
            "842        [[0.0040344056, 0.00016598772, 0.9957996]]\n",
            "843             [[0.05395275, 0.0934791, 0.85256815]]\n",
            "844       [[0.0018161905, 8.0617145e-05, 0.99810314]]\n",
            "845            [[0.060957912, 0.41282758, 0.5262145]]\n",
            "846             [[0.08648632, 0.42203772, 0.4914759]]\n",
            "847       [[0.0018161905, 8.0617145e-05, 0.99810314]]\n",
            "848         [[0.0019390582, 0.0008772433, 0.9971836]]\n",
            "849         [[0.0041891914, 0.0032912116, 0.9925196]]\n",
            "850          [[0.0021117944, 0.001083649, 0.9968046]]\n",
            "851       [[0.00062959624, 1.526673e-05, 0.99935514]]\n",
            "852             [[0.019641327, 0.2645628, 0.7157959]]\n",
            "853        [[0.00077221065, 0.0027959628, 0.9964318]]\n",
            "854        [[0.0009496834, 0.00071571313, 0.9983346]]\n",
            "855        [[0.0004594514, 0.00019368684, 0.9993468]]\n",
            "856        [[0.0011675125, 0.0072670984, 0.99156547]]\n",
            "857           [[0.0018232113, 0.07630907, 0.9218678]]\n",
            "858       [[0.0011040821, 0.00018936182, 0.99870646]]\n",
            "859       [[0.0014172668, 0.00012537945, 0.99845743]]\n",
            "860          [[0.008588681, 0.027884986, 0.96352637]]\n",
            "861           [[0.0017359386, 0.00864879, 0.9896152]]\n",
            "862       [[0.0011635165, 0.00049790955, 0.99833846]]\n",
            "863           [[0.0040163775, 0.5463836, 0.44959998]]\n",
            "864        [[8.8864326e-05, 0.9991943, 0.0007168037]]\n",
            "865         [[7.073815e-05, 0.99873966, 0.001189615]]\n",
            "866        [[0.00019805843, 0.99331105, 0.006490969]]\n",
            "867         [[5.71765e-05, 0.99896264, 0.0009801525]]\n",
            "868           [[0.08351563, 0.0093840705, 0.9071003]]\n",
            "869           [[0.08351563, 0.0093840705, 0.9071003]]\n",
            "870           [[0.08351563, 0.0093840705, 0.9071003]]\n",
            "871        [[0.0015660566, 0.0001180018, 0.99831593]]\n",
            "872        [[0.0014285998, 0.99687225, 0.0016992019]]\n",
            "873         [[0.0019423825, 0.99555653, 0.002501107]]\n",
            "874          [[0.0015377579, 0.996317, 0.0021451926]]\n",
            "875             [[0.022752717, 0.925378, 0.05186925]]\n",
            "876             [[0.68929935, 0.2899807, 0.02071993]]\n",
            "877            [[0.8628777, 0.030160172, 0.10696208]]\n",
            "878       [[0.0014117906, 0.00012317361, 0.99846506]]\n",
            "879          [[0.004133227, 0.041471507, 0.95439523]]\n",
            "880             [[0.0029632463, 0.12830676, 0.86873]]\n",
            "881          [[0.004133227, 0.041471507, 0.95439523]]\n",
            "882         [[0.0006059758, 0.9962619, 0.0031320935]]\n",
            "883         [[0.00029454665, 1.68202e-05, 0.9996886]]\n",
            "884         [[0.00044592482, 0.003718841, 0.9958353]]\n",
            "885        [[0.0009241219, 0.00050011085, 0.9985758]]\n",
            "886      [[0.00034883217, 0.00014720969, 0.99950397]]\n",
            "887          [[0.00040360194, 0.08216613, 0.9174303]]\n",
            "888       [[0.00055613654, 0.00013401874, 0.9993099]]\n",
            "889       [[0.0018030233, 8.0786594e-05, 0.99811625]]\n",
            "890         [[0.0019637644, 5.073524e-05, 0.9979855]]\n",
            "891       [[0.0008986405, 2.6983509e-05, 0.99907434]]\n",
            "892       [[0.0003586498, 4.4165718e-05, 0.99959713]]\n",
            "893        [[0.0028120228, 3.6423862e-05, 0.9971517]]\n",
            "894             [[0.39309597, 0.5911786, 0.01572541]]\n",
            "895          [[0.97706646, 0.013161339, 0.009772183]]\n",
            "896        [[0.0021809686, 0.0001711745, 0.99764794]]\n",
            "897         [[0.0016078859, 0.048221435, 0.95017076]]\n",
            "898          [[0.0019081928, 0.32691184, 0.67117995]]\n",
            "899          [[0.9695202, 0.022915956, 0.0075638522]]\n",
            "900        [[0.00050211424, 4.9969272e-05, 0.999448]]\n",
            "901        [[0.0015683875, 0.00015370916, 0.9982779]]\n",
            "902          [[0.95896024, 0.0032812764, 0.03775853]]\n",
            "903        [[0.99500954, 0.0033136266, 0.0016768975]]\n",
            "904        [[0.99500954, 0.0033136266, 0.0016768975]]\n",
            "905         [[0.9949588, 0.0039678537, 0.0010734636]]\n",
            "906            [[0.019543234, 0.012333665, 0.968123]]\n",
            "907        [[0.00053471257, 0.0001460892, 0.9993192]]\n",
            "908       [[0.0002983533, 3.5293022e-05, 0.99966633]]\n",
            "909        [[0.00021114809, 3.69863e-05, 0.99975187]]\n",
            "910        [[0.0002840886, 7.627074e-05, 0.99963963]]\n",
            "911           [[0.0010853204, 0.08973713, 0.9091775]]\n",
            "912         [[0.0002494151, 0.00081757613, 0.998933]]\n",
            "913       [[0.00065821805, 0.00023776459, 0.9991041]]\n",
            "914       [[0.00050339877, 0.0002948463, 0.99920183]]\n",
            "915       [[0.0009373677, 1.1538931e-05, 0.99905103]]\n",
            "916           [[0.85493845, 0.010647026, 0.13441458]]\n",
            "917           [[0.008513726, 0.58123916, 0.41024712]]\n",
            "918         [[0.0012135411, 0.0004208789, 0.9983656]]\n",
            "919          [[0.00064992247, 0.00230037, 0.9970497]]\n",
            "920        [[0.00044332354, 0.0010768807, 0.9984798]]\n",
            "921            [[0.001764235, 0.021519886, 0.976716]]\n",
            "922        [[0.0010646036, 4.443755e-05, 0.99889106]]\n",
            "923           [[0.0067859995, 0.8568358, 0.13637827]]\n",
            "924        [[0.00043920949, 0.9958016, 0.0037592216]]\n",
            "925          [[0.0012962453, 0.9892647, 0.009438981]]\n",
            "926            [[0.001764235, 0.021519886, 0.976716]]\n",
            "927      [[0.00034378967, 0.00020969132, 0.99944645]]\n",
            "928         [[0.0002661904, 4.968002e-05, 0.9996841]]\n",
            "929      [[0.00029882975, 1.1711312e-05, 0.99968946]]\n",
            "930        [[0.00028411622, 2.576214e-05, 0.9996902]]\n",
            "931           [[0.0035620641, 0.31273124, 0.6837067]]\n",
            "932       [[0.0015322603, 2.4640663e-05, 0.99844307]]\n",
            "933       [[0.00013331878, 3.4177436e-05, 0.9998324]]\n",
            "934       [[0.00036070694, 0.00070808287, 0.9989312]]\n",
            "935        [[0.98209536, 0.00024620717, 0.017658366]]\n",
            "936         [[0.95415044, 3.9531744e-05, 0.04580996]]\n",
            "937      [[0.00018766763, 0.99975306, 5.9314407e-05]]\n",
            "938              [[0.62566835, 0.04724867, 0.327083]]\n",
            "939           [[0.008486325, 0.55763865, 0.43387505]]\n",
            "940          [[0.0039801756, 0.28864652, 0.70737326]]\n",
            "941         [[7.252413e-05, 0.9984831, 0.0014443628]]\n",
            "942       [[0.00092895946, 0.00053877564, 0.9985323]]\n",
            "943         [[9.350026e-05, 0.0021340891, 0.9977724]]\n",
            "944         [[0.00027666564, 0.010196216, 0.9895272]]\n",
            "945             [[0.012676326, 0.0657405, 0.9215831]]\n",
            "946           [[0.0012558458, 0.45157138, 0.5471727]]\n",
            "947           [[0.0010527581, 0.8927169, 0.10623036]]\n",
            "948     [[0.00078044017, 0.000118423704, 0.99910116]]\n",
            "949         [[0.0008767557, 0.0010530031, 0.9980703]]\n",
            "950          [[0.0008825937, 0.034030553, 0.9650868]]\n",
            "951          [[0.0014498717, 0.63447106, 0.36407906]]\n",
            "952         [[0.0016954759, 0.0050505064, 0.9932541]]\n",
            "953             [[0.11228778, 0.45304537, 0.4346669]]\n",
            "954        [[0.00066554965, 0.042818848, 0.95651555]]\n",
            "955          [[0.000283797, 6.506504e-05, 0.9996512]]\n",
            "956         [[0.001122339, 0.0018829929, 0.99699473]]\n",
            "957         [[0.0026992843, 8.158291e-05, 0.9972192]]\n",
            "958            [[0.33286142, 0.57283443, 0.09430418]]\n",
            "959            [[0.33286142, 0.57283443, 0.09430418]]\n",
            "960        [[0.00018840923, 0.0008223439, 0.9989893]]\n",
            "961       [[0.00033129533, 0.00032606113, 0.9993426]]\n",
            "962       [[0.00027108548, 8.528684e-05, 0.99964356]]\n",
            "963        [[0.00018840923, 0.0008223439, 0.9989893]]\n",
            "964       [[0.00019319479, 0.99746513, 0.0023416926]]\n",
            "965          [[0.0008045607, 0.024159145, 0.9750363]]\n",
            "966       [[0.0058077914, 2.4593717e-05, 0.99416757]]\n",
            "967       [[0.0058077914, 2.4593717e-05, 0.99416757]]\n",
            "968            [[0.5680523, 0.31713992, 0.114807695]]\n",
            "969             [[0.014023725, 0.46770224, 0.518274]]\n",
            "970         [[0.0017453103, 0.96511257, 0.033142153]]\n",
            "971         [[0.0019289493, 0.016864838, 0.98120624]]\n",
            "972       [[0.00017169281, 1.3386128e-05, 0.9998149]]\n",
            "973        [[0.0030238342, 4.924248e-05, 0.99692696]]\n",
            "974          [[0.012215369, 0.00018560019, 0.987599]]\n",
            "975             [[0.030821256, 0.17121279, 0.797966]]\n",
            "976          [[0.0025830094, 0.006314812, 0.9911022]]\n",
            "977           [[0.98625934, 0.00070118, 0.013039453]]\n",
            "978          [[0.012215369, 0.00018560019, 0.987599]]\n",
            "979       [[0.0005992694, 1.1841101e-05, 0.99938893]]\n",
            "980             [[0.10554225, 0.7581856, 0.13627213]]\n",
            "981        [[0.0006962704, 6.6510314e-05, 0.9992373]]\n",
            "982            [[0.005552703, 0.056590308, 0.937857]]\n",
            "983          [[0.040725637, 0.0004652539, 0.9588092]]\n",
            "984       [[0.0011893263, 0.00040189674, 0.99840873]]\n",
            "985       [[0.00058248994, 2.3225457e-05, 0.9993943]]\n",
            "986      [[0.00080765027, 0.00010056801, 0.99909186]]\n",
            "987         [[0.0024109725, 0.029365433, 0.96822363]]\n",
            "988           [[0.015199382, 0.057648964, 0.9271516]]\n",
            "989           [[0.9264386, 0.028336404, 0.045225013]]\n",
            "990           [[0.9264386, 0.028336404, 0.045225013]]\n",
            "991           [[0.9264386, 0.028336404, 0.045225013]]\n",
            "992         [[0.0075491345, 0.98690355, 0.005547366]]\n",
            "993           [[0.030530833, 0.17733938, 0.79212976]]\n",
            "994       [[0.0019307879, 0.00010429755, 0.99796486]]\n",
            "995       [[0.00026703053, 5.527192e-05, 0.99967766]]\n",
            "996       [[0.0009257551, 0.00013107213, 0.99894315]]\n",
            "997        [[0.0010170261, 1.4903478e-05, 0.9989681]]\n",
            "998           [[0.0031420356, 0.16206725, 0.8347907]]\n",
            "999       [[0.99862874, 0.0004509015, 0.00092031946]]\n",
            "1000           [[0.019003138, 0.5030971, 0.47789973]]\n",
            "1001          [[0.0031420356, 0.16206725, 0.8347907]]\n",
            "1002          [[0.0031420356, 0.16206725, 0.8347907]]\n",
            "1003          [[0.04556523, 0.0011560966, 0.9532787]]\n",
            "1004         [[0.0021733015, 0.032913875, 0.9649129]]\n",
            "1005          [[0.04556523, 0.0011560966, 0.9532787]]\n",
            "1006          [[0.04556523, 0.0011560966, 0.9532787]]\n",
            "1007        [[0.0069283727, 0.0006242372, 0.9924474]]\n",
            "1008         [[0.0028624248, 0.0020705322, 0.995067]]\n",
            "1009       [[0.00051283586, 0.0001277012, 0.9993594]]\n",
            "1010           [[0.016760385, 0.12574995, 0.8574897]]\n",
            "1011          [[0.006648437, 0.9815475, 0.011804056]]\n",
            "1012          [[0.0025573338, 0.8910417, 0.10640098]]\n",
            "1013          [[0.0020882718, 0.9949704, 0.00294133]]\n",
            "1014      [[0.00023900559, 0.00017576657, 0.9995852]]\n",
            "1015          [[0.03500147, 0.0002554644, 0.9647431]]\n",
            "1016          [[0.03500147, 0.0002554644, 0.9647431]]\n",
            "1017        [[0.0003386479, 9.423403e-06, 0.9996519]]\n",
            "1018       [[0.0004950678, 1.7675797e-05, 0.9994873]]\n",
            "1019        [[0.0003386479, 9.423403e-06, 0.9996519]]\n",
            "1020      [[0.00078275247, 6.3661595e-05, 0.9991536]]\n",
            "1021         [[0.086631946, 0.017912745, 0.89545536]]\n",
            "1022      [[0.0005160235, 0.00042416726, 0.99905974]]\n",
            "1023            [[0.02253233, 0.7018492, 0.27561846]]\n",
            "1024      [[7.964818e-05, 0.00019339555, 0.99972695]]\n",
            "1025      [[0.0015576172, 0.00037026088, 0.99807215]]\n",
            "1026          [[0.004904673, 0.53763163, 0.45746368]]\n",
            "1027          [[0.009465116, 0.010809528, 0.9797254]]\n",
            "1028        [[0.0020387478, 0.002457845, 0.99550337]]\n",
            "1029         [[0.0016705452, 0.012725078, 0.9856044]]\n",
            "1030        [[0.0013534615, 0.003123243, 0.99552333]]\n",
            "1031          [[0.0005721519, 2.29286e-05, 0.999405]]\n",
            "1032     [[0.00054307055, 3.3741744e-05, 0.99942327]]\n",
            "1033       [[0.0004735894, 0.0013885439, 0.99813783]]\n",
            "1034       [[0.0010097254, 0.0018954629, 0.99709475]]\n",
            "1035      [[0.00060293503, 3.9697174e-05, 0.9993574]]\n",
            "1036         [[0.015704367, 0.96851325, 0.015782433]]\n",
            "1037       [[0.00037026827, 0.95679593, 0.042833745]]\n",
            "1038         [[0.015704367, 0.96851325, 0.015782433]]\n",
            "1039     [[0.00027512034, 2.2047303e-05, 0.99970275]]\n",
            "1040       [[0.0002935209, 0.00019238595, 0.9995141]]\n",
            "1041        [[0.0010091306, 0.94334114, 0.055649735]]\n",
            "1042        [[0.0001275914, 0.9967828, 0.0030896533]]\n",
            "1043         [[0.010504654, 0.9861769, 0.0033184947]]\n",
            "1044        [[0.0053453697, 0.9897876, 0.0048670634]]\n",
            "1045          [[0.9849244, 0.005907008, 0.009168561]]\n",
            "1046       [[0.98594296, 0.00015642555, 0.013900571]]\n",
            "1047       [[0.0026962382, 4.025713e-05, 0.99726343]]\n",
            "1048        [[0.96969956, 0.0029980876, 0.027302299]]\n",
            "1049      [[0.0003500705, 1.6439355e-05, 0.99963343]]\n",
            "1050     [[0.00066603953, 0.00011927015, 0.99921465]]\n",
            "1051         [[0.94851536, 0.0008603246, 0.05062424]]\n",
            "1052      [[0.0003500705, 1.6439355e-05, 0.99963343]]\n",
            "1053      [[0.00041032236, 0.00012134695, 0.9994684]]\n",
            "1054      [[0.00041032236, 0.00012134695, 0.9994684]]\n",
            "1055            [[0.0492581, 0.15325874, 0.79748315]]\n",
            "1056       [[0.0004658548, 0.0002844312, 0.99924964]]\n",
            "1057      [[0.00060229184, 0.00076462625, 0.9986331]]\n",
            "1058      [[0.00041032236, 0.00012134695, 0.9994684]]\n",
            "1059         [[0.0020519667, 5.899173e-05, 0.997889]]\n",
            "1060       [[0.0009446991, 4.533059e-05, 0.99900985]]\n",
            "1061         [[0.0012985559, 0.017617533, 0.9810839]]\n",
            "1062        [[0.0004601396, 0.0022026487, 0.9973373]]\n",
            "1063        [[0.0004601396, 0.0022026487, 0.9973373]]\n",
            "1064       [[0.004083831, 2.7437682e-05, 0.99588877]]\n",
            "1065       [[0.00062643737, 2.0569329e-05, 0.999353]]\n",
            "1066         [[0.017240293, 0.0009038049, 0.9818558]]\n",
            "1067         [[0.09225139, 0.0065393355, 0.90120924]]\n",
            "1068        [[0.0035760384, 0.0018314589, 0.9945925]]\n",
            "1069         [[0.89765435, 0.042472303, 0.059873335]]\n",
            "1070           [[0.29040205, 0.09439451, 0.61520344]]\n",
            "1071          [[0.0017452895, 0.5430869, 0.45516783]]\n",
            "1072         [[0.0026912976, 0.008787125, 0.9885216]]\n",
            "1073          [[0.005644447, 0.006058568, 0.9882969]]\n",
            "1074       [[0.0017112319, 2.0176953e-05, 0.9982685]]\n",
            "1075     [[0.00039257843, 2.0030695e-05, 0.99958736]]\n",
            "1076      [[0.00040906592, 3.9449544e-05, 0.9995515]]\n",
            "1077      [[0.00027788006, 3.6701913e-05, 0.9996854]]\n",
            "1078        [[0.0002821199, 1.227013e-05, 0.9997056]]\n",
            "1079        [[0.876697, 0.000115544244, 0.123187385]]\n",
            "1080           [[0.13939415, 0.8530965, 0.007509369]]\n",
            "1081           [[0.00653988, 0.014400484, 0.9790596]]\n",
            "1082           [[0.01420183, 0.20008065, 0.78571755]]\n",
            "1083        [[0.0011079623, 6.209587e-05, 0.9988299]]\n",
            "1084          [[0.013928467, 0.07268386, 0.91338766]]\n",
            "1085        [[0.876697, 0.000115544244, 0.123187385]]\n",
            "1086           [[0.9191139, 0.003947649, 0.07693846]]\n",
            "1087            [[0.09558688, 0.16951782, 0.7348952]]\n",
            "1088        [[0.0006785382, 4.291585e-05, 0.9992786]]\n",
            "1089          [[0.13720211, 0.113534085, 0.74926376]]\n",
            "1090        [[0.0005624803, 0.00045859817, 0.998979]]\n",
            "1091       [[0.00061859016, 2.095732e-05, 0.9993605]]\n",
            "1092           [[0.0076591484, 0.3428874, 0.6494534]]\n",
            "1093           [[0.5294554, 0.45033538, 0.020209257]]\n",
            "1094             [[0.33877137, 0.00491667, 0.656312]]\n",
            "1095           [[0.09082998, 0.02277609, 0.88639396]]\n",
            "1096     [[0.00037976366, 1.6139298e-05, 0.99960417]]\n",
            "1097       [[0.00027786547, 0.0001377407, 0.9995844]]\n",
            "1098          [[0.005448301, 0.11305574, 0.88149595]]\n",
            "1099          [[0.005448301, 0.11305574, 0.88149595]]\n",
            "1100        [[0.0005473991, 0.0012880508, 0.9981646]]\n",
            "1101       [[0.0008593545, 8.4801286e-05, 0.9990558]]\n",
            "1102        [[0.0013943161, 0.028754437, 0.96985126]]\n",
            "1103           [[0.31033617, 0.55045706, 0.13920677]]\n",
            "1104          [[0.005448301, 0.11305574, 0.88149595]]\n",
            "1105       [[0.0012888971, 3.9322353e-05, 0.9986719]]\n",
            "1106       [[0.0012823318, 1.6546383e-05, 0.9987011]]\n",
            "1107            [[0.02200316, 0.6376821, 0.34031484]]\n",
            "1108        [[0.0010748889, 0.0005089866, 0.9984162]]\n",
            "1109        [[0.0006553372, 2.3739301e-05, 0.999321]]\n",
            "1110       [[0.00091190863, 4.645421e-05, 0.9990416]]\n",
            "1111      [[0.0015182566, 0.00026507364, 0.99821657]]\n",
            "1112      [[0.00077412935, 4.427997e-05, 0.99918157]]\n",
            "1113       [[0.0009117772, 2.6709751e-05, 0.9990615]]\n",
            "1114       [[0.0006612121, 3.9423834e-05, 0.9992993]]\n",
            "1115        [[0.0018211473, 0.0047896584, 0.9933891]]\n",
            "1116       [[0.00068134366, 0.0021821896, 0.9971365]]\n",
            "1117       [[0.0006061768, 2.7133481e-05, 0.9993667]]\n",
            "1118          [[0.0024252415, 0.17932568, 0.8182491]]\n",
            "1119          [[0.0001919706, 0.99779, 0.0020180359]]\n",
            "1120          [[0.0001919706, 0.99779, 0.0020180359]]\n",
            "1121           [[0.016888084, 0.7465017, 0.23661022]]\n",
            "1122          [[0.0020279943, 0.05390587, 0.9440661]]\n",
            "1123         [[0.00044530505, 0.9286263, 0.07092846]]\n",
            "1124          [[0.0001919706, 0.99779, 0.0020180359]]\n",
            "1125          [[0.0024252415, 0.17932568, 0.8182491]]\n",
            "1126         [[0.0018105821, 0.00039943276, 0.99779]]\n",
            "1127       [[0.0011750603, 1.2091023e-05, 0.9988128]]\n",
            "1128         [[0.008086046, 0.006128941, 0.98578495]]\n",
            "1129           [[0.025705094, 0.32389307, 0.6504019]]\n",
            "1130           [[0.025705094, 0.32389307, 0.6504019]]\n",
            "1131      [[0.00052142475, 3.344913e-05, 0.99944514]]\n",
            "1132      [[0.0005860718, 0.00035732493, 0.99905664]]\n",
            "1133      [[0.00052142475, 3.344913e-05, 0.99944514]]\n",
            "1134            [[0.20913555, 0.13162838, 0.6592361]]\n",
            "1135       [[0.00072734774, 3.121864e-05, 0.9992415]]\n",
            "1136        [[0.003485719, 0.00019437393, 0.9963199]]\n",
            "1137      [[0.00030162313, 1.44471505e-05, 0.999684]]\n",
            "1138      [[0.00046290475, 2.9321898e-05, 0.9995078]]\n",
            "1139      [[0.0010616971, 9.6909214e-05, 0.99884146]]\n",
            "1140       [[0.0017910824, 4.3707158e-05, 0.9981653]]\n",
            "1141          [[0.0068213125, 0.37240875, 0.6207699]]\n",
            "1142          [[0.9805862, 0.010443871, 0.008969944]]\n",
            "1143         [[0.0020288518, 0.89063954, 0.10733156]]\n",
            "1144          [[0.0020901877, 0.7954228, 0.20248711]]\n",
            "1145          [[0.0016114215, 0.9194401, 0.07894851]]\n",
            "1146          [[0.007615651, 0.019821694, 0.9725627]]\n",
            "1147          [[0.042125355, 0.013463442, 0.9444112]]\n",
            "1148           [[0.003079533, 0.24444918, 0.7524712]]\n",
            "1149           [[0.021985633, 0.8003598, 0.17765461]]\n",
            "1150           [[0.021985633, 0.8003598, 0.17765461]]\n",
            "1151       [[0.0022708045, 0.00010149028, 0.9976278]]\n",
            "1152      [[0.00068374194, 4.168107e-05, 0.99927455]]\n",
            "1153          [[0.0001976, 0.00018513617, 0.9996172]]\n",
            "1154        [[0.016838301, 0.0044910996, 0.97867066]]\n",
            "1155        [[0.0004142206, 0.0002185668, 0.9993672]]\n",
            "1156         [[0.0012408028, 0.00533508, 0.99342406]]\n",
            "1157        [[0.0039078905, 0.018521525, 0.97757053]]\n",
            "1158       [[0.00029331204, 0.0005569193, 0.9991497]]\n",
            "1159         [[0.0012408028, 0.00533508, 0.99342406]]\n",
            "1160       [[0.0008088527, 1.9693998e-05, 0.9991715]]\n",
            "1161        [[0.0008616117, 0.0002224702, 0.9989159]]\n",
            "1162        [[0.013703473, 0.0022066752, 0.98408985]]\n",
            "1163         [[0.0012408028, 0.00533508, 0.99342406]]\n",
            "1164     [[0.0019294926, 0.000112509435, 0.99795794]]\n",
            "1165      [[0.00051426556, 8.966572e-06, 0.99947685]]\n",
            "1166      [[0.0008407253, 3.9754505e-05, 0.99911946]]\n",
            "1167      [[0.0010120216, 0.00010269504, 0.99888533]]\n",
            "1168          [[0.015992615, 0.032612972, 0.9513944]]\n",
            "1169     [[0.0019294926, 0.000112509435, 0.99795794]]\n",
            "1170        [[0.0010940911, 0.0006127303, 0.9982931]]\n",
            "1171     [[0.00014140994, 0.00053904025, 0.99931955]]\n",
            "1172          [[0.0015143136, 0.14861989, 0.8498658]]\n",
            "1173     [[0.00025515902, 3.7726113e-05, 0.99970704]]\n",
            "1174        [[0.00021330533, 2.173686e-05, 0.999765]]\n",
            "1175       [[0.00027172946, 2.471784e-05, 0.9997036]]\n",
            "1176         [[0.0014739408, 1.001722e-05, 0.998516]]\n",
            "1177      [[0.00070751534, 0.0032931056, 0.99599934]]\n",
            "1178         [[0.0014356965, 0.0017452149, 0.996819]]\n",
            "1179           [[0.04600035, 0.095594935, 0.8584047]]\n",
            "1180             [[0.06889872, 0.3826806, 0.5484206]]\n",
            "1181         [[0.0022290072, 9.98106e-05, 0.9976712]]\n",
            "1182      [[0.00068274303, 2.6035817e-05, 0.9992912]]\n",
            "1183          [[0.22345144, 0.7754268, 0.0011217649]]\n",
            "1184          [[0.9061095, 0.09194009, 0.0019503117]]\n",
            "1185          [[0.00091873173, 0.14410928, 0.854972]]\n",
            "1186      [[0.00031659906, 0.00019028863, 0.9994931]]\n",
            "1187         [[0.0005070199, 0.015216648, 0.9842763]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# state_dict/bert_spc_combined_ori_val_f1_0.784\n",
        "!cd ta-dictabsa && python3 infer_example.py"
      ],
      "id": "dc3c319d-6779-4f11-a7cc-c9ea8549650b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB_57JpCIn79"
      },
      "source": [
        "## s1 state_dict/bert_spc_combined_raw_know_val_f1_0.7698"
      ],
      "id": "uB_57JpCIn79"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "IkXPso-NIn8A"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IkXPso-NIn8A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "baaabfa9-8d83-4b1b-e51e-e85549da5f8d",
        "id": "961QzHUyIn8A"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0              [[0.5265422, 0.30811977, 0.16533808]]\n",
            "1            [[0.031332083, 0.68561375, 0.28305417]]\n",
            "2              [[0.10825963, 0.54537684, 0.3463635]]\n",
            "3             [[0.38406143, 0.5610393, 0.054899275]]\n",
            "4              [[0.2524697, 0.41002357, 0.33750674]]\n",
            "5            [[0.010593324, 0.040807478, 0.9485992]]\n",
            "6               [[0.00979819, 0.2995249, 0.6906769]]\n",
            "7             [[0.010683374, 0.28025395, 0.7090627]]\n",
            "8            [[0.0054024383, 0.34369457, 0.6509029]]\n",
            "9              [[0.057671413, 0.11432454, 0.828004]]\n",
            "10           [[0.014093807, 0.027419038, 0.9584872]]\n",
            "11          [[0.0008356667, 0.93532246, 0.06384182]]\n",
            "12         [[0.0054037217, 0.91935664, 0.075239636]]\n",
            "13           [[0.0007835832, 0.9677558, 0.03146061]]\n",
            "14             [[0.006443215, 0.833248, 0.16030878]]\n",
            "15           [[0.013900374, 0.003724908, 0.9823747]]\n",
            "16          [[0.9819978, 0.013329866, 0.0046723494]]\n",
            "17           [[0.0013248404, 0.00504342, 0.9936318]]\n",
            "18         [[0.002087357, 0.0023276415, 0.99558496]]\n",
            "19          [[0.0007419524, 0.011174763, 0.9880833]]\n",
            "20           [[0.036159515, 0.31261033, 0.65123016]]\n",
            "21              [[0.032988213, 0.343954, 0.6230578]]\n",
            "22          [[0.022979159, 0.036272805, 0.94074804]]\n",
            "23           [[0.036159515, 0.31261033, 0.65123016]]\n",
            "24           [[0.036159515, 0.31261033, 0.65123016]]\n",
            "25            [[0.063634224, 0.5135094, 0.42285636]]\n",
            "26          [[0.0033898028, 0.0002922176, 0.996318]]\n",
            "27          [[0.009502026, 0.0014489101, 0.9890491]]\n",
            "28         [[0.001796423, 0.00034013705, 0.9978635]]\n",
            "29        [[0.0010419716, 0.0019323061, 0.99702567]]\n",
            "30            [[0.002736439, 0.28409195, 0.7131716]]\n",
            "31            [[0.05555449, 0.12984173, 0.81460375]]\n",
            "32          [[0.0022353868, 0.025963793, 0.9718008]]\n",
            "33        [[0.0013646408, 0.0006445931, 0.99799085]]\n",
            "34          [[0.007661451, 0.085203774, 0.90713483]]\n",
            "35         [[0.0022564041, 0.0050686607, 0.9926749]]\n",
            "36             [[0.008162292, 0.3872696, 0.6045681]]\n",
            "37            [[0.59882057, 0.35658935, 0.04459007]]\n",
            "38           [[0.036380142, 0.51934946, 0.44427043]]\n",
            "39        [[0.0031968902, 0.0008650091, 0.99593806]]\n",
            "40           [[0.0073528984, 0.09985833, 0.8927887]]\n",
            "41         [[0.0053394474, 0.0011138105, 0.9935468]]\n",
            "42        [[0.003655138, 0.00074639835, 0.99559844]]\n",
            "43           [[0.0017219464, 0.0019180073, 0.99636]]\n",
            "44            [[0.05612911, 0.9190327, 0.024838163]]\n",
            "45           [[0.053337064, 0.24825467, 0.69840825]]\n",
            "46              [[0.40406814, 0.30707383, 0.288858]]\n",
            "47          [[0.015982842, 0.93072265, 0.053294513]]\n",
            "48            [[0.05555449, 0.12984173, 0.81460375]]\n",
            "49              [[0.054456722, 0.7291762, 0.216367]]\n",
            "50          [[0.0016389551, 0.07957771, 0.91878325]]\n",
            "51            [[0.06155173, 0.30649957, 0.63194877]]\n",
            "52             [[0.06437856, 0.33917278, 0.5964486]]\n",
            "53           [[0.019794744, 0.43405244, 0.54615283]]\n",
            "54            [[0.004727956, 0.34745985, 0.6478122]]\n",
            "55            [[0.023129858, 0.63527226, 0.3415978]]\n",
            "56            [[0.016244816, 0.11316869, 0.8705865]]\n",
            "57            [[0.027710233, 0.3116923, 0.66059744]]\n",
            "58           [[0.006422902, 0.79238737, 0.20118971]]\n",
            "59           [[0.034760457, 0.81102216, 0.15421735]]\n",
            "60         [[0.0048282123, 0.0030999966, 0.9920718]]\n",
            "61           [[0.001916705, 0.046914827, 0.9511685]]\n",
            "62         [[0.008984018, 0.0030480945, 0.98796785]]\n",
            "63            [[0.009597281, 0.002333677, 0.988069]]\n",
            "64          [[0.011479729, 0.029908052, 0.95861214]]\n",
            "65           [[0.024581587, 0.0046004495, 0.970818]]\n",
            "66          [[0.015908405, 0.002325755, 0.98176587]]\n",
            "67        [[0.99307173, 0.0046518287, 0.0022763473]]\n",
            "68            [[0.090113185, 0.18314204, 0.7267447]]\n",
            "69         [[0.049083587, 0.94276947, 0.0081469575]]\n",
            "70             [[0.9054257, 0.0863844, 0.008189955]]\n",
            "71             [[0.71224016, 0.05248751, 0.2352724]]\n",
            "72         [[0.0025254765, 0.0056666043, 0.9918079]]\n",
            "73           [[0.005138366, 0.124971874, 0.8698898]]\n",
            "74           [[0.001409976, 0.017465867, 0.9811242]]\n",
            "75           [[0.47591978, 0.019065367, 0.50501484]]\n",
            "76           [[0.0033697602, 0.12152579, 0.8751045]]\n",
            "77            [[0.49597114, 0.15556641, 0.34846246]]\n",
            "78            [[0.02886733, 0.07441731, 0.89671534]]\n",
            "79            [[0.04397688, 0.19052437, 0.76549876]]\n",
            "80          [[0.0009848317, 0.008790221, 0.9902249]]\n",
            "81         [[0.0030925162, 0.0018261158, 0.9950814]]\n",
            "82           [[0.009137132, 0.00250841, 0.98835444]]\n",
            "83            [[0.9913311, 0.0018332605, 0.0068357]]\n",
            "84          [[0.0076352484, 0.004127972, 0.9882367]]\n",
            "85           [[0.25021437, 0.70853066, 0.041254934]]\n",
            "86           [[0.8548762, 0.14087047, 0.0042532706]]\n",
            "87        [[0.0022408646, 0.0012096677, 0.99654937]]\n",
            "88           [[0.019335313, 0.038134035, 0.9425307]]\n",
            "89            [[0.047578007, 0.105751015, 0.846671]]\n",
            "90         [[0.0023664704, 0.0011657762, 0.9964677]]\n",
            "91          [[0.015173947, 0.96453464, 0.020291347]]\n",
            "92         [[0.0011102365, 0.122236595, 0.87665313]]\n",
            "93            [[0.03873902, 0.8451355, 0.116125435]]\n",
            "94             [[0.69266915, 0.1513765, 0.15595435]]\n",
            "95            [[0.8508906, 0.042560104, 0.10654925]]\n",
            "96            [[0.03621558, 0.16896318, 0.79482126]]\n",
            "97         [[0.0034184589, 0.0071325866, 0.9894489]]\n",
            "98            [[0.024204163, 0.029146794, 0.946649]]\n",
            "99          [[0.01013478, 0.0013973523, 0.98846775]]\n",
            "100       [[0.0034446989, 0.0008255279, 0.99572974]]\n",
            "101          [[0.0017158248, 0.27535897, 0.7229251]]\n",
            "102          [[0.0018440761, 0.025473898, 0.972682]]\n",
            "103          [[0.005685876, 0.014396968, 0.9799171]]\n",
            "104          [[0.008723017, 0.006144231, 0.9851328]]\n",
            "105          [[0.003302646, 0.056596424, 0.9401009]]\n",
            "106        [[0.0024464715, 0.0014376352, 0.9961158]]\n",
            "107         [[0.0016943754, 0.031377092, 0.9669284]]\n",
            "108        [[0.0015240476, 0.0037542107, 0.9947218]]\n",
            "109         [[0.0015002368, 0.014432612, 0.9840671]]\n",
            "110           [[0.038865082, 0.15991352, 0.8012214]]\n",
            "111        [[0.0016402426, 0.0014369816, 0.9969228]]\n",
            "112          [[0.051914703, 0.19900613, 0.74907917]]\n",
            "113           [[0.04327421, 0.67518395, 0.28154188]]\n",
            "114            [[0.25897697, 0.6504877, 0.09053533]]\n",
            "115           [[0.03801221, 0.71355414, 0.24843363]]\n",
            "116          [[0.022745114, 0.82823837, 0.14901653]]\n",
            "117        [[0.0014732173, 0.001776387, 0.99675035]]\n",
            "118          [[0.0007650681, 0.8743975, 0.12483739]]\n",
            "119          [[0.025415115, 0.54692304, 0.42766184]]\n",
            "120          [[0.0038653763, 0.6693361, 0.32679853]]\n",
            "121         [[0.0048865643, 0.007129178, 0.9879843]]\n",
            "122           [[0.034629337, 0.27125615, 0.6941145]]\n",
            "123         [[0.006996519, 0.0016806215, 0.9913229]]\n",
            "124          [[0.014106247, 0.68194234, 0.30395144]]\n",
            "125          [[0.009454081, 0.010883719, 0.9796622]]\n",
            "126            [[0.014109361, 0.2290833, 0.7568074]]\n",
            "127         [[0.0068973815, 0.10608262, 0.88701993]]\n",
            "128           [[0.036514506, 0.3987846, 0.56470084]]\n",
            "129        [[0.0049686125, 0.0011637581, 0.9938676]]\n",
            "130           [[0.006635407, 0.016416589, 0.976948]]\n",
            "131          [[0.992078, 0.0027213334, 0.005200653]]\n",
            "132            [[0.4645584, 0.10574716, 0.42969438]]\n",
            "133           [[0.03545593, 0.16200686, 0.80253726]]\n",
            "134           [[0.20569019, 0.7250844, 0.069225386]]\n",
            "135           [[0.043697543, 0.8909905, 0.06531191]]\n",
            "136         [[0.008768009, 0.047082003, 0.94415003]]\n",
            "137           [[0.010911084, 0.01797421, 0.9711148]]\n",
            "138        [[0.001650455, 0.0015823363, 0.99676716]]\n",
            "139          [[0.027815154, 0.07572691, 0.89645797]]\n",
            "140        [[0.017545128, 0.0025237522, 0.97993124]]\n",
            "141         [[0.98557657, 0.003616813, 0.010806587]]\n",
            "142           [[0.8453275, 0.12603317, 0.028639376]]\n",
            "143           [[0.00092502, 0.010452213, 0.9886227]]\n",
            "144           [[0.008511176, 0.1796893, 0.81179947]]\n",
            "145        [[0.0019596484, 0.0010528654, 0.9969875]]\n",
            "146        [[0.0025675416, 0.008959259, 0.98847324]]\n",
            "147          [[0.004330271, 0.89886105, 0.09680872]]\n",
            "148          [[0.41664225, 0.46784762, 0.115510136]]\n",
            "149        [[0.0032127702, 0.016076686, 0.98071045]]\n",
            "150          [[0.003244704, 0.011024396, 0.9857308]]\n",
            "151           [[0.22421633, 0.41522384, 0.36055985]]\n",
            "152        [[0.0020417129, 0.009999166, 0.98795915]]\n",
            "153       [[0.0003649966, 0.99872786, 0.0009070835]]\n",
            "154         [[0.0012450418, 0.024918167, 0.9738367]]\n",
            "155          [[0.0012979516, 0.982018, 0.016684014]]\n",
            "156           [[0.004835668, 0.9499289, 0.04523549]]\n",
            "157           [[0.023466714, 0.8955685, 0.08096481]]\n",
            "158           [[0.33380342, 0.6401022, 0.026094357]]\n",
            "159         [[0.027970714, 0.93166655, 0.040362768]]\n",
            "160           [[0.009265525, 0.8884515, 0.10228302]]\n",
            "161            [[0.07845609, 0.16930869, 0.7522352]]\n",
            "162        [[0.014832103, 0.00092882226, 0.9842391]]\n",
            "163             [[0.01570407, 0.1725077, 0.8117882]]\n",
            "164           [[0.037111938, 0.05764794, 0.9052402]]\n",
            "165        [[0.97380584, 0.0012839799, 0.024910167]]\n",
            "166         [[0.92793804, 0.025504168, 0.046557818]]\n",
            "167        [[0.0023446663, 0.0012942132, 0.9963612]]\n",
            "168             [[0.06884345, 0.40863252, 0.522524]]\n",
            "169        [[0.009648407, 0.0049176565, 0.98543394]]\n",
            "170         [[0.008797847, 0.011192435, 0.98000973]]\n",
            "171         [[0.0051557873, 0.009366817, 0.9854775]]\n",
            "172           [[0.018767457, 0.08324267, 0.8979898]]\n",
            "173         [[0.015885826, 0.014213541, 0.96990067]]\n",
            "174              [[0.027202, 0.44872537, 0.5240726]]\n",
            "175       [[0.0020429774, 0.0012241493, 0.99673283]]\n",
            "176         [[0.0031262082, 0.007859556, 0.9890142]]\n",
            "177         [[0.0019631744, 0.015023684, 0.9830131]]\n",
            "178         [[0.0050954362, 0.010502129, 0.9844024]]\n",
            "179           [[0.008611615, 0.7691888, 0.22219953]]\n",
            "180         [[0.9808775, 0.0061223805, 0.013000093]]\n",
            "181         [[0.0061449264, 0.007533367, 0.9863217]]\n",
            "182            [[0.04615437, 0.35545424, 0.5983915]]\n",
            "183           [[0.014999244, 0.18950443, 0.7954963]]\n",
            "184           [[0.14867292, 0.022941267, 0.8283858]]\n",
            "185        [[0.0034869676, 0.0099808015, 0.9865323]]\n",
            "186        [[0.0024438878, 0.0038975936, 0.9936585]]\n",
            "187        [[0.0034869676, 0.0099808015, 0.9865323]]\n",
            "188          [[0.022291193, 0.09917528, 0.87853354]]\n",
            "189           [[0.00547148, 0.48541275, 0.50911576]]\n",
            "190           [[0.007529945, 0.5837533, 0.40871674]]\n",
            "191            [[0.0642651, 0.38565865, 0.55007625]]\n",
            "192         [[0.0040793167, 0.84263676, 0.15328392]]\n",
            "193         [[0.0058824164, 0.051141303, 0.9429763]]\n",
            "194        [[0.0061853877, 0.054165907, 0.93964875]]\n",
            "195            [[0.01561462, 0.8688111, 0.11557429]]\n",
            "196        [[0.0015060013, 0.9928591, 0.0056348946]]\n",
            "197        [[0.00039745707, 0.95851487, 0.04108759]]\n",
            "198         [[0.002580243, 0.0043806727, 0.9930392]]\n",
            "199        [[0.0030384397, 0.026783736, 0.97017777]]\n",
            "200             [[0.5543587, 0.19904268, 0.2465986]]\n",
            "201            [[0.02934692, 0.013995062, 0.956658]]\n",
            "202         [[0.004160798, 0.010374619, 0.98546463]]\n",
            "203          [[0.9942767, 0.002158015, 0.003565339]]\n",
            "204           [[0.013789814, 0.7806638, 0.20554638]]\n",
            "205        [[0.0042673596, 0.011231978, 0.98450065]]\n",
            "206          [[0.011939351, 0.9782615, 0.009799095]]\n",
            "207             [[0.10575628, 0.1185418, 0.7757019]]\n",
            "208         [[0.0030493436, 0.012936606, 0.9840141]]\n",
            "209         [[0.0025881492, 0.009037121, 0.9883747]]\n",
            "210          [[0.009429834, 0.006503477, 0.9840667]]\n",
            "211      [[0.0034718742, 0.00050521235, 0.99602294]]\n",
            "212      [[0.0020175907, 0.00081232213, 0.99717003]]\n",
            "213           [[0.040964916, 0.4649873, 0.49404782]]\n",
            "214          [[0.0044507612, 0.30117476, 0.6943745]]\n",
            "215          [[0.0010162587, 0.010474744, 0.988509]]\n",
            "216         [[0.00071002106, 0.8975803, 0.10170963]]\n",
            "217         [[0.0020666067, 0.015689347, 0.9822441]]\n",
            "218        [[0.0012477312, 0.020537447, 0.97821486]]\n",
            "219          [[0.0062133423, 0.01022513, 0.9835616]]\n",
            "220        [[0.0029572314, 0.026370322, 0.97067237]]\n",
            "221        [[0.0017726719, 0.0019115203, 0.9963159]]\n",
            "222        [[0.0032839742, 0.0041275066, 0.9925884]]\n",
            "223            [[0.10093019, 0.7062628, 0.19280697]]\n",
            "224         [[0.003907799, 0.018557692, 0.97753453]]\n",
            "225        [[0.008800046, 0.0036686251, 0.98753136]]\n",
            "226             [[0.5170973, 0.3531002, 0.12980251]]\n",
            "227           [[0.0030900468, 0.793648, 0.20326196]]\n",
            "228        [[0.0003786933, 0.99274457, 0.006876737]]\n",
            "229        [[0.0009132756, 0.96395564, 0.035131045]]\n",
            "230          [[0.0066623897, 0.32019985, 0.6731378]]\n",
            "231             [[0.05554306, 0.3784823, 0.5659746]]\n",
            "232          [[0.36606362, 0.092809215, 0.54112715]]\n",
            "233       [[0.0016790733, 0.0069696307, 0.99135125]]\n",
            "234            [[0.7491005, 0.14127852, 0.10962096]]\n",
            "235         [[0.032792225, 0.041136477, 0.92607135]]\n",
            "236             [[0.013537496, 0.0413965, 0.945066]]\n",
            "237            [[0.004170284, 0.03015182, 0.965678]]\n",
            "238         [[0.98816305, 0.005657964, 0.006178944]]\n",
            "239          [[0.007248281, 0.007694559, 0.9850572]]\n",
            "240            [[0.6071188, 0.21260999, 0.18027121]]\n",
            "241         [[0.0028372055, 0.010108165, 0.9870546]]\n",
            "242           [[0.05197399, 0.14522047, 0.80280554]]\n",
            "243          [[0.050334167, 0.73195773, 0.21770808]]\n",
            "244            [[0.04063915, 0.16483921, 0.7945216]]\n",
            "245        [[0.000822122, 0.99222517, 0.0069526657]]\n",
            "246         [[0.026782611, 0.0028501777, 0.9703672]]\n",
            "247         [[0.081847146, 0.009724437, 0.90842843]]\n",
            "248            [[0.050060503, 0.0200821, 0.9298575]]\n",
            "249       [[0.0042245057, 0.00096693396, 0.9948085]]\n",
            "250          [[0.0024892907, 0.00608296, 0.9914278]]\n",
            "251        [[0.0066231233, 0.0036596912, 0.9897171]]\n",
            "252        [[0.0066231233, 0.0036596912, 0.9897171]]\n",
            "253       [[0.0018690717, 0.0021131423, 0.99601775]]\n",
            "254          [[0.010322869, 0.18336289, 0.80631423]]\n",
            "255            [[0.00489232, 0.1485812, 0.84652644]]\n",
            "256          [[0.006107344, 0.33821306, 0.65567964]]\n",
            "257         [[0.003051478, 0.013235519, 0.98371303]]\n",
            "258        [[0.0011316583, 0.0034695647, 0.9953988]]\n",
            "259          [[0.0029504753, 0.13768473, 0.8593648]]\n",
            "260         [[0.0028707085, 0.89803857, 0.09909068]]\n",
            "261           [[0.008366585, 0.7826574, 0.20897602]]\n",
            "262          [[0.0050487444, 0.46854383, 0.5264074]]\n",
            "263           [[0.019529115, 0.09162912, 0.8888417]]\n",
            "264      [[0.99813277, 0.00028096588, 0.0015863653]]\n",
            "265          [[0.03211339, 0.121857755, 0.84602886]]\n",
            "266           [[0.010438137, 0.0629562, 0.92660564]]\n",
            "267            [[0.15304816, 0.20583318, 0.6411187]]\n",
            "268            [[0.15304816, 0.20583318, 0.6411187]]\n",
            "269            [[0.09280292, 0.10874341, 0.7984536]]\n",
            "270          [[0.20652235, 0.027723592, 0.76575404]]\n",
            "271            [[0.6773482, 0.07988917, 0.24276266]]\n",
            "272         [[0.004078911, 0.005820211, 0.99010086]]\n",
            "273          [[0.0016740395, 0.012125049, 0.986201]]\n",
            "274        [[0.0018575175, 0.003676677, 0.99446577]]\n",
            "275          [[0.0021263415, 0.49578488, 0.5020888]]\n",
            "276        [[0.0022186846, 0.109683365, 0.88809794]]\n",
            "277           [[0.010454156, 0.09096908, 0.8985768]]\n",
            "278        [[0.0048254887, 0.0025041613, 0.9926703]]\n",
            "279           [[0.009118181, 0.03139855, 0.9594833]]\n",
            "280          [[0.038711395, 0.12680326, 0.83448535]]\n",
            "281         [[0.0015192423, 0.88504046, 0.11344031]]\n",
            "282         [[0.0016809141, 0.001728712, 0.9965904]]\n",
            "283          [[0.0037503703, 0.16488522, 0.8313644]]\n",
            "284         [[0.010982339, 0.115118906, 0.87389874]]\n",
            "285        [[0.0005602085, 0.9861604, 0.0132794045]]\n",
            "286          [[0.0018579535, 0.6901871, 0.30795497]]\n",
            "287        [[0.0061614253, 0.004612956, 0.98922557]]\n",
            "288           [[0.40255055, 0.10098355, 0.49646598]]\n",
            "289        [[0.004048687, 0.0011560643, 0.99479514]]\n",
            "290           [[0.40255055, 0.10098355, 0.49646598]]\n",
            "291          [[0.046213787, 0.075069636, 0.8787166]]\n",
            "292         [[0.0021774387, 0.032510396, 0.9653122]]\n",
            "293        [[0.010395038, 0.0025571554, 0.98704785]]\n",
            "294           [[0.022908127, 0.6879883, 0.28910357]]\n",
            "295           [[0.003683677, 0.18590459, 0.8104117]]\n",
            "296           [[0.0088304775, 0.23990758, 0.751262]]\n",
            "297         [[0.0022635548, 0.9668086, 0.030927783]]\n",
            "298           [[0.004806007, 0.6449946, 0.35019937]]\n",
            "299           [[0.006782732, 0.013408375, 0.979809]]\n",
            "300        [[0.010948364, 0.0049257493, 0.98412585]]\n",
            "301          [[0.003829171, 0.95898825, 0.03718254]]\n",
            "302       [[0.0014509426, 0.99645257, 0.0020964649]]\n",
            "303           [[0.006117032, 0.45560437, 0.5382786]]\n",
            "304         [[0.0031844552, 0.012632283, 0.9841834]]\n",
            "305           [[0.00414952, 0.78070414, 0.21514632]]\n",
            "306           [[0.010036998, 0.24294357, 0.7470194]]\n",
            "307           [[0.005171006, 0.16513626, 0.8296928]]\n",
            "308          [[0.0057371063, 0.6087621, 0.38550076]]\n",
            "309           [[0.009762665, 0.6785946, 0.31164277]]\n",
            "310         [[0.0062503647, 0.0028317452, 0.990918]]\n",
            "311         [[0.0048954934, 0.0018804871, 0.993224]]\n",
            "312          [[0.006780277, 0.80243576, 0.19078395]]\n",
            "313        [[0.006123349, 0.0077086594, 0.98616797]]\n",
            "314       [[0.0007702677, 0.00068948173, 0.9985403]]\n",
            "315       [[0.0099068135, 0.0027234307, 0.98736984]]\n",
            "316          [[0.003530114, 0.005370557, 0.9910993]]\n",
            "317       [[0.0015844011, 0.0014636066, 0.99695194]]\n",
            "318       [[0.0023193746, 0.0008677556, 0.99681276]]\n",
            "319            [[0.00865383, 0.34876454, 0.6425816]]\n",
            "320           [[0.005770029, 0.53022444, 0.4640055]]\n",
            "321          [[0.030067395, 0.05310142, 0.91683114]]\n",
            "322        [[0.0073991553, 0.0013544345, 0.9912464]]\n",
            "323       [[0.0018700133, 0.0014062534, 0.99672383]]\n",
            "324           [[0.07998626, 0.14362939, 0.77638435]]\n",
            "325           [[0.00782028, 0.019494979, 0.9726847]]\n",
            "326           [[0.02421197, 0.013191285, 0.9625967]]\n",
            "327          [[0.040890668, 0.12767793, 0.83143145]]\n",
            "328         [[0.9974153, 0.001278107, 0.0013066451]]\n",
            "329            [[0.039111596, 0.10109239, 0.859796]]\n",
            "330         [[0.95627046, 0.023314798, 0.020414846]]\n",
            "331            [[0.039111596, 0.10109239, 0.859796]]\n",
            "332           [[0.8318711, 0.13385206, 0.034276918]]\n",
            "333          [[0.00549529, 0.0014654106, 0.9930393]]\n",
            "334         [[0.93981624, 0.051880978, 0.008302751]]\n",
            "335         [[0.0032810795, 0.96103114, 0.03568778]]\n",
            "336          [[0.76310825, 0.22672093, 0.010170745]]\n",
            "337         [[0.013047529, 0.0020427254, 0.9849097]]\n",
            "338        [[0.017710054, 0.0046673957, 0.97762257]]\n",
            "339         [[0.9536342, 0.0073752585, 0.038990587]]\n",
            "340            [[0.46990576, 0.513985, 0.016109303]]\n",
            "341            [[0.038132958, 0.1270718, 0.8347952]]\n",
            "342          [[0.0014840701, 0.002764937, 0.995751]]\n",
            "343      [[0.0034684162, 0.00084288185, 0.99568874]]\n",
            "344           [[0.082477175, 0.06502974, 0.8524931]]\n",
            "345       [[0.0021313862, 0.0022396834, 0.99562895]]\n",
            "346         [[0.004205923, 0.0013202113, 0.9944739]]\n",
            "347        [[0.99136263, 0.0036626812, 0.004974813]]\n",
            "348         [[0.023061056, 0.030605616, 0.94633335]]\n",
            "349            [[0.039501052, 0.0928662, 0.8676328]]\n",
            "350           [[0.18692394, 0.35714594, 0.45593017]]\n",
            "351        [[0.9930566, 0.0032352367, 0.0037081544]]\n",
            "352          [[0.0037862663, 0.012045749, 0.984168]]\n",
            "353           [[0.011434735, 0.46804807, 0.5205172]]\n",
            "354        [[0.0033668224, 0.024563387, 0.97206986]]\n",
            "355         [[0.0034913896, 0.008414369, 0.9880943]]\n",
            "356          [[0.0059488527, 0.26256138, 0.7314898]]\n",
            "357         [[0.005771575, 0.064653665, 0.92957485]]\n",
            "358           [[0.0149345035, 0.5183824, 0.4666831]]\n",
            "359          [[0.0061580837, 0.12476912, 0.8690728]]\n",
            "360           [[0.12586114, 0.39846972, 0.47566915]]\n",
            "361           [[0.015548614, 0.8865199, 0.09793147]]\n",
            "362           [[0.00448358, 0.96085995, 0.03465643]]\n",
            "363         [[0.0123096155, 0.042006735, 0.9456837]]\n",
            "364       [[0.0034917241, 0.99321765, 0.0032906458]]\n",
            "365         [[0.001294144, 0.9967816, 0.0019242448]]\n",
            "366       [[0.0009948805, 0.9984849, 0.00052028726]]\n",
            "367          [[0.82756853, 0.16122264, 0.011208867]]\n",
            "368       [[0.0049070544, 0.98393655, 0.0111564705]]\n",
            "369           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "370         [[0.0044083567, 0.014757327, 0.9808343]]\n",
            "371         [[0.0050416444, 0.016207546, 0.9787507]]\n",
            "372          [[0.006040262, 0.9789949, 0.014964793]]\n",
            "373        [[0.001073368, 0.00075479184, 0.9981718]]\n",
            "374          [[0.0019279023, 0.068804145, 0.929268]]\n",
            "375          [[0.035103455, 0.07961001, 0.88528657]]\n",
            "376         [[0.047230106, 0.019692512, 0.93307734]]\n",
            "377           [[0.7000838, 0.22082044, 0.079095684]]\n",
            "378            [[0.64287597, 0.1466275, 0.21049656]]\n",
            "379            [[0.03997889, 0.03526171, 0.9247595]]\n",
            "380           [[0.016646937, 0.8887569, 0.09459625]]\n",
            "381        [[0.004918336, 0.0053658937, 0.98971575]]\n",
            "382           [[0.9461793, 0.04520796, 0.008612744]]\n",
            "383          [[0.020206803, 0.89762616, 0.08216707]]\n",
            "384          [[0.020206803, 0.89762616, 0.08216707]]\n",
            "385         [[0.018945986, 0.88738865, 0.093665436]]\n",
            "386         [[0.0037775857, 0.003481647, 0.9927408]]\n",
            "387          [[0.00286802, 0.99131197, 0.005819999]]\n",
            "388           [[0.020302018, 0.08643101, 0.8932669]]\n",
            "389         [[0.0057099457, 0.9402557, 0.054034367]]\n",
            "390            [[0.10416823, 0.2307136, 0.66511816]]\n",
            "391           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "392         [[0.009275539, 0.009040137, 0.98168427]]\n",
            "393         [[0.027640633, 0.0030060324, 0.9693533]]\n",
            "394          [[0.011647417, 0.009498433, 0.9788542]]\n",
            "395            [[0.030990638, 0.81905437, 0.149955]]\n",
            "396             [[0.01665496, 0.959516, 0.02382899]]\n",
            "397        [[0.008801596, 0.98775953, 0.0034389254]]\n",
            "398          [[0.0030410646, 0.5076644, 0.48929456]]\n",
            "399          [[0.051632907, 0.16925414, 0.77911294]]\n",
            "400         [[0.0061501293, 0.9436096, 0.050240267]]\n",
            "401        [[0.0008405963, 0.96871334, 0.030446095]]\n",
            "402         [[0.0045989407, 0.17801195, 0.81738913]]\n",
            "403         [[0.0042176708, 0.9343922, 0.061390113]]\n",
            "404         [[0.000489594, 0.9966168, 0.0028936465]]\n",
            "405           [[0.004979098, 0.8590588, 0.13596213]]\n",
            "406      [[0.00021247054, 0.99686795, 0.0029195885]]\n",
            "407          [[0.013281553, 0.9720143, 0.014704116]]\n",
            "408        [[0.00027173912, 0.9917605, 0.007967778]]\n",
            "409            [[0.01167218, 0.7544486, 0.23387925]]\n",
            "410        [[0.0026957302, 0.040643826, 0.95666045]]\n",
            "411          [[0.010508389, 0.52407944, 0.46541223]]\n",
            "412           [[0.012633443, 0.7349385, 0.25242805]]\n",
            "413       [[0.0001495583, 0.99774593, 0.0021044398]]\n",
            "414        [[0.0032206841, 0.94915324, 0.047626052]]\n",
            "415            [[0.08903493, 0.51171666, 0.3992484]]\n",
            "416         [[0.0053853327, 0.020771874, 0.9738428]]\n",
            "417           [[0.09598811, 0.16267958, 0.74133223]]\n",
            "418         [[0.085817866, 0.033201925, 0.88098013]]\n",
            "419          [[0.009871936, 0.012947379, 0.9771806]]\n",
            "420          [[0.009871936, 0.012947379, 0.9771806]]\n",
            "421         [[0.0046523297, 0.0123646585, 0.982983]]\n",
            "422           [[0.024945272, 0.2652601, 0.70979464]]\n",
            "423            [[0.1983363, 0.058778983, 0.7428847]]\n",
            "424         [[0.004715539, 0.0077473684, 0.9875371]]\n",
            "425           [[0.22112882, 0.43269935, 0.34617183]]\n",
            "426          [[0.04844189, 0.005619912, 0.94593817]]\n",
            "427         [[0.002416957, 0.0068178438, 0.9907652]]\n",
            "428           [[0.004782197, 0.19276439, 0.8024534]]\n",
            "429       [[0.003974509, 0.00048072872, 0.99554473]]\n",
            "430           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "431          [[0.0040014707, 0.01863231, 0.9773662]]\n",
            "432        [[0.0042808424, 0.011339913, 0.98437923]]\n",
            "433         [[0.0020254047, 0.0032425825, 0.994732]]\n",
            "434           [[0.8295731, 0.015005577, 0.15542132]]\n",
            "435       [[0.00020359026, 0.9980621, 0.0017342842]]\n",
            "436         [[0.005192886, 0.0009873236, 0.9938198]]\n",
            "437            [[0.0381314, 0.09373125, 0.86813736]]\n",
            "438          [[0.014959766, 0.048473407, 0.9365668]]\n",
            "439       [[0.00084839127, 0.96640956, 0.032741997]]\n",
            "440           [[0.00056062, 0.9514543, 0.047985114]]\n",
            "441          [[0.0039631077, 0.16696574, 0.8290711]]\n",
            "442          [[0.029116523, 0.85573584, 0.11514767]]\n",
            "443        [[0.0012977852, 0.034032244, 0.96466994]]\n",
            "444          [[0.0034028783, 0.16292836, 0.8336687]]\n",
            "445         [[0.001524886, 0.0065425755, 0.9919326]]\n",
            "446          [[0.005306404, 0.041954476, 0.9527391]]\n",
            "447       [[0.0021077234, 0.0023610222, 0.99553126]]\n",
            "448           [[0.004597938, 0.12790541, 0.8674966]]\n",
            "449         [[0.0029750443, 0.49121872, 0.50580627]]\n",
            "450           [[0.007688917, 0.3593353, 0.63297576]]\n",
            "451            [[0.02120558, 0.6951551, 0.28363937]]\n",
            "452           [[0.025988381, 0.8495294, 0.12448231]]\n",
            "453            [[0.03533527, 0.34991938, 0.6147454]]\n",
            "454         [[0.0007082928, 0.95540327, 0.04388837]]\n",
            "455         [[0.009106695, 0.022424428, 0.96846884]]\n",
            "456         [[0.0028555554, 0.003127405, 0.9940171]]\n",
            "457           [[0.026860895, 0.10917102, 0.8639681]]\n",
            "458            [[0.06458517, 0.14371322, 0.7917017]]\n",
            "459           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "460        [[0.0019758998, 0.0020937114, 0.9959304]]\n",
            "461         [[0.0051644626, 0.021127272, 0.9737083]]\n",
            "462            [[0.011448849, 0.5688224, 0.4197288]]\n",
            "463          [[0.037537318, 0.09114595, 0.87131673]]\n",
            "464          [[0.0038519965, 0.10810556, 0.8880424]]\n",
            "465         [[0.0021655643, 0.006820053, 0.9910144]]\n",
            "466          [[0.0035399408, 0.9230786, 0.07338143]]\n",
            "467          [[0.006795768, 0.016107043, 0.9770972]]\n",
            "468          [[0.035560403, 0.65839034, 0.30604926]]\n",
            "469         [[0.0009073329, 0.021277582, 0.9778151]]\n",
            "470        [[0.0069129053, 0.023749422, 0.96933764]]\n",
            "471        [[0.98004514, 0.0054999357, 0.014454943]]\n",
            "472        [[0.0035171746, 0.0026401097, 0.9938427]]\n",
            "473        [[0.98004514, 0.0054999357, 0.014454943]]\n",
            "474        [[0.0075784414, 0.0022534486, 0.9901681]]\n",
            "475           [[0.0031738, 0.008393199, 0.98843306]]\n",
            "476        [[0.0031913903, 0.006113303, 0.99069524]]\n",
            "477          [[0.002731074, 0.006046306, 0.9912226]]\n",
            "478       [[0.0077548376, 0.0052608945, 0.98698425]]\n",
            "479          [[0.0040585925, 0.008630347, 0.987311]]\n",
            "480           [[0.0037917157, 0.0445179, 0.9516904]]\n",
            "481       [[0.0029015366, 0.0026769927, 0.99442154]]\n",
            "482          [[0.00092173705, 0.928115, 0.07096322]]\n",
            "483       [[0.0034822111, 0.0020587726, 0.99445903]]\n",
            "484       [[0.0013510606, 0.0017088146, 0.99694014]]\n",
            "485         [[0.0035691166, 0.01291101, 0.98351985]]\n",
            "486          [[0.0035572662, 0.9401063, 0.05633638]]\n",
            "487         [[0.0076986295, 0.65583324, 0.33646813]]\n",
            "488           [[0.008194073, 0.62423337, 0.3675726]]\n",
            "489             [[0.00792616, 0.0886374, 0.9034364]]\n",
            "490         [[0.0099143805, 0.011610978, 0.9784747]]\n",
            "491           [[0.042813003, 0.11699135, 0.8401956]]\n",
            "492            [[0.14034106, 0.14219877, 0.7174602]]\n",
            "493          [[0.00912605, 0.0018513355, 0.9890225]]\n",
            "494         [[0.012525696, 0.026243703, 0.96123064]]\n",
            "495             [[0.00792616, 0.0886374, 0.9034364]]\n",
            "496          [[0.038715295, 0.90706974, 0.05421494]]\n",
            "497            [[0.37851882, 0.4421216, 0.17935957]]\n",
            "498            [[0.17574744, 0.23726498, 0.5869875]]\n",
            "499           [[0.008076423, 0.43142065, 0.5605029]]\n",
            "500             [[0.04789585, 0.1394809, 0.8126232]]\n",
            "501         [[0.0054914705, 0.0010045249, 0.993504]]\n",
            "502           [[0.015842453, 0.47275087, 0.5114066]]\n",
            "503            [[0.5031039, 0.12797357, 0.36892253]]\n",
            "504           [[0.23837085, 0.18190125, 0.57972795]]\n",
            "505           [[0.05791308, 0.59751886, 0.34456804]]\n",
            "506         [[0.006495351, 0.0027559472, 0.9907487]]\n",
            "507           [[0.014732692, 0.8502816, 0.13498566]]\n",
            "508           [[0.15370774, 0.52489984, 0.32139242]]\n",
            "509        [[0.0022526584, 0.012895253, 0.98485214]]\n",
            "510         [[0.00387927, 0.0023730018, 0.99374783]]\n",
            "511           [[0.052119944, 0.11023938, 0.8376406]]\n",
            "512        [[0.0052965693, 0.0016833376, 0.9930201]]\n",
            "513      [[0.0046181977, 0.00078967295, 0.99459213]]\n",
            "514         [[0.008905864, 0.023157617, 0.96793646]]\n",
            "515           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "516          [[0.011676181, 0.015382016, 0.9729418]]\n",
            "517          [[0.018432645, 0.32572755, 0.65583986]]\n",
            "518          [[0.005511108, 0.46144488, 0.53304404]]\n",
            "519          [[0.010385485, 0.068095945, 0.9215186]]\n",
            "520          [[0.014099137, 0.033438224, 0.9524626]]\n",
            "521          [[0.010889513, 0.05418081, 0.93492967]]\n",
            "522        [[0.0045483154, 0.0010763931, 0.9943752]]\n",
            "523        [[0.0028298267, 0.00038120899, 0.996789]]\n",
            "524        [[0.049274415, 0.0027209152, 0.94800466]]\n",
            "525         [[0.05400151, 0.0044046803, 0.94159377]]\n",
            "526          [[0.034875274, 0.61545974, 0.34966493]]\n",
            "527         [[0.0067937938, 0.002463134, 0.9907431]]\n",
            "528             [[0.053102054, 0.11348782, 0.83341]]\n",
            "529           [[0.010190791, 0.5335371, 0.45627218]]\n",
            "530          [[0.14079145, 0.005711144, 0.85349745]]\n",
            "531         [[0.074374914, 0.0037054427, 0.9219197]]\n",
            "532          [[0.006423702, 0.0042942213, 0.989282]]\n",
            "533           [[0.039011512, 0.05738236, 0.9036062]]\n",
            "534          [[0.010550024, 0.26545888, 0.72399116]]\n",
            "535         [[0.0043398812, 0.04493271, 0.95072746]]\n",
            "536          [[0.006129722, 0.16878593, 0.82508427]]\n",
            "537         [[0.008899682, 0.021480452, 0.96961987]]\n",
            "538            [[0.6137495, 0.3463706, 0.039879855]]\n",
            "539           [[0.06713606, 0.8459937, 0.086870246]]\n",
            "540           [[0.06783665, 0.08948576, 0.84267765]]\n",
            "541             [[0.7372769, 0.1499137, 0.11280934]]\n",
            "542           [[0.21204023, 0.28034022, 0.50761956]]\n",
            "543         [[0.003876577, 0.0052110725, 0.9909123]]\n",
            "544          [[0.0022027188, 0.0628655, 0.93493176]]\n",
            "545        [[0.0013082763, 0.0010483431, 0.9976433]]\n",
            "546         [[0.0012593264, 0.84021455, 0.15852608]]\n",
            "547        [[0.008714158, 0.0018859216, 0.98939985]]\n",
            "548         [[0.009967527, 0.030993795, 0.95903873]]\n",
            "549           [[0.005838482, 0.04020197, 0.9539595]]\n",
            "550        [[0.9853033, 0.0062813796, 0.0084153805]]\n",
            "551        [[0.0025805722, 0.96144694, 0.035972558]]\n",
            "552          [[0.0033109663, 0.45076278, 0.5459262]]\n",
            "553           [[0.008955492, 0.6290156, 0.36202887]]\n",
            "554           [[0.005251952, 0.13783549, 0.8569126]]\n",
            "555           [[0.005251952, 0.13783549, 0.8569126]]\n",
            "556         [[0.006812855, 0.031237813, 0.96194935]]\n",
            "557         [[0.0040418445, 0.031367976, 0.9645902]]\n",
            "558      [[0.0030642208, 0.00096971437, 0.99596596]]\n",
            "559             [[0.00767407, 0.240234, 0.75209194]]\n",
            "560          [[0.0035941435, 0.8378672, 0.15853868]]\n",
            "561            [[0.009097255, 0.4042849, 0.5866179]]\n",
            "562          [[0.0049062464, 0.06502618, 0.9300676]]\n",
            "563          [[0.003177121, 0.16953188, 0.82729095]]\n",
            "564          [[0.006963263, 0.079773314, 0.9132634]]\n",
            "565            [[0.01020856, 0.19596347, 0.7938279]]\n",
            "566            [[0.006177189, 0.6297347, 0.3640881]]\n",
            "567            [[0.013693312, 0.2639222, 0.7223845]]\n",
            "568         [[0.0038702632, 0.90294164, 0.09318809]]\n",
            "569        [[0.0026728755, 0.0025000898, 0.9948271]]\n",
            "570         [[0.0022462693, 0.004973169, 0.9927806]]\n",
            "571        [[0.0013449934, 0.0019668296, 0.9966882]]\n",
            "572       [[0.0037772974, 0.0023238843, 0.99389875]]\n",
            "573       [[0.0035278741, 0.00048745848, 0.9959847]]\n",
            "574        [[0.009992576, 0.0009795442, 0.98902786]]\n",
            "575        [[0.0033990412, 0.038370524, 0.95823044]]\n",
            "576            [[0.045716852, 0.4295262, 0.5247569]]\n",
            "577        [[0.0061614825, 0.0060588233, 0.9877796]]\n",
            "578           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "579            [[0.5567174, 0.091445446, 0.3518372]]\n",
            "580          [[0.9851341, 0.0019899807, 0.01287593]]\n",
            "581           [[0.73686695, 0.046164867, 0.2169682]]\n",
            "582           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "583       [[0.0016849805, 0.0011147113, 0.99720037]]\n",
            "584            [[0.23614235, 0.5895684, 0.17428929]]\n",
            "585       [[0.0061273486, 0.0059993644, 0.98787326]]\n",
            "586             [[0.0700288, 0.6889392, 0.24103193]]\n",
            "587        [[0.0101388935, 0.0055638514, 0.9842972]]\n",
            "588           [[0.15146923, 0.14746992, 0.70106083]]\n",
            "589         [[0.033406846, 0.9627565, 0.0038366944]]\n",
            "590        [[0.009180013, 0.0008627295, 0.98995715]]\n",
            "591       [[0.0020157355, 0.00046010205, 0.9975242]]\n",
            "592         [[0.024655972, 0.067091346, 0.90825266]]\n",
            "593        [[0.008613737, 0.00085092155, 0.9905353]]\n",
            "594         [[0.0014728704, 0.0015941588, 0.996933]]\n",
            "595          [[0.005172757, 0.88111603, 0.11371116]]\n",
            "596        [[0.0059507866, 0.009953088, 0.98409605]]\n",
            "597         [[0.004789031, 0.0016576442, 0.9935533]]\n",
            "598           [[0.01693452, 0.07656747, 0.90649796]]\n",
            "599         [[0.00049482496, 0.9278394, 0.07166577]]\n",
            "600          [[0.019905029, 0.026759675, 0.9533353]]\n",
            "601            [[0.23361297, 0.4202813, 0.34610566]]\n",
            "602           [[0.034657322, 0.08434739, 0.8809953]]\n",
            "603        [[0.0019928862, 0.000597977, 0.99740916]]\n",
            "604             [[0.40737242, 0.18303356, 0.409594]]\n",
            "605         [[0.011586223, 0.012562905, 0.97585094]]\n",
            "606         [[0.0035183064, 0.048085354, 0.9483963]]\n",
            "607           [[0.05140417, 0.08967325, 0.85892254]]\n",
            "608        [[0.0021170313, 0.0018385554, 0.9960445]]\n",
            "609        [[0.0066181277, 0.089599006, 0.90378284]]\n",
            "610         [[0.0015515151, 0.03842908, 0.96001935]]\n",
            "611            [[0.020782724, 0.2235399, 0.7556774]]\n",
            "612          [[0.93972325, 0.016007304, 0.04426945]]\n",
            "613           [[0.026483659, 0.02053923, 0.9529771]]\n",
            "614          [[0.009607833, 0.9349321, 0.055460073]]\n",
            "615            [[0.8654536, 0.0931352, 0.041411277]]\n",
            "616             [[0.798082, 0.1719653, 0.029952768]]\n",
            "617          [[0.8854749, 0.061406747, 0.053118285]]\n",
            "618           [[0.04504075, 0.12819758, 0.82676166]]\n",
            "619         [[0.00071926985, 0.9914123, 0.00786845]]\n",
            "620          [[0.0030113251, 0.44497234, 0.5520163]]\n",
            "621         [[0.0069758845, 0.9892847, 0.003739449]]\n",
            "622        [[0.00091846986, 0.9474409, 0.051640607]]\n",
            "623       [[0.00049019826, 0.9953306, 0.0041792234]]\n",
            "624      [[0.00033824955, 0.99775225, 0.0019095344]]\n",
            "625         [[0.0007233751, 0.9540929, 0.045183696]]\n",
            "626          [[0.003771612, 0.0029824188, 0.993246]]\n",
            "627         [[0.0072387494, 0.32243696, 0.67032427]]\n",
            "628         [[0.0052995114, 0.28632107, 0.70837945]]\n",
            "629       [[4.7135396e-05, 0.9989543, 0.0009985947]]\n",
            "630       [[0.0022314976, 0.0017030889, 0.99606544]]\n",
            "631       [[0.0013359996, 0.0006172185, 0.99804676]]\n",
            "632        [[0.0016593842, 0.030743541, 0.96759707]]\n",
            "633       [[0.0025349136, 0.00058243575, 0.9968827]]\n",
            "634          [[0.043357074, 0.11862413, 0.83801883]]\n",
            "635         [[0.00222769, 0.00075865694, 0.9970137]]\n",
            "636          [[0.030497056, 0.07563384, 0.89386904]]\n",
            "637            [[0.33609438, 0.15158637, 0.5123192]]\n",
            "638     [[0.99924755, 0.00024182076, 0.00051071256]]\n",
            "639      [[0.99923027, 0.00018260551, 0.0005871455]]\n",
            "640        [[0.0020273253, 0.039136883, 0.95883566]]\n",
            "641          [[0.045341328, 0.82453656, 0.13012214]]\n",
            "642            [[0.06262872, 0.5871844, 0.35018685]]\n",
            "643        [[0.002591819, 0.0031144568, 0.99429363]]\n",
            "644       [[0.0016094776, 0.0074779955, 0.99091256]]\n",
            "645         [[0.003828759, 0.018511223, 0.97765994]]\n",
            "646           [[0.020067934, 0.45728916, 0.5226429]]\n",
            "647        [[0.0020273253, 0.039136883, 0.95883566]]\n",
            "648             [[0.003176103, 0.3409609, 0.655863]]\n",
            "649           [[0.002999805, 0.36698204, 0.6300181]]\n",
            "650       [[0.0016094776, 0.0074779955, 0.99091256]]\n",
            "651       [[0.0036831147, 0.0031419743, 0.99317485]]\n",
            "652        [[0.9954099, 0.0037908792, 0.0007991949]]\n",
            "653           [[0.45164695, 0.02991123, 0.51844186]]\n",
            "654         [[0.0015511165, 0.012598395, 0.9858505]]\n",
            "655      [[0.0029396717, 0.00060268905, 0.99645764]]\n",
            "656        [[0.0032872946, 0.9936015, 0.0031111743]]\n",
            "657        [[0.0016306645, 0.0023989133, 0.9959705]]\n",
            "658          [[0.010311008, 0.004863052, 0.9848259]]\n",
            "659            [[0.006555035, 0.3809281, 0.6125168]]\n",
            "660       [[0.0057688854, 0.0031301805, 0.99110097]]\n",
            "661        [[0.0063100434, 0.0017150014, 0.9919749]]\n",
            "662         [[0.0120301945, 0.013531472, 0.9744383]]\n",
            "663       [[0.0044076736, 0.0010441035, 0.99454814]]\n",
            "664        [[0.0023954273, 0.0015359872, 0.9960685]]\n",
            "665        [[0.0021055515, 0.017348725, 0.98054576]]\n",
            "666           [[0.008904747, 0.3149203, 0.67617494]]\n",
            "667          [[0.0021718484, 0.9627512, 0.03507699]]\n",
            "668           [[0.9386711, 0.03682841, 0.024500513]]\n",
            "669           [[0.04534958, 0.01746801, 0.93718237]]\n",
            "670         [[0.0087508755, 0.17822225, 0.81302685]]\n",
            "671        [[0.0018144639, 0.0012661413, 0.9969194]]\n",
            "672          [[0.003085872, 0.9608485, 0.036065638]]\n",
            "673            [[0.05747046, 0.9407672, 0.00176231]]\n",
            "674         [[0.0015902685, 0.9393311, 0.059078697]]\n",
            "675          [[0.77485377, 0.026268924, 0.19887723]]\n",
            "676           [[0.5344045, 0.44242665, 0.023168873]]\n",
            "677             [[0.421452, 0.51524746, 0.06330057]]\n",
            "678             [[0.0830562, 0.68142426, 0.2355195]]\n",
            "679            [[0.013086668, 0.941954, 0.04495935]]\n",
            "680           [[0.20055483, 0.7567888, 0.042656336]]\n",
            "681          [[0.86974895, 0.06914241, 0.061108578]]\n",
            "682            [[0.6825538, 0.3085737, 0.008872443]]\n",
            "683           [[0.8457808, 0.15152775, 0.002691415]]\n",
            "684          [[0.038732212, 0.8426358, 0.118631944]]\n",
            "685         [[0.0033579497, 0.0018780775, 0.994764]]\n",
            "686          [[0.0030948864, 0.3379321, 0.65897304]]\n",
            "687         [[0.0012414779, 0.73552126, 0.26323727]]\n",
            "688         [[0.0043932805, 0.86414874, 0.13145795]]\n",
            "689           [[0.86349803, 0.04171416, 0.09478779]]\n",
            "690       [[0.0029278928, 0.0010913819, 0.99598074]]\n",
            "691          [[0.0017443388, 0.5738562, 0.42439952]]\n",
            "692          [[0.0025468944, 0.9428666, 0.05458651]]\n",
            "693           [[0.0014301967, 0.3143766, 0.6841932]]\n",
            "694          [[0.0017443388, 0.5738562, 0.42439952]]\n",
            "695           [[0.000522231, 0.9967951, 0.00268267]]\n",
            "696          [[0.0041788085, 0.36102238, 0.6347989]]\n",
            "697        [[0.0026069272, 0.011461345, 0.98593163]]\n",
            "698        [[0.0018710954, 0.016731933, 0.98139703]]\n",
            "699           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "700      [[0.0015063289, 0.00069657096, 0.99779713]]\n",
            "701          [[0.021174468, 0.17729649, 0.80152905]]\n",
            "702         [[0.0076196343, 0.72292423, 0.26945618]]\n",
            "703           [[0.017170703, 0.05382905, 0.9290002]]\n",
            "704            [[0.004675223, 0.23751383, 0.757811]]\n",
            "705        [[0.0057955887, 0.011302263, 0.98290205]]\n",
            "706             [[0.004355409, 0.01361469, 0.98203]]\n",
            "707       [[0.0005802425, 0.99481225, 0.0046075187]]\n",
            "708          [[0.0049908087, 0.91560537, 0.0794038]]\n",
            "709         [[0.0025821743, 0.9667712, 0.030646594]]\n",
            "710            [[0.083872005, 0.3664751, 0.5496529]]\n",
            "711        [[0.0034697948, 0.99032414, 0.006206084]]\n",
            "712            [[0.25957093, 0.4864569, 0.25397214]]\n",
            "713         [[0.0010803544, 0.9681637, 0.030755984]]\n",
            "714         [[0.024785466, 0.054366622, 0.92084795]]\n",
            "715          [[0.001691706, 0.65384346, 0.34446487]]\n",
            "716         [[0.0057140267, 0.23717944, 0.75710654]]\n",
            "717           [[0.00143776, 0.9919097, 0.006652495]]\n",
            "718       [[0.0013902386, 0.99751747, 0.0010923623]]\n",
            "719           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "720         [[0.0016048137, 0.9881876, 0.010207623]]\n",
            "721         [[0.0010911726, 0.9936714, 0.005237344]]\n",
            "722           [[0.77871215, 0.13940218, 0.08188565]]\n",
            "723            [[0.08856888, 0.10099827, 0.8104329]]\n",
            "724            [[0.6319434, 0.08729906, 0.28075758]]\n",
            "725             [[0.37348187, 0.1851847, 0.4413334]]\n",
            "726            [[0.29183272, 0.14216258, 0.5660047]]\n",
            "727           [[0.6087208, 0.025505677, 0.36577356]]\n",
            "728           [[0.0035275621, 0.0451944, 0.9512781]]\n",
            "729        [[0.008406346, 0.0011760287, 0.99041754]]\n",
            "730           [[0.010374435, 0.19348799, 0.7961375]]\n",
            "731         [[0.004191071, 0.081563875, 0.91424507]]\n",
            "732          [[0.0048590484, 0.06548937, 0.9296516]]\n",
            "733           [[0.022010986, 0.24607685, 0.7319122]]\n",
            "734         [[0.023005178, 0.033685837, 0.94330895]]\n",
            "735           [[0.7924151, 0.103926525, 0.10365841]]\n",
            "736           [[0.03205311, 0.18976904, 0.77817786]]\n",
            "737              [[0.024293017, 0.611576, 0.364131]]\n",
            "738           [[0.014593939, 0.46783054, 0.5175755]]\n",
            "739           [[0.7924151, 0.103926525, 0.10365841]]\n",
            "740          [[0.010577124, 0.21432212, 0.77510077]]\n",
            "741          [[0.0120576015, 0.5554743, 0.43246815]]\n",
            "742          [[0.0017811728, 0.10882056, 0.8893983]]\n",
            "743       [[0.0023054439, 0.0059884773, 0.99170613]]\n",
            "744        [[0.0023034816, 0.031043973, 0.96665245]]\n",
            "745       [[0.00017407481, 0.98319364, 0.016632266]]\n",
            "746            [[0.010475761, 0.48491722, 0.504607]]\n",
            "747           [[0.09168238, 0.24568067, 0.66263694]]\n",
            "748            [[0.01441831, 0.29327518, 0.6923065]]\n",
            "749        [[0.0073231184, 0.047747348, 0.94492954]]\n",
            "750           [[0.005461201, 0.7555276, 0.23901115]]\n",
            "751            [[0.08741009, 0.12772174, 0.7848681]]\n",
            "752            [[0.14702736, 0.6810751, 0.17189755]]\n",
            "753         [[0.0015885915, 0.9410474, 0.057364047]]\n",
            "754         [[0.0010227632, 0.91369957, 0.08527771]]\n",
            "755          [[0.0026264642, 0.21493834, 0.7824352]]\n",
            "756        [[0.0005352183, 0.9941829, 0.0052818656]]\n",
            "757           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "758           [[0.0010791558, 0.2400612, 0.7588597]]\n",
            "759      [[0.0034753892, 0.00095567916, 0.99556905]]\n",
            "760        [[0.0015679727, 0.0057916404, 0.9926403]]\n",
            "761       [[0.000313844, 0.99919504, 0.00049108727]]\n",
            "762         [[0.0019536614, 0.77797055, 0.22007583]]\n",
            "763       [[0.0042675785, 0.0011077768, 0.99462456]]\n",
            "764           [[0.3639898, 0.022298543, 0.61371166]]\n",
            "765          [[0.46370462, 0.039123215, 0.49717218]]\n",
            "766          [[0.020878052, 0.013614519, 0.9655074]]\n",
            "767           [[0.078937314, 0.8890479, 0.03201476]]\n",
            "768           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "769          [[0.061688412, 0.07835042, 0.85996115]]\n",
            "770           [[0.018354136, 0.870259, 0.111386925]]\n",
            "771          [[0.015310659, 0.0051753935, 0.979514]]\n",
            "772           [[0.030314138, 0.10959229, 0.8600936]]\n",
            "773          [[0.004797718, 0.73420733, 0.26099494]]\n",
            "774           [[0.007522444, 0.19031808, 0.8021595]]\n",
            "775        [[0.0018169092, 0.007535247, 0.99064785]]\n",
            "776          [[0.007845942, 0.024798669, 0.9673554]]\n",
            "777           [[0.027996475, 0.03885795, 0.9331455]]\n",
            "778         [[0.0049677463, 0.19430526, 0.80072707]]\n",
            "779           [[0.00770554, 0.15624239, 0.83605206]]\n",
            "780          [[0.009847831, 0.021227336, 0.9689248]]\n",
            "781          [[0.0033499065, 0.00664621, 0.9900039]]\n",
            "782        [[0.0031099664, 0.046194173, 0.95069593]]\n",
            "783          [[0.025762862, 0.13935274, 0.83488435]]\n",
            "784          [[0.002504017, 0.004730944, 0.9927651]]\n",
            "785          [[0.015881645, 0.50110966, 0.48300874]]\n",
            "786         [[0.008901059, 0.0043351366, 0.9867638]]\n",
            "787          [[0.007336502, 0.048351012, 0.9443126]]\n",
            "788        [[0.0077933115, 0.004887713, 0.98731893]]\n",
            "789        [[0.0070884707, 0.0054128575, 0.9874987]]\n",
            "790         [[0.9950171, 0.0015616739, 0.003421252]]\n",
            "791          [[0.87645555, 0.054400954, 0.06914342]]\n",
            "792      [[0.99625766, 0.00068761635, 0.0030547425]]\n",
            "793         [[0.0014213377, 0.80612785, 0.19245085]]\n",
            "794        [[0.00078285567, 0.97998786, 0.01922927]]\n",
            "795        [[0.0003230255, 0.9983463, 0.0013306193]]\n",
            "796      [[0.00016192283, 0.99864966, 0.0011884838]]\n",
            "797        [[0.0002811716, 0.9986494, 0.0010693808]]\n",
            "798        [[0.00043085145, 0.9984964, 0.001072733]]\n",
            "799       [[0.00026615034, 0.9976204, 0.0021133937]]\n",
            "800        [[0.0003530955, 0.99500424, 0.004642626]]\n",
            "801        [[0.0027428458, 0.9951088, 0.0021483414]]\n",
            "802         [[0.00012584499, 0.9993304, 0.00054376]]\n",
            "803       [[0.0029469945, 0.0026736774, 0.99437934]]\n",
            "804        [[0.0016926639, 0.0005470352, 0.9977603]]\n",
            "805             [[0.10736495, 0.0371992, 0.8554359]]\n",
            "806           [[0.6854418, 0.24352425, 0.071033895]]\n",
            "807          [[0.017730013, 0.35875288, 0.62351716]]\n",
            "808          [[0.010859911, 0.34697562, 0.64216447]]\n",
            "809          [[0.0053535686, 0.10307017, 0.8915763]]\n",
            "810          [[0.026379265, 0.020830352, 0.9527903]]\n",
            "811       [[0.0039429376, 0.0014865434, 0.99457055]]\n",
            "812         [[0.0007259973, 0.91561836, 0.08365565]]\n",
            "813          [[0.0030665223, 0.6771504, 0.31978306]]\n",
            "814          [[0.0046560946, 0.8137968, 0.18154712]]\n",
            "815        [[0.0021858874, 0.9923826, 0.0054314793]]\n",
            "816        [[0.9910088, 0.0067383833, 0.0022527778]]\n",
            "817           [[0.009015722, 0.29907495, 0.6919094]]\n",
            "818            [[0.19736518, 0.6920347, 0.11060011]]\n",
            "819          [[0.012820596, 0.034309603, 0.9528699]]\n",
            "820          [[0.004197851, 0.018785711, 0.9770164]]\n",
            "821           [[0.008568255, 0.79399395, 0.1974378]]\n",
            "822           [[0.03567568, 0.26699716, 0.69732714]]\n",
            "823       [[0.004136257, 0.00068010035, 0.99518365]]\n",
            "824           [[0.990266, 0.006818803, 0.002915055]]\n",
            "825        [[0.98764193, 0.0065806787, 0.005777375]]\n",
            "826       [[0.011211898, 0.00046895214, 0.98831916]]\n",
            "827        [[0.0013758009, 0.0019810342, 0.9966432]]\n",
            "828           [[0.001077577, 0.036993347, 0.961929]]\n",
            "829         [[0.0013787167, 0.031698864, 0.9669224]]\n",
            "830           [[0.009294559, 0.0201028, 0.97060263]]\n",
            "831       [[0.0026446232, 0.0007040854, 0.99665135]]\n",
            "832        [[0.0034484304, 0.003307344, 0.99324423]]\n",
            "833        [[0.0034744383, 0.0034119696, 0.9931136]]\n",
            "834        [[0.0028475225, 0.0032083397, 0.9939442]]\n",
            "835           [[0.0334099, 0.0058432673, 0.9607468]]\n",
            "836          [[0.030481003, 0.29678702, 0.67273194]]\n",
            "837           [[0.00904969, 0.19419537, 0.79675496]]\n",
            "838        [[0.009023625, 0.0123451175, 0.97863126]]\n",
            "839        [[0.0063221217, 0.0011226204, 0.9925552]]\n",
            "840          [[0.09328562, 0.011631485, 0.89508283]]\n",
            "841         [[0.9578836, 0.0071992977, 0.034917172]]\n",
            "842           [[0.020631718, 0.10493281, 0.8744355]]\n",
            "843          [[0.0047385227, 0.04409044, 0.9511711]]\n",
            "844          [[0.0018220012, 0.9803847, 0.01779328]]\n",
            "845          [[0.046707302, 0.23876774, 0.71452504]]\n",
            "846           [[0.008805196, 0.006829749, 0.984365]]\n",
            "847          [[0.0070464476, 0.003559504, 0.989394]]\n",
            "848           [[0.0027654583, 0.011884513, 0.98535]]\n",
            "849          [[0.022349136, 0.23702428, 0.74062663]]\n",
            "850        [[0.0073644873, 0.011772666, 0.98086286]]\n",
            "851        [[0.0032311822, 0.0048053376, 0.9919634]]\n",
            "852             [[0.02063957, 0.0299913, 0.9493691]]\n",
            "853         [[0.0103056505, 0.08496533, 0.90472895]]\n",
            "854            [[0.021744018, 0.48855203, 0.489704]]\n",
            "855            [[0.028147591, 0.7467875, 0.2250649]]\n",
            "856           [[0.15627457, 0.54434186, 0.29938358]]\n",
            "857        [[0.0073026163, 0.042937875, 0.94975954]]\n",
            "858           [[0.028930554, 0.2934575, 0.67761195]]\n",
            "859            [[0.05062742, 0.30040735, 0.6489652]]\n",
            "860      [[0.99896264, 0.0004930726, 0.00054436043]]\n",
            "861         [[0.0067729736, 0.009954213, 0.9832728]]\n",
            "862          [[0.010320583, 0.9278286, 0.061850756]]\n",
            "863           [[0.45347336, 0.29478058, 0.25174603]]\n",
            "864         [[0.003691981, 0.024795383, 0.97151256]]\n",
            "865        [[0.0032558758, 0.009958894, 0.98678523]]\n",
            "866             [[0.004333501, 0.044566512, 0.9511]]\n",
            "867        [[0.0039058449, 0.067831576, 0.92826253]]\n",
            "868         [[0.0049816268, 0.010620728, 0.9843977]]\n",
            "869          [[0.007782493, 0.9718635, 0.020353977]]\n",
            "870           [[0.011121458, 0.9099727, 0.07890581]]\n",
            "871       [[0.99400157, 0.0024754053, 0.0035228974]]\n",
            "872       [[0.99400157, 0.0024754053, 0.0035228974]]\n",
            "873        [[0.0015278427, 0.92988646, 0.068585716]]\n",
            "874           [[0.21810009, 0.36852065, 0.41337928]]\n",
            "875            [[0.005727755, 0.3380792, 0.6561931]]\n",
            "876         [[0.0018429777, 0.9529173, 0.045239795]]\n",
            "877         [[0.016979098, 0.0022194975, 0.9808014]]\n",
            "878          [[0.002708168, 0.003419386, 0.9938724]]\n",
            "879         [[0.021571802, 0.004468098, 0.97396004]]\n",
            "880         [[0.9950637, 0.003266519, 0.0016697969]]\n",
            "881         [[0.91248703, 0.08534575, 0.0021672184]]\n",
            "882        [[0.98706704, 0.0055665886, 0.007366314]]\n",
            "883         [[0.033237867, 0.033001352, 0.93376076]]\n",
            "884          [[0.011705171, 0.08489312, 0.90340173]]\n",
            "885        [[0.0063510113, 0.0031006925, 0.9905482]]\n",
            "886        [[0.0019901907, 0.0012141591, 0.9967956]]\n",
            "887        [[0.0012911486, 0.011266783, 0.98744196]]\n",
            "888        [[0.0031932772, 0.033236068, 0.96357065]]\n",
            "889          [[0.00912081, 0.0035769076, 0.9873023]]\n",
            "890          [[0.006866852, 0.011106571, 0.9820265]]\n",
            "891         [[0.022529619, 0.005159868, 0.97231054]]\n",
            "892          [[0.003337895, 0.034774136, 0.9618879]]\n",
            "893        [[0.0030090844, 0.0018907494, 0.9951002]]\n",
            "894         [[0.0009886429, 0.9479458, 0.051065613]]\n",
            "895            [[0.018605608, 0.6330132, 0.3483812]]\n",
            "896         [[0.0034517054, 0.02664669, 0.96990156]]\n",
            "897         [[0.005467151, 0.0052665053, 0.9892664]]\n",
            "898        [[0.007983781, 0.0015093451, 0.99050677]]\n",
            "899       [[0.0041269446, 0.0033180953, 0.99255496]]\n",
            "900      [[0.0037039837, 0.00040471225, 0.99589133]]\n",
            "901           [[0.01007807, 0.78286284, 0.20705907]]\n",
            "902           [[0.8922596, 0.06515183, 0.042588588]]\n",
            "903           [[0.6569337, 0.31243637, 0.030629924]]\n",
            "904          [[0.63750917, 0.34772375, 0.014767064]]\n",
            "905          [[0.08094323, 0.86734813, 0.051708613]]\n",
            "906         [[0.014228125, 0.080173224, 0.90559864]]\n",
            "907           [[0.59985054, 0.38709515, 0.01305432]]\n",
            "908          [[0.064630754, 0.8925296, 0.042839672]]\n",
            "909           [[0.3190619, 0.066414915, 0.61452323]]\n",
            "910          [[0.9225903, 0.056941897, 0.020467866]]\n",
            "911             [[0.5767436, 0.3547027, 0.06855364]]\n",
            "912            [[0.969545, 0.025189703, 0.00526527]]\n",
            "913         [[0.93498033, 0.047267836, 0.017751813]]\n",
            "914          [[0.91222644, 0.06635978, 0.021413803]]\n",
            "915       [[0.0048810807, 0.0014711991, 0.99364775]]\n",
            "916       [[0.9970697, 0.0019668792, 0.00096336793]]\n",
            "917      [[0.99886847, 0.0005687286, 0.00056287146]]\n",
            "918           [[0.05425381, 0.94018173, 0.00556444]]\n",
            "919           [[0.022824906, 0.8295274, 0.14764772]]\n",
            "920            [[0.016166847, 0.3509135, 0.6329196]]\n",
            "921           [[0.93886703, 0.04774756, 0.01338535]]\n",
            "922        [[0.0030520167, 0.9952055, 0.0017424547]]\n",
            "923          [[0.008494385, 0.30947208, 0.68203354]]\n",
            "924             [[0.32661918, 0.1477705, 0.5256104]]\n",
            "925            [[0.10505847, 0.2867429, 0.60819864]]\n",
            "926         [[0.0024679324, 0.91128343, 0.08624865]]\n",
            "927         [[0.0005334987, 0.9950624, 0.004404056]]\n",
            "928          [[0.011433226, 0.018954568, 0.9696121]]\n",
            "929         [[0.002463686, 0.011637512, 0.98589885]]\n",
            "930       [[0.0017303842, 0.0073269326, 0.99094266]]\n",
            "931       [[0.0036148292, 0.0031349396, 0.99325037]]\n",
            "932            [[0.006838609, 0.6176832, 0.3754782]]\n",
            "933           [[0.006649157, 0.03045032, 0.9629006]]\n",
            "934         [[0.036148578, 0.0033826125, 0.9604688]]\n",
            "935         [[0.036148578, 0.0033826125, 0.9604688]]\n",
            "936           [[0.14684504, 0.32012805, 0.53302693]]\n",
            "937       [[0.0032403946, 0.0074297865, 0.98932976]]\n",
            "938           [[0.040536564, 0.09704786, 0.8624156]]\n",
            "939          [[0.012410488, 0.004485645, 0.9831039]]\n",
            "940          [[0.007563983, 0.042847294, 0.9495887]]\n",
            "941           [[0.004430326, 0.082241684, 0.913328]]\n",
            "942          [[0.010147706, 0.86930066, 0.12055159]]\n",
            "943        [[0.001157375, 0.0006768908, 0.99816567]]\n",
            "944       [[0.0031090542, 0.0013824266, 0.99550855]]\n",
            "945           [[0.044891715, 0.12562509, 0.8294833]]\n",
            "946         [[0.002972052, 0.004429322, 0.99259865]]\n",
            "947       [[0.0038232692, 0.0025051432, 0.99367154]]\n",
            "948          [[0.0010829525, 0.42123216, 0.5776849]]\n",
            "949         [[0.0039040602, 0.003207314, 0.9928886]]\n",
            "950         [[0.0017334408, 0.017049795, 0.9812167]]\n",
            "951          [[0.0034535006, 0.38505498, 0.6114915]]\n",
            "952           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "953        [[0.0014997051, 0.007925639, 0.99057466]]\n",
            "954            [[0.2127131, 0.30327296, 0.48401392]]\n",
            "955       [[0.0022114175, 0.0049663247, 0.99282223]]\n",
            "956           [[0.05555449, 0.12984173, 0.81460375]]\n",
            "957            [[0.0181631, 0.011244728, 0.9705921]]\n",
            "958          [[0.01797922, 0.0062309126, 0.9757898]]\n",
            "959         [[0.028610216, 0.94240934, 0.028980384]]\n",
            "960          [[0.006931834, 0.057517257, 0.9355509]]\n",
            "961        [[0.0024728228, 0.001954606, 0.99557257]]\n",
            "962         [[0.010293047, 0.025267787, 0.96443915]]\n",
            "963        [[0.0038724265, 0.012868805, 0.98325884]]\n",
            "964            [[0.076525554, 0.4710532, 0.4524212]]\n",
            "965         [[0.003497779, 0.011925946, 0.98457634]]\n",
            "966           [[0.048917353, 0.20260617, 0.7484765]]\n",
            "967           [[0.048917353, 0.20260617, 0.7484765]]\n",
            "968           [[0.016999807, 0.1367701, 0.84623003]]\n",
            "969         [[0.010923341, 0.055419974, 0.93365663]]\n",
            "970          [[0.006153052, 0.45065185, 0.54319507]]\n",
            "971          [[0.008459886, 0.060377326, 0.9311628]]\n",
            "972          [[0.001481421, 0.04982439, 0.94869417]]\n",
            "973       [[0.0033534197, 0.0012494812, 0.99539703]]\n",
            "974            [[0.05898693, 0.07182749, 0.8691856]]\n",
            "975            [[0.05898693, 0.07182749, 0.8691856]]\n",
            "976          [[0.007566592, 0.009353056, 0.9830804]]\n",
            "977          [[0.063586496, 0.65067506, 0.28573847]]\n",
            "978           [[0.028349832, 0.80016714, 0.1714831]]\n",
            "979            [[0.06559457, 0.1362071, 0.79819834]]\n",
            "980            [[0.062429756, 0.07379828, 0.863772]]\n",
            "981            [[0.7431461, 0.10459368, 0.15226018]]\n",
            "982             [[0.1223042, 0.8217848, 0.05591105]]\n",
            "983         [[0.0046563894, 0.012638785, 0.9827048]]\n",
            "984             [[0.1144385, 0.7038318, 0.18172973]]\n",
            "985            [[0.7431461, 0.10459368, 0.15226018]]\n",
            "986           [[0.0020017251, 0.9224389, 0.0755593]]\n",
            "987             [[0.02514307, 0.25646195, 0.718395]]\n",
            "988         [[0.022436699, 0.019306397, 0.95825684]]\n",
            "989        [[0.0015119051, 0.0022960233, 0.9961921]]\n",
            "990        [[0.010401192, 0.0034432781, 0.98615557]]\n",
            "991       [[0.00011666171, 0.99685526, 0.003028043]]\n",
            "992           [[0.047855474, 0.16998826, 0.7821563]]\n",
            "993          [[0.0027811853, 0.1788285, 0.81839025]]\n",
            "994         [[0.0007279795, 0.56402516, 0.43524686]]\n",
            "995          [[0.0016575493, 0.8387557, 0.15958674]]\n",
            "996         [[0.0011585844, 0.9608342, 0.038007226]]\n",
            "997         [[0.009612517, 0.012020295, 0.97836715]]\n",
            "998          [[0.016823191, 0.040575452, 0.9426013]]\n",
            "999        [[0.0076577077, 0.009898877, 0.98244345]]\n",
            "1000         [[0.003193818, 0.006535521, 0.9902706]]\n",
            "1001        [[0.0044349297, 0.017082637, 0.9784824]]\n",
            "1002      [[0.0025019052, 0.0015392653, 0.99595875]]\n",
            "1003            [[0.6399112, 0.16203415, 0.1980546]]\n",
            "1004       [[0.0033778853, 0.0015473947, 0.9950747]]\n",
            "1005           [[0.009184423, 0.3200603, 0.6707553]]\n",
            "1006      [[0.0075952997, 0.0014978435, 0.99090683]]\n",
            "1007      [[0.0075952997, 0.0014978435, 0.99090683]]\n",
            "1008       [[0.002565514, 0.00055598625, 0.9968785]]\n",
            "1009        [[0.0029956575, 0.9702664, 0.026737893]]\n",
            "1010         [[0.062434383, 0.12854372, 0.80902195]]\n",
            "1011           [[0.015035071, 0.1044261, 0.8805388]]\n",
            "1012        [[0.005320588, 0.0024666993, 0.9922126]]\n",
            "1013         [[0.023361642, 0.071826145, 0.9048122]]\n",
            "1014         [[0.75169873, 0.22406137, 0.024239944]]\n",
            "1015       [[0.0043806215, 0.0033359067, 0.9922835]]\n",
            "1016      [[0.0032337974, 0.0013659403, 0.99540037]]\n",
            "1017          [[0.001265248, 0.9341066, 0.06462811]]\n",
            "1018          [[0.046126228, 0.08365312, 0.8702206]]\n",
            "1019        [[0.0036286127, 0.002947069, 0.9934244]]\n",
            "1020        [[0.051941372, 0.095026046, 0.85303265]]\n",
            "1021           [[0.13350148, 0.7122791, 0.15421945]]\n",
            "1022         [[0.056522775, 0.01233116, 0.93114614]]\n",
            "1023       [[0.0009311434, 0.0029252123, 0.9961437]]\n",
            "1024          [[0.0015363896, 0.1799205, 0.8185432]]\n",
            "1025          [[0.9168529, 0.013360628, 0.06978653]]\n",
            "1026          [[0.49659666, 0.40518457, 0.09821877]]\n",
            "1027       [[0.007302704, 0.0023000056, 0.99039733]]\n",
            "1028         [[0.048847742, 0.07775695, 0.87339526]]\n",
            "1029           [[0.06111505, 0.0426042, 0.89628077]]\n",
            "1030         [[0.038888287, 0.057596147, 0.9035156]]\n",
            "1031          [[0.08745647, 0.24140742, 0.67113614]]\n",
            "1032          [[0.031636182, 0.21143927, 0.7569245]]\n",
            "1033         [[0.76447344, 0.014648074, 0.22087848]]\n",
            "1034      [[0.0077144704, 0.0016659704, 0.99061954]]\n",
            "1035       [[0.004584659, 0.0011659263, 0.99424946]]\n",
            "1036        [[0.0077488474, 0.000561277, 0.9916898]]\n",
            "1037         [[0.007954299, 0.84785396, 0.14419174]]\n",
            "1038         [[0.074263744, 0.13276027, 0.79297596]]\n",
            "1039          [[0.013950547, 0.0952811, 0.89076835]]\n",
            "1040         [[0.0062151034, 0.19889249, 0.7948924]]\n",
            "1041         [[0.006195021, 0.9352231, 0.058581892]]\n",
            "1042        [[0.0029860558, 0.9785407, 0.018473184]]\n",
            "1043          [[0.01233934, 0.89977336, 0.08788731]]\n",
            "1044         [[0.007950132, 0.72870517, 0.26334473]]\n",
            "1045      [[0.0010141999, 0.0013808964, 0.99760485]]\n",
            "1046       [[0.0018003469, 0.0010141245, 0.9971855]]\n",
            "1047      [[0.00080130954, 0.00072570756, 0.998473]]\n",
            "1048       [[0.99638593, 0.0022123067, 0.001401768]]\n",
            "1049          [[0.44551447, 0.27547792, 0.27900755]]\n",
            "1050         [[0.9803816, 0.01892952, 0.0006888725]]\n",
            "1051        [[0.0033318303, 0.018112196, 0.9785559]]\n",
            "1052          [[0.011105564, 0.18684366, 0.8020507]]\n",
            "1053        [[0.006711802, 0.080694675, 0.91259354]]\n",
            "1054          [[0.08668343, 0.26837423, 0.64494234]]\n",
            "1055           [[0.05902396, 0.14346138, 0.7975146]]\n",
            "1056       [[0.0034569094, 0.002620937, 0.99392223]]\n",
            "1057      [[0.00038836518, 0.002938881, 0.99667275]]\n",
            "1058          [[0.020039788, 0.05173556, 0.9282246]]\n",
            "1059          [[0.015523575, 0.3469713, 0.63750505]]\n",
            "1060         [[0.0017740759, 0.08285743, 0.9153685]]\n",
            "1061        [[0.001745306, 0.0012248638, 0.9970298]]\n",
            "1062           [[0.0015849622, 0.0012241, 0.997191]]\n",
            "1063          [[0.32787627, 0.11029158, 0.56183213]]\n",
            "1064            [[0.866013, 0.11736257, 0.01662444]]\n",
            "1065          [[0.005032489, 0.50886995, 0.4860976]]\n",
            "1066          [[0.005032489, 0.50886995, 0.4860976]]\n",
            "1067         [[0.014532322, 0.55711156, 0.42835608]]\n",
            "1068         [[0.0063062576, 0.03707537, 0.9566183]]\n",
            "1069        [[0.0015580993, 0.060830064, 0.9376119]]\n",
            "1070         [[0.0016581524, 0.009733762, 0.988608]]\n",
            "1071       [[0.0010231982, 0.006711198, 0.99226564]]\n",
            "1072        [[0.0015580993, 0.060830064, 0.9376119]]\n",
            "1073            [[0.3842081, 0.06084148, 0.5549504]]\n",
            "1074           [[0.30323112, 0.10832066, 0.5884482]]\n",
            "1075        [[0.008072769, 0.003157733, 0.98876953]]\n",
            "1076         [[0.0007464554, 0.9169523, 0.08230128]]\n",
            "1077      [[0.0015620717, 0.00086715707, 0.9975707]]\n",
            "1078       [[0.001418275, 0.00044924716, 0.9981324]]\n",
            "1079      [[0.0015554335, 0.0006578336, 0.99778664]]\n",
            "1080           [[0.12269703, 0.5921846, 0.28511834]]\n",
            "1081     [[0.00025067476, 0.99720395, 0.0025454196]]\n",
            "1082         [[0.0014204581, 0.82501477, 0.1735648]]\n",
            "1083         [[0.0021526255, 0.00821256, 0.9896347]]\n",
            "1084       [[0.0017744832, 0.0128389895, 0.9853866]]\n",
            "1085         [[0.0017638243, 0.11584234, 0.8823939]]\n",
            "1086        [[0.0011732858, 0.062051006, 0.9367758]]\n",
            "1087         [[0.00211785, 0.019053014, 0.97882915]]\n",
            "1088           [[0.05902396, 0.14346138, 0.7975146]]\n",
            "1089        [[0.00063188886, 0.21509856, 0.7842695]]\n",
            "1090          [[0.00015275247, 0.98666, 0.01318722]]\n",
            "1091         [[0.8845667, 0.103750214, 0.011683075]]\n",
            "1092        [[0.0067131296, 0.002757309, 0.9905296]]\n",
            "1093      [[0.98549634, 0.0112185115, 0.0032851363]]\n",
            "1094          [[0.96458733, 0.01922067, 0.01619197]]\n",
            "1095         [[0.024030238, 0.011424572, 0.9645452]]\n",
            "1096      [[0.0010552912, 0.0022803834, 0.99666435]]\n",
            "1097       [[0.0020467334, 0.002080889, 0.99587244]]\n",
            "1098           [[0.013073731, 0.00853023, 0.978396]]\n",
            "1099        [[0.030855527, 0.088163525, 0.88098097]]\n",
            "1100      [[0.0047026845, 0.0048148576, 0.99048245]]\n",
            "1101      [[0.0013428926, 0.0029574747, 0.99569964]]\n",
            "1102         [[0.0077987034, 0.03502971, 0.9571716]]\n",
            "1103         [[0.003824168, 0.019750673, 0.9764251]]\n",
            "1104        [[0.0017433909, 0.0032985955, 0.994958]]\n",
            "1105        [[0.0014564735, 0.032174997, 0.9663685]]\n",
            "1106         [[0.013130703, 0.08083951, 0.90602976]]\n",
            "1107       [[0.0014456081, 0.0021048856, 0.9964495]]\n",
            "1108        [[0.002150708, 0.006261327, 0.99158806]]\n",
            "1109        [[0.0015177139, 0.003784071, 0.9946983]]\n",
            "1110        [[0.0029412694, 0.007874782, 0.9891839]]\n",
            "1111         [[0.031426836, 0.34096956, 0.62760365]]\n",
            "1112        [[0.0015191096, 0.046754546, 0.9517263]]\n",
            "1113         [[0.0029195864, 0.24338457, 0.7536958]]\n",
            "1114       [[0.0022208367, 0.0053642965, 0.9924149]]\n",
            "1115         [[0.016634826, 0.18328167, 0.80008346]]\n",
            "1116          [[0.06398133, 0.37030864, 0.56571007]]\n",
            "1117          [[0.006345845, 0.07499691, 0.9186573]]\n",
            "1118        [[0.0028941594, 0.10358643, 0.89351946]]\n",
            "1119         [[0.01251088, 0.025241058, 0.96224815]]\n",
            "1120           [[0.003244072, 0.7303689, 0.2663871]]\n",
            "1121          [[0.014079747, 0.01715256, 0.9687677]]\n",
            "1122       [[0.9982717, 0.0009144809, 0.0008137246]]\n",
            "1123         [[0.060169436, 0.9171524, 0.022678176]]\n",
            "1124       [[0.0070112874, 0.0042702756, 0.9887185]]\n",
            "1125      [[0.0013747494, 0.0008310642, 0.99779415]]\n",
            "1126          [[0.0030207909, 0.3990137, 0.5979655]]\n",
            "1127       [[0.00062368915, 0.98758554, 0.01179076]]\n",
            "1128         [[0.002359521, 0.93191564, 0.06572478]]\n",
            "1129     [[0.00032289536, 0.99662685, 0.0030502535]]\n",
            "1130      [[0.0031962402, 0.0025181612, 0.99428564]]\n",
            "1131           [[0.010558614, 0.033165, 0.95627636]]\n",
            "1132         [[0.041859772, 0.16717052, 0.79096967]]\n",
            "1133          [[0.087682426, 0.1624697, 0.74984795]]\n",
            "1134         [[0.11656794, 0.034839682, 0.84859246]]\n",
            "1135        [[0.004334494, 0.010012297, 0.98565316]]\n",
            "1136       [[0.0020007743, 0.0057003954, 0.9922988]]\n",
            "1137         [[0.061591465, 0.11867935, 0.81972915]]\n",
            "1138        [[0.0021495756, 0.019178612, 0.9786718]]\n",
            "1139        [[0.0022382368, 0.009100365, 0.9886614]]\n",
            "1140          [[0.023739787, 0.20017928, 0.7760809]]\n",
            "1141       [[0.0006519706, 0.96988153, 0.029466549]]\n",
            "1142         [[0.0016034457, 0.11421824, 0.8841783]]\n",
            "1143           [[0.3631324, 0.25763282, 0.37923485]]\n",
            "1144           [[0.46327677, 0.08021363, 0.4565096]]\n",
            "1145          [[0.8786258, 0.09628122, 0.025092995]]\n",
            "1146           [[0.04379448, 0.15180255, 0.8044029]]\n",
            "1147          [[0.27895567, 0.22316211, 0.49788213]]\n",
            "1148       [[0.0083847875, 0.00055622245, 0.991059]]\n",
            "1149           [[0.3531699, 0.004806026, 0.6420241]]\n",
            "1150         [[0.038432814, 0.09855407, 0.86301315]]\n",
            "1151          [[0.020867057, 0.44299877, 0.5361341]]\n",
            "1152         [[0.0122945625, 0.5423812, 0.44532418]]\n",
            "1153          [[0.05424498, 0.13399766, 0.81175727]]\n",
            "1154          [[0.055592112, 0.06923549, 0.8751723]]\n",
            "1155          [[0.60504776, 0.3804133, 0.014538944]]\n",
            "1156           [[0.052933086, 0.1020858, 0.8449811]]\n",
            "1157       [[0.015514737, 0.0043516974, 0.98013353]]\n",
            "1158         [[0.030281216, 0.018509017, 0.9512097]]\n",
            "1159           [[0.05468402, 0.6993811, 0.24593487]]\n",
            "1160          [[0.038095523, 0.6581277, 0.30377674]]\n",
            "1161          [[0.052978896, 0.11641417, 0.8306069]]\n",
            "1162        [[0.012005069, 0.0044454485, 0.9835495]]\n",
            "1163           [[0.042495508, 0.04002244, 0.917482]]\n",
            "1164       [[0.0014305472, 0.011168023, 0.98740155]]\n",
            "1165          [[0.036571607, 0.08643358, 0.8769948]]\n",
            "1166           [[0.015330092, 0.0877276, 0.8969423]]\n",
            "1167         [[0.0058085364, 0.08672704, 0.9074645]]\n",
            "1168        [[0.0047500324, 0.020539641, 0.9747104]]\n",
            "1169        [[0.0044026775, 0.012302796, 0.9832945]]\n",
            "1170         [[0.006507474, 0.056917027, 0.9365755]]\n",
            "1171         [[0.009778802, 0.15134187, 0.83887935]]\n",
            "1172        [[0.002577349, 0.011149311, 0.98627335]]\n",
            "1173          [[0.0014637937, 0.7718284, 0.2267078]]\n",
            "1174          [[0.8010777, 0.18658757, 0.012334683]]\n",
            "1175         [[0.019704431, 0.51801544, 0.46228012]]\n",
            "1176       [[0.073286794, 0.92338884, 0.0033243548]]\n",
            "1177        [[0.004331591, 0.022167578, 0.97350085]]\n",
            "1178         [[0.035703182, 0.11142956, 0.85286725]]\n",
            "1179            [[0.03475326, 0.2104936, 0.7547532]]\n",
            "1180       [[0.015654003, 0.0019172194, 0.98242885]]\n",
            "1181        [[0.014655446, 0.0017869872, 0.9835576]]\n",
            "1182       [[0.073113844, 0.0012293607, 0.92565674]]\n",
            "1183        [[0.012638817, 0.0006195099, 0.9867416]]\n",
            "1184         [[0.0016305526, 0.02082918, 0.9775403]]\n",
            "1185       [[0.0015733322, 0.0010032308, 0.9974235]]\n",
            "1186         [[0.02365692, 0.006513981, 0.96982914]]\n",
            "1187         [[0.076925814, 0.19901991, 0.72405434]]\n",
            "1188        [[0.009679897, 0.0029297092, 0.9873904]]\n",
            "1189         [[0.010685352, 0.074964456, 0.9143502]]\n",
            "1190          [[0.002767414, 0.016801566, 0.980431]]\n",
            "1191      [[0.0025549189, 0.0070061577, 0.99043894]]\n",
            "1192        [[0.0069326367, 0.38984755, 0.60321987]]\n",
            "1193        [[0.0041580964, 0.00198978, 0.99385214]]\n",
            "1194      [[0.0066496097, 0.0012816731, 0.99206877]]\n",
            "1195     [[0.0026380094, 0.00037090536, 0.99699104]]\n",
            "1196        [[0.0029731647, 0.104748935, 0.8922779]]\n",
            "1197      [[0.0014181358, 0.0011226062, 0.99745935]]\n",
            "1198       [[0.0038630548, 0.056385364, 0.93975157]]\n",
            "1199        [[0.0032395432, 0.027023597, 0.9697369]]\n",
            "1200         [[0.001654935, 0.68562055, 0.31272447]]\n",
            "1201       [[0.011554402, 0.0015818009, 0.98686373]]\n",
            "1202         [[0.0022109237, 0.001990007, 0.995799]]\n",
            "1203          [[0.1008752, 0.011232471, 0.88789237]]\n",
            "1204          [[0.9156934, 0.04180113, 0.042505454]]\n",
            "1205       [[0.012033189, 0.0049486747, 0.98301804]]\n",
            "1206        [[0.008004933, 0.0059054573, 0.9860896]]\n",
            "1207          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1208         [[0.006173522, 0.021007128, 0.9728194]]\n",
            "1209            [[0.27984977, 0.4593626, 0.2607876]]\n",
            "1210        [[0.015206935, 0.89556617, 0.089226946]]\n",
            "1211           [[0.02333034, 0.68772805, 0.2889416]]\n",
            "1212          [[0.6210709, 0.28381222, 0.095116846]]\n",
            "1213        [[0.003552789, 0.0020240229, 0.9944232]]\n",
            "1214        [[0.0025423276, 0.016539954, 0.9809178]]\n",
            "1215       [[0.0011192695, 0.011951253, 0.98692954]]\n",
            "1216        [[0.0025423276, 0.016539954, 0.9809178]]\n",
            "1217        [[0.0007337219, 0.07827256, 0.92099375]]\n",
            "1218      [[0.0022529224, 0.00059580506, 0.9971513]]\n",
            "1219       [[0.0010786391, 0.0038801616, 0.9950413]]\n",
            "1220          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1221       [[0.0026211697, 0.008323874, 0.98905504]]\n",
            "1222         [[0.017571323, 0.003302467, 0.9791262]]\n",
            "1223           [[0.42026916, 0.04151898, 0.5382119]]\n",
            "1224         [[0.0036719479, 0.13129075, 0.8650373]]\n",
            "1225          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1226         [[0.014942111, 0.00207988, 0.98297805]]\n",
            "1227          [[0.047151744, 0.09203987, 0.8608084]]\n",
            "1228         [[0.006999438, 0.022020528, 0.9709801]]\n",
            "1229           [[0.06343329, 0.13452321, 0.8020435]]\n",
            "1230             [[0.04662355, 0.10963648, 0.84374]]\n",
            "1231        [[0.004527204, 0.0025724028, 0.9929005]]\n",
            "1232          [[0.79895264, 0.1964689, 0.004578538]]\n",
            "1233        [[0.012539071, 0.0022713533, 0.9851895]]\n",
            "1234         [[0.04254884, 0.102800965, 0.85465014]]\n",
            "1235          [[0.7706324, 0.028107196, 0.20126039]]\n",
            "1236          [[0.18812032, 0.0107976915, 0.801082]]\n",
            "1237            [[0.22440849, 0.14257948, 0.633012]]\n",
            "1238          [[0.004600171, 0.01958018, 0.9758197]]\n",
            "1239          [[0.010949036, 0.0024910101, 0.98656]]\n",
            "1240        [[0.012357347, 0.0010406962, 0.9866019]]\n",
            "1241         [[0.011150699, 0.007952695, 0.9808966]]\n",
            "1242         [[0.004275541, 0.041386086, 0.9543383]]\n",
            "1243           [[0.010540605, 0.2241122, 0.7653472]]\n",
            "1244       [[0.00073226925, 0.9901181, 0.009149636]]\n",
            "1245         [[0.0029288307, 0.09807934, 0.8989918]]\n",
            "1246        [[0.0014996423, 0.83000886, 0.16849151]]\n",
            "1247          [[0.004368412, 0.0887388, 0.90689284]]\n",
            "1248       [[0.0037992762, 0.003489768, 0.99271095]]\n",
            "1249          [[0.9158482, 0.06932494, 0.014826858]]\n",
            "1250       [[0.0035984907, 0.030466808, 0.96593475]]\n",
            "1251          [[0.01686705, 0.78020775, 0.20292518]]\n",
            "1252           [[0.5871589, 0.079870574, 0.3329705]]\n",
            "1253        [[0.010149345, 0.95882165, 0.031028971]]\n",
            "1254         [[0.008202762, 0.009814574, 0.9819827]]\n",
            "1255       [[0.0015459617, 0.0028753306, 0.9955787]]\n",
            "1256         [[0.0013240475, 0.019054975, 0.979621]]\n",
            "1257       [[0.0013078827, 0.021617195, 0.97707486]]\n",
            "1258       [[0.00083773583, 0.017248059, 0.9819142]]\n",
            "1259      [[0.00092798535, 0.012115671, 0.98695636]]\n",
            "1260        [[0.0011384853, 0.8896471, 0.109214365]]\n",
            "1261          [[0.026152866, 0.35476175, 0.6190854]]\n",
            "1262        [[0.0033884908, 0.002582135, 0.9940294]]\n",
            "1263        [[0.94763595, 0.04410002, 0.0082640005]]\n",
            "1264      [[0.0037030892, 0.0113194585, 0.98497736]]\n",
            "1265        [[0.0031394896, 0.08708119, 0.90977925]]\n",
            "1266        [[0.0034647936, 0.00802637, 0.98850876]]\n",
            "1267          [[0.007263873, 0.03357051, 0.9591656]]\n",
            "1268           [[0.050239384, 0.3992333, 0.5505273]]\n",
            "1269         [[0.26269007, 0.62202805, 0.115281865]]\n",
            "1270          [[0.007341292, 0.9210978, 0.07156089]]\n",
            "1271          [[0.7759738, 0.092133984, 0.13189223]]\n",
            "1272        [[0.00039963512, 0.995301, 0.004299296]]\n",
            "1273       [[0.0032095427, 0.95928097, 0.037509445]]\n",
            "1274          [[0.065517336, 0.00515434, 0.9293283]]\n",
            "1275          [[0.054230813, 0.16244352, 0.7833257]]\n",
            "1276          [[0.024809785, 0.9106815, 0.06450875]]\n",
            "1277           [[0.3060746, 0.6847359, 0.009189495]]\n",
            "1278       [[0.0030486996, 0.004091017, 0.99286026]]\n",
            "1279         [[0.010234094, 0.33115128, 0.65861464]]\n",
            "1280          [[0.009884339, 0.31154746, 0.6785682]]\n",
            "1281        [[0.005042221, 0.0074195764, 0.9875382]]\n",
            "1282         [[0.051434264, 0.15826401, 0.79030174]]\n",
            "1283      [[0.0018938925, 0.0015628348, 0.99654335]]\n",
            "1284         [[0.001429763, 0.004570235, 0.9940001]]\n",
            "1285        [[0.0022284184, 0.003171224, 0.9946003]]\n",
            "1286         [[0.0029965509, 0.16582516, 0.8311783]]\n",
            "1287     [[0.0021465102, 0.00044331266, 0.99741024]]\n",
            "1288          [[0.009253503, 0.8406064, 0.15014014]]\n",
            "1289         [[0.71526366, 0.26993746, 0.014798852]]\n",
            "1290         [[0.78553176, 0.085388504, 0.12907967]]\n",
            "1291       [[0.005209578, 0.0011210551, 0.99366933]]\n",
            "1292          [[0.9820433, 0.011284906, 0.00667176]]\n",
            "1293       [[0.0066857566, 0.0039448338, 0.9893694]]\n",
            "1294       [[0.0021956093, 0.0005328958, 0.9972716]]\n",
            "1295          [[0.34302017, 0.51697046, 0.14000937]]\n",
            "1296       [[0.002877387, 0.0027987063, 0.99432397]]\n",
            "1297         [[0.04455653, 0.008478976, 0.94696456]]\n",
            "1298          [[0.005946318, 0.18893814, 0.8051156]]\n",
            "1299        [[0.0043162405, 0.036508273, 0.9591756]]\n",
            "1300         [[0.106483296, 0.42605644, 0.46746024]]\n",
            "1301        [[0.0048016123, 0.055116978, 0.9400814]]\n",
            "1302       [[0.005095011, 0.0058425954, 0.98906237]]\n",
            "1303        [[0.0013378749, 0.88162017, 0.11704195]]\n",
            "1304         [[0.006855027, 0.15413651, 0.83900845]]\n",
            "1305        [[0.0026687165, 0.100819714, 0.8965116]]\n",
            "1306       [[0.0043540965, 0.055826724, 0.93981916]]\n",
            "1307        [[0.001570004, 0.0006373133, 0.9977927]]\n",
            "1308        [[0.0026277867, 0.0019272144, 0.995445]]\n",
            "1309       [[0.0023317034, 0.005624879, 0.99204344]]\n",
            "1310          [[0.0061616, 0.0077308402, 0.9861076]]\n",
            "1311          [[0.0012991655, 0.0216373, 0.9770635]]\n",
            "1312        [[0.002510586, 0.013088933, 0.98440045]]\n",
            "1313         [[0.002827204, 0.025668286, 0.9715045]]\n",
            "1314       [[0.0051731337, 0.015826074, 0.97900087]]\n",
            "1315         [[0.0014482173, 0.9096705, 0.08888128]]\n",
            "1316          [[0.07660969, 0.32469591, 0.59869444]]\n",
            "1317          [[0.04031654, 0.10535326, 0.85433024]]\n",
            "1318        [[0.003556795, 0.008777571, 0.98766565]]\n",
            "1319         [[0.0041753077, 0.01938753, 0.9764372]]\n",
            "1320        [[0.0058228094, 0.008345783, 0.9858314]]\n",
            "1321         [[0.0023343938, 0.040276583, 0.957389]]\n",
            "1322       [[0.0007977508, 0.95928735, 0.039914936]]\n",
            "1323        [[0.0014821369, 0.9939652, 0.004552629]]\n",
            "1324        [[0.0017907979, 0.9798662, 0.018343033]]\n",
            "1325     [[0.00020496073, 0.99715614, 0.0026388415]]\n",
            "1326     [[0.000103051345, 0.9988042, 0.0010927805]]\n",
            "1327         [[0.027323944, 0.12728621, 0.84538984]]\n",
            "1328      [[0.00063021615, 0.036827706, 0.96254206]]\n",
            "1329        [[0.00075312145, 0.07510024, 0.9241467]]\n",
            "1330         [[0.0020656248, 0.8108273, 0.18710707]]\n",
            "1331        [[0.0009864238, 0.58099025, 0.41802332]]\n",
            "1332       [[0.0013424517, 0.0025204623, 0.9961371]]\n",
            "1333          [[0.005161122, 0.047914922, 0.946924]]\n",
            "1334       [[0.0013440691, 0.99039745, 0.008258493]]\n",
            "1335         [[0.014564081, 0.035159986, 0.9502759]]\n",
            "1336        [[0.026408989, 0.95831156, 0.015279486]]\n",
            "1337            [[0.022071753, 0.361741, 0.6161872]]\n",
            "1338      [[0.0050515477, 0.0118007045, 0.98314774]]\n",
            "1339            [[0.12746362, 0.5081376, 0.3643988]]\n",
            "1340         [[0.005119044, 0.014351519, 0.9805295]]\n",
            "1341       [[0.0055392757, 0.002057381, 0.99240327]]\n",
            "1342         [[0.016421266, 0.005850904, 0.9777279]]\n",
            "1343           [[0.37475342, 0.3379976, 0.28724897]]\n",
            "1344            [[0.2728837, 0.2898349, 0.43728146]]\n",
            "1345             [[0.064566, 0.14012852, 0.7953055]]\n",
            "1346           [[0.03599669, 0.27203456, 0.6919688]]\n",
            "1347       [[0.0041966974, 0.0060279877, 0.9897753]]\n",
            "1348       [[0.0089455815, 0.0017466401, 0.9893078]]\n",
            "1349         [[0.034433227, 0.07723066, 0.88833606]]\n",
            "1350        [[0.010582179, 0.091675244, 0.89774257]]\n",
            "1351           [[0.09441911, 0.12413521, 0.7814456]]\n",
            "1352           [[0.06914789, 0.23564321, 0.6952089]]\n",
            "1353        [[0.001809292, 0.0009282122, 0.9972625]]\n",
            "1354          [[0.040353924, 0.04764525, 0.9120009]]\n",
            "1355          [[0.021638017, 0.12219842, 0.8561636]]\n",
            "1356        [[0.006380005, 0.0035226762, 0.9900973]]\n",
            "1357           [[0.7401862, 0.14038059, 0.11943323]]\n",
            "1358        [[0.008623572, 0.002263998, 0.98911244]]\n",
            "1359          [[0.060547587, 0.19767463, 0.7417777]]\n",
            "1360       [[0.0042525497, 0.0018359921, 0.9939114]]\n",
            "1361      [[0.0015728045, 0.0040466045, 0.99438065]]\n",
            "1362          [[0.9318503, 0.01933349, 0.048816174]]\n",
            "1363        [[0.000947887, 0.006041123, 0.99301106]]\n",
            "1364       [[0.00033420918, 0.9608974, 0.038768392]]\n",
            "1365          [[0.00339344, 0.49477443, 0.50183207]]\n",
            "1366       [[0.0054600905, 0.027251447, 0.96728855]]\n",
            "1367       [[0.002706246, 0.0060051004, 0.99128866]]\n",
            "1368         [[0.005181627, 0.21739078, 0.77742755]]\n",
            "1369          [[0.007133038, 0.08515891, 0.9077081]]\n",
            "1370          [[0.00665592, 0.86090976, 0.13243431]]\n",
            "1371        [[0.0020005328, 0.9774589, 0.020540545]]\n",
            "1372     [[0.0014833203, 0.00087785895, 0.99763894]]\n",
            "1373          [[0.029540153, 0.00783367, 0.9626261]]\n",
            "1374        [[0.0029394596, 0.03988881, 0.95717174]]\n",
            "1375        [[0.0005327315, 0.9968689, 0.002598389]]\n",
            "1376       [[0.0013611994, 0.0040718853, 0.9945669]]\n",
            "1377       [[0.0132975215, 0.070045374, 0.91665703]]\n",
            "1378          [[0.001772832, 0.02909757, 0.9691297]]\n",
            "1379        [[0.0009520105, 0.007944524, 0.9911034]]\n",
            "1380        [[0.96995723, 0.025988158, 0.004054573]]\n",
            "1381         [[0.047148567, 0.13209952, 0.82075197]]\n",
            "1382      [[0.99920756, 0.0001640657, 0.0006283951]]\n",
            "1383          [[0.33391902, 0.58891124, 0.07716974]]\n",
            "1384         [[0.083165936, 0.16286922, 0.75396484]]\n",
            "1385         [[0.010445193, 0.046966244, 0.9425886]]\n",
            "1386        [[0.011033905, 0.0028925445, 0.9860736]]\n",
            "1387      [[0.0010935584, 0.0011517598, 0.99775475]]\n",
            "1388         [[0.012235939, 0.19945522, 0.78830886]]\n",
            "1389           [[0.1614963, 0.15115424, 0.68734944]]\n",
            "1390            [[0.0204724, 0.66473126, 0.3147963]]\n",
            "1391        [[0.004468192, 0.006170901, 0.98936087]]\n",
            "1392        [[0.020297637, 0.030091709, 0.94961065]]\n",
            "1393      [[0.008072149, 0.00078582036, 0.99114203]]\n",
            "1394         [[0.011942864, 0.01666088, 0.97139627]]\n",
            "1395           [[0.01830738, 0.13869433, 0.8429983]]\n",
            "1396       [[0.0061133197, 0.018986002, 0.97490054]]\n",
            "1397          [[0.013066397, 0.21071914, 0.7762144]]\n",
            "1398         [[0.0059934165, 0.07808311, 0.9159234]]\n",
            "1399         [[0.016866798, 0.76456416, 0.21856904]]\n",
            "1400           [[0.007251163, 0.7704247, 0.2223241]]\n",
            "1401        [[0.019774009, 0.0019424971, 0.9782834]]\n",
            "1402        [[0.0017615978, 0.19007821, 0.80816025]]\n",
            "1403       [[0.0016208353, 0.0023295563, 0.9960497]]\n",
            "1404             [[0.10043159, 0.67848, 0.22108842]]\n",
            "1405             [[0.10043159, 0.67848, 0.22108842]]\n",
            "1406           [[0.29305404, 0.5010922, 0.20585375]]\n",
            "1407             [[0.10043159, 0.67848, 0.22108842]]\n",
            "1408         [[0.0068475585, 0.51949805, 0.4736544]]\n",
            "1409          [[0.020470118, 0.7012714, 0.27825847]]\n",
            "1410          [[0.019332774, 0.22259575, 0.7580715]]\n",
            "1411         [[0.015609104, 0.09836256, 0.88602835]]\n",
            "1412            [[0.018894, 0.20376346, 0.77734256]]\n",
            "1413      [[0.0016573414, 0.0024117003, 0.99593097]]\n",
            "1414          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1415           [[0.034424394, 0.5574825, 0.4080931]]\n",
            "1416          [[0.07336312, 0.46466395, 0.46197295]]\n",
            "1417            [[0.144789, 0.8323546, 0.022856362]]\n",
            "1418          [[0.011674115, 0.03886263, 0.9494633]]\n",
            "1419          [[0.0057586893, 0.5602317, 0.4340096]]\n",
            "1420        [[0.008948283, 0.090497725, 0.90055394]]\n",
            "1421        [[0.002115232, 0.002454512, 0.99543035]]\n",
            "1422         [[0.005736004, 0.010015172, 0.9842488]]\n",
            "1423        [[0.0030702082, 0.031727646, 0.9652022]]\n",
            "1424          [[0.34319434, 0.21689868, 0.43990698]]\n",
            "1425         [[0.004259185, 0.11994218, 0.87579864]]\n",
            "1426          [[0.007316263, 0.0631788, 0.92950493]]\n",
            "1427         [[0.0062380433, 0.8682532, 0.12550882]]\n",
            "1428          [[0.008448272, 0.81304187, 0.1785099]]\n",
            "1429           [[0.010839611, 0.71101743, 0.278143]]\n",
            "1430          [[0.016457964, 0.08421114, 0.8993309]]\n",
            "1431         [[0.010040749, 0.09471488, 0.89524436]]\n",
            "1432        [[0.006169839, 0.016715407, 0.97711474]]\n",
            "1433          [[0.014193781, 0.8090065, 0.17679968]]\n",
            "1434         [[0.0010531617, 0.9266202, 0.07232671]]\n",
            "1435       [[0.0027308268, 0.008920306, 0.98834884]]\n",
            "1436       [[0.0028826774, 0.013222117, 0.98389524]]\n",
            "1437        [[0.0025030426, 0.027940797, 0.9695562]]\n",
            "1438           [[0.06343329, 0.13452321, 0.8020435]]\n",
            "1439         [[0.0080657555, 0.8750638, 0.11687049]]\n",
            "1440         [[0.008391417, 0.22400057, 0.76760805]]\n",
            "1441          [[0.007107289, 0.79912144, 0.1937713]]\n",
            "1442            [[0.02861267, 0.16339032, 0.807997]]\n",
            "1443         [[0.0093277795, 0.8458574, 0.14481488]]\n",
            "1444            [[0.1608268, 0.6418317, 0.19734149]]\n",
            "1445             [[0.01695812, 0.709693, 0.2733489]]\n",
            "1446         [[0.013905605, 0.036831863, 0.9492626]]\n",
            "1447           [[0.040418703, 0.2984196, 0.6611617]]\n",
            "1448          [[0.041984744, 0.25111035, 0.7069049]]\n",
            "1449           [[0.7549568, 0.15861681, 0.08642636]]\n",
            "1450         [[0.012066461, 0.8878341, 0.100099415]]\n",
            "1451         [[0.041911803, 0.75900745, 0.19908069]]\n",
            "1452         [[0.030334495, 0.60483015, 0.36483535]]\n",
            "1453      [[0.00018624522, 0.99419975, 0.005614026]]\n",
            "1454        [[0.0012194777, 0.9868138, 0.011966774]]\n",
            "1455        [[0.0022642275, 0.027017655, 0.9707181]]\n",
            "1456          [[0.071576275, 0.02987657, 0.8985472]]\n",
            "1457          [[0.34130964, 0.22759117, 0.43109924]]\n",
            "1458            [[0.0473144, 0.6612144, 0.29147112]]\n",
            "1459      [[0.0071186787, 0.0016597224, 0.99122155]]\n",
            "1460       [[0.0038053177, 0.0010342445, 0.9951604]]\n",
            "1461          [[0.05534578, 0.09021895, 0.85443527]]\n",
            "1462          [[0.002572334, 0.03738698, 0.9600407]]\n",
            "1463        [[0.0038735452, 0.27257952, 0.72354686]]\n",
            "1464      [[0.0031317053, 0.0015763928, 0.99529195]]\n",
            "1465        [[0.013229207, 0.032400712, 0.95437014]]\n",
            "1466         [[0.006174516, 0.01382788, 0.97999763]]\n",
            "1467       [[0.003542312, 0.0135710295, 0.98288673]]\n",
            "1468       [[0.008350805, 0.0021968305, 0.98945236]]\n",
            "1469         [[0.01664474, 0.013428372, 0.96992695]]\n",
            "1470      [[0.0026249518, 0.0042690984, 0.99310595]]\n",
            "1471       [[0.0010413486, 0.0050451267, 0.9939135]]\n",
            "1472      [[0.0051507987, 0.0061697336, 0.98867947]]\n",
            "1473     [[0.99920243, 0.00030751954, 0.0004900607]]\n",
            "1474          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1475          [[0.00851688, 0.010713656, 0.9807694]]\n",
            "1476         [[0.033384968, 0.86596686, 0.10064819]]\n",
            "1477       [[0.0045792116, 0.0026494877, 0.9927713]]\n",
            "1478          [[0.010831696, 0.06438783, 0.9247805]]\n",
            "1479           [[0.6811677, 0.15551162, 0.16332063]]\n",
            "1480      [[0.00042945705, 0.9979532, 0.0016173966]]\n",
            "1481          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1482          [[0.3039683, 0.6914663, 0.0045653945]]\n",
            "1483           [[0.5049438, 0.4928912, 0.002165043]]\n",
            "1484        [[0.009736906, 0.0034724562, 0.9867907]]\n",
            "1485         [[0.54106927, 0.39688995, 0.062040787]]\n",
            "1486          [[0.56833893, 0.37440035, 0.05726076]]\n",
            "1487       [[0.98436654, 0.008868593, 0.0067648124]]\n",
            "1488          [[0.06490327, 0.42321464, 0.51188207]]\n",
            "1489          [[0.57623005, 0.3917744, 0.031995624]]\n",
            "1490          [[0.58782965, 0.32414687, 0.08802352]]\n",
            "1491         [[0.058292966, 0.21349503, 0.72821194]]\n",
            "1492       [[0.0019953565, 0.0012673385, 0.9967373]]\n",
            "1493             [[0.08393687, 0.190952, 0.7251112]]\n",
            "1494       [[0.0046824077, 0.0025929967, 0.9927246]]\n",
            "1495         [[0.006516197, 0.57442373, 0.41906005]]\n",
            "1496        [[0.0035892383, 0.9799728, 0.016438052]]\n",
            "1497        [[0.0035892383, 0.9799728, 0.016438052]]\n",
            "1498        [[0.08095078, 0.91507673, 0.0039725034]]\n",
            "1499          [[0.054953363, 0.31008095, 0.6349657]]\n",
            "1500         [[0.0038240636, 0.006219879, 0.989956]]\n",
            "1501      [[0.0014155792, 0.0023359163, 0.99624854]]\n",
            "1502          [[0.004977219, 0.09601651, 0.8990063]]\n",
            "1503       [[0.005765876, 0.0026757845, 0.99155843]]\n",
            "1504         [[0.000496365, 0.011529893, 0.9879738]]\n",
            "1505         [[0.016818376, 0.07710582, 0.90607584]]\n",
            "1506     [[0.0020811937, 0.00077275746, 0.99714607]]\n",
            "1507       [[0.0032782813, 0.002090652, 0.99463105]]\n",
            "1508        [[0.0023383289, 0.50840753, 0.48925412]]\n",
            "1509          [[0.015307739, 0.05869055, 0.9260017]]\n",
            "1510         [[0.0044574337, 0.01363889, 0.9819036]]\n",
            "1511        [[0.0055840677, 0.008836442, 0.9855795]]\n",
            "1512          [[0.007914432, 0.01193485, 0.9801507]]\n",
            "1513          [[0.036388315, 0.16125134, 0.8023603]]\n",
            "1514          [[0.015307739, 0.05869055, 0.9260017]]\n",
            "1515          [[0.018387413, 0.5298861, 0.45172647]]\n",
            "1516          [[0.11966606, 0.16359052, 0.71674335]]\n",
            "1517         [[0.029365301, 0.073915884, 0.8967188]]\n",
            "1518          [[0.010144517, 0.39701325, 0.5928422]]\n",
            "1519            [[0.0497753, 0.09149301, 0.8587317]]\n",
            "1520         [[0.9643039, 0.019414257, 0.016281826]]\n",
            "1521          [[0.50765514, 0.23958552, 0.25275937]]\n",
            "1522          [[0.8615582, 0.10309673, 0.035345078]]\n",
            "1523      [[0.0072133434, 0.0028172557, 0.98996943]]\n",
            "1524         [[0.51792663, 0.008580174, 0.47349313]]\n",
            "1525         [[0.016691133, 0.73470515, 0.24860375]]\n",
            "1526          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1527        [[0.008926274, 0.0053983335, 0.9856754]]\n",
            "1528          [[0.025087109, 0.06838733, 0.9065255]]\n",
            "1529        [[0.004338881, 0.016830456, 0.97883064]]\n",
            "1530        [[0.004338881, 0.016830456, 0.97883064]]\n",
            "1531        [[0.0046750223, 0.027787108, 0.9675378]]\n",
            "1532       [[0.0052352985, 0.019444834, 0.97531986]]\n",
            "1533         [[0.003850401, 0.009614704, 0.9865349]]\n",
            "1534           [[0.03751739, 0.16527724, 0.7972054]]\n",
            "1535         [[0.018504502, 0.48105735, 0.50043815]]\n",
            "1536       [[0.99785906, 0.0008123401, 0.001328583]]\n",
            "1537        [[0.97625697, 0.014793062, 0.008949995]]\n",
            "1538     [[0.9993123, 0.00021603698, 0.00047175566]]\n",
            "1539          [[0.00714359, 0.002600124, 0.9902563]]\n",
            "1540       [[0.0061861025, 0.0012143872, 0.9925995]]\n",
            "1541       [[0.0017541097, 0.0039341673, 0.9943117]]\n",
            "1542         [[0.002168873, 0.00954676, 0.98828435]]\n",
            "1543       [[0.0019903118, 0.0016710326, 0.9963387]]\n",
            "1544      [[0.0044859014, 0.0062061935, 0.98930794]]\n",
            "1545         [[0.0034950424, 0.3020917, 0.69441324]]\n",
            "1546         [[0.013941753, 0.042485647, 0.9435725]]\n",
            "1547       [[0.0033244244, 0.027663896, 0.96901166]]\n",
            "1548         [[0.014949734, 0.0131353075, 0.971915]]\n",
            "1549         [[0.049296856, 0.8285409, 0.122162245]]\n",
            "1550         [[0.0051625054, 0.5117067, 0.48313072]]\n",
            "1551       [[0.0050418125, 0.042782452, 0.95217574]]\n",
            "1552        [[0.006186574, 0.015266418, 0.97854704]]\n",
            "1553        [[0.0027268163, 0.009110997, 0.9881622]]\n",
            "1554      [[0.0058637285, 0.0058706054, 0.98826563]]\n",
            "1555        [[0.0033668638, 0.07850646, 0.91812664]]\n",
            "1556       [[0.0020339976, 0.043867413, 0.95409864]]\n",
            "1557         [[0.009033437, 0.032183483, 0.9587831]]\n",
            "1558          [[0.022983387, 0.23112167, 0.7458949]]\n",
            "1559           [[0.008792937, 0.7252599, 0.2659471]]\n",
            "1560         [[0.014655137, 0.62473375, 0.36061114]]\n",
            "1561         [[0.011787758, 0.8799175, 0.108294725]]\n",
            "1562        [[0.006734798, 0.93852955, 0.054735668]]\n",
            "1563         [[0.00823877, 0.030416055, 0.96134514]]\n",
            "1564          [[0.124420136, 0.5025307, 0.37304914]]\n",
            "1565          [[0.04165005, 0.119890556, 0.8384594]]\n",
            "1566          [[0.003404338, 0.9811017, 0.01549394]]\n",
            "1567         [[0.09814661, 0.79611516, 0.105738185]]\n",
            "1568       [[0.00066685316, 0.9653256, 0.034007493]]\n",
            "1569       [[0.00055786286, 0.9898258, 0.009616419]]\n",
            "1570       [[0.0002031881, 0.9959196, 0.0038772179]]\n",
            "1571         [[0.010148846, 0.67658937, 0.31326178]]\n",
            "1572      [[0.0032974004, 0.0016734819, 0.99502915]]\n",
            "1573         [[0.014416108, 0.60382307, 0.38176087]]\n",
            "1574              [[0.5265959, 0.068375, 0.4050291]]\n",
            "1575         [[0.35897338, 0.007016444, 0.63401014]]\n",
            "1576      [[0.99837995, 0.0006408613, 0.0009791311]]\n",
            "1577              [[0.5265959, 0.068375, 0.4050291]]\n",
            "1578       [[0.0024082244, 0.0006234532, 0.9969683]]\n",
            "1579          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1580          [[0.055419486, 0.12823936, 0.8163411]]\n",
            "1581        [[0.0012719732, 0.022193948, 0.9765341]]\n",
            "1582          [[0.003004836, 0.08261684, 0.9143783]]\n",
            "1583         [[0.002224469, 0.9925315, 0.005244076]]\n",
            "1584         [[0.028815296, 0.8903673, 0.080817394]]\n",
            "1585           [[0.11695969, 0.62391573, 0.2591246]]\n",
            "1586          [[0.057107937, 0.3063605, 0.63653153]]\n",
            "1587          [[0.025885038, 0.6710436, 0.30307144]]\n",
            "1588        [[0.00053866906, 0.990519, 0.008942348]]\n",
            "1589        [[0.0068940003, 0.058924675, 0.9341813]]\n",
            "1590        [[0.002018622, 0.0072686365, 0.9907128]]\n",
            "1591          [[0.018766565, 0.05168669, 0.9295467]]\n",
            "1592          [[0.047342237, 0.4820311, 0.47062665]]\n",
            "1593           [[0.014297878, 0.5265387, 0.4591634]]\n",
            "1594        [[0.003660333, 0.010704832, 0.98563486]]\n",
            "1595        [[0.0046201088, 0.031473283, 0.9639066]]\n",
            "1596          [[0.006870368, 0.21571656, 0.7774131]]\n",
            "1597          [[0.008257269, 0.22380103, 0.7679417]]\n",
            "1598          [[0.008360071, 0.76213133, 0.2295086]]\n",
            "1599     [[7.6472264e-05, 0.99678934, 0.0031342134]]\n",
            "1600      [[5.692539e-05, 0.99780923, 0.0021339133]]\n",
            "1601      [[0.00024681955, 0.98936635, 0.010386785]]\n",
            "1602          [[0.004992694, 0.35166103, 0.6433463]]\n",
            "1603      [[0.00027715517, 0.9972754, 0.0024474317]]\n",
            "1604         [[0.006861808, 0.005408086, 0.9877301]]\n",
            "1605            [[0.1180497, 0.19746552, 0.6844848]]\n",
            "1606         [[0.006106766, 0.009227095, 0.9846661]]\n",
            "1607        [[0.0038122474, 0.014694167, 0.9814936]]\n",
            "1608            [[0.6171066, 0.1501161, 0.23277724]]\n",
            "1609          [[0.05794964, 0.16541995, 0.77663034]]\n",
            "1610        [[0.9816766, 0.0095607415, 0.008762743]]\n",
            "1611           [[0.24904306, 0.38261142, 0.3683455]]\n",
            "1612           [[0.22596744, 0.3606783, 0.41335434]]\n",
            "1613         [[0.006106766, 0.009227095, 0.9846661]]\n",
            "1614         [[0.021550516, 0.023364706, 0.9550848]]\n",
            "1615       [[0.0017076981, 0.014685333, 0.98360693]]\n",
            "1616      [[0.00038182773, 0.89622974, 0.103388496]]\n",
            "1617           [[0.03219124, 0.10853851, 0.8592703]]\n",
            "1618        [[0.000485796, 0.048820555, 0.95069355]]\n",
            "1619       [[0.0028920972, 0.0013623668, 0.9957456]]\n",
            "1620       [[0.0058276528, 0.0021406037, 0.9920317]]\n",
            "1621        [[0.0041868035, 0.020729357, 0.9750838]]\n",
            "1622       [[0.0011351402, 0.0013412238, 0.9975236]]\n",
            "1623      [[0.00070962874, 0.0015852323, 0.9977053]]\n",
            "1624       [[0.002080584, 0.00062523055, 0.9972941]]\n",
            "1625        [[0.0029189144, 0.10584849, 0.89123255]]\n",
            "1626       [[0.011192799, 0.0013245159, 0.98748267]]\n",
            "1627          [[0.02125673, 0.005142366, 0.9736009]]\n",
            "1628      [[0.0063768215, 0.00081396906, 0.9928092]]\n",
            "1629         [[0.0062567284, 0.04755092, 0.9461923]]\n",
            "1630        [[0.004761804, 0.015423949, 0.97981423]]\n",
            "1631          [[0.019848026, 0.21512671, 0.7650253]]\n",
            "1632        [[0.024784673, 0.0097980015, 0.9654174]]\n",
            "1633       [[0.0014511896, 0.0018990344, 0.9966498]]\n",
            "1634      [[0.0011854584, 0.0039204876, 0.99489415]]\n",
            "1635           [[0.09544443, 0.04001787, 0.8645377]]\n",
            "1636         [[0.005632414, 0.019215224, 0.9751524]]\n",
            "1637        [[0.9822464, 0.015486541, 0.0022670766]]\n",
            "1638         [[0.0099293655, 0.27415374, 0.7159169]]\n",
            "1639       [[0.0014399063, 0.96411985, 0.034440257]]\n",
            "1640           [[0.04374614, 0.14122431, 0.8150295]]\n",
            "1641        [[0.0019947654, 0.009559313, 0.9884459]]\n",
            "1642       [[0.0014399063, 0.96411985, 0.034440257]]\n",
            "1643           [[0.08602767, 0.5388517, 0.37512067]]\n",
            "1644        [[0.0065952586, 0.58468324, 0.40872148]]\n",
            "1645           [[0.08629168, 0.6573879, 0.25632033]]\n",
            "1646         [[0.022267548, 0.37898225, 0.59875023]]\n",
            "1647          [[0.0015890257, 0.971763, 0.02664798]]\n",
            "1648       [[0.0027691156, 0.027491298, 0.96973956]]\n",
            "1649        [[0.0029247317, 0.36882696, 0.62824833]]\n",
            "1650         [[0.004412399, 0.09947959, 0.89610803]]\n",
            "1651        [[0.0038680797, 0.71375805, 0.28237385]]\n",
            "1652         [[0.007385957, 0.22861598, 0.76399803]]\n",
            "1653          [[0.032365926, 0.03917598, 0.9284581]]\n",
            "1654          [[0.023598429, 0.05429329, 0.9221083]]\n",
            "1655            [[0.824339, 0.02245661, 0.15320437]]\n",
            "1656          [[0.012535785, 0.01047953, 0.9769846]]\n",
            "1657          [[0.7882121, 0.123936586, 0.08785124]]\n",
            "1658           [[0.03503549, 0.24193728, 0.7230272]]\n",
            "1659           [[0.21453151, 0.2525481, 0.53292036]]\n",
            "1660       [[0.007521439, 0.0007775615, 0.99170107]]\n",
            "1661       [[0.0054640234, 0.0025177426, 0.9920183]]\n",
            "1662         [[0.014022589, 0.048110917, 0.9378665]]\n",
            "1663        [[0.003683656, 0.058921468, 0.93739486]]\n",
            "1664        [[0.003683656, 0.058921468, 0.93739486]]\n",
            "1665       [[0.0019492144, 0.0036219596, 0.9944289]]\n",
            "1666        [[0.00334356, 0.0019603153, 0.99469614]]\n",
            "1667       [[0.0020174086, 0.010647835, 0.98733485]]\n",
            "1668         [[0.74014825, 0.080699064, 0.17915267]]\n",
            "1669          [[0.02689177, 0.64167476, 0.33143348]]\n",
            "1670      [[0.0051070014, 0.0024392563, 0.99245375]]\n",
            "1671       [[0.009128483, 0.0017400379, 0.98913145]]\n",
            "1672           [[0.028997287, 0.1820109, 0.7889918]]\n",
            "1673           [[0.05914304, 0.14131452, 0.7995424]]\n",
            "1674           [[0.6089519, 0.21369252, 0.17735556]]\n",
            "1675         [[0.9286131, 0.056179848, 0.015207011]]\n",
            "1676        [[0.046884947, 0.9424303, 0.0106847575]]\n",
            "1677          [[0.055744097, 0.11267243, 0.8315835]]\n",
            "1678            [[0.1133643, 0.8220965, 0.06453919]]\n",
            "1679          [[0.06154633, 0.71522194, 0.22323175]]\n",
            "1680         [[0.028796207, 0.052906074, 0.9182977]]\n",
            "1681        [[0.022417316, 0.038827278, 0.93875533]]\n",
            "1682        [[0.008480171, 0.0049292403, 0.9865906]]\n",
            "1683         [[0.020267773, 0.041122053, 0.9386102]]\n",
            "1684      [[0.0021415572, 0.00092356594, 0.9969349]]\n",
            "1685     [[0.99863285, 0.0009503351, 0.00041678964]]\n",
            "1686           [[0.05453525, 0.19463392, 0.7508308]]\n",
            "1687      [[0.0061682817, 0.0055913455, 0.98824036]]\n",
            "1688         [[0.022552464, 0.022366056, 0.9550815]]\n",
            "1689           [[0.24282858, 0.01102501, 0.7461464]]\n",
            "1690       [[0.0025694415, 0.0091255475, 0.9883051]]\n",
            "1691           [[0.0610077, 0.8822555, 0.056736805]]\n",
            "1692          [[0.9262198, 0.06862665, 0.005153621]]\n",
            "1693           [[0.010440748, 0.58946425, 0.400095]]\n",
            "1694          [[0.8962341, 0.07543124, 0.028334716]]\n",
            "1695          [[0.022686474, 0.0732183, 0.90409523]]\n",
            "1696           [[0.024316011, 0.2725892, 0.7030947]]\n",
            "1697          [[0.010937505, 0.0401294, 0.94893306]]\n",
            "1698        [[0.0026247231, 0.8942687, 0.103106536]]\n",
            "1699          [[0.005307503, 0.0548716, 0.93982095]]\n",
            "1700        [[0.0027880068, 0.028392907, 0.9688191]]\n",
            "1701          [[0.00221673, 0.030985437, 0.9667978]]\n",
            "1702      [[0.00081574556, 0.97543734, 0.023746919]]\n",
            "1703           [[0.0002868508, 0.980419, 0.0192942]]\n",
            "1704         [[0.000919699, 0.9462787, 0.052801613]]\n",
            "1705        [[0.0016363659, 0.001577119, 0.9967866]]\n",
            "1706        [[0.0008121483, 0.92572063, 0.07346719]]\n",
            "1707           [[0.0025046826, 0.787098, 0.2103973]]\n",
            "1708        [[0.0005089108, 0.9737544, 0.025736699]]\n",
            "1709         [[0.074912995, 0.8976981, 0.027388886]]\n",
            "1710           [[0.16676708, 0.824912, 0.008320942]]\n",
            "1711         [[0.9550475, 0.028841257, 0.016111163]]\n",
            "1712          [[0.34456095, 0.47924158, 0.17619748]]\n",
            "1713         [[0.04865233, 0.016142175, 0.93520546]]\n",
            "1714          [[0.021454114, 0.6008781, 0.37766773]]\n",
            "1715         [[0.9937982, 0.003798616, 0.002403139]]\n",
            "1716      [[0.0010356021, 0.00074531964, 0.9982191]]\n",
            "1717           [[0.042892847, 0.6503304, 0.3067767]]\n",
            "1718          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1719        [[0.011065261, 0.013152159, 0.97578263]]\n",
            "1720     [[0.9990044, 0.00053877616, 0.00045677726]]\n",
            "1721          [[0.03904302, 0.014361172, 0.9465958]]\n",
            "1722           [[0.04299607, 0.4142301, 0.54277384]]\n",
            "1723          [[0.07708889, 0.11789095, 0.80502015]]\n",
            "1724           [[0.041901197, 0.4845263, 0.4735724]]\n",
            "1725      [[0.0025086515, 0.0056070117, 0.99188435]]\n",
            "1726        [[0.0061678886, 0.04699995, 0.94683224]]\n",
            "1727        [[0.0046907584, 0.042864863, 0.9524444]]\n",
            "1728          [[0.19771484, 0.29752597, 0.50475925]]\n",
            "1729         [[0.052725077, 0.29582602, 0.65144885]]\n",
            "1730       [[0.0024723534, 0.0013981351, 0.9961295]]\n",
            "1731      [[0.0010452699, 0.0015511486, 0.99740356]]\n",
            "1732        [[0.0029629504, 0.000693764, 0.9963433]]\n",
            "1733       [[0.0019020827, 0.025716959, 0.97238094]]\n",
            "1734        [[0.002940468, 0.0064781825, 0.9905813]]\n",
            "1735      [[0.0024587754, 0.99278885, 0.0047524013]]\n",
            "1736       [[0.0017565334, 0.006275651, 0.99196786]]\n",
            "1737      [[0.0013757496, 0.0025637073, 0.99606055]]\n",
            "1738      [[0.0011771884, 0.0012601243, 0.99756265]]\n",
            "1739           [[0.044634998, 0.204753, 0.75061196]]\n",
            "1740        [[0.0035798717, 0.81393903, 0.18248105]]\n",
            "1741            [[0.0161086, 0.8167147, 0.16717674]]\n",
            "1742         [[0.0095019955, 0.6331215, 0.35737646]]\n",
            "1743          [[0.03316048, 0.86267066, 0.10416878]]\n",
            "1744      [[0.0016925633, 0.0059205424, 0.99238694]]\n",
            "1745       [[0.013795146, 0.0010631699, 0.98514175]]\n",
            "1746        [[0.004838574, 0.00054541713, 0.994616]]\n",
            "1747        [[0.02699324, 0.0028945834, 0.97011214]]\n",
            "1748           [[0.06775323, 0.7060539, 0.22619288]]\n",
            "1749          [[0.018119177, 0.017059775, 0.964821]]\n",
            "1750          [[0.010322294, 0.21709548, 0.7725823]]\n",
            "1751        [[0.0016604393, 0.020574028, 0.9777655]]\n",
            "1752          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1753         [[0.018678386, 0.13318984, 0.84813184]]\n",
            "1754         [[0.31501102, 0.66338015, 0.021608794]]\n",
            "1755         [[0.49745315, 0.49306485, 0.009481993]]\n",
            "1756          [[0.17568591, 0.39161414, 0.43269992]]\n",
            "1757           [[0.5856028, 0.29659143, 0.11780579]]\n",
            "1758          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1759         [[0.031282693, 0.84578377, 0.12293347]]\n",
            "1760          [[0.002343196, 0.7714586, 0.22619814]]\n",
            "1761         [[0.002795922, 0.52006924, 0.47713482]]\n",
            "1762           [[0.6451789, 0.13525483, 0.21956623]]\n",
            "1763          [[0.19150716, 0.10287651, 0.70561635]]\n",
            "1764       [[0.0048784744, 0.005100359, 0.99002117]]\n",
            "1765          [[0.008112804, 0.2794475, 0.71243966]]\n",
            "1766          [[0.0013344445, 0.11726662, 0.881399]]\n",
            "1767          [[0.008232871, 0.46087182, 0.5308953]]\n",
            "1768           [[0.008485394, 0.045123, 0.94639164]]\n",
            "1769       [[0.0014579884, 0.0013631255, 0.9971789]]\n",
            "1770       [[0.0017392219, 0.0021293983, 0.9961314]]\n",
            "1771        [[0.0014966564, 0.98080003, 0.01770331]]\n",
            "1772        [[0.014527448, 0.047725894, 0.93774664]]\n",
            "1773      [[0.9990325, 0.0003614329, 0.00060610473]]\n",
            "1774          [[0.0028221235, 0.1529334, 0.8442445]]\n",
            "1775           [[0.010474209, 0.4291979, 0.5603279]]\n",
            "1776          [[0.008703823, 0.19450751, 0.7967887]]\n",
            "1777          [[0.012090556, 0.5734687, 0.41444075]]\n",
            "1778          [[0.0032148394, 0.3431733, 0.6536119]]\n",
            "1779        [[0.0077151433, 0.75211585, 0.24016908]]\n",
            "1780         [[0.003319415, 0.9033619, 0.093318656]]\n",
            "1781           [[0.25821564, 0.6769257, 0.06485871]]\n",
            "1782         [[0.0016481989, 0.13882022, 0.8595315]]\n",
            "1783         [[0.094409525, 0.020817766, 0.8847727]]\n",
            "1784         [[0.109236225, 0.18477073, 0.70599306]]\n",
            "1785        [[0.0007912134, 0.9865544, 0.012654327]]\n",
            "1786       [[0.0029049716, 0.044572342, 0.95252264]]\n",
            "1787       [[0.0020639207, 0.0056562237, 0.9922799]]\n",
            "1788           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1789           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1790           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1791           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1792         [[0.010047424, 0.52657026, 0.46338233]]\n",
            "1793          [[0.013558435, 0.5794967, 0.40694487]]\n",
            "1794          [[0.012800999, 0.49124777, 0.4959512]]\n",
            "1795           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1796          [[0.011581967, 0.23692785, 0.7514902]]\n",
            "1797           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1798           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1799           [[0.015851576, 0.4838106, 0.5003378]]\n",
            "1800         [[0.0008403385, 0.100360684, 0.898799]]\n",
            "1801     [[0.0021156983, 0.00078718795, 0.99709713]]\n",
            "1802       [[0.0017631496, 0.98783743, 0.010399345]]\n",
            "1803           [[0.0075332723, 0.1853817, 0.807085]]\n",
            "1804       [[0.0014210613, 0.9921644, 0.0064145965]]\n",
            "1805          [[0.004637876, 0.8585785, 0.13678366]]\n",
            "1806           [[0.013292727, 0.6826849, 0.3040224]]\n",
            "1807         [[0.0004656114, 0.994603, 0.004931449]]\n",
            "1808        [[0.001190971, 0.98907965, 0.009729429]]\n",
            "1809        [[0.003966901, 0.0016342516, 0.9943989]]\n",
            "1810         [[0.002524072, 0.0004989122, 0.996977]]\n",
            "1811      [[0.0023012483, 0.99547464, 0.0022240633]]\n",
            "1812         [[0.023300778, 0.03459928, 0.94209987]]\n",
            "1813        [[0.010826517, 0.0022442022, 0.9869293]]\n",
            "1814          [[0.006767228, 0.40137026, 0.5918625]]\n",
            "1815          [[0.14452358, 0.011932709, 0.8435437]]\n",
            "1816         [[0.005019424, 0.003463758, 0.9915168]]\n",
            "1817          [[0.019160073, 0.03980632, 0.9410336]]\n",
            "1818       [[0.9877594, 0.0056090183, 0.0066316035]]\n",
            "1819           [[0.54658973, 0.27622616, 0.1771841]]\n",
            "1820        [[0.019170355, 0.011289727, 0.96953994]]\n",
            "1821         [[0.019672902, 0.00762515, 0.97270185]]\n",
            "1822          [[0.031730622, 0.11849151, 0.8497778]]\n",
            "1823          [[0.13545159, 0.66321015, 0.20133825]]\n",
            "1824          [[0.37950504, 0.34554988, 0.27494514]]\n",
            "1825          [[0.004854806, 0.02703139, 0.9681139]]\n",
            "1826           [[0.08873935, 0.14590943, 0.7653512]]\n",
            "1827           [[0.2613176, 0.31941485, 0.41926757]]\n",
            "1828         [[0.053874422, 0.9253589, 0.020766677]]\n",
            "1829          [[0.9007142, 0.012218682, 0.08706718]]\n",
            "1830         [[0.112564996, 0.27807292, 0.60936207]]\n",
            "1831         [[0.023121737, 0.14353177, 0.83334655]]\n",
            "1832           [[0.02851511, 0.11450169, 0.8569832]]\n",
            "1833          [[0.06754155, 0.64168656, 0.29077184]]\n",
            "1834          [[0.073795184, 0.7096481, 0.21655679]]\n",
            "1835          [[0.02348459, 0.059250955, 0.9172645]]\n",
            "1836           [[0.5047893, 0.25890344, 0.23630725]]\n",
            "1837         [[0.030501451, 0.098751076, 0.8707475]]\n",
            "1838         [[0.032627955, 0.47772852, 0.48964345]]\n",
            "1839           [[0.4631413, 0.4881358, 0.048722852]]\n",
            "1840          [[0.07735049, 0.27604827, 0.64660126]]\n",
            "1841         [[0.054906446, 0.48465577, 0.46043786]]\n",
            "1842          [[0.057129424, 0.21501939, 0.7278512]]\n",
            "1843          [[0.011635718, 0.056302298, 0.932062]]\n",
            "1844           [[0.07604712, 0.09107123, 0.8328817]]\n",
            "1845        [[0.0041787173, 0.0010822933, 0.994739]]\n",
            "1846        [[0.003077559, 0.0057349554, 0.9911875]]\n",
            "1847       [[0.009265074, 0.0049266913, 0.98580825]]\n",
            "1848         [[0.010428864, 0.02749282, 0.96207833]]\n",
            "1849        [[0.0022939397, 0.023340303, 0.9743658]]\n",
            "1850         [[0.01728432, 0.028299984, 0.95441574]]\n",
            "1851       [[0.061188877, 0.0060915076, 0.93271965]]\n",
            "1852       [[0.0030822337, 0.0020894497, 0.9948283]]\n",
            "1853      [[0.0113528045, 0.0005839599, 0.98806316]]\n",
            "1854            [[0.5580362, 0.19015503, 0.2518088]]\n",
            "1855          [[0.9555068, 0.0396594, 0.0048337877]]\n",
            "1856          [[0.8836046, 0.029399352, 0.08699607]]\n",
            "1857         [[0.00916199, 0.033560727, 0.95727736]]\n",
            "1858         [[0.009080944, 0.053935684, 0.9369834]]\n",
            "1859        [[0.0020863686, 0.007874207, 0.9900394]]\n",
            "1860       [[0.0062635555, 0.014004315, 0.97973216]]\n",
            "1861        [[0.0043125832, 0.12376026, 0.87192714]]\n",
            "1862       [[0.0027118938, 0.023561971, 0.97372615]]\n",
            "1863        [[0.0051465933, 0.025427721, 0.9694258]]\n",
            "1864       [[0.0018766749, 0.0030267627, 0.9950966]]\n",
            "1865        [[0.0061048237, 0.015147449, 0.9787477]]\n",
            "1866          [[0.031054117, 0.40178427, 0.5671616]]\n",
            "1867        [[0.0024555023, 0.09640014, 0.90114427]]\n",
            "1868         [[0.0030147445, 0.6347022, 0.36228308]]\n",
            "1869         [[0.0012005466, 0.7747635, 0.22403587]]\n",
            "1870         [[0.0058364263, 0.8178569, 0.17630668]]\n",
            "1871      [[0.0031798263, 0.0021904225, 0.99462974]]\n",
            "1872       [[0.0035202976, 0.015003817, 0.98147583]]\n",
            "1873         [[0.00254614, 0.0052027167, 0.9922512]]\n",
            "1874       [[0.0011171638, 0.0019882577, 0.9968945]]\n",
            "1875           [[0.05881263, 0.31891465, 0.6222728]]\n",
            "1876          [[0.0025373737, 0.7013776, 0.2960851]]\n",
            "1877        [[0.0022935176, 0.003909628, 0.9937968]]\n",
            "1878         [[0.003690179, 0.026189715, 0.9701201]]\n",
            "1879         [[0.003709066, 0.007275592, 0.9890154]]\n",
            "1880         [[0.00884696, 0.038028847, 0.95312417]]\n",
            "1881         [[0.0033185321, 0.14969195, 0.8469895]]\n",
            "1882        [[0.0012307666, 0.003351638, 0.9954176]]\n",
            "1883         [[0.006491028, 0.00899272, 0.98451626]]\n",
            "1884       [[0.0016694695, 0.0023259223, 0.9960045]]\n",
            "1885       [[0.0045213546, 0.0019669773, 0.9935116]]\n",
            "1886         [[0.049344487, 0.05876099, 0.89189446]]\n",
            "1887         [[0.004934484, 0.019957406, 0.9751081]]\n",
            "1888          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1889          [[0.79619753, 0.17437881, 0.02942365]]\n",
            "1890           [[0.12390534, 0.6181124, 0.25798225]]\n",
            "1891          [[0.055075783, 0.11559709, 0.8293271]]\n",
            "1892          [[0.048597865, 0.28807425, 0.6633279]]\n",
            "1893         [[0.94736177, 0.015177286, 0.03746097]]\n",
            "1894        [[0.0026450236, 0.001277849, 0.9960771]]\n",
            "1895       [[0.0014667715, 0.016620994, 0.98191226]]\n",
            "1896            [[0.024615264, 0.0831197, 0.892265]]\n",
            "1897          [[0.008226152, 0.8100927, 0.18168113]]\n",
            "1898          [[0.51527053, 0.4736025, 0.011126985]]\n",
            "1899         [[0.016182674, 0.9604496, 0.023367684]]\n",
            "1900          [[0.16769996, 0.7717811, 0.060519002]]\n",
            "1901           [[0.26372406, 0.32654968, 0.4097263]]\n",
            "1902       [[0.0049791792, 0.004710561, 0.99031025]]\n",
            "1903          [[0.6189597, 0.021716448, 0.35932374]]\n",
            "1904          [[0.68641514, 0.2892605, 0.024324333]]\n",
            "1905       [[0.98421454, 0.013794816, 0.0019907395]]\n",
            "1906          [[0.39045817, 0.57554674, 0.03399509]]\n",
            "1907        [[0.0015829309, 0.012814314, 0.9856026]]\n",
            "1908         [[0.005218981, 0.0038360257, 0.990945]]\n",
            "1909            [[0.13951632, 0.4240473, 0.4364364]]\n",
            "1910       [[0.0019178443, 0.0013405634, 0.9967416]]\n",
            "1911          [[0.035508934, 0.12207054, 0.8424205]]\n",
            "1912         [[0.0067062066, 0.51786023, 0.4754336]]\n",
            "1913         [[0.013257105, 0.118898265, 0.8678445]]\n",
            "1914       [[0.008423742, 0.0082086595, 0.98336756]]\n",
            "1915        [[0.006829383, 0.0117617315, 0.9814089]]\n",
            "1916           [[0.010512971, 0.07356504, 0.915922]]\n",
            "1917         [[0.022673637, 0.55607796, 0.42124838]]\n",
            "1918          [[0.01090183, 0.47401157, 0.51508665]]\n",
            "1919        [[0.011947982, 0.034935057, 0.95311695]]\n",
            "1920         [[0.003307274, 0.04388845, 0.95280427]]\n",
            "1921           [[0.3712975, 0.08718259, 0.54151994]]\n",
            "1922          [[0.8487504, 0.025452983, 0.12579654]]\n",
            "1923         [[0.0054684775, 0.23494132, 0.7595902]]\n",
            "1924       [[0.0028963478, 0.003023403, 0.99408025]]\n",
            "1925       [[0.002200835, 0.0022938256, 0.99550533]]\n",
            "1926        [[0.00178369, 0.0012971207, 0.99691916]]\n",
            "1927        [[0.002192691, 0.0005266422, 0.9972806]]\n",
            "1928         [[0.001025644, 0.05733981, 0.94163454]]\n",
            "1929       [[0.0005501006, 0.0031747336, 0.9962752]]\n",
            "1930      [[0.0013165912, 0.0010137508, 0.99766964]]\n",
            "1931      [[0.0008554611, 0.0030408285, 0.99610376]]\n",
            "1932       [[0.0005501006, 0.0031747336, 0.9962752]]\n",
            "1933           [[0.935113, 0.031650007, 0.03323701]]\n",
            "1934      [[0.99317497, 0.0041236957, 0.0027012627]]\n",
            "1935      [[0.99739814, 0.0017437958, 0.0008581434]]\n",
            "1936            [[0.12893789, 0.585511, 0.28555113]]\n",
            "1937       [[0.0030432635, 0.0005183156, 0.9964385]]\n",
            "1938           [[0.02696757, 0.054766424, 0.918266]]\n",
            "1939          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "1940           [[0.005671297, 0.04318366, 0.951145]]\n",
            "1941           [[0.08665769, 0.026477238, 0.886865]]\n",
            "1942       [[0.0034424646, 0.0020856834, 0.9944719]]\n",
            "1943         [[0.005545133, 0.36954007, 0.62491477]]\n",
            "1944      [[0.0064917016, 0.0062902328, 0.98721814]]\n",
            "1945          [[0.941211, 0.002609167, 0.056179848]]\n",
            "1946       [[0.0076065026, 0.0077266446, 0.9846668]]\n",
            "1947            [[0.04153628, 0.2296235, 0.7288402]]\n",
            "1948           [[0.088603646, 0.26455832, 0.646838]]\n",
            "1949         [[0.0018378064, 0.8676743, 0.13048789]]\n",
            "1950       [[0.0026203762, 0.011950334, 0.98542935]]\n",
            "1951      [[0.0040513854, 0.0051895306, 0.99075913]]\n",
            "1952          [[0.008067953, 0.23081496, 0.7611171]]\n",
            "1953      [[0.0027591793, 0.0011985842, 0.99604225]]\n",
            "1954          [[0.005681279, 0.09940732, 0.8949114]]\n",
            "1955       [[0.0021977765, 0.0073628123, 0.9904394]]\n",
            "1956       [[0.00067164685, 0.01425454, 0.98507375]]\n",
            "1957        [[0.0060234107, 0.15670331, 0.83727336]]\n",
            "1958          [[0.004099155, 0.7568266, 0.23907429]]\n",
            "1959           [[0.7369018, 0.2516896, 0.011408547]]\n",
            "1960       [[0.0030323504, 0.9928966, 0.0040710364]]\n",
            "1961           [[0.025696151, 0.8191926, 0.1551113]]\n",
            "1962        [[0.0014654564, 0.017859112, 0.9806755]]\n",
            "1963         [[0.0132624805, 0.3736995, 0.61303806]]\n",
            "1964       [[0.007794956, 0.0045067878, 0.98769826]]\n",
            "1965       [[0.007794956, 0.0045067878, 0.98769826]]\n",
            "1966        [[0.0037898195, 0.077165104, 0.9190451]]\n",
            "1967          [[0.021313021, 0.6253601, 0.35332692]]\n",
            "1968          [[0.026985837, 0.7368322, 0.23618189]]\n",
            "1969          [[0.63016826, 0.35234582, 0.01748587]]\n",
            "1970         [[0.0032384351, 0.9634973, 0.03326426]]\n",
            "1971        [[0.016581362, 0.0035280362, 0.9798906]]\n",
            "1972       [[0.010497955, 0.0007639851, 0.98873806]]\n",
            "1973          [[0.012717004, 0.24704723, 0.7402358]]\n",
            "1974          [[0.018287534, 0.015613481, 0.966099]]\n",
            "1975        [[0.0045280643, 0.001040859, 0.9944311]]\n",
            "1976        [[0.004674232, 0.93986815, 0.055457618]]\n",
            "1977          [[0.088247836, 0.36916485, 0.5425873]]\n",
            "1978          [[0.008449051, 0.10403935, 0.8875116]]\n",
            "1979          [[0.026049465, 0.7259242, 0.24802633]]\n",
            "1980           [[0.0147501, 0.07476946, 0.91048044]]\n",
            "1981          [[0.010484335, 0.03412552, 0.9553901]]\n",
            "1982       [[0.004676867, 0.0067418143, 0.98858124]]\n",
            "1983        [[0.003878165, 0.0011969612, 0.9949249]]\n",
            "1984       [[0.019979544, 0.0014567192, 0.97856367]]\n",
            "1985        [[0.008583708, 0.001424423, 0.98999184]]\n",
            "1986       [[0.0068275547, 0.013511553, 0.97966087]]\n",
            "1987        [[0.008263439, 0.0071367146, 0.9845999]]\n",
            "1988       [[0.0005969999, 0.9968106, 0.0025923604]]\n",
            "1989          [[0.030243002, 0.5588976, 0.41085935]]\n",
            "1990        [[0.0116554415, 0.90128565, 0.08705894]]\n",
            "1991       [[0.0076594106, 0.95032316, 0.042017445]]\n",
            "1992           [[0.005819804, 0.11794619, 0.876234]]\n",
            "1993         [[0.016626244, 0.005738412, 0.9776354]]\n",
            "1994         [[0.0016335774, 0.43367717, 0.5646893]]\n",
            "1995         [[0.0040002866, 0.15029112, 0.8457086]]\n",
            "1996         [[0.075709425, 0.69560385, 0.22868669]]\n",
            "1997          [[0.009263452, 0.7400683, 0.25066823]]\n",
            "1998          [[0.011047813, 0.20211524, 0.7868369]]\n",
            "1999        [[0.0031462982, 0.14301097, 0.85384274]]\n",
            "2000        [[0.0038117722, 0.056597672, 0.9395906]]\n",
            "2001        [[0.0090207085, 0.046275932, 0.9447034]]\n",
            "2002          [[0.016779676, 0.30079103, 0.6824293]]\n",
            "2003        [[0.0026283006, 0.9660918, 0.031279843]]\n",
            "2004     [[0.00025844434, 0.99850637, 0.0012351044]]\n",
            "2005    [[0.00015163142, 0.99911064, 0.00073774793]]\n",
            "2006      [[0.00028954545, 0.96828383, 0.031426642]]\n",
            "2007         [[0.019098198, 0.03221051, 0.94869125]]\n",
            "2008       [[0.0026728834, 0.9909133, 0.0064138835]]\n",
            "2009           [[0.1783146, 0.36098316, 0.46070233]]\n",
            "2010             [[0.5044123, 0.029997734, 0.46559]]\n",
            "2011          [[0.024151592, 0.8521034, 0.12374501]]\n",
            "2012       [[0.002928643, 0.0007832683, 0.99628806]]\n",
            "2013         [[0.013409694, 0.55455625, 0.43203405]]\n",
            "2014       [[0.010225872, 0.0014863225, 0.98828787]]\n",
            "2015           [[0.30432355, 0.17388774, 0.5217887]]\n",
            "2016        [[0.016320353, 0.014834392, 0.96884537]]\n",
            "2017        [[0.0005039815, 0.9924321, 0.007063836]]\n",
            "2018          [[0.22539376, 0.12564059, 0.64896566]]\n",
            "2019         [[0.0062093986, 0.3327937, 0.66099685]]\n",
            "2020         [[0.0031584094, 0.11187124, 0.8849704]]\n",
            "2021        [[0.0063831364, 0.008501969, 0.9851149]]\n",
            "2022         [[0.15089686, 0.049376745, 0.79972637]]\n",
            "2023        [[0.077881835, 0.0019880412, 0.9201302]]\n",
            "2024           [[0.025816068, 0.07694991, 0.897234]]\n",
            "2025        [[0.0026482583, 0.023638459, 0.9737133]]\n",
            "2026        [[0.008412445, 0.025267493, 0.96632004]]\n",
            "2027       [[0.010458415, 0.0058210795, 0.98372054]]\n",
            "2028       [[0.009019296, 0.0022433212, 0.98873734]]\n",
            "2029           [[0.001504058, 0.26848894, 0.730007]]\n",
            "2030        [[0.0038719778, 0.03527855, 0.96084946]]\n",
            "2031         [[0.08050505, 0.013043659, 0.90645134]]\n",
            "2032       [[0.0038228726, 0.011665461, 0.98451173]]\n",
            "2033        [[0.006792814, 0.028007584, 0.96519953]]\n",
            "2034         [[0.0025087944, 0.007949184, 0.989542]]\n",
            "2035           [[0.00446068, 0.8457109, 0.14982843]]\n",
            "2036        [[0.0008184905, 0.9941261, 0.005055423]]\n",
            "2037         [[0.0009590327, 0.9937383, 0.00530272]]\n",
            "2038        [[0.0023662208, 0.9677046, 0.029929226]]\n",
            "2039       [[0.0013035173, 0.9928784, 0.0058180685]]\n",
            "2040           [[0.06580915, 0.8864263, 0.04776449]]\n",
            "2041            [[0.03094982, 0.24646512, 0.722585]]\n",
            "2042          [[0.012635943, 0.73313135, 0.2542327]]\n",
            "2043           [[0.008230032, 0.3156885, 0.6760814]]\n",
            "2044          [[0.014319384, 0.8026872, 0.18299337]]\n",
            "2045         [[0.007335915, 0.89824617, 0.09441784]]\n",
            "2046          [[0.007873809, 0.8676816, 0.12444455]]\n",
            "2047         [[0.008900113, 0.9464455, 0.044654384]]\n",
            "2048           [[0.6089279, 0.36726213, 0.02380998]]\n",
            "2049          [[0.9141239, 0.07200667, 0.013869414]]\n",
            "2050            [[0.1537283, 0.24038032, 0.6058914]]\n",
            "2051        [[0.0015399295, 0.50326973, 0.49519026]]\n",
            "2052         [[0.0020507595, 0.03225104, 0.9656982]]\n",
            "2053        [[0.0011405421, 0.012154011, 0.9867055]]\n",
            "2054         [[0.0017167442, 0.06173088, 0.9365524]]\n",
            "2055        [[0.0009337719, 0.0012012529, 0.997865]]\n",
            "2056        [[0.0009198914, 0.04020976, 0.95887035]]\n",
            "2057       [[0.0018935697, 0.008459523, 0.98964685]]\n",
            "2058          [[0.003827017, 0.05693069, 0.9392423]]\n",
            "2059        [[0.00072397577, 0.20482062, 0.7944554]]\n",
            "2060         [[0.004873735, 0.0065902267, 0.988536]]\n",
            "2061       [[0.004374924, 0.0020393704, 0.99358577]]\n",
            "2062         [[0.042318854, 0.004970043, 0.9527111]]\n",
            "2063           [[0.03924581, 0.05694106, 0.9038131]]\n",
            "2064            [[0.02950611, 0.1391478, 0.8313461]]\n",
            "2065       [[0.0034775587, 0.005175744, 0.99134666]]\n",
            "2066         [[0.85852736, 0.13528922, 0.006183483]]\n",
            "2067        [[0.9856725, 0.012629554, 0.0016980188]]\n",
            "2068        [[0.012327504, 0.009701934, 0.97797054]]\n",
            "2069       [[0.0028009221, 0.008328034, 0.98887104]]\n",
            "2070         [[0.006281378, 0.029588798, 0.9641299]]\n",
            "2071     [[0.9989182, 0.00049185095, 0.00058998395]]\n",
            "2072          [[0.00967903, 0.04781033, 0.94251066]]\n",
            "2073         [[0.0054904846, 0.06299765, 0.9315119]]\n",
            "2074         [[0.95189476, 0.018526385, 0.02957886]]\n",
            "2075          [[0.029451746, 0.07102921, 0.8995191]]\n",
            "2076      [[0.99453425, 0.0017707885, 0.0036949294]]\n",
            "2077       [[0.9917985, 0.0063054874, 0.0018959898]]\n",
            "2078           [[0.1929266, 0.57792044, 0.22915292]]\n",
            "2079         [[0.0020406384, 0.02187886, 0.9760804]]\n",
            "2080         [[0.0020814168, 0.04736892, 0.9505496]]\n",
            "2081       [[0.0013065261, 0.0034332385, 0.9952603]]\n",
            "2082          [[0.032940406, 0.07927736, 0.8877822]]\n",
            "2083       [[0.0023040234, 0.021594483, 0.97610146]]\n",
            "2084        [[0.0016121292, 0.020428631, 0.9779593]]\n",
            "2085         [[0.0051659476, 0.20941941, 0.7854146]]\n",
            "2086         [[0.0023392832, 0.7436411, 0.25401968]]\n",
            "2087      [[0.0017538082, 0.0023171052, 0.99592906]]\n",
            "2088      [[0.99629813, 0.0024292099, 0.0012727185]]\n",
            "2089        [[0.0008406892, 0.9787627, 0.020396674]]\n",
            "2090        [[0.004208831, 0.008011433, 0.98777974]]\n",
            "2091         [[0.004660383, 0.013644174, 0.9816954]]\n",
            "2092         [[0.00128815, 0.037455946, 0.96125597]]\n",
            "2093         [[0.0036907932, 0.80848134, 0.1878279]]\n",
            "2094      [[0.0044294773, 0.0032708717, 0.99229974]]\n",
            "2095         [[0.026213545, 0.32750344, 0.64628303]]\n",
            "2096       [[0.0003920451, 0.9966342, 0.0029737842]]\n",
            "2097           [[0.00158378, 0.967068, 0.031348262]]\n",
            "2098         [[0.0036907932, 0.80848134, 0.1878279]]\n",
            "2099       [[0.0036991092, 0.014887192, 0.98141366]]\n",
            "2100        [[0.0024331224, 0.008724168, 0.9888427]]\n",
            "2101       [[0.0030462998, 0.003358032, 0.99359566]]\n",
            "2102        [[0.0023891635, 0.009062462, 0.9885484]]\n",
            "2103          [[0.0014944121, 0.012065599, 0.98644]]\n",
            "2104         [[0.04484941, 0.117317185, 0.83783346]]\n",
            "2105       [[0.0021503908, 0.0014974636, 0.9963521]]\n",
            "2106       [[0.0014213579, 0.0030003982, 0.9955782]]\n",
            "2107     [[0.99793017, 0.00082414906, 0.0012456847]]\n",
            "2108     [[0.99745387, 0.00019987971, 0.0023462889]]\n",
            "2109       [[0.0032556588, 0.9939512, 0.0027931558]]\n",
            "2110           [[0.08871622, 0.23333253, 0.6779512]]\n",
            "2111          [[0.015973806, 0.9155568, 0.06846939]]\n",
            "2112           [[0.04851552, 0.4940951, 0.45738944]]\n",
            "2113           [[0.046269353, 0.3969271, 0.5568035]]\n",
            "2114          [[0.14814326, 0.50284654, 0.34901017]]\n",
            "2115          [[0.007065069, 0.09979711, 0.8931379]]\n",
            "2116         [[0.001469932, 0.22835135, 0.77017874]]\n",
            "2117           [[0.14139979, 0.36615926, 0.4924409]]\n",
            "2118         [[0.0022468374, 0.21622838, 0.7815247]]\n",
            "2119       [[0.0058639334, 0.065254934, 0.92888117]]\n",
            "2120           [[0.06815545, 0.13493913, 0.7969054]]\n",
            "2121       [[0.0016905263, 0.024023043, 0.97428656]]\n",
            "2122        [[0.006707687, 0.008943428, 0.98434883]]\n",
            "2123        [[0.008005656, 0.090946846, 0.90104747]]\n",
            "2124          [[0.061918166, 0.14696941, 0.7911124]]\n",
            "2125          [[0.015353582, 0.58496094, 0.3996854]]\n",
            "2126      [[0.00050386233, 0.010809168, 0.98868704]]\n",
            "2127        [[0.0025532441, 0.0021978708, 0.995249]]\n",
            "2128         [[0.010815055, 0.16112436, 0.82806057]]\n",
            "2129        [[0.0031830485, 0.001560379, 0.9952565]]\n",
            "2130         [[0.9024576, 0.088687874, 0.008854491]]\n",
            "2131           [[0.8486125, 0.14005986, 0.01132768]]\n",
            "2132        [[0.0047252397, 0.00397065, 0.99130416]]\n",
            "2133         [[0.027446808, 0.06595719, 0.90659595]]\n",
            "2134       [[0.0038926045, 0.0034392693, 0.9926681]]\n",
            "2135        [[0.0047252397, 0.00397065, 0.99130416]]\n",
            "2136              [[0.5910349, 0.1298861, 0.279079]]\n",
            "2137         [[0.013263552, 0.01889118, 0.96784526]]\n",
            "2138         [[0.053263202, 0.16070393, 0.78603286]]\n",
            "2139          [[0.34098303, 0.22108543, 0.43793157]]\n",
            "2140            [[0.09093324, 0.4403469, 0.4687199]]\n",
            "2141         [[0.0013098663, 0.95572627, 0.0429639]]\n",
            "2142        [[0.0028930327, 0.91787165, 0.07923528]]\n",
            "2143        [[0.0022280428, 0.026234841, 0.9715371]]\n",
            "2144      [[0.0018757359, 0.00060452934, 0.9975197]]\n",
            "2145         [[0.062811054, 0.018259492, 0.9189294]]\n",
            "2146       [[0.0040194173, 0.0052453014, 0.9907353]]\n",
            "2147          [[0.7433377, 0.074505195, 0.18215713]]\n",
            "2148            [[0.23810373, 0.1357514, 0.6261449]]\n",
            "2149        [[0.9928188, 0.0018600755, 0.005321136]]\n",
            "2150        [[0.94307494, 0.007283036, 0.049642082]]\n",
            "2151         [[0.07915224, 0.011073222, 0.90977454]]\n",
            "2152          [[0.038511235, 0.5745005, 0.38698822]]\n",
            "2153           [[0.13552213, 0.28305918, 0.5814187]]\n",
            "2154         [[0.0019193708, 0.005378621, 0.992702]]\n",
            "2155           [[0.25250468, 0.14579907, 0.6016963]]\n",
            "2156          [[0.0057219467, 0.2752842, 0.7189939]]\n",
            "2157            [[0.04100842, 0.09928556, 0.859706]]\n",
            "2158       [[0.004697876, 0.0036626372, 0.99163955]]\n",
            "2159           [[0.018619934, 0.1408635, 0.8405165]]\n",
            "2160        [[0.014072588, 0.026779031, 0.95914835]]\n",
            "2161       [[0.009208281, 0.0037311662, 0.98706055]]\n",
            "2162     [[0.99804854, 0.00071235263, 0.0012391424]]\n",
            "2163          [[0.16937718, 0.7998703, 0.030752528]]\n",
            "2164        [[0.0005698295, 0.9948514, 0.004578776]]\n",
            "2165          [[0.023176791, 0.04085639, 0.9359668]]\n",
            "2166         [[0.008034258, 0.015170994, 0.9767948]]\n",
            "2167          [[0.005094834, 0.004000211, 0.990905]]\n",
            "2168          [[0.017193163, 0.004991935, 0.977815]]\n",
            "2169        [[0.020979486, 0.0021120799, 0.9769084]]\n",
            "2170           [[0.007844195, 0.2650444, 0.7271114]]\n",
            "2171      [[0.9984302, 0.0010601544, 0.00050963584]]\n",
            "2172          [[0.00255959, 0.00595592, 0.99148446]]\n",
            "2173           [[0.007844195, 0.2650444, 0.7271114]]\n",
            "2174           [[0.007844195, 0.2650444, 0.7271114]]\n",
            "2175         [[0.046722855, 0.108984575, 0.8442926]]\n",
            "2176          [[0.033170097, 0.03186064, 0.9349693]]\n",
            "2177          [[0.085888036, 0.2219045, 0.69220746]]\n",
            "2178           [[0.4505767, 0.20875227, 0.34067103]]\n",
            "2179             [[0.353396, 0.3172093, 0.32939473]]\n",
            "2180          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "2181        [[0.0034396637, 0.014976996, 0.9815834]]\n",
            "2182          [[0.03957118, 0.02025879, 0.94017005]]\n",
            "2183        [[0.0039252266, 0.9824421, 0.013632665]]\n",
            "2184         [[0.013781921, 0.11263732, 0.87358075]]\n",
            "2185         [[0.017335927, 0.03672957, 0.94593453]]\n",
            "2186        [[0.0020538499, 0.004916362, 0.9930298]]\n",
            "2187         [[0.053811904, 0.01318475, 0.93300337]]\n",
            "2188         [[0.053811904, 0.01318475, 0.93300337]]\n",
            "2189      [[0.0015283583, 0.0015298049, 0.99694186]]\n",
            "2190       [[0.0022136443, 0.0033144746, 0.9944719]]\n",
            "2191      [[0.0014452458, 0.0009640744, 0.99759066]]\n",
            "2192        [[0.0021213097, 0.007188642, 0.9906901]]\n",
            "2193          [[0.018372951, 0.026098164, 0.955529]]\n",
            "2194        [[0.0024297843, 0.035079554, 0.9624906]]\n",
            "2195         [[0.0067052403, 0.5322915, 0.46100333]]\n",
            "2196        [[0.0014562398, 0.045885626, 0.9526581]]\n",
            "2197          [[0.06892747, 0.20535102, 0.72572154]]\n",
            "2198         [[0.0039548664, 0.061429102, 0.934616]]\n",
            "2199           [[0.00526077, 0.17468955, 0.8200497]]\n",
            "2200         [[0.007762836, 0.33326676, 0.65897036]]\n",
            "2201          [[0.005033166, 0.12029828, 0.8746686]]\n",
            "2202        [[0.0032993248, 0.014759447, 0.9819412]]\n",
            "2203           [[0.031933922, 0.1671305, 0.8009356]]\n",
            "2204       [[0.0030765384, 0.014281855, 0.98264164]]\n",
            "2205         [[0.006133854, 0.045040365, 0.9488257]]\n",
            "2206        [[0.0029560516, 0.011435374, 0.9856086]]\n",
            "2207       [[0.0021609426, 0.0064027836, 0.9914363]]\n",
            "2208          [[0.008738108, 0.8688789, 0.12238295]]\n",
            "2209         [[0.0037579765, 0.7594612, 0.23678078]]\n",
            "2210            [[0.007944815, 0.0804832, 0.911572]]\n",
            "2211       [[0.0034178188, 0.009351874, 0.98723024]]\n",
            "2212      [[0.0017043379, 0.0060139485, 0.99228173]]\n",
            "2213       [[0.0009268913, 0.97772115, 0.021351965]]\n",
            "2214     [[0.00035135518, 0.99719113, 0.0024575307]]\n",
            "2215         [[0.013273397, 0.9449033, 0.041823238]]\n",
            "2216        [[0.0016699649, 0.9903769, 0.007953167]]\n",
            "2217        [[0.9785705, 0.018130627, 0.0032989231]]\n",
            "2218      [[0.99467963, 0.0022869776, 0.0030333395]]\n",
            "2219         [[0.08342814, 0.0025142317, 0.9140577]]\n",
            "2220         [[0.68801665, 0.049042832, 0.26294053]]\n",
            "2221       [[0.0016980591, 0.008173592, 0.99012834]]\n",
            "2222       [[0.0011741343, 0.004177127, 0.99464875]]\n",
            "2223          [[0.05319637, 0.095350236, 0.8514535]]\n",
            "2224      [[0.0018504562, 0.0011367142, 0.99701285]]\n",
            "2225       [[0.0018843213, 0.028553769, 0.96956193]]\n",
            "2226         [[0.0053177094, 0.00971971, 0.9849626]]\n",
            "2227        [[0.0069452757, 0.34306574, 0.64998895]]\n",
            "2228          [[0.032664757, 0.0764123, 0.89092296]]\n",
            "2229         [[0.0038562096, 0.00936732, 0.9867764]]\n",
            "2230        [[0.0025079548, 0.006313253, 0.9911788]]\n",
            "2231        [[0.007621551, 0.010610164, 0.98176837]]\n",
            "2232        [[0.0064290552, 0.017443806, 0.9761271]]\n",
            "2233         [[0.028463276, 0.10613025, 0.86540645]]\n",
            "2234       [[0.0052429712, 0.006668494, 0.98808855]]\n",
            "2235       [[0.0052429712, 0.006668494, 0.98808855]]\n",
            "2236      [[0.0034770933, 0.00034208578, 0.9961808]]\n",
            "2237       [[0.0016912656, 0.0016684862, 0.9966403]]\n",
            "2238        [[0.0032826024, 0.008966706, 0.9877507]]\n",
            "2239         [[0.016122075, 0.015827706, 0.9680503]]\n",
            "2240        [[0.0048799305, 0.003648434, 0.9914716]]\n",
            "2241    [[0.99917823, 0.00043696407, 0.00038467546]]\n",
            "2242         [[0.24586637, 0.036012907, 0.71812063]]\n",
            "2243            [[0.1069332, 0.28644422, 0.6066226]]\n",
            "2244          [[0.08774971, 0.06401571, 0.84823453]]\n",
            "2245          [[0.88144326, 0.07425955, 0.04429722]]\n",
            "2246        [[0.0032974682, 0.0032154047, 0.993487]]\n",
            "2247      [[0.0020854406, 0.0015188952, 0.99639565]]\n",
            "2248         [[0.0014622519, 0.000993844, 0.997544]]\n",
            "2249      [[0.0018738356, 0.0005810621, 0.99754506]]\n",
            "2250       [[0.0016884238, 0.001527186, 0.99678445]]\n",
            "2251        [[0.92967004, 0.026294168, 0.044035744]]\n",
            "2252           [[0.1661397, 0.7761813, 0.057679024]]\n",
            "2253          [[0.09710108, 0.71707946, 0.18581939]]\n",
            "2254             [[0.6086411, 0.281076, 0.11028286]]\n",
            "2255           [[0.21211009, 0.5392387, 0.24865119]]\n",
            "2256          [[0.10087418, 0.095733404, 0.8033924]]\n",
            "2257            [[0.2737058, 0.25836733, 0.4679268]]\n",
            "2258           [[0.25697765, 0.4711301, 0.27189222]]\n",
            "2259           [[0.08514354, 0.05291209, 0.8619444]]\n",
            "2260         [[0.010257291, 0.056405783, 0.9333369]]\n",
            "2261         [[0.010600881, 0.016781518, 0.9726176]]\n",
            "2262         [[0.009285991, 0.30743358, 0.68328047]]\n",
            "2263         [[0.020869156, 0.22774446, 0.75138634]]\n",
            "2264         [[0.008429675, 0.24651985, 0.74505043]]\n",
            "2265          [[0.7395813, 0.25259376, 0.007824985]]\n",
            "2266          [[0.21558785, 0.043345656, 0.7410666]]\n",
            "2267           [[0.16640514, 0.6173975, 0.21619734]]\n",
            "2268         [[0.0031471888, 0.006127814, 0.990725]]\n",
            "2269         [[0.018873347, 0.031469498, 0.9496571]]\n",
            "2270         [[0.007660982, 0.19529624, 0.79704285]]\n",
            "2271         [[0.007660982, 0.19529624, 0.79704285]]\n",
            "2272        [[0.003917172, 0.021110721, 0.97497207]]\n",
            "2273       [[0.0018992143, 0.0084782895, 0.9896225]]\n",
            "2274        [[0.004520584, 0.045094915, 0.95038456]]\n",
            "2275           [[0.1525128, 0.48073983, 0.36674732]]\n",
            "2276         [[0.007660982, 0.19529624, 0.79704285]]\n",
            "2277          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "2278        [[0.003011774, 0.0005934701, 0.9963948]]\n",
            "2279           [[0.09619898, 0.19671679, 0.7070842]]\n",
            "2280         [[0.002704205, 0.021491142, 0.9758046]]\n",
            "2281       [[0.0030484921, 0.0031081752, 0.9938433]]\n",
            "2282      [[0.0040827724, 0.0071249753, 0.98879224]]\n",
            "2283        [[0.006123856, 0.0051451223, 0.9887311]]\n",
            "2284          [[0.03479029, 0.09737429, 0.86783546]]\n",
            "2285          [[0.05430806, 0.12425613, 0.82143575]]\n",
            "2286       [[0.004229445, 0.0015052516, 0.99426526]]\n",
            "2287          [[0.008741187, 0.25384063, 0.7374182]]\n",
            "2288          [[0.008859321, 0.015563618, 0.975577]]\n",
            "2289        [[0.007829208, 0.0039175767, 0.9882532]]\n",
            "2290         [[0.04803313, 0.87560505, 0.076361865]]\n",
            "2291        [[0.010804324, 0.86641246, 0.122783184]]\n",
            "2292        [[0.010804324, 0.86641246, 0.122783184]]\n",
            "2293          [[0.120819435, 0.38391015, 0.4952704]]\n",
            "2294         [[0.002457644, 0.019480143, 0.9780621]]\n",
            "2295       [[0.0003599037, 0.99427164, 0.005368534]]\n",
            "2296           [[0.010100021, 0.860723, 0.12917697]]\n",
            "2297         [[0.04803313, 0.87560505, 0.076361865]]\n",
            "2298       [[0.008762594, 0.0031136714, 0.98812383]]\n",
            "2299         [[0.019261083, 0.016668886, 0.9640701]]\n",
            "2300         [[0.012002163, 0.42765364, 0.56034416]]\n",
            "2301           [[0.05841682, 0.23467682, 0.7069063]]\n",
            "2302           [[0.5440881, 0.12109045, 0.33482134]]\n",
            "2303       [[0.0053254403, 0.029587694, 0.96508694]]\n",
            "2304         [[0.013139565, 0.17390554, 0.81295484]]\n",
            "2305        [[0.0059903017, 0.040866792, 0.9531428]]\n",
            "2306          [[0.33695203, 0.15011089, 0.51293707]]\n",
            "2307          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "2308       [[0.0019359145, 0.020161115, 0.97790295]]\n",
            "2309        [[0.0011411714, 0.004532687, 0.9943262]]\n",
            "2310         [[0.010393136, 0.10574781, 0.88385904]]\n",
            "2311           [[0.02919957, 0.16350076, 0.8072997]]\n",
            "2312        [[0.018020468, 0.002893085, 0.97908646]]\n",
            "2313          [[0.004524107, 0.08761323, 0.9078626]]\n",
            "2314       [[0.9966685, 0.0017030608, 0.0016284105]]\n",
            "2315      [[0.00018750332, 0.9959044, 0.0039081317]]\n",
            "2316         [[0.0044231093, 0.4365735, 0.55900335]]\n",
            "2317     [[0.00016849396, 0.99714065, 0.0026909318]]\n",
            "2318          [[0.012622929, 0.37397337, 0.6134037]]\n",
            "2319         [[0.064566135, 0.14049146, 0.79494244]]\n",
            "2320         [[0.0023729424, 0.11559941, 0.8820277]]\n",
            "2321         [[0.005205263, 0.38163593, 0.61315876]]\n",
            "2322         [[0.005205263, 0.38163593, 0.61315876]]\n",
            "2323        [[0.009798789, 0.0031486955, 0.9870525]]\n",
            "2324        [[0.017915413, 0.026354302, 0.95573026]]\n",
            "2325         [[0.0039080423, 0.00694407, 0.9891479]]\n",
            "2326            [[0.6912909, 0.03429084, 0.2744182]]\n",
            "2327      [[0.0025028358, 0.00057583867, 0.9969214]]\n",
            "2328          [[0.05555449, 0.12984173, 0.81460375]]\n",
            "2329            [[0.00928272, 0.1396206, 0.8510967]]\n",
            "2330        [[0.0029901217, 0.013068545, 0.9839414]]\n",
            "2331           [[0.06212627, 0.1069668, 0.83090687]]\n",
            "2332       [[0.0022543264, 0.0040055458, 0.9937401]]\n",
            "2333      [[0.0020581286, 0.0015856614, 0.99635625]]\n",
            "2334          [[0.037279204, 0.11329643, 0.8494243]]\n",
            "2335          [[0.052975208, 0.16403024, 0.7829945]]\n",
            "2336         [[0.0044425162, 0.043569528, 0.951988]]\n",
            "2337       [[0.008373012, 0.0018536377, 0.98977333]]\n",
            "2338           [[0.02793354, 0.22047302, 0.7515934]]\n",
            "2339         [[0.012493528, 0.25125802, 0.73624843]]\n",
            "2340          [[0.42308956, 0.08489382, 0.49201664]]\n",
            "2341        [[0.0029286377, 0.020888425, 0.9761829]]\n",
            "2342        [[0.0016553855, 0.005417217, 0.9929274]]\n",
            "2343       [[0.0020041424, 0.0056382422, 0.9923577]]\n",
            "2344        [[0.002139484, 0.019710552, 0.97814995]]\n",
            "2345      [[0.0019778628, 0.00092788757, 0.9970943]]\n",
            "2346       [[0.0043291096, 0.009897795, 0.98577315]]\n",
            "2347        [[0.0037496702, 0.012597766, 0.9836526]]\n",
            "2348       [[0.0028218562, 0.0026278421, 0.9945503]]\n",
            "2349          [[0.010615292, 0.40240744, 0.5869773]]\n",
            "2350          [[0.007563807, 0.7080862, 0.28434998]]\n",
            "2351          [[0.036034122, 0.8950489, 0.06891698]]\n",
            "2352      [[0.0023404837, 0.99138767, 0.0062718303]]\n",
            "2353       [[0.007828559, 0.0034327651, 0.98873866]]\n",
            "2354           [[0.009826853, 0.02191608, 0.968257]]\n",
            "2355       [[0.030465629, 0.96659386, 0.0029404901]]\n",
            "2356           [[0.8849858, 0.10630381, 0.00871036]]\n",
            "2357          [[0.002594348, 0.03584435, 0.9615613]]\n",
            "2358       [[0.0019640054, 0.00076295814, 0.997273]]\n",
            "2359      [[0.0012981169, 0.0051319245, 0.99356997]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_raw_know_val_f1_0.7698'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# bert_spc_combined_raw_know_val_f1_0.7698\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "961QzHUyIn8A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUnNl3owFKXG"
      },
      "source": [
        "## s2 state_dict/bert_spc_combined_raw_know_val_f1_0.8014"
      ],
      "id": "fUnNl3owFKXG"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/y_insert_trimmed_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "POMudb55FKXL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "POMudb55FKXL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "341561f6-6c07-4e4a-df99-6ab5022820d4",
        "id": "S2YfnJpqFKXL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0             [[0.006949133, 0.103362955, 0.88968796]]\n",
            "1            [[0.00063931354, 0.02976206, 0.96959865]]\n",
            "2             [[0.9402042, 0.052643225, 0.0071525793]]\n",
            "3                [[0.40619925, 0.5210592, 0.07274155]]\n",
            "4               [[0.9619504, 0.011517827, 0.02653179]]\n",
            "5           [[0.00010225844, 3.105967e-05, 0.9998666]]\n",
            "6             [[0.00058505987, 0.04686607, 0.9525489]]\n",
            "7            [[0.00035736107, 0.004553057, 0.9950896]]\n",
            "8            [[0.00021747344, 0.0052856156, 0.994497]]\n",
            "9          [[0.00017239228, 3.1616164e-05, 0.9997961]]\n",
            "10           [[0.00038689942, 0.004700631, 0.9949125]]\n",
            "11             [[0.0010612418, 0.8091602, 0.18977861]]\n",
            "12            [[8.949722e-05, 0.995605, 0.0043055546]]\n",
            "13           [[5.356238e-05, 0.99187523, 0.008071239]]\n",
            "14           [[8.415844e-05, 0.97424614, 0.025669659]]\n",
            "15           [[0.0010086645, 0.0011002772, 0.9978911]]\n",
            "16              [[0.8106262, 0.15365195, 0.035721917]]\n",
            "17             [[0.001168021, 0.000868074, 0.9979639]]\n",
            "18         [[0.0004195856, 2.5468833e-05, 0.99955493]]\n",
            "19           [[0.0015172849, 0.020794531, 0.97768825]]\n",
            "20            [[0.0013018366, 0.04795719, 0.95074105]]\n",
            "21            [[0.0011548104, 0.003628685, 0.9952165]]\n",
            "22         [[0.00034910397, 5.0075145e-05, 0.9996008]]\n",
            "23            [[0.0013018366, 0.04795719, 0.95074105]]\n",
            "24            [[0.0013018366, 0.04795719, 0.95074105]]\n",
            "25             [[0.0007235069, 0.31995627, 0.6793203]]\n",
            "26         [[0.0009921651, 1.0885387e-05, 0.99899703]]\n",
            "27          [[0.0011003105, 1.6371625e-05, 0.9988834]]\n",
            "28        [[0.00015047491, 1.1903608e-05, 0.99983764]]\n",
            "29         [[0.00015452223, 5.653878e-05, 0.99978894]]\n",
            "30             [[0.0012446004, 0.059787355, 0.938968]]\n",
            "31        [[0.00027682938, 1.7882032e-05, 0.99970526]]\n",
            "32         [[8.853747e-05, 0.00015093268, 0.99976057]]\n",
            "33         [[0.00012686028, 1.2014574e-05, 0.9998611]]\n",
            "34           [[0.00024555725, 0.000703098, 0.9990513]]\n",
            "35         [[0.00014233502, 0.00020820896, 0.9996495]]\n",
            "36            [[0.0004044696, 0.39782634, 0.60176927]]\n",
            "37               [[0.7232758, 0.26616678, 0.01055744]]\n",
            "38         [[0.0006291398, 1.09303855e-05, 0.9993599]]\n",
            "39          [[0.0002876589, 1.553033e-05, 0.99969685]]\n",
            "40        [[0.00014051633, 0.00045741044, 0.99940217]]\n",
            "41           [[0.0004002139, 1.285698e-05, 0.9995869]]\n",
            "42         [[0.00024536814, 3.688834e-05, 0.99971765]]\n",
            "43           [[0.0002829988, 1.926496e-05, 0.9996977]]\n",
            "44            [[0.011398541, 0.96120644, 0.027395092]]\n",
            "45           [[0.0105681475, 0.98071504, 0.008716847]]\n",
            "46                [[0.04218718, 0.91053, 0.047282856]]\n",
            "47               [[0.15799882, 0.6312541, 0.21074706]]\n",
            "48           [[0.0003219135, 5.4127533e-05, 0.999624]]\n",
            "49              [[0.022379609, 0.7165419, 0.26107854]]\n",
            "50          [[0.00042887504, 0.0019196629, 0.9976515]]\n",
            "51           [[0.00028669392, 0.001472725, 0.9982406]]\n",
            "52         [[0.00042827876, 0.00032962774, 0.9992422]]\n",
            "53             [[0.011678069, 0.13231893, 0.85600305]]\n",
            "54           [[9.6389675e-05, 0.00440927, 0.99549437]]\n",
            "55              [[0.001852472, 0.17722917, 0.8209183]]\n",
            "56         [[0.00046403846, 0.00011305519, 0.9994229]]\n",
            "57             [[0.019836048, 0.23230787, 0.74785614]]\n",
            "58           [[0.0006034876, 0.0084480755, 0.9909484]]\n",
            "59             [[0.031843007, 0.045129094, 0.9230278]]\n",
            "60         [[0.00030828422, 1.6473723e-05, 0.9996753]]\n",
            "61         [[0.00016885526, 0.0086691305, 0.99116206]]\n",
            "62        [[0.00035911877, 0.00089831976, 0.99874264]]\n",
            "63        [[0.00010523418, 6.5093045e-05, 0.99982965]]\n",
            "64          [[8.209973e-05, 5.546274e-05, 0.99986243]]\n",
            "65           [[0.0010487392, 0.0010076689, 0.9979436]]\n",
            "66           [[0.0011663502, 0.0018738143, 0.9969598]]\n",
            "67           [[0.98120636, 0.0020122393, 0.016781459]]\n",
            "68             [[0.64607185, 0.00034910123, 0.353579]]\n",
            "69           [[0.0007861372, 0.93986297, 0.059350837]]\n",
            "70               [[0.62610286, 0.2825845, 0.09131267]]\n",
            "71               [[0.6343211, 0.15477961, 0.21089928]]\n",
            "72            [[0.0006825467, 0.062427934, 0.9368895]]\n",
            "73              [[0.0005170917, 0.7821678, 0.2173151]]\n",
            "74           [[0.00039520007, 0.37289068, 0.62671405]]\n",
            "75            [[0.0031187958, 0.00482063, 0.99206054]]\n",
            "76           [[0.00023527742, 0.02780571, 0.97195894]]\n",
            "77         [[0.0004808616, 2.5704312e-05, 0.99949336]]\n",
            "78          [[0.00021643135, 6.672683e-05, 0.9997168]]\n",
            "79         [[0.00016907383, 2.7417429e-05, 0.9998035]]\n",
            "80          [[0.00024531258, 0.0026462423, 0.9971084]]\n",
            "81          [[6.077026e-05, 1.9052239e-05, 0.9999201]]\n",
            "82          [[0.0007860327, 4.2610613e-05, 0.9991714]]\n",
            "83           [[0.99226415, 0.000508193, 0.0072276746]]\n",
            "84         [[0.00018163263, 0.00030180108, 0.9995166]]\n",
            "85              [[0.2857847, 0.68372536, 0.030489974]]\n",
            "86                [[0.4732388, 0.516927, 0.009834183]]\n",
            "87         [[0.00013666418, 1.7212402e-05, 0.9998461]]\n",
            "88              [[0.0046510883, 0.3058861, 0.6894629]]\n",
            "89         [[8.277004e-05, 0.00085689884, 0.99906033]]\n",
            "90        [[0.00015369387, 1.2904589e-05, 0.99983346]]\n",
            "91              [[0.16639186, 0.8276802, 0.005927974]]\n",
            "92              [[0.000348776, 0.57379645, 0.4258548]]\n",
            "93         [[0.0010316201, 0.00026762523, 0.99870074]]\n",
            "94          [[0.001998041, 0.00031093115, 0.99769104]]\n",
            "95                [[0.7862869, 0.02503583, 0.1886773]]\n",
            "96        [[0.00027025855, 0.000109561806, 0.9996202]]\n",
            "97         [[0.00017196832, 1.0988839e-05, 0.9998171]]\n",
            "98          [[0.0001375716, 1.8971134e-05, 0.9998435]]\n",
            "99        [[0.00033992654, 2.0430049e-05, 0.99963963]]\n",
            "100          [[0.0004206829, 1.0327902e-05, 0.999569]]\n",
            "101         [[0.00020038475, 0.040521033, 0.95927864]]\n",
            "102        [[0.0001289368, 0.00012663165, 0.99974436]]\n",
            "103         [[0.00041179731, 0.011165127, 0.98842305]]\n",
            "104        [[0.0006200414, 2.8517006e-05, 0.99935144]]\n",
            "105           [[0.000165495, 0.0016923415, 0.9981421]]\n",
            "106           [[9.20123e-05, 0.000176598, 0.99973136]]\n",
            "107          [[7.247781e-05, 0.0031493392, 0.9967782]]\n",
            "108       [[0.00014896972, 1.5041002e-05, 0.99983597]]\n",
            "109         [[8.287313e-05, 2.0760826e-05, 0.9998964]]\n",
            "110        [[9.2675764e-05, 0.0020240657, 0.99788326]]\n",
            "111       [[0.00012111017, 6.2975673e-06, 0.99987257]]\n",
            "112         [[0.00018660852, 0.0012231225, 0.9985902]]\n",
            "113             [[0.009146276, 0.47885525, 0.5119984]]\n",
            "114           [[0.032715056, 0.9627986, 0.0044863024]]\n",
            "115         [[0.00047783126, 0.9966646, 0.0028575773]]\n",
            "116           [[0.0014814035, 0.089072764, 0.9094459]]\n",
            "117        [[0.00045323043, 1.9494546e-05, 0.9995272]]\n",
            "118          [[0.0005587187, 0.97067606, 0.028765192]]\n",
            "119           [[0.0006801612, 0.92661864, 0.07270116]]\n",
            "120            [[0.0003763236, 0.5668004, 0.43282324]]\n",
            "121        [[9.7249766e-05, 0.00010221239, 0.9998005]]\n",
            "122          [[0.0001037401, 1.720985e-05, 0.9998791]]\n",
            "123        [[0.00037871415, 7.000202e-05, 0.99955136]]\n",
            "124         [[0.00035062182, 0.007964314, 0.99168503]]\n",
            "125          [[0.0012918699, 0.0023235502, 0.9963846]]\n",
            "126          [[0.0006745969, 0.0012912682, 0.9980342]]\n",
            "127           [[0.0006561121, 0.11033682, 0.88900703]]\n",
            "128           [[0.00021379265, 0.7794111, 0.22037514]]\n",
            "129         [[0.00028642427, 2.5631905e-05, 0.999688]]\n",
            "130              [[0.01372576, 0.06382497, 0.9224493]]\n",
            "131          [[0.98759997, 0.0027674413, 0.009632595]]\n",
            "132            [[0.87567085, 0.003634759, 0.12069441]]\n",
            "133        [[0.00015699452, 4.848977e-05, 0.99979454]]\n",
            "134            [[0.0037568104, 0.7741642, 0.22207898]]\n",
            "135            [[0.08711661, 0.87121433, 0.041669067]]\n",
            "136           [[0.0005359544, 0.022215541, 0.9772485]]\n",
            "137        [[0.00022037304, 6.5285335e-06, 0.9997731]]\n",
            "138        [[0.00014702805, 2.8259446e-05, 0.9998247]]\n",
            "139        [[7.958024e-05, 0.00011040849, 0.99981004]]\n",
            "140       [[0.00022000709, 2.5627376e-05, 0.99975437]]\n",
            "141            [[0.5944218, 0.0008993481, 0.40467876]]\n",
            "142               [[0.09673162, 0.7726992, 0.1305692]]\n",
            "143           [[8.87918e-05, 0.0011866577, 0.9987245]]\n",
            "144              [[0.006446831, 0.87567014, 0.117883]]\n",
            "145         [[0.00030906033, 9.517158e-06, 0.9996815]]\n",
            "146          [[9.983253e-05, 0.0007823073, 0.9991179]]\n",
            "147         [[0.00013720761, 0.007244531, 0.99261826]]\n",
            "148          [[0.0069740717, 0.9922995, 0.0007265105]]\n",
            "149        [[5.1287352e-05, 0.0003904567, 0.99955827]]\n",
            "150         [[0.00010151787, 5.993869e-05, 0.9998385]]\n",
            "151        [[0.00028942316, 0.99844897, 0.0012615278]]\n",
            "152        [[6.7400106e-05, 2.3125323e-05, 0.9999095]]\n",
            "153         [[0.00060514617, 0.96151656, 0.037878286]]\n",
            "154          [[0.00012716948, 0.0024397979, 0.997433]]\n",
            "155           [[0.0009948967, 0.8931774, 0.105827674]]\n",
            "156            [[0.0044403225, 0.5753566, 0.42020306]]\n",
            "157             [[0.006181955, 0.7597559, 0.23406206]]\n",
            "158              [[0.10142872, 0.8825907, 0.01598054]]\n",
            "159          [[0.014490479, 0.98288894, 0.0026205508]]\n",
            "160             [[0.012364296, 0.32326907, 0.6643666]]\n",
            "161          [[0.001155715, 1.3194047e-05, 0.9988311]]\n",
            "162       [[0.00056022767, 1.8466288e-05, 0.99942136]]\n",
            "163         [[0.0013037273, 0.0028191288, 0.99587715]]\n",
            "164        [[0.00043350994, 1.1072021e-05, 0.9995554]]\n",
            "165         [[0.0023741117, 0.00017672646, 0.9974492]]\n",
            "166           [[0.0107166665, 0.9780803, 0.011203034]]\n",
            "167         [[0.00036207592, 2.337922e-05, 0.9996146]]\n",
            "168             [[0.001691697, 0.5865099, 0.41179845]]\n",
            "169            [[0.0024625123, 0.07304535, 0.9244922]]\n",
            "170          [[0.00044430586, 0.015071848, 0.9844839]]\n",
            "171          [[0.00025957837, 9.542172e-05, 0.999645]]\n",
            "172         [[0.00060859084, 0.031050516, 0.96834093]]\n",
            "173             [[0.03990128, 0.09104808, 0.86905056]]\n",
            "174        [[0.00021950912, 0.9988689, 0.00091158703]]\n",
            "175         [[0.0010598284, 0.00016993089, 0.9987703]]\n",
            "176       [[0.00020552344, 0.00020279766, 0.99959165]]\n",
            "177          [[0.0001556107, 0.0009015083, 0.9989429]]\n",
            "178           [[0.000580382, 0.038064517, 0.96135515]]\n",
            "179            [[0.005522198, 0.9571816, 0.037296243]]\n",
            "180          [[0.98535675, 0.0005632066, 0.014080004]]\n",
            "181            [[0.012209667, 0.018781804, 0.9690085]]\n",
            "182             [[0.019245563, 0.07661887, 0.9041356]]\n",
            "183          [[0.0008973647, 0.0010640906, 0.9980386]]\n",
            "184        [[0.00043525157, 1.4771197e-05, 0.9995499]]\n",
            "185       [[0.00063385436, 0.00038070235, 0.99898535]]\n",
            "186        [[0.00024325223, 3.283554e-05, 0.99972385]]\n",
            "187       [[0.00063385436, 0.00038070235, 0.99898535]]\n",
            "188        [[0.00041009192, 8.356302e-05, 0.99950635]]\n",
            "189             [[0.0022200958, 0.14857095, 0.849209]]\n",
            "190            [[0.002168151, 0.35306075, 0.64477116]]\n",
            "191           [[0.0008577519, 0.012313992, 0.9868283]]\n",
            "192          [[0.00045316745, 0.78883326, 0.21071361]]\n",
            "193        [[0.00015965343, 6.4491665e-05, 0.9997758]]\n",
            "194           [[0.000280774, 0.0006278112, 0.9990915]]\n",
            "195         [[0.0012276302, 0.0016084985, 0.99716395]]\n",
            "196           [[0.00093306816, 0.8555871, 0.14347985]]\n",
            "197            [[0.00020177581, 0.11716926, 0.882629]]\n",
            "198        [[0.00016318352, 0.00010820906, 0.9997286]]\n",
            "199        [[0.00011630059, 0.00016461874, 0.9997191]]\n",
            "200         [[0.0013396634, 0.0016793004, 0.99698097]]\n",
            "201             [[0.71172726, 0.04691594, 0.24135682]]\n",
            "202        [[0.00010259579, 1.7927428e-05, 0.9998795]]\n",
            "203             [[0.9293029, 0.035388805, 0.03530833]]\n",
            "204         [[0.00017241375, 0.0067162355, 0.9931114]]\n",
            "205        [[0.00012345129, 2.2905926e-05, 0.9998536]]\n",
            "206           [[6.755938e-05, 0.9914159, 0.008516466]]\n",
            "207         [[0.0002878185, 8.923729e-05, 0.99962294]]\n",
            "208         [[0.00027159907, 0.0002641759, 0.9994642]]\n",
            "209        [[0.00019802772, 6.5187065e-05, 0.9997367]]\n",
            "210         [[7.419124e-05, 0.00069530815, 0.9992305]]\n",
            "211         [[0.0001059491, 1.2383604e-05, 0.9998816]]\n",
            "212           [[0.000273942, 1.915854e-05, 0.9997068]]\n",
            "213        [[0.00082630425, 0.00040994046, 0.9987638]]\n",
            "214          [[0.00030477057, 0.010706568, 0.9889887]]\n",
            "215        [[0.00012354966, 0.00074801757, 0.9991285]]\n",
            "216           [[0.0014776892, 0.15574045, 0.84278184]]\n",
            "217          [[0.0002891569, 0.019979507, 0.97973126]]\n",
            "218        [[8.649519e-05, 0.00035085983, 0.99956256]]\n",
            "219        [[0.00010494752, 0.00014290062, 0.9997521]]\n",
            "220          [[0.00014356816, 3.09914e-05, 0.9998254]]\n",
            "221       [[0.00015361793, 3.3159755e-05, 0.99981326]]\n",
            "222         [[8.395796e-05, 3.301896e-05, 0.99988306]]\n",
            "223          [[0.0003349848, 0.9930414, 0.0066235783]]\n",
            "224         [[7.6246426e-05, 0.0001262607, 0.9997975]]\n",
            "225          [[0.00030409935, 2.5918253e-05, 0.99967]]\n",
            "226            [[0.50863016, 0.48521283, 0.006156999]]\n",
            "227           [[0.001520189, 0.96920186, 0.029277913]]\n",
            "228        [[2.5320294e-05, 0.9995394, 0.00043537817]]\n",
            "229            [[0.0005892939, 0.8463635, 0.15304717]]\n",
            "230         [[0.00020615847, 0.0017663887, 0.9980274]]\n",
            "231         [[0.00011955973, 0.0001914254, 0.9996891]]\n",
            "232           [[0.023619302, 0.016589431, 0.95979124]]\n",
            "233         [[0.00023679888, 0.0015462714, 0.9982169]]\n",
            "234             [[0.45445925, 0.4892307, 0.056310106]]\n",
            "235       [[0.00042688206, 4.1394498e-05, 0.99953175]]\n",
            "236         [[0.0001715015, 4.5959187e-05, 0.9997825]]\n",
            "237         [[8.959496e-05, 0.0006484307, 0.99926203]]\n",
            "238         [[0.99129194, 0.0028906236, 0.0058174897]]\n",
            "239        [[0.0013380215, 0.00024041164, 0.99842155]]\n",
            "240               [[0.18030523, 0.30637875, 0.513316]]\n",
            "241         [[0.00021403567, 0.0003145044, 0.9994715]]\n",
            "242        [[6.992734e-05, 0.00084015983, 0.99908996]]\n",
            "243             [[0.009185341, 0.7323392, 0.25847548]]\n",
            "244          [[0.00013617554, 0.000668627, 0.9991953]]\n",
            "245       [[4.7135793e-05, 0.99964976, 0.00030314724]]\n",
            "246          [[0.0025037732, 2.174843e-05, 0.9974745]]\n",
            "247          [[0.0124547575, 0.064093836, 0.92345136]]\n",
            "248           [[0.0020841544, 0.0037408331, 0.994175]]\n",
            "249        [[0.00012894014, 2.5379433e-05, 0.9998456]]\n",
            "250        [[0.00011736277, 0.0005570923, 0.99932563]]\n",
            "251         [[0.00022965482, 6.2356885e-05, 0.999708]]\n",
            "252         [[0.00022965482, 6.2356885e-05, 0.999708]]\n",
            "253          [[0.00011281907, 8.98823e-05, 0.9997973]]\n",
            "254           [[0.0033311236, 0.041396234, 0.9552726]]\n",
            "255           [[0.0004937046, 0.0070443805, 0.992462]]\n",
            "256           [[0.0004057165, 0.022481227, 0.9771131]]\n",
            "257         [[0.0004923939, 7.539348e-05, 0.99943215]]\n",
            "258        [[8.4193205e-05, 1.9475558e-05, 0.9998964]]\n",
            "259            [[0.001365756, 0.59575176, 0.40288243]]\n",
            "260            [[0.0014026581, 0.9169204, 0.08167693]]\n",
            "261            [[0.00022394037, 0.9655597, 0.0342164]]\n",
            "262            [[0.00038197477, 0.5570978, 0.4425202]]\n",
            "263            [[0.049111016, 0.043510526, 0.9073784]]\n",
            "264           [[0.9831026, 0.00026422585, 0.01663309]]\n",
            "265         [[0.0019946792, 0.0057621603, 0.99224323]]\n",
            "266           [[0.0020142794, 0.08328658, 0.91469914]]\n",
            "267           [[0.010532267, 0.00096568104, 0.988502]]\n",
            "268           [[0.010532267, 0.00096568104, 0.988502]]\n",
            "269        [[0.00021617426, 3.0951935e-05, 0.9997528]]\n",
            "270          [[0.06188722, 0.00068743626, 0.93742526]]\n",
            "271           [[0.91576433, 0.021309974, 0.062925726]]\n",
            "272          [[0.00070899015, 0.0010899609, 0.998201]]\n",
            "273          [[0.00073894963, 0.004982341, 0.9942788]]\n",
            "274          [[0.0002356952, 3.508951e-05, 0.9997292]]\n",
            "275         [[0.00045651026, 0.028400715, 0.97114277]]\n",
            "276            [[0.0026249464, 0.24188088, 0.7554941]]\n",
            "277         [[7.0523034e-05, 0.0002908039, 0.9996387]]\n",
            "278        [[0.00028697334, 0.00061670406, 0.9990964]]\n",
            "279       [[0.00020859325, 5.4594864e-05, 0.99973685]]\n",
            "280       [[0.00015320841, 2.1393054e-05, 0.99982554]]\n",
            "281           [[0.00016069088, 0.95674413, 0.0430952]]\n",
            "282         [[9.209854e-05, 2.745282e-05, 0.99988043]]\n",
            "283         [[0.00014974145, 0.018508876, 0.98134136]]\n",
            "284           [[0.00010123107, 0.01476741, 0.9851313]]\n",
            "285         [[0.00014807463, 0.9966589, 0.0031930532]]\n",
            "286           [[0.00045773076, 0.16178758, 0.8377547]]\n",
            "287           [[0.0007307059, 0.009729059, 0.9895403]]\n",
            "288            [[0.005663274, 0.70309496, 0.29124177]]\n",
            "289          [[0.0001811898, 9.406137e-05, 0.9997248]]\n",
            "290            [[0.005663274, 0.70309496, 0.29124177]]\n",
            "291        [[0.00027708037, 5.951865e-06, 0.99971694]]\n",
            "292       [[7.7189565e-05, 0.00021686533, 0.99970585]]\n",
            "293           [[0.000312182, 1.6760785e-05, 0.999671]]\n",
            "294         [[0.000102753744, 0.03415188, 0.96574533]]\n",
            "295          [[6.55768e-05, 0.0032368584, 0.99669755]]\n",
            "296         [[0.00012247807, 0.005941251, 0.99393624]]\n",
            "297        [[0.00025946827, 0.99296945, 0.0067711174]]\n",
            "298           [[0.0008812833, 0.39249104, 0.60662764]]\n",
            "299          [[0.0014723181, 0.00067675195, 0.997851]]\n",
            "300         [[0.0006448477, 0.00017902053, 0.9991761]]\n",
            "301           [[0.0007199241, 0.15571064, 0.84356946]]\n",
            "302        [[0.00037778058, 0.99141675, 0.0082055405]]\n",
            "303            [[0.0006918758, 0.93116856, 0.0681396]]\n",
            "304        [[0.00021126751, 0.0003743101, 0.99941444]]\n",
            "305           [[0.0009882192, 0.66893744, 0.33007437]]\n",
            "306          [[0.00040119595, 0.0059807985, 0.993618]]\n",
            "307         [[0.0001386911, 0.0011676417, 0.99869365]]\n",
            "308           [[0.00035424414, 0.19497828, 0.8046674]]\n",
            "309           [[0.0010180237, 0.08220208, 0.91677994]]\n",
            "310         [[0.0007595702, 2.3422821e-05, 0.9992169]]\n",
            "311         [[0.0005160959, 6.814083e-05, 0.99941576]]\n",
            "312           [[0.0008964019, 0.60410875, 0.39499485]]\n",
            "313          [[0.00021621784, 0.004998167, 0.9947857]]\n",
            "314       [[0.00014114179, 0.00064349663, 0.99921536]]\n",
            "315          [[0.0008754641, 0.00069661794, 0.998428]]\n",
            "316        [[0.00024665653, 2.088498e-05, 0.99973243]]\n",
            "317         [[9.0678914e-05, 1.5313235e-05, 0.999894]]\n",
            "318        [[0.0001237662, 2.6093594e-05, 0.99985015]]\n",
            "319            [[0.0014674052, 0.33876428, 0.6597684]]\n",
            "320          [[0.00037729245, 0.38631913, 0.61330354]]\n",
            "321         [[0.0013078483, 0.0053435625, 0.99334866]]\n",
            "322         [[0.00026739517, 3.428187e-06, 0.9997291]]\n",
            "323       [[0.00019427619, 4.3564482e-06, 0.99980134]]\n",
            "324       [[0.00032909022, 4.9633807e-05, 0.99962115]]\n",
            "325         [[0.0018017724, 3.0993757e-05, 0.9981673]]\n",
            "326         [[0.0060708034, 0.00014782436, 0.9937814]]\n",
            "327           [[0.0006606384, 0.00010931984, 0.99923]]\n",
            "328         [[0.99797636, 0.0013056911, 0.0007179162]]\n",
            "329              [[0.0384395, 0.81977063, 0.14178991]]\n",
            "330                [[0.561276, 0.3317449, 0.10697905]]\n",
            "331              [[0.0384395, 0.81977063, 0.14178991]]\n",
            "332               [[0.1363954, 0.7081406, 0.15546398]]\n",
            "333           [[0.002630968, 0.002004949, 0.99536407]]\n",
            "334             [[0.45653257, 0.5292545, 0.014212946]]\n",
            "335            [[0.0014146514, 0.9649483, 0.03363707]]\n",
            "336           [[0.026324444, 0.9719197, 0.0017558278]]\n",
            "337        [[0.00043363913, 2.1451273e-05, 0.9995449]]\n",
            "338          [[0.0006465375, 7.139822e-06, 0.9993463]]\n",
            "339         [[0.0031260385, 5.0831324e-05, 0.9968231]]\n",
            "340             [[0.5127822, 0.48127598, 0.005941871]]\n",
            "341         [[0.0003222627, 4.543551e-05, 0.99963236]]\n",
            "342          [[7.227402e-05, 4.607289e-05, 0.9998816]]\n",
            "343         [[7.773493e-05, 0.00014346621, 0.9997788]]\n",
            "344            [[0.03241432, 0.034486867, 0.93309885]]\n",
            "345       [[0.00013939392, 1.3663113e-05, 0.99984694]]\n",
            "346        [[0.00014209082, 1.7225379e-05, 0.9998406]]\n",
            "347             [[0.9809873, 0.0012446996, 0.0177679]]\n",
            "348           [[0.0012544564, 6.00667e-05, 0.9986854]]\n",
            "349         [[0.001356677, 0.00015600336, 0.99848723]]\n",
            "350              [[0.39812136, 0.5704298, 0.03144887]]\n",
            "351           [[0.997033, 0.0003133923, 0.0026536058]]\n",
            "352       [[0.00040384431, 0.00014651276, 0.99944955]]\n",
            "353           [[0.0006131437, 0.03463509, 0.96475184]]\n",
            "354        [[0.00022625526, 4.9545797e-05, 0.9997242]]\n",
            "355         [[0.00024557704, 1.5322224e-05, 0.999739]]\n",
            "356            [[0.0018999461, 0.3659034, 0.63219666]]\n",
            "357              [[0.002184154, 0.1377441, 0.8600717]]\n",
            "358            [[0.011062433, 0.9691113, 0.019826297]]\n",
            "359           [[0.00056345237, 0.011127616, 0.988309]]\n",
            "360               [[0.2815747, 0.12618998, 0.5922353]]\n",
            "361         [[0.00046469134, 0.97095215, 0.028583208]]\n",
            "362           [[0.0017879605, 0.996855, 0.0013569663]]\n",
            "363           [[0.002024316, 0.010918616, 0.98705703]]\n",
            "364         [[0.00011644759, 0.9997893, 9.431913e-05]]\n",
            "365        [[0.00035037976, 0.9995646, 8.5017884e-05]]\n",
            "366        [[0.00013134583, 0.99984527, 2.338593e-05]]\n",
            "367           [[0.0017866729, 0.9642294, 0.033983886]]\n",
            "368         [[0.00045597728, 0.9985424, 0.0010015809]]\n",
            "369         [[0.00038963574, 2.585967e-05, 0.9995845]]\n",
            "370        [[0.0002417395, 0.00033199295, 0.99942625]]\n",
            "371       [[0.00019581232, 0.00018184025, 0.99962234]]\n",
            "372           [[0.0007507039, 0.85662794, 0.14262138]]\n",
            "373        [[0.00020968165, 8.675006e-06, 0.99978167]]\n",
            "374         [[9.860306e-05, 4.740023e-05, 0.99985397]]\n",
            "375        [[0.00018540725, 4.583883e-06, 0.99981004]]\n",
            "376         [[0.0003824431, 0.00026901063, 0.9993486]]\n",
            "377             [[0.033056516, 0.26479653, 0.7021469]]\n",
            "378            [[0.002798228, 0.18269849, 0.81450325]]\n",
            "379          [[0.0004476346, 0.0022426485, 0.9973098]]\n",
            "380          [[0.00074822357, 0.9644519, 0.034799796]]\n",
            "381        [[0.00020412539, 1.6591217e-05, 0.9997793]]\n",
            "382          [[0.9588961, 0.00059907057, 0.040504765]]\n",
            "383           [[0.002500231, 0.089717194, 0.90778255]]\n",
            "384           [[0.002500231, 0.089717194, 0.90778255]]\n",
            "385            [[0.0038240633, 0.38929364, 0.6068823]]\n",
            "386        [[0.00028852237, 1.6639584e-05, 0.9996948]]\n",
            "387            [[0.019816099, 0.32866764, 0.65151626]]\n",
            "388        [[0.00019150831, 2.1256672e-05, 0.9997873]]\n",
            "389             [[0.006811094, 0.8953643, 0.09782465]]\n",
            "390             [[0.028571526, 0.001964404, 0.969464]]\n",
            "391         [[0.00021295664, 1.585099e-05, 0.9997712]]\n",
            "392            [[0.0033256768, 0.03061069, 0.9660637]]\n",
            "393         [[0.0010502151, 1.3988845e-05, 0.9989359]]\n",
            "394          [[0.000833302, 0.0003493688, 0.99881727]]\n",
            "395           [[0.0017243216, 0.13990426, 0.85837144]]\n",
            "396           [[0.0022973425, 0.55707675, 0.44062585]]\n",
            "397            [[0.0031200503, 0.9337732, 0.06310665]]\n",
            "398           [[0.0016001689, 0.28370628, 0.71469355]]\n",
            "399              [[0.000547297, 0.0408231, 0.9586296]]\n",
            "400         [[7.7671335e-05, 0.99971765, 0.000204707]]\n",
            "401          [[0.00074492145, 0.9191761, 0.080078945]]\n",
            "402         [[0.00053470256, 0.0028055182, 0.9966599]]\n",
            "403           [[7.254613e-05, 0.9820801, 0.017847419]]\n",
            "404          [[0.00012446163, 0.998324, 0.0015515173]]\n",
            "405        [[0.00028654447, 0.99685574, 0.0028577205]]\n",
            "406       [[4.1015905e-05, 0.99939585, 0.00056311284]]\n",
            "407         [[3.8530314e-05, 0.9998895, 7.192091e-05]]\n",
            "408        [[5.8054928e-05, 0.99717146, 0.0027705517]]\n",
            "409           [[0.00044041505, 0.6272564, 0.37230322]]\n",
            "410       [[0.00019774614, 0.00072043395, 0.99908185]]\n",
            "411        [[0.00015774851, 0.00033753022, 0.9995047]]\n",
            "412         [[0.00020199326, 0.0015643334, 0.9982337]]\n",
            "413          [[0.00013785291, 0.9746361, 0.025226112]]\n",
            "414           [[0.0009295211, 0.84810203, 0.15096837]]\n",
            "415         [[0.98775023, 0.00020790745, 0.012041835]]\n",
            "416        [[0.00064501294, 0.00016257484, 0.9991924]]\n",
            "417         [[0.0038106993, 1.2032124e-05, 0.9961773]]\n",
            "418          [[0.0031335617, 5.285128e-05, 0.9968136]]\n",
            "419        [[0.0005813599, 2.4493585e-05, 0.99939406]]\n",
            "420        [[0.0005813599, 2.4493585e-05, 0.99939406]]\n",
            "421       [[0.00031113072, 2.1647458e-05, 0.99966717]]\n",
            "422             [[0.0024330528, 0.17768894, 0.819878]]\n",
            "423          [[0.0012594284, 5.390562e-05, 0.9986866]]\n",
            "424        [[0.0003702462, 0.00020790045, 0.99942183]]\n",
            "425           [[0.9809383, 0.0013917866, 0.017669918]]\n",
            "426             [[0.031328876, 0.00946522, 0.9592058]]\n",
            "427           [[0.0001627962, 0.011798978, 0.9880383]]\n",
            "428           [[0.0014247424, 0.46087748, 0.53769785]]\n",
            "429         [[0.00032178537, 4.4193388e-05, 0.999634]]\n",
            "430          [[0.000552372, 1.6270393e-05, 0.9994313]]\n",
            "431         [[0.00011328777, 0.0004724067, 0.9994143]]\n",
            "432         [[0.0007988515, 0.00071481307, 0.9984864]]\n",
            "433        [[0.0001679151, 0.00010199808, 0.99973005]]\n",
            "434          [[0.010892541, 0.0032362682, 0.98587114]]\n",
            "435          [[0.00080486224, 0.9733027, 0.025892442]]\n",
            "436        [[0.00040283898, 1.3244019e-05, 0.9995839]]\n",
            "437        [[0.00019259834, 2.9295694e-05, 0.9997781]]\n",
            "438       [[0.00014283675, 3.9149287e-05, 0.99981815]]\n",
            "439            [[0.00087862177, 0.6164659, 0.3826555]]\n",
            "440          [[6.679364e-05, 0.99021333, 0.009719925]]\n",
            "441         [[0.00028894507, 0.0028685115, 0.9968425]]\n",
            "442          [[0.0005213094, 0.030657502, 0.96882117]]\n",
            "443         [[0.00020724065, 0.0009892973, 0.9988034]]\n",
            "444        [[8.251063e-05, 0.00082805887, 0.99908936]]\n",
            "445        [[0.00012806154, 1.0449334e-05, 0.9998615]]\n",
            "446       [[0.00023974497, 1.0211101e-05, 0.99974996]]\n",
            "447        [[0.00010752557, 1.9024006e-05, 0.9998734]]\n",
            "448         [[0.0002124486, 0.0010842063, 0.99870336]]\n",
            "449          [[0.00015995147, 0.9849064, 0.014933635]]\n",
            "450            [[0.0006663705, 0.7190611, 0.28027254]]\n",
            "451             [[0.004421856, 0.9354216, 0.06015664]]\n",
            "452            [[0.0040681283, 0.9304849, 0.06544699]]\n",
            "453           [[0.0060178665, 0.9698295, 0.024152616]]\n",
            "454          [[0.00064129074, 0.9821447, 0.017214006]]\n",
            "455              [[0.048563775, 0.1223326, 0.8291036]]\n",
            "456        [[0.0001538313, 3.5558343e-05, 0.99981064]]\n",
            "457         [[0.0007473945, 0.0009326008, 0.99832004]]\n",
            "458          [[0.00075912435, 0.0002628552, 0.998978]]\n",
            "459       [[0.00047561844, 1.39578615e-05, 0.9995104]]\n",
            "460       [[0.00014504709, 1.4110163e-05, 0.99984086]]\n",
            "461       [[0.00018253142, 1.6844304e-05, 0.99980074]]\n",
            "462           [[0.00044234743, 0.10717879, 0.8923789]]\n",
            "463       [[0.00043512287, 0.00013751448, 0.99942744]]\n",
            "464             [[0.006869008, 0.23618852, 0.7569425]]\n",
            "465        [[0.00011277949, 2.9902862e-05, 0.9998573]]\n",
            "466          [[4.608205e-05, 0.9966689, 0.0032850604]]\n",
            "467           [[0.000287437, 9.609496e-05, 0.9996165]]\n",
            "468             [[0.027210206, 0.24016398, 0.7326259]]\n",
            "469             [[0.0006903661, 0.3226985, 0.6766111]]\n",
            "470          [[0.00060593616, 0.041968435, 0.9574256]]\n",
            "471           [[0.03710499, 0.0007435586, 0.96215147]]\n",
            "472         [[0.001291303, 0.00024014819, 0.99846846]]\n",
            "473           [[0.03710499, 0.0007435586, 0.96215147]]\n",
            "474         [[0.0015531876, 0.00034619006, 0.9981006]]\n",
            "475             [[0.002388468, 0.28089535, 0.7167162]]\n",
            "476        [[0.00032625004, 0.0013519407, 0.99832183]]\n",
            "477         [[0.00025891757, 0.000656206, 0.99908483]]\n",
            "478          [[0.0006569579, 0.005763119, 0.99357986]]\n",
            "479        [[0.00041302756, 2.4805206e-05, 0.9995622]]\n",
            "480         [[0.00026959914, 0.00056149974, 0.999169]]\n",
            "481        [[0.0003807244, 3.7568338e-05, 0.99958175]]\n",
            "482            [[0.0043464205, 0.5509124, 0.44474125]]\n",
            "483        [[0.00019232601, 2.727659e-05, 0.99978036]]\n",
            "484       [[0.00032412593, 2.0445379e-05, 0.99965537]]\n",
            "485        [[0.00024466816, 2.4930863e-05, 0.9997304]]\n",
            "486           [[0.00019056765, 0.8955429, 0.10426655]]\n",
            "487            [[0.0006386089, 0.14250857, 0.8568528]]\n",
            "488         [[0.00015976127, 0.014281289, 0.98555887]]\n",
            "489         [[0.00036380102, 0.035523232, 0.96411294]]\n",
            "490        [[0.00017315336, 0.0018703114, 0.99795663]]\n",
            "491        [[0.00016868785, 1.9775294e-05, 0.9998116]]\n",
            "492          [[0.00016204444, 1.686625e-05, 0.999821]]\n",
            "493        [[0.00021875936, 2.8513115e-05, 0.9997527]]\n",
            "494        [[0.00014557625, 7.3130905e-05, 0.9997813]]\n",
            "495         [[0.00036380102, 0.035523232, 0.96411294]]\n",
            "496             [[0.026819749, 0.6563357, 0.31684458]]\n",
            "497                [[0.35947, 0.25169167, 0.38883832]]\n",
            "498        [[0.00016508713, 3.0833435e-05, 0.9998041]]\n",
            "499         [[0.00084748305, 0.019385537, 0.97976696]]\n",
            "500        [[0.00028219222, 8.746214e-06, 0.99970907]]\n",
            "501       [[0.00045573924, 1.16082065e-05, 0.9995327]]\n",
            "502          [[0.00063800294, 0.06447057, 0.93489134]]\n",
            "503        [[0.0005365885, 3.0583236e-05, 0.99943274]]\n",
            "504         [[0.0005354337, 0.00035475785, 0.9991097]]\n",
            "505           [[0.0005486872, 0.008193191, 0.9912581]]\n",
            "506       [[0.00016236452, 0.00058840023, 0.99924916]]\n",
            "507         [[2.1132786e-05, 0.9978278, 0.0021510338]]\n",
            "508          [[4.980567e-05, 0.9977502, 0.0021999753]]\n",
            "509           [[0.00014393909, 0.009752953, 0.990103]]\n",
            "510         [[0.000333028, 0.00024081401, 0.99942625]]\n",
            "511          [[0.0005103879, 8.014055e-06, 0.9994816]]\n",
            "512         [[0.00067867624, 6.2992076e-06, 0.999315]]\n",
            "513       [[0.00047777273, 7.2697003e-06, 0.99951494]]\n",
            "514          [[0.0008752241, 3.097841e-05, 0.9990938]]\n",
            "515             [[0.000828829, 0.0019211518, 0.99725]]\n",
            "516         [[0.00028590608, 0.0004546348, 0.9992594]]\n",
            "517           [[0.00029885914, 0.05098831, 0.9487128]]\n",
            "518          [[0.00021165074, 0.9925029, 0.007285389]]\n",
            "519          [[8.176043e-05, 0.0025998545, 0.9973183]]\n",
            "520           [[0.0011201022, 0.14535174, 0.85352814]]\n",
            "521         [[0.00014772343, 0.0029804592, 0.9968719]]\n",
            "522         [[0.0002952935, 0.00015877456, 0.9995459]]\n",
            "523        [[0.00020107474, 1.611914e-05, 0.99978286]]\n",
            "524          [[0.0016952165, 7.794427e-05, 0.9982268]]\n",
            "525         [[0.0018260112, 0.00057449285, 0.9975994]]\n",
            "526            [[0.003844217, 0.9761071, 0.020048635]]\n",
            "527         [[0.0011613526, 0.0040329266, 0.99480575]]\n",
            "528        [[0.0008718161, 1.28230395e-05, 0.9991153]]\n",
            "529        [[0.00019295549, 0.0004962991, 0.99931073]]\n",
            "530        [[0.0016926177, 0.00023080873, 0.99807656]]\n",
            "531          [[0.0004431829, 9.499985e-05, 0.9994618]]\n",
            "532        [[0.00017198842, 8.7627974e-05, 0.9997404]]\n",
            "533       [[0.00015066052, 1.1033513e-05, 0.99983823]]\n",
            "534             [[0.0013660002, 0.8577046, 0.1409294]]\n",
            "535          [[8.169094e-05, 0.0020516135, 0.9978667]]\n",
            "536          [[0.00029401688, 0.02259911, 0.97710687]]\n",
            "537        [[0.00021568619, 3.9255636e-05, 0.9997451]]\n",
            "538            [[0.45879254, 0.5399689, 0.0012385397]]\n",
            "539            [[0.002744524, 0.9823056, 0.014949829]]\n",
            "540        [[0.0005552354, 0.00019963004, 0.99924517]]\n",
            "541            [[0.2972584, 0.69661885, 0.0061227256]]\n",
            "542            [[0.012874239, 0.018777005, 0.9683488]]\n",
            "543          [[0.0002237102, 0.0002435504, 0.9995328]]\n",
            "544       [[0.00010432365, 0.00013397746, 0.99976176]]\n",
            "545          [[6.267139e-05, 3.8230104e-05, 0.999899]]\n",
            "546          [[0.00029094837, 0.9706362, 0.029072851]]\n",
            "547         [[0.0011067265, 7.805795e-06, 0.99888545]]\n",
            "548         [[0.00013627457, 2.8730565e-05, 0.999835]]\n",
            "549        [[0.00021168934, 0.0003762063, 0.99941206]]\n",
            "550          [[0.9952807, 0.00016729123, 0.004551945]]\n",
            "551           [[0.0013490985, 0.12383115, 0.87481976]]\n",
            "552           [[0.0002618795, 0.080154605, 0.9195835]]\n",
            "553           [[0.0010576741, 0.06919337, 0.92974895]]\n",
            "554           [[0.0002216432, 0.0041913213, 0.995587]]\n",
            "555           [[0.0002216432, 0.0041913213, 0.995587]]\n",
            "556        [[6.43418e-05, 0.000102090766, 0.99983346]]\n",
            "557          [[0.0001303457, 0.008566698, 0.99130297]]\n",
            "558        [[0.000104798026, 2.546529e-05, 0.9998697]]\n",
            "559            [[0.005640287, 0.14434405, 0.85001564]]\n",
            "560            [[0.00050781365, 0.906831, 0.09266113]]\n",
            "561         [[0.00021838523, 0.0014360438, 0.9983456]]\n",
            "562            [[0.00076263974, 0.3202817, 0.6789556]]\n",
            "563          [[0.0005883289, 0.014450879, 0.98496073]]\n",
            "564        [[8.1059596e-05, 9.401276e-05, 0.99982494]]\n",
            "565         [[0.00018030468, 0.0022034487, 0.9976163]]\n",
            "566           [[0.0004993135, 0.24482596, 0.75467473]]\n",
            "567        [[0.0003640666, 0.00038614075, 0.99924976]]\n",
            "568          [[0.00031350588, 0.38782927, 0.61185724]]\n",
            "569         [[0.00012556084, 0.0010837448, 0.9987907]]\n",
            "570        [[9.4697694e-05, 0.00023410696, 0.9996712]]\n",
            "571          [[6.91142e-05, 2.2663588e-05, 0.9999082]]\n",
            "572        [[0.00020059466, 1.9871111e-05, 0.9997795]]\n",
            "573        [[0.00020028165, 8.637369e-05, 0.99971324]]\n",
            "574       [[0.00045114977, 0.00010918688, 0.99943966]]\n",
            "575          [[0.00082530105, 0.00857475, 0.99059993]]\n",
            "576       [[0.00029016615, 0.00096717064, 0.99874276]]\n",
            "577           [[0.0004662727, 0.000574906, 0.9989588]]\n",
            "578          [[0.99420196, 0.0003673991, 0.005430628]]\n",
            "579             [[0.31627554, 0.0001814612, 0.683543]]\n",
            "580           [[0.9765015, 0.0019623023, 0.021536151]]\n",
            "581          [[0.020204011, 0.0008285393, 0.97896737]]\n",
            "582        [[0.0003699429, 0.00010269373, 0.99952734]]\n",
            "583          [[0.0011475327, 0.0001629039, 0.9986896]]\n",
            "584               [[0.2972336, 0.28999105, 0.4127753]]\n",
            "585        [[0.00020632595, 0.00086202926, 0.9989316]]\n",
            "586              [[0.5810963, 0.29228294, 0.12662077]]\n",
            "587        [[0.00083629024, 0.0005239438, 0.99863976]]\n",
            "588              [[0.06742211, 0.19868602, 0.7338919]]\n",
            "589         [[0.016497046, 0.98265725, 0.00084563927]]\n",
            "590        [[0.00031101826, 4.9607832e-05, 0.9996394]]\n",
            "591       [[0.00022662668, 1.2887487e-05, 0.99976045]]\n",
            "592          [[0.0016673771, 9.725678e-06, 0.9983229]]\n",
            "593         [[0.004119517, 1.06707175e-05, 0.9958698]]\n",
            "594       [[0.00017905612, 1.3479069e-05, 0.99980754]]\n",
            "595          [[0.0009802519, 0.9931993, 0.0058204317]]\n",
            "596           [[0.0006658665, 0.0005991089, 0.998735]]\n",
            "597        [[0.00030534176, 3.4919958e-05, 0.9996598]]\n",
            "598        [[0.00028320274, 1.1379518e-05, 0.9997055]]\n",
            "599           [[0.0034562976, 0.63407904, 0.36246464]]\n",
            "600        [[0.00069706823, 7.459716e-06, 0.99929535]]\n",
            "601            [[0.0008866877, 0.9639345, 0.03517878]]\n",
            "602         [[0.0009467807, 3.3668595e-05, 0.9990195]]\n",
            "603       [[0.000109844026, 0.00010440318, 0.9997857]]\n",
            "604            [[0.009649003, 0.15270716, 0.83764386]]\n",
            "605         [[0.00044220328, 0.00037975275, 0.999178]]\n",
            "606         [[0.0003067739, 0.00045240542, 0.9992409]]\n",
            "607            [[0.017589934, 0.053335164, 0.9290749]]\n",
            "608        [[0.00018655433, 1.3567851e-05, 0.9997999]]\n",
            "609          [[0.0001526803, 0.0002666733, 0.9995807]]\n",
            "610           [[0.0011230797, 0.01386047, 0.98501647]]\n",
            "611        [[0.00042865556, 0.00021941346, 0.9993519]]\n",
            "612            [[0.015074704, 0.011605983, 0.9733193]]\n",
            "613        [[0.0009730991, 0.00059393654, 0.99843293]]\n",
            "614          [[0.0010414518, 0.99322164, 0.005736879]]\n",
            "615            [[0.95486265, 0.02785896, 0.017278353]]\n",
            "616             [[0.7199805, 0.011024586, 0.26899496]]\n",
            "617             [[0.4960944, 0.037340254, 0.46656528]]\n",
            "618          [[0.00026317188, 0.001528826, 0.9982079]]\n",
            "619       [[3.3851582e-05, 0.99956423, 0.00040191723]]\n",
            "620          [[6.7136614e-05, 0.998061, 0.0018718294]]\n",
            "621         [[6.444962e-05, 0.9997434, 0.00019212055]]\n",
            "622            [[6.93867e-05, 0.9508127, 0.049117867]]\n",
            "623          [[2.26065e-05, 0.9996074, 0.00037003568]]\n",
            "624         [[7.751132e-05, 0.9994941, 0.00042842122]]\n",
            "625         [[4.5965033e-05, 0.9994311, 0.0005229203]]\n",
            "626        [[0.0005703513, 0.00061978016, 0.99880993]]\n",
            "627            [[0.0039756056, 0.8544107, 0.14161363]]\n",
            "628           [[0.0011171711, 0.02091607, 0.97796667]]\n",
            "629        [[0.00013874834, 0.99593973, 0.0039214985]]\n",
            "630       [[0.00021834752, 0.00081706874, 0.99896455]]\n",
            "631         [[4.5970504e-05, 2.921085e-05, 0.9999248]]\n",
            "632          [[0.00091042777, 0.021320228, 0.9777694]]\n",
            "633        [[8.7989734e-05, 1.6265043e-05, 0.9998958]]\n",
            "634       [[6.9800044e-05, 1.6066464e-05, 0.99991405]]\n",
            "635          [[0.000274521, 2.139335e-05, 0.99970394]]\n",
            "636       [[0.00072022923, 1.2177692e-05, 0.99926764]]\n",
            "637            [[0.013304362, 0.018718934, 0.9679767]]\n",
            "638        [[0.99275726, 0.00022906903, 0.0070136786]]\n",
            "639         [[0.99179065, 6.9876005e-05, 0.008139463]]\n",
            "640         [[0.00053656835, 0.0012654165, 0.9981981]]\n",
            "641         [[0.00044228596, 0.998744, 0.00081366795]]\n",
            "642              [[0.023064252, 0.06783478, 0.909101]]\n",
            "643       [[0.00013181548, 0.000107294385, 0.9997609]]\n",
            "644          [[0.00036699756, 0.021015229, 0.9786178]]\n",
            "645       [[0.00026587615, 0.00025751078, 0.99947673]]\n",
            "646          [[0.00011327363, 0.96672666, 0.03316004]]\n",
            "647         [[0.00053656835, 0.0012654165, 0.9981981]]\n",
            "648           [[0.00035069627, 0.97591984, 0.0237294]]\n",
            "649           [[0.0011001187, 0.41231677, 0.58658314]]\n",
            "650          [[0.00036699756, 0.021015229, 0.9786178]]\n",
            "651        [[0.00034738088, 0.00034573922, 0.9993069]]\n",
            "652              [[0.820122, 0.17315134, 0.006726731]]\n",
            "653             [[0.8823643, 0.032304388, 0.08533128]]\n",
            "654         [[0.0011079565, 0.0014486028, 0.99744344]]\n",
            "655        [[0.00031274956, 1.5788071e-05, 0.9996716]]\n",
            "656           [[0.0067773173, 0.9894593, 0.003763435]]\n",
            "657       [[0.00022178456, 4.6240642e-05, 0.99973196]]\n",
            "658         [[0.0005753032, 1.6796916e-05, 0.9994079]]\n",
            "659        [[0.00043667146, 0.00047323768, 0.9990902]]\n",
            "660        [[0.00014031674, 0.00014430126, 0.9997154]]\n",
            "661       [[0.00016655734, 2.4660727e-05, 0.99980885]]\n",
            "662       [[0.00045531875, 0.00074699055, 0.99879766]]\n",
            "663        [[0.00016753537, 0.00038276787, 0.9994497]]\n",
            "664        [[0.00021542823, 0.00019571037, 0.9995889]]\n",
            "665          [[0.00074849895, 0.048172005, 0.9510794]]\n",
            "666             [[0.002699064, 0.15021862, 0.8470823]]\n",
            "667           [[0.0026696352, 0.79749674, 0.19983369]]\n",
            "668            [[0.026817191, 0.053172253, 0.9200105]]\n",
            "669           [[0.0038535378, 0.0095104175, 0.986636]]\n",
            "670            [[0.0023166437, 0.14966524, 0.8480181]]\n",
            "671        [[0.00013964692, 2.1459875e-05, 0.9998388]]\n",
            "672           [[0.0077617085, 0.45554665, 0.53669167]]\n",
            "673          [[0.0018807922, 0.9965449, 0.0015742793]]\n",
            "674         [[0.00044448764, 0.97675544, 0.022800146]]\n",
            "675           [[0.0015107825, 0.024089905, 0.9743994]]\n",
            "676            [[0.043273777, 0.55459386, 0.40213236]]\n",
            "677             [[0.04610181, 0.65645814, 0.29744008]]\n",
            "678           [[0.0058972156, 0.91784644, 0.07625635]]\n",
            "679           [[0.0036770909, 0.9557188, 0.040604096]]\n",
            "680            [[0.06741022, 0.9275414, 0.0050484547]]\n",
            "681              [[0.5202469, 0.03515605, 0.44459707]]\n",
            "682             [[0.6791227, 0.30706602, 0.013811337]]\n",
            "683            [[0.40595907, 0.5903267, 0.0037142157]]\n",
            "684            [[0.00422728, 0.0014475785, 0.9943252]]\n",
            "685        [[0.0004635636, 1.2060788e-05, 0.99952435]]\n",
            "686         [[0.0003255064, 0.0013439119, 0.99833065]]\n",
            "687             [[0.000922144, 0.10494756, 0.8941303]]\n",
            "688           [[0.0010719468, 0.27385518, 0.72507286]]\n",
            "689          [[0.98935765, 0.0021475102, 0.008494888]]\n",
            "690        [[0.00034592533, 5.604255e-06, 0.99964845]]\n",
            "691            [[0.0035697778, 0.7778355, 0.21859471]]\n",
            "692          [[7.894309e-05, 0.99569845, 0.004222591]]\n",
            "693            [[0.0012150545, 0.5655103, 0.43327466]]\n",
            "694            [[0.0035697778, 0.7778355, 0.21859471]]\n",
            "695         [[7.765044e-05, 0.9996183, 0.00030406448]]\n",
            "696             [[0.000473016, 0.8234513, 0.17607571]]\n",
            "697         [[0.00012097331, 0.00068001746, 0.999199]]\n",
            "698        [[0.00023889694, 0.00020516811, 0.9995559]]\n",
            "699           [[0.000210239, 1.330755e-05, 0.9997764]]\n",
            "700          [[8.0643586e-05, 4.232025e-05, 0.999877]]\n",
            "701         [[6.2373576e-05, 0.00019658983, 0.999741]]\n",
            "702            [[0.0023821043, 0.24745476, 0.7501631]]\n",
            "703         [[0.000142159, 2.5619596e-05, 0.99983215]]\n",
            "704          [[0.00023818684, 0.0034478512, 0.996314]]\n",
            "705         [[0.0001202358, 3.837272e-05, 0.99984133]]\n",
            "706           [[0.0018269975, 0.11745687, 0.88071615]]\n",
            "707       [[0.00010887207, 0.99950385, 0.00038729917]]\n",
            "708           [[6.67461e-05, 0.9930943, 0.0068389922]]\n",
            "709           [[9.6586715e-05, 0.9805854, 0.01931796]]\n",
            "710            [[0.0007799355, 0.12904155, 0.8701785]]\n",
            "711          [[0.000699839, 0.99354315, 0.0057570366]]\n",
            "712             [[0.018908437, 0.49326125, 0.4878303]]\n",
            "713           [[0.0004691482, 0.92056024, 0.07897058]]\n",
            "714        [[0.0004783757, 1.0955956e-05, 0.99951065]]\n",
            "715          [[0.0001491956, 0.97831637, 0.021534408]]\n",
            "716           [[0.0022773915, 0.080551445, 0.9171712]]\n",
            "717        [[0.00043775066, 0.99853325, 0.0010289571]]\n",
            "718        [[0.0001349725, 0.99937564, 0.00048939197]]\n",
            "719         [[0.0006244326, 0.00019196319, 0.9991836]]\n",
            "720         [[0.0002721151, 0.99805874, 0.0016690993]]\n",
            "721         [[0.00020790493, 0.99786997, 0.001922129]]\n",
            "722            [[0.094198376, 0.21322486, 0.69257677]]\n",
            "723          [[0.0007535906, 0.0018617035, 0.9973847]]\n",
            "724             [[0.986182, 0.0017251072, 0.01209285]]\n",
            "725          [[0.9948507, 0.00011609804, 0.005033241]]\n",
            "726           [[0.013611761, 9.449645e-05, 0.9862937]]\n",
            "727            [[0.054863922, 0.057228163, 0.8879079]]\n",
            "728            [[0.0042315777, 0.7770992, 0.21866924]]\n",
            "729        [[0.00075480656, 1.3358164e-05, 0.9992318]]\n",
            "730         [[0.00031153363, 0.0031063722, 0.9965821]]\n",
            "731         [[0.00021585295, 0.006675376, 0.99310875]]\n",
            "732       [[0.000103502214, 3.1837557e-05, 0.9998647]]\n",
            "733            [[0.0014082754, 0.42854077, 0.5700509]]\n",
            "734          [[0.0012683297, 0.0079406155, 0.9907911]]\n",
            "735         [[0.0036614097, 3.2381864e-05, 0.9963062]]\n",
            "736             [[0.053731382, 0.8667897, 0.07947891]]\n",
            "737          [[0.0057478156, 0.98146397, 0.012788245]]\n",
            "738         [[0.00041110054, 0.014667941, 0.98492104]]\n",
            "739         [[0.0036614097, 3.2381864e-05, 0.9963062]]\n",
            "740          [[0.0004832008, 0.016758561, 0.98275834]]\n",
            "741           [[0.0009851145, 0.014330476, 0.9846844]]\n",
            "742         [[0.00015517103, 0.005317173, 0.99452764]]\n",
            "743          [[4.476396e-05, 0.0018631625, 0.9980921]]\n",
            "744          [[0.00027027793, 0.008896229, 0.9908336]]\n",
            "745          [[0.00017318125, 0.9424336, 0.057393253]]\n",
            "746          [[0.00030131606, 0.78032595, 0.21937273]]\n",
            "747          [[0.0014054143, 8.481404e-05, 0.9985097]]\n",
            "748           [[0.00016370694, 0.9634065, 0.03642978]]\n",
            "749         [[0.0017713332, 0.0008244577, 0.99740416]]\n",
            "750            [[0.0016518424, 0.4507822, 0.54756594]]\n",
            "751         [[0.0006577672, 0.00024204305, 0.9991002]]\n",
            "752            [[0.02087142, 0.9743242, 0.0048043677]]\n",
            "753         [[0.00011720242, 0.00043474196, 0.999448]]\n",
            "754            [[0.0005551778, 0.12335199, 0.8760928]]\n",
            "755             [[0.0011876547, 0.07387348, 0.924939]]\n",
            "756          [[4.133842e-05, 0.9966993, 0.0032593529]]\n",
            "757       [[0.00020361153, 1.2361145e-05, 0.99978405]]\n",
            "758           [[0.00029546244, 0.8920326, 0.10767194]]\n",
            "759       [[0.00018838547, 2.7668104e-05, 0.99978393]]\n",
            "760          [[0.0001486077, 0.0002922069, 0.9995592]]\n",
            "761            [[0.001200128, 0.9590935, 0.039706353]]\n",
            "762        [[0.00017628138, 0.99599755, 0.0038261802]]\n",
            "763        [[0.00047039427, 1.2231127e-05, 0.9995173]]\n",
            "764          [[0.0068549803, 0.0019837578, 0.9911612]]\n",
            "765         [[0.020901991, 0.00053633633, 0.97856164]]\n",
            "766             [[0.038800497, 0.02191876, 0.9392807]]\n",
            "767            [[0.080154166, 0.50123084, 0.41861498]]\n",
            "768          [[0.0006456531, 9.230921e-06, 0.9993451]]\n",
            "769             [[0.005620163, 0.09582802, 0.8985519]]\n",
            "770               [[0.0132465, 0.62575376, 0.3609997]]\n",
            "771         [[0.00045506936, 1.5921227e-05, 0.999529]]\n",
            "772            [[0.0008250035, 0.0018850025, 0.99729]]\n",
            "773         [[0.00026000454, 0.95207316, 0.047666825]]\n",
            "774          [[0.0002713735, 0.98052055, 0.019208066]]\n",
            "775           [[0.000225395, 0.0005589374, 0.9992157]]\n",
            "776       [[0.00018687156, 0.00023393054, 0.99957925]]\n",
            "777       [[0.00081772293, 0.00010043129, 0.99908185]]\n",
            "778          [[0.00019136521, 0.9735169, 0.026291775]]\n",
            "779           [[0.00046795767, 0.8635154, 0.13601668]]\n",
            "780        [[0.00034521156, 8.488191e-05, 0.99956995]]\n",
            "781            [[0.00033261752, 0.01332338, 0.986344]]\n",
            "782         [[6.242211e-05, 0.0020562438, 0.99788123]]\n",
            "783        [[8.1558675e-05, 4.485982e-05, 0.99987364]]\n",
            "784        [[7.638175e-05, 8.2748644e-05, 0.99984086]]\n",
            "785           [[0.0004758508, 0.21113978, 0.78838444]]\n",
            "786             [[0.0029933145, 0.6274906, 0.3695161]]\n",
            "787           [[8.452237e-05, 0.00020546703, 0.99971]]\n",
            "788           [[0.0003418423, 4.80493e-05, 0.9996101]]\n",
            "789        [[0.00027338282, 0.00061126845, 0.9991154]]\n",
            "790           [[0.9797506, 0.0003262526, 0.019923199]]\n",
            "791              [[0.3431419, 0.29434866, 0.36250943]]\n",
            "792         [[0.9940252, 4.8170426e-05, 0.0059266267]]\n",
            "793         [[0.0018270474, 0.0031149045, 0.99505806]]\n",
            "794           [[0.0031432342, 0.20798884, 0.78886795]]\n",
            "795         [[0.00048326913, 0.99167913, 0.007837566]]\n",
            "796           [[0.0007425779, 0.9770274, 0.022230012]]\n",
            "797          [[0.0017052926, 0.98619926, 0.012095403]]\n",
            "798           [[0.0004340024, 0.99832267, 0.00124327]]\n",
            "799            [[0.0050291526, 0.7749638, 0.22000709]]\n",
            "800           [[0.0010645142, 0.9837532, 0.015182331]]\n",
            "801           [[0.012402273, 0.9862592, 0.0013385552]]\n",
            "802         [[0.00091896515, 0.9972396, 0.0018414718]]\n",
            "803        [[0.0001525485, 0.00033494114, 0.99951255]]\n",
            "804          [[6.448306e-05, 2.903872e-05, 0.9999064]]\n",
            "805               [[0.01267012, 0.6117374, 0.3755925]]\n",
            "806              [[0.57240075, 0.13525808, 0.2923411]]\n",
            "807            [[0.0013904219, 0.00447325, 0.9941362]]\n",
            "808           [[0.0023472686, 0.43006825, 0.56758446]]\n",
            "809             [[0.0014807121, 0.4257772, 0.5727421]]\n",
            "810            [[0.7819741, 0.0013021383, 0.21672374]]\n",
            "811        [[0.0023490048, 2.3485129e-05, 0.99762756]]\n",
            "812          [[9.741349e-05, 0.97433937, 0.025563175]]\n",
            "813           [[0.00035316177, 0.7162912, 0.28335568]]\n",
            "814         [[0.00025110014, 0.99515367, 0.004595233]]\n",
            "815         [[0.0015266406, 0.99499464, 0.0034786419]]\n",
            "816           [[0.010272618, 0.97293067, 0.016796783]]\n",
            "817          [[0.00048062074, 0.027749877, 0.9717695]]\n",
            "818                [[0.19781786, 0.5258662, 0.276316]]\n",
            "819        [[0.00030855802, 2.5848849e-05, 0.9996656]]\n",
            "820       [[0.00026547408, 3.4669727e-05, 0.99969983]]\n",
            "821             [[0.008387799, 0.17384835, 0.8177638]]\n",
            "822          [[0.0031355855, 0.010630596, 0.98623383]]\n",
            "823       [[0.00021357328, 2.1060157e-05, 0.99976534]]\n",
            "824           [[0.9904446, 0.00078442536, 0.00877097]]\n",
            "825        [[0.99355936, 0.00066709216, 0.0057735927]]\n",
            "826        [[0.0010940478, 1.3687425e-05, 0.99889225]]\n",
            "827         [[0.00028109664, 1.341752e-05, 0.9997054]]\n",
            "828        [[0.00017289598, 0.0012143997, 0.99861276]]\n",
            "829         [[0.00020630448, 0.000821263, 0.99897254]]\n",
            "830         [[0.0003597836, 1.5885285e-05, 0.9996244]]\n",
            "831         [[0.00022887315, 9.891634e-06, 0.9997613]]\n",
            "832        [[0.00012222434, 8.867511e-05, 0.99978906]]\n",
            "833         [[0.00025015423, 0.0003375851, 0.9994122]]\n",
            "834       [[0.00073582295, 0.000116957264, 0.9991472]]\n",
            "835        [[0.00050959905, 1.9610448e-05, 0.9994708]]\n",
            "836           [[0.0004758393, 0.001784286, 0.9977398]]\n",
            "837        [[0.00063885143, 0.0031114102, 0.99624974]]\n",
            "838       [[0.00027292824, 0.00079456274, 0.99893254]]\n",
            "839        [[0.00048006725, 1.003294e-05, 0.99950993]]\n",
            "840         [[0.0017319523, 0.00011527055, 0.9981527]]\n",
            "841            [[0.8883551, 0.0018208825, 0.10982407]]\n",
            "842           [[0.001751904, 0.013113431, 0.98513466]]\n",
            "843              [[0.00265351, 0.17549004, 0.8218565]]\n",
            "844            [[0.0030729016, 0.8569464, 0.13998069]]\n",
            "845        [[0.00057122525, 0.000115737064, 0.999313]]\n",
            "846         [[0.0004881862, 2.6336511e-05, 0.9994855]]\n",
            "847        [[0.00031399805, 1.6726648e-05, 0.9996693]]\n",
            "848       [[0.00012481748, 0.00021758261, 0.99965763]]\n",
            "849         [[0.00030088218, 0.0053968434, 0.9943024]]\n",
            "850        [[0.00023022844, 5.0495055e-05, 0.9997192]]\n",
            "851       [[0.00013566877, 2.9108798e-05, 0.99983525]]\n",
            "852        [[0.00015518913, 2.8370032e-05, 0.9998165]]\n",
            "853          [[8.519584e-05, 9.60345e-05, 0.99981874]]\n",
            "854          [[0.0008667517, 0.046826184, 0.95230705]]\n",
            "855             [[0.001140144, 0.6318649, 0.36699495]]\n",
            "856             [[0.008688478, 0.25007644, 0.7412351]]\n",
            "857           [[0.00015007392, 0.00022398, 0.9996259]]\n",
            "858            [[0.043463238, 0.50618905, 0.45034778]]\n",
            "859          [[0.0046759094, 0.027181964, 0.96814215]]\n",
            "860         [[0.9979381, 0.00042630266, 0.0016356414]]\n",
            "861       [[0.00022306704, 3.4409037e-05, 0.99974245]]\n",
            "862           [[5.593348e-05, 0.994947, 0.0049970564]]\n",
            "863              [[0.15402757, 0.834204, 0.011768454]]\n",
            "864           [[0.0012223473, 0.48737144, 0.51140624]]\n",
            "865         [[0.00012944595, 0.0001943538, 0.9996762]]\n",
            "866             [[0.005246175, 0.71614903, 0.2786048]]\n",
            "867           [[0.0005428813, 0.11739454, 0.88206255]]\n",
            "868          [[0.0005085473, 0.0031300336, 0.9963613]]\n",
            "869          [[0.000916521, 0.9986094, 0.00047401065]]\n",
            "870          [[0.00096143177, 0.99109846, 0.00794005]]\n",
            "871            [[0.82507634, 0.08210006, 0.092823654]]\n",
            "872            [[0.82507634, 0.08210006, 0.092823654]]\n",
            "873          [[0.00064742344, 0.020801663, 0.9785509]]\n",
            "874              [[0.20436873, 0.12972696, 0.6659043]]\n",
            "875              [[0.00941874, 0.10445162, 0.8861296]]\n",
            "876             [[0.002464353, 0.36263692, 0.6348987]]\n",
            "877         [[0.0010823795, 0.0018613666, 0.99705637]]\n",
            "878       [[0.00014806613, 4.8087364e-05, 0.99980396]]\n",
            "879          [[0.0036487728, 0.0044334047, 0.9919178]]\n",
            "880              [[0.53191704, 0.1420131, 0.32606983]]\n",
            "881            [[0.47662836, 0.51734704, 0.006024566]]\n",
            "882             [[0.843099, 0.033318747, 0.123582184]]\n",
            "883        [[0.0022036019, 0.00079364283, 0.99700266]]\n",
            "884       [[0.00059061457, 0.00018225961, 0.99922717]]\n",
            "885        [[0.00037755823, 5.2931505e-06, 0.9996172]]\n",
            "886         [[0.00019050071, 5.141202e-05, 0.9997582]]\n",
            "887          [[0.0006287664, 0.026286151, 0.97308517]]\n",
            "888        [[0.00038340714, 0.0074327188, 0.99218386]]\n",
            "889           [[0.0003298683, 0.0005490244, 0.999121]]\n",
            "890           [[0.0008976768, 0.000801893, 0.9983005]]\n",
            "891        [[0.0002902496, 2.4113797e-05, 0.99968565]]\n",
            "892         [[0.0004818523, 0.0017342208, 0.99778396]]\n",
            "893         [[0.00016396247, 8.318951e-05, 0.9997528]]\n",
            "894          [[3.903825e-05, 0.9979487, 0.0020123282]]\n",
            "895          [[0.00078268634, 0.9206601, 0.078557216]]\n",
            "896         [[0.00030674136, 0.0011194533, 0.9985738]]\n",
            "897        [[0.00030128425, 3.9383245e-05, 0.9996594]]\n",
            "898        [[0.00021003092, 1.5779022e-05, 0.9997743]]\n",
            "899         [[0.0008978906, 0.00054108124, 0.9985611]]\n",
            "900         [[0.00011209439, 7.888176e-06, 0.9998801]]\n",
            "901              [[0.000760058, 0.8627754, 0.1364646]]\n",
            "902            [[0.86401147, 0.053204924, 0.08278355]]\n",
            "903          [[0.0063317516, 0.99136305, 0.002305118]]\n",
            "904         [[0.002165573, 0.99754107, 0.00029332866]]\n",
            "905         [[0.00012416411, 0.9997955, 8.038356e-05]]\n",
            "906              [[0.01012892, 0.24127468, 0.7485965]]\n",
            "907           [[0.0010496101, 0.996305, 0.0026454027]]\n",
            "908             [[0.123523265, 0.7713541, 0.10512267]]\n",
            "909         [[0.0018136869, 0.0001664143, 0.99801993]]\n",
            "910            [[0.93411225, 0.04295064, 0.022937093]]\n",
            "911          [[0.0018487363, 0.023119038, 0.97503227]]\n",
            "912            [[0.36451623, 0.023035295, 0.61244845]]\n",
            "913              [[0.16190977, 0.83451, 0.0035802084]]\n",
            "914            [[0.9324088, 0.0008680282, 0.06672325]]\n",
            "915        [[0.00010579571, 3.1771055e-05, 0.9998623]]\n",
            "916          [[0.99066085, 0.0025982433, 0.006740937]]\n",
            "917         [[0.9957408, 0.00030658455, 0.0039526606]]\n",
            "918          [[0.02945493, 0.97002786, 0.00051716215]]\n",
            "919             [[0.008725683, 0.9207299, 0.07054437]]\n",
            "920                [[0.0056936, 0.780405, 0.21390145]]\n",
            "921            [[0.032411177, 0.46977618, 0.49781263]]\n",
            "922       [[0.00039953462, 0.99941456, 0.00018594718]]\n",
            "923           [[0.0011980203, 0.33061108, 0.66819096]]\n",
            "924            [[0.014204932, 0.03483387, 0.95096123]]\n",
            "925         [[0.00031056145, 0.0057890355, 0.9939004]]\n",
            "926            [[0.0034681472, 0.8703336, 0.12619825]]\n",
            "927           [[0.000137858, 0.9983523, 0.0015099314]]\n",
            "928         [[0.0060384907, 0.0034142002, 0.99054724]]\n",
            "929         [[0.00029902725, 0.0005941102, 0.9991068]]\n",
            "930          [[0.0005091034, 0.0029310014, 0.9965599]]\n",
            "931        [[0.00037308136, 0.00070602837, 0.9989209]]\n",
            "932            [[0.0026528835, 0.7457711, 0.25157595]]\n",
            "933       [[0.00033359329, 0.00049997703, 0.99916637]]\n",
            "934          [[0.108628094, 0.00012643832, 0.8912454]]\n",
            "935          [[0.108628094, 0.00012643832, 0.8912454]]\n",
            "936        [[0.00042433324, 4.3583528e-05, 0.9995321]]\n",
            "937          [[0.0004869199, 8.424626e-05, 0.9994288]]\n",
            "938       [[0.00031643073, 1.1009929e-05, 0.99967265]]\n",
            "939         [[0.0003125124, 0.0006281982, 0.99905926]]\n",
            "940         [[0.00032793224, 0.005630386, 0.99404174]]\n",
            "941          [[0.00023231773, 0.01009444, 0.98967326]]\n",
            "942              [[0.014310667, 0.45312536, 0.532564]]\n",
            "943        [[0.00013645296, 1.4462056e-05, 0.9998491]]\n",
            "944        [[0.0002396445, 1.07403575e-05, 0.9997496]]\n",
            "945           [[0.00027147346, 0.18032044, 0.8194081]]\n",
            "946        [[0.00037332787, 0.00047746516, 0.9991492]]\n",
            "947        [[0.00011626441, 0.00010380788, 0.9997799]]\n",
            "948         [[0.00017531312, 0.055508874, 0.94431585]]\n",
            "949         [[0.00012181575, 0.0001037426, 0.9997745]]\n",
            "950            [[0.00039426459, 0.4656216, 0.5339841]]\n",
            "951             [[0.0013346752, 0.7260616, 0.2726037]]\n",
            "952         [[0.00018148072, 7.434655e-05, 0.9997441]]\n",
            "953         [[0.00017906696, 0.025778882, 0.97404206]]\n",
            "954             [[0.012203545, 0.07833102, 0.9094655]]\n",
            "955         [[0.0001809891, 0.0006375944, 0.99918145]]\n",
            "956          [[0.000360052, 5.6487774e-05, 0.9995834]]\n",
            "957          [[0.00041881026, 0.00023117465, 0.99935]]\n",
            "958          [[0.0012736303, 0.0007822469, 0.9979442]]\n",
            "959            [[0.001217877, 0.96982366, 0.02895846]]\n",
            "960           [[0.0006954109, 0.0006285327, 0.998676]]\n",
            "961        [[0.00013519404, 9.203255e-06, 0.99985564]]\n",
            "962         [[0.00031241856, 1.907886e-05, 0.9996685]]\n",
            "963         [[0.0006459353, 1.8308925e-05, 0.9993357]]\n",
            "964              [[0.026474958, 0.4383224, 0.5352026]]\n",
            "965         [[0.00021221174, 0.0002990657, 0.9994887]]\n",
            "966           [[0.0065034265, 0.42150113, 0.57199544]]\n",
            "967           [[0.0065034265, 0.42150113, 0.57199544]]\n",
            "968           [[0.003142845, 0.027055426, 0.96980166]]\n",
            "969        [[0.00014413241, 2.9521283e-05, 0.9998264]]\n",
            "970        [[0.000121790836, 0.0028691248, 0.9970091]]\n",
            "971               [[0.00190056, 0.15349346, 0.844606]]\n",
            "972           [[0.00069325423, 0.25934988, 0.7399569]]\n",
            "973        [[0.0004529569, 0.00017563149, 0.99937147]]\n",
            "974             [[0.066587135, 0.35459936, 0.5788135]]\n",
            "975             [[0.066587135, 0.35459936, 0.5788135]]\n",
            "976        [[0.00013670968, 0.00034598142, 0.9995173]]\n",
            "977           [[0.0016858827, 0.010040719, 0.9882734]]\n",
            "978           [[0.0021315848, 0.83067477, 0.16719368]]\n",
            "979         [[0.00034102256, 0.009838713, 0.98982024]]\n",
            "980         [[0.0010528244, 0.0001322324, 0.99881494]]\n",
            "981            [[0.5466062, 0.0023452449, 0.45104852]]\n",
            "982           [[0.0006454921, 0.64086056, 0.35849395]]\n",
            "983        [[9.6414355e-05, 6.1563354e-05, 0.9998419]]\n",
            "984           [[0.0012900721, 0.021794412, 0.9769155]]\n",
            "985            [[0.5466062, 0.0023452449, 0.45104852]]\n",
            "986           [[0.0005495658, 0.002536588, 0.9969139]]\n",
            "987          [[0.010540295, 0.00020644227, 0.9892532]]\n",
            "988        [[0.00034018213, 2.8976336e-05, 0.9996308]]\n",
            "989        [[0.000102755825, 2.1184487e-05, 0.999876]]\n",
            "990         [[0.0003750327, 4.2156847e-05, 0.9995828]]\n",
            "991         [[1.8444005e-05, 0.9987581, 0.0012234338]]\n",
            "992        [[5.5708293e-05, 2.346202e-05, 0.99992085]]\n",
            "993          [[0.0028613973, 0.024270022, 0.97286856]]\n",
            "994          [[0.0007269231, 0.0104809115, 0.9887921]]\n",
            "995            [[0.00010495127, 0.964889, 0.03500599]]\n",
            "996           [[0.00072573556, 0.78575236, 0.2135219]]\n",
            "997       [[0.00065103505, 0.00027034484, 0.99907863]]\n",
            "998             [[0.003402722, 0.03413024, 0.9624671]]\n",
            "999         [[0.00046450936, 0.0017411105, 0.9977944]]\n",
            "1000       [[0.00014495564, 0.00045011664, 0.9994049]]\n",
            "1001        [[0.00095412496, 0.014058374, 0.98498744]]\n",
            "1002        [[0.00022777791, 0.00010134282, 0.999671]]\n",
            "1003         [[0.000935042, 0.0076857805, 0.99137914]]\n",
            "1004      [[0.00020401806, 2.3869365e-05, 0.99977213]]\n",
            "1005           [[0.0003525966, 0.4359972, 0.56365013]]\n",
            "1006       [[0.0003954126, 4.7079604e-05, 0.99955755]]\n",
            "1007       [[0.0003954126, 4.7079604e-05, 0.99955755]]\n",
            "1008       [[0.00031233815, 6.7870233e-06, 0.9996809]]\n",
            "1009           [[0.062035143, 0.9260396, 0.011925299]]\n",
            "1010       [[0.0006680514, 1.8022307e-05, 0.99931395]]\n",
            "1011       [[0.00022918331, 4.6709694e-05, 0.9997241]]\n",
            "1012      [[0.00031613422, 0.00019622875, 0.99948764]]\n",
            "1013       [[9.157219e-05, 3.3506498e-05, 0.99987495]]\n",
            "1014           [[0.9678353, 0.02980402, 0.0023607293]]\n",
            "1015          [[0.007308613, 0.0050527616, 0.9876387]]\n",
            "1016        [[0.0007076677, 1.9918847e-05, 0.9992724]]\n",
            "1017         [[0.0004383487, 0.008220156, 0.99134153]]\n",
            "1018      [[0.00033180535, 2.3430213e-05, 0.99964476]]\n",
            "1019       [[0.00016792737, 2.3396717e-05, 0.9998087]]\n",
            "1020         [[0.00085727323, 1.55718e-05, 0.9991271]]\n",
            "1021          [[0.0023151613, 0.8962626, 0.101422265]]\n",
            "1022         [[0.0015396373, 0.0009564886, 0.9975038]]\n",
            "1023       [[0.00035439228, 0.0038089063, 0.99583673]]\n",
            "1024           [[0.0016406705, 0.5309776, 0.46738172]]\n",
            "1025            [[0.9388455, 0.016744759, 0.04440969]]\n",
            "1026        [[0.00044375562, 0.0074913553, 0.9920649]]\n",
            "1027         [[0.000126465, 1.659591e-05, 0.99985695]]\n",
            "1028        [[0.00017482536, 0.00019815372, 0.999627]]\n",
            "1029       [[0.00092253415, 0.00011549269, 0.9989619]]\n",
            "1030      [[0.00040256002, 0.00017930125, 0.99941814]]\n",
            "1031         [[0.00055260153, 0.024612969, 0.9748344]]\n",
            "1032       [[0.000110793226, 0.00088024535, 0.999009]]\n",
            "1033         [[0.95020765, 0.0018462702, 0.047946047]]\n",
            "1034          [[0.0002581626, 1.27015e-05, 0.9997291]]\n",
            "1035      [[0.00018506208, 4.7624428e-05, 0.99976724]]\n",
            "1036       [[0.00024907198, 1.3176887e-05, 0.9997377]]\n",
            "1037            [[0.007650549, 0.35474595, 0.6376035]]\n",
            "1038       [[0.00019194228, 0.00015370136, 0.9996543]]\n",
            "1039      [[0.00018892043, 0.00021761078, 0.99959356]]\n",
            "1040      [[0.00021372818, 0.00092788175, 0.99885833]]\n",
            "1041         [[0.0011251187, 0.98689276, 0.011982116]]\n",
            "1042       [[5.8056623e-05, 0.9997993, 0.00014267315]]\n",
            "1043         [[0.0008392079, 0.98186594, 0.017294846]]\n",
            "1044           [[0.0012253803, 0.05974122, 0.9390333]]\n",
            "1045      [[0.00027670048, 8.2238585e-05, 0.99964106]]\n",
            "1046        [[0.00040458195, 5.060087e-05, 0.9995448]]\n",
            "1047      [[0.00012348418, 1.0288931e-05, 0.99986625]]\n",
            "1048            [[0.9937908, 0.0001830132, 0.0060262]]\n",
            "1049           [[0.9615265, 0.0035384896, 0.03493505]]\n",
            "1050         [[0.98752743, 0.01194579, 0.00052678946]]\n",
            "1051         [[0.00014901975, 0.005695922, 0.9941551]]\n",
            "1052       [[0.00011365219, 0.00015602443, 0.9997303]]\n",
            "1053       [[9.039108e-05, 0.00020126463, 0.99970835]]\n",
            "1054        [[0.0001044281, 6.765128e-05, 0.99982786]]\n",
            "1055       [[0.00055416167, 3.088093e-05, 0.99941504]]\n",
            "1056       [[0.00043727574, 0.00037245254, 0.9991903]]\n",
            "1057           [[0.00026732506, 0.12600368, 0.873729]]\n",
            "1058          [[8.82166e-05, 0.0001492988, 0.9997625]]\n",
            "1059      [[5.7984384e-05, 0.00045116508, 0.99949074]]\n",
            "1060        [[0.0002229452, 0.0014026591, 0.99837434]]\n",
            "1061        [[8.218105e-05, 0.00028215692, 0.9996356]]\n",
            "1062          [[0.0005129293, 0.011900395, 0.9875866]]\n",
            "1063         [[0.0009452394, 0.004417204, 0.99463755]]\n",
            "1064          [[0.96902037, 0.007443278, 0.023536364]]\n",
            "1065           [[0.007995695, 0.39604858, 0.59595567]]\n",
            "1066           [[0.007995695, 0.39604858, 0.59595567]]\n",
            "1067           [[0.0006643044, 0.9372716, 0.06206414]]\n",
            "1068       [[0.00018293745, 0.0009323366, 0.99888474]]\n",
            "1069          [[0.0018235545, 0.019174052, 0.9790025]]\n",
            "1070       [[0.00020109113, 0.0011572448, 0.99864167]]\n",
            "1071        [[0.00023203265, 6.469976e-05, 0.9997032]]\n",
            "1072          [[0.0018235545, 0.019174052, 0.9790025]]\n",
            "1073          [[0.0021602968, 0.0009937412, 0.996846]]\n",
            "1074         [[0.0003534598, 0.0003861248, 0.9992605]]\n",
            "1075      [[0.00051820395, 0.00026650948, 0.99921536]]\n",
            "1076         [[0.00034967886, 0.9293237, 0.070326634]]\n",
            "1077         [[9.327005e-05, 7.266175e-06, 0.9998995]]\n",
            "1078         [[4.962148e-05, 8.17333e-05, 0.99986863]]\n",
            "1079        [[4.338869e-05, 5.565435e-05, 0.99990094]]\n",
            "1080            [[0.034272015, 0.5949704, 0.37075758]]\n",
            "1081            [[0.004560376, 0.63379586, 0.3616437]]\n",
            "1082           [[0.0010933721, 0.47565624, 0.5232504]]\n",
            "1083        [[0.00025043538, 9.937695e-06, 0.9997397]]\n",
            "1084        [[0.00028178058, 1.070225e-05, 0.9997075]]\n",
            "1085       [[0.00069138146, 0.0052357935, 0.99407285]]\n",
            "1086          [[0.00043821882, 0.46827343, 0.5312883]]\n",
            "1087        [[0.0001435985, 0.0008825785, 0.99897385]]\n",
            "1088        [[0.00043707096, 0.011961904, 0.98760104]]\n",
            "1089             [[0.000354745, 0.5370557, 0.4625896]]\n",
            "1090          [[0.00013096663, 0.9816444, 0.01822464]]\n",
            "1091            [[0.33224392, 0.63391477, 0.03384135]]\n",
            "1092        [[0.00020143094, 0.00012261186, 0.999676]]\n",
            "1093            [[0.8832812, 0.11155549, 0.005163338]]\n",
            "1094               [[0.275055, 0.7081913, 0.01675368]]\n",
            "1095         [[0.0031556683, 0.0008224225, 0.9960219]]\n",
            "1096       [[0.00020248789, 0.0016602384, 0.99813724]]\n",
            "1097       [[0.000111273715, 2.408628e-05, 0.9998646]]\n",
            "1098        [[0.00037043824, 8.646512e-05, 0.9995431]]\n",
            "1099       [[0.0003650971, 5.0672308e-05, 0.99958426]]\n",
            "1100        [[8.902804e-05, 0.0002580922, 0.99965286]]\n",
            "1101       [[0.00027733223, 0.00065395073, 0.9990687]]\n",
            "1102       [[0.00011949219, 7.1741575e-05, 0.9998087]]\n",
            "1103        [[0.0008075801, 0.0015620711, 0.99763024]]\n",
            "1104         [[0.000525389, 0.0029229352, 0.99655163]]\n",
            "1105         [[0.00022547261, 0.002741381, 0.9970331]]\n",
            "1106       [[8.443841e-05, 2.4417726e-05, 0.99989116]]\n",
            "1107       [[7.5225355e-05, 2.3387665e-05, 0.9999014]]\n",
            "1108         [[6.200517e-05, 8.132622e-05, 0.9998567]]\n",
            "1109        [[6.892107e-05, 0.00040454388, 0.9995266]]\n",
            "1110       [[8.2367624e-05, 0.00070344703, 0.9992142]]\n",
            "1111         [[0.009807793, 0.0031818491, 0.98701024]]\n",
            "1112          [[0.0011004168, 0.31872988, 0.68016964]]\n",
            "1113       [[0.00021334946, 0.00093856716, 0.9988481]]\n",
            "1114       [[0.00013218104, 5.9248894e-05, 0.9998086]]\n",
            "1115        [[0.00016520797, 2.1801536e-05, 0.999813]]\n",
            "1116             [[0.16167761, 0.16084315, 0.6774792]]\n",
            "1117          [[0.0021329445, 0.05016777, 0.94769925]]\n",
            "1118        [[5.360521e-05, 0.0026189503, 0.99732745]]\n",
            "1119          [[0.002401835, 0.0020319514, 0.9955662]]\n",
            "1120         [[0.0043336092, 0.0014258912, 0.9942404]]\n",
            "1121           [[0.000445381, 1.4673386e-05, 0.99954]]\n",
            "1122        [[0.99502844, 0.0010775636, 0.0038940222]]\n",
            "1123         [[0.0052156863, 0.9877263, 0.0070580924]]\n",
            "1124      [[0.00026517542, 0.00017739683, 0.99955744]]\n",
            "1125       [[0.00015159874, 1.1395667e-05, 0.9998369]]\n",
            "1126        [[0.00038920844, 0.028454687, 0.97115606]]\n",
            "1127          [[0.0019460875, 0.97367746, 0.02437652]]\n",
            "1128        [[0.00062433037, 0.98936534, 0.010010334]]\n",
            "1129          [[0.0007446603, 0.9821004, 0.017154856]]\n",
            "1130       [[0.0005020826, 5.9492348e-05, 0.99943846]]\n",
            "1131           [[0.005004545, 0.092593335, 0.9024021]]\n",
            "1132            [[0.029778756, 0.31574687, 0.6544743]]\n",
            "1133       [[0.0004335679, 2.3533426e-05, 0.99954283]]\n",
            "1134           [[0.31153542, 0.045111552, 0.64335304]]\n",
            "1135         [[0.0006984983, 0.0015598369, 0.9977417]]\n",
            "1136        [[9.331705e-05, 2.8733553e-05, 0.9998779]]\n",
            "1137      [[0.000114580784, 0.00023270695, 0.9996526]]\n",
            "1138         [[8.1580074e-05, 7.23959e-05, 0.9998461]]\n",
            "1139        [[8.268819e-05, 0.00044768522, 0.9994697]]\n",
            "1140        [[0.00040264547, 8.958452e-05, 0.9995078]]\n",
            "1141           [[0.0010552108, 0.7754122, 0.22353251]]\n",
            "1142           [[0.0011539628, 0.6185318, 0.38031426]]\n",
            "1143         [[0.0021020365, 0.009970814, 0.98792714]]\n",
            "1144       [[0.0010166876, 0.000100125784, 0.9988832]]\n",
            "1145             [[0.2879341, 0.54763293, 0.16443296]]\n",
            "1146        [[7.292107e-05, 3.409145e-05, 0.99989295]]\n",
            "1147        [[0.0002467356, 1.774649e-05, 0.99973553]]\n",
            "1148        [[0.00021248075, 8.606241e-06, 0.9997789]]\n",
            "1149       [[0.00068089116, 5.8508784e-05, 0.9992606]]\n",
            "1150        [[0.00012805621, 0.0001398311, 0.9997321]]\n",
            "1151      [[0.00015274668, 0.00054878055, 0.99929845]]\n",
            "1152            [[0.0004035471, 0.1048048, 0.8947916]]\n",
            "1153       [[8.7173314e-05, 0.00012928687, 0.9997836]]\n",
            "1154          [[0.024700316, 0.003712089, 0.97158754]]\n",
            "1155            [[0.03630173, 0.87980694, 0.08389133]]\n",
            "1156       [[0.00059049344, 7.1900645e-06, 0.9994024]]\n",
            "1157        [[0.00048260888, 2.004026e-05, 0.9994974]]\n",
            "1158        [[0.0011000321, 3.2471118e-05, 0.9988675]]\n",
            "1159       [[0.00048509985, 0.00028651874, 0.9992285]]\n",
            "1160        [[0.00067360804, 0.0014799384, 0.9978465]]\n",
            "1161         [[0.0027268683, 0.0014186411, 0.9958545]]\n",
            "1162        [[0.0010444802, 0.00012118556, 0.9988343]]\n",
            "1163           [[0.014881324, 0.008549004, 0.9765696]]\n",
            "1164        [[0.00023764372, 0.0009975026, 0.9987649]]\n",
            "1165         [[0.0014023102, 0.0059206556, 0.9926771]]\n",
            "1166         [[0.00041707573, 0.0009209673, 0.998662]]\n",
            "1167        [[0.00010121965, 8.212307e-05, 0.9998167]]\n",
            "1168        [[0.00011881734, 0.00021521936, 0.999666]]\n",
            "1169       [[7.5487005e-05, 0.00010537679, 0.9998192]]\n",
            "1170            [[0.0010919916, 0.2801206, 0.7187874]]\n",
            "1171      [[0.00015249594, 3.3148037e-05, 0.99981445]]\n",
            "1172       [[0.0003465713, 0.00010708787, 0.99954623]]\n",
            "1173          [[0.00022641706, 0.02087446, 0.9788992]]\n",
            "1174         [[0.94099784, 0.056487445, 0.0025147616]]\n",
            "1175            [[0.35111377, 0.63249964, 0.01638659]]\n",
            "1176          [[0.02132844, 0.9785178, 0.00015373822]]\n",
            "1177       [[0.00018623722, 0.00017490111, 0.9996388]]\n",
            "1178          [[0.0002828002, 9.189487e-06, 0.999708]]\n",
            "1179        [[0.00045271983, 0.0012542021, 0.9982931]]\n",
            "1180         [[0.0017404265, 1.596923e-05, 0.9982437]]\n",
            "1181        [[0.0019172741, 1.6015718e-05, 0.9980667]]\n",
            "1182        [[0.0017197068, 1.676767e-05, 0.99826354]]\n",
            "1183        [[0.00079471583, 1.9306033e-05, 0.999186]]\n",
            "1184        [[0.00035832034, 0.003945162, 0.99569654]]\n",
            "1185      [[0.000108706634, 9.583629e-06, 0.99988174]]\n",
            "1186          [[0.0030318408, 0.02266229, 0.97430587]]\n",
            "1187         [[0.0039902613, 0.0087618595, 0.9872479]]\n",
            "1188        [[0.0016541102, 6.160657e-05, 0.99828416]]\n",
            "1189        [[0.00037609856, 0.0007125399, 0.9989114]]\n",
            "1190       [[0.00012228926, 0.00017583439, 0.9997019]]\n",
            "1191       [[9.957474e-05, 8.9776855e-05, 0.99981076]]\n",
            "1192        [[0.00062362256, 0.0067216232, 0.9926548]]\n",
            "1193       [[0.00076684746, 7.4046686e-05, 0.9991591]]\n",
            "1194        [[0.0005857503, 5.913725e-05, 0.99935514]]\n",
            "1195        [[0.00030935014, 6.542057e-06, 0.9996841]]\n",
            "1196    [[0.000111269095, 0.000120837336, 0.99976784]]\n",
            "1197      [[6.2135136e-05, 0.00012837978, 0.99980956]]\n",
            "1198         [[0.00068367086, 0.23897676, 0.76033956]]\n",
            "1199           [[0.0010765493, 0.22658162, 0.7723418]]\n",
            "1200            [[0.002022164, 0.5681176, 0.42986023]]\n",
            "1201       [[0.00018608067, 1.9520372e-05, 0.9997944]]\n",
            "1202        [[8.950249e-05, 2.002483e-05, 0.99989045]]\n",
            "1203        [[0.00066797103, 6.345222e-05, 0.9992686]]\n",
            "1204            [[0.6193724, 0.003977608, 0.37664998]]\n",
            "1205       [[0.00034182437, 2.3821416e-05, 0.9996344]]\n",
            "1206      [[0.00031372107, 0.00036804902, 0.99931824]]\n",
            "1207       [[0.00045728518, 1.768454e-05, 0.99952507]]\n",
            "1208       [[0.00033004914, 1.4425732e-05, 0.9996555]]\n",
            "1209            [[0.014994094, 0.01668631, 0.9683196]]\n",
            "1210           [[0.0009626446, 0.989988, 0.009049356]]\n",
            "1211         [[0.0023422053, 0.103989705, 0.89366806]]\n",
            "1212           [[0.008225643, 0.016421098, 0.9753533]]\n",
            "1213       [[0.00033124027, 3.6611935e-05, 0.9996321]]\n",
            "1214         [[0.0011202899, 0.0058521833, 0.9930275]]\n",
            "1215        [[0.0005107395, 0.0003186448, 0.99917066]]\n",
            "1216         [[0.0011202899, 0.0058521833, 0.9930275]]\n",
            "1217         [[0.00018018555, 0.055992644, 0.9438272]]\n",
            "1218         [[9.070336e-05, 9.951574e-06, 0.9998994]]\n",
            "1219         [[0.000103938, 0.0030480106, 0.99684805]]\n",
            "1220       [[0.00036081346, 1.555006e-05, 0.99962366]]\n",
            "1221       [[0.00048246264, 0.00011715113, 0.9994004]]\n",
            "1222        [[0.0025543312, 0.0058713793, 0.99157435]]\n",
            "1223          [[0.35398588, 0.0074802334, 0.63853395]]\n",
            "1224        [[0.00036669686, 0.023459075, 0.97617424]]\n",
            "1225       [[0.00034491086, 3.8929606e-06, 0.9996512]]\n",
            "1226        [[0.0025142522, 0.0018526367, 0.99563307]]\n",
            "1227       [[0.00030840008, 1.7278247e-05, 0.9996743]]\n",
            "1228         [[0.00023300748, 0.003267595, 0.9964994]]\n",
            "1229        [[0.000647826, 1.4245662e-05, 0.99933785]]\n",
            "1230       [[0.00079805707, 1.5282903e-05, 0.9991867]]\n",
            "1231       [[0.0003537067, 1.7808808e-05, 0.99962854]]\n",
            "1232          [[0.83517265, 0.15245835, 0.0123689575]]\n",
            "1233           [[0.0023762628, 0.08776999, 0.9098537]]\n",
            "1234        [[0.0007773802, 2.9068346e-05, 0.9991936]]\n",
            "1235            [[0.19384803, 0.7831311, 0.023020808]]\n",
            "1236              [[0.28136972, 0.3730352, 0.3455951]]\n",
            "1237       [[0.0009602237, 4.3892498e-05, 0.99899584]]\n",
            "1238        [[0.0001323848, 0.00020584563, 0.9996618]]\n",
            "1239          [[0.0038118232, 0.022973897, 0.9732143]]\n",
            "1240       [[0.0003019341, 1.7457573e-05, 0.99968064]]\n",
            "1241        [[0.0006041682, 0.00082701095, 0.9985689]]\n",
            "1242          [[0.0002579789, 0.0008899911, 0.998852]]\n",
            "1243         [[0.00053461385, 0.005848142, 0.9936173]]\n",
            "1244         [[0.00080985244, 0.9848355, 0.014354663]]\n",
            "1245         [[8.129089e-05, 0.0005059734, 0.9994128]]\n",
            "1246         [[0.00036010428, 0.057562664, 0.9420771]]\n",
            "1247       [[0.00012768242, 0.00042166712, 0.9994506]]\n",
            "1248         [[8.364692e-05, 5.0244875e-05, 0.999866]]\n",
            "1249          [[0.31923583, 0.67822355, 0.0025406447]]\n",
            "1250         [[0.00039860993, 0.9564979, 0.043103527]]\n",
            "1251              [[0.00920235, 0.17900366, 0.811794]]\n",
            "1252          [[0.0030814102, 0.0008346398, 0.996084]]\n",
            "1253            [[0.041156705, 0.47268692, 0.4861563]]\n",
            "1254       [[0.00015858891, 0.0012652188, 0.99857616]]\n",
            "1255       [[0.00012499501, 0.00020954576, 0.9996655]]\n",
            "1256        [[9.5440344e-05, 8.346729e-05, 0.9998211]]\n",
            "1257            [[0.003495418, 0.19165288, 0.8048517]]\n",
            "1258         [[0.00034980368, 0.011725574, 0.9879246]]\n",
            "1259        [[0.00020081167, 0.0012186631, 0.9985806]]\n",
            "1260          [[0.0004994708, 0.56779975, 0.43170077]]\n",
            "1261         [[0.0005395536, 0.0015136463, 0.9979468]]\n",
            "1262        [[0.0002991577, 1.0501186e-05, 0.9996904]]\n",
            "1263          [[0.98774195, 0.0010651214, 0.01119285]]\n",
            "1264      [[0.00025169147, 1.1285773e-05, 0.99973696]]\n",
            "1265       [[0.00021140858, 0.0009365212, 0.99885213]]\n",
            "1266        [[0.00022374411, 0.0011630213, 0.9986131]]\n",
            "1267             [[0.002428302, 0.0363678, 0.9612039]]\n",
            "1268        [[0.0017393801, 0.0019900114, 0.99627054]]\n",
            "1269            [[0.20161647, 0.7887217, 0.009661855]]\n",
            "1270            [[0.7488075, 0.086783655, 0.16440886]]\n",
            "1271           [[0.97725755, 0.00946071, 0.013281706]]\n",
            "1272          [[0.00025321054, 0.9583734, 0.04137333]]\n",
            "1273         [[0.0006819053, 0.98898906, 0.010329082]]\n",
            "1274       [[0.0007993046, 0.00021238362, 0.99898833]]\n",
            "1275         [[0.0008170014, 8.55325e-05, 0.99909747]]\n",
            "1276          [[0.0010298736, 0.98109424, 0.01787589]]\n",
            "1277         [[0.0069839703, 0.9912503, 0.0017657309]]\n",
            "1278         [[0.0035953731, 0.025203265, 0.97120136]]\n",
            "1279           [[0.0060468568, 0.40304685, 0.5909063]]\n",
            "1280            [[0.005093561, 0.18308489, 0.8118215]]\n",
            "1281         [[0.0013741368, 0.0035621668, 0.9950637]]\n",
            "1282      [[0.00010160355, 2.7944763e-05, 0.99987054]]\n",
            "1283       [[0.00016350813, 7.296388e-05, 0.99976355]]\n",
            "1284      [[0.000116673466, 0.00056222884, 0.9993211]]\n",
            "1285      [[0.000116589195, 0.00018832528, 0.9996952]]\n",
            "1286           [[0.003069042, 0.19163586, 0.80529505]]\n",
            "1287       [[0.00015301985, 5.607288e-06, 0.99984133]]\n",
            "1288       [[0.00029941087, 0.99439996, 0.0053006723]]\n",
            "1289        [[0.0012342724, 0.99716115, 0.0016046567]]\n",
            "1290          [[0.005709073, 0.004077593, 0.99021333]]\n",
            "1291      [[0.00022849014, 5.3268494e-05, 0.99971825]]\n",
            "1292            [[0.8152424, 0.08580219, 0.098955356]]\n",
            "1293       [[7.479616e-05, 0.00018083565, 0.99974436]]\n",
            "1294        [[0.00012733991, 4.596578e-05, 0.9998267]]\n",
            "1295            [[0.4271775, 0.51599264, 0.056829914]]\n",
            "1296       [[0.00022471616, 2.4509081e-05, 0.9997507]]\n",
            "1297         [[0.000635589, 0.00017023743, 0.9991942]]\n",
            "1298        [[0.00028113573, 0.0010902126, 0.9986286]]\n",
            "1299      [[0.00011341125, 0.00024610636, 0.99964046]]\n",
            "1300        [[0.0011397031, 0.00016743214, 0.9986929]]\n",
            "1301        [[7.087683e-05, 0.00032919965, 0.9995999]]\n",
            "1302         [[6.149748e-05, 8.574038e-05, 0.9998528]]\n",
            "1303            [[0.0007698106, 0.5527864, 0.4464438]]\n",
            "1304          [[0.0009813176, 0.30324388, 0.69577485]]\n",
            "1305       [[0.00010579607, 0.00017237701, 0.9997218]]\n",
            "1306       [[0.00024580528, 0.00043934307, 0.9993149]]\n",
            "1307        [[0.00018614782, 7.150118e-05, 0.9997423]]\n",
            "1308       [[0.00015678196, 1.7908964e-05, 0.9998254]]\n",
            "1309       [[0.00012853275, 2.510464e-05, 0.99984634]]\n",
            "1310         [[0.0001766994, 3.466841e-05, 0.9997886]]\n",
            "1311          [[0.000848358, 0.122426555, 0.87672514]]\n",
            "1312       [[4.2185355e-05, 0.00019694054, 0.9997609]]\n",
            "1313         [[0.0004260206, 0.030754054, 0.96881986]]\n",
            "1314       [[0.00017291686, 4.1650233e-05, 0.9997855]]\n",
            "1315          [[0.0005050735, 0.57586014, 0.42363474]]\n",
            "1316             [[0.0007288377, 0.242257, 0.7570142]]\n",
            "1317        [[0.00014156506, 9.257587e-06, 0.9998491]]\n",
            "1318       [[0.00018685202, 1.1489129e-05, 0.9998017]]\n",
            "1319       [[0.00028194624, 4.4577755e-05, 0.9996735]]\n",
            "1320         [[0.00030758372, 1.641156e-05, 0.999676]]\n",
            "1321       [[0.00010808008, 0.00093579455, 0.9989561]]\n",
            "1322            [[0.0045247218, 0.69718033, 0.298295]]\n",
            "1323       [[0.00039011633, 0.99744284, 0.0021669865]]\n",
            "1324          [[0.0011835304, 0.9131335, 0.085682966]]\n",
            "1325          [[0.0016824469, 0.94142646, 0.05689109]]\n",
            "1326         [[0.00082001317, 0.9968099, 0.002370082]]\n",
            "1327      [[9.7061165e-05, 0.00012774738, 0.99977523]]\n",
            "1328        [[6.943027e-05, 0.0006941501, 0.99923646]]\n",
            "1329        [[0.00015830199, 0.0027345587, 0.9971071]]\n",
            "1330        [[0.00010635612, 0.9978397, 0.0020539758]]\n",
            "1331          [[0.0017256946, 0.05328138, 0.94499284]]\n",
            "1332      [[0.00020075444, 2.2797401e-05, 0.99977654]]\n",
            "1333           [[0.000273333, 5.20011e-05, 0.9996747]]\n",
            "1334             [[0.002471585, 0.778958, 0.21857044]]\n",
            "1335        [[0.00030685755, 0.0003189396, 0.9993742]]\n",
            "1336             [[0.11174233, 0.7416133, 0.14664437]]\n",
            "1337      [[0.00014420842, 0.00092071283, 0.99893504]]\n",
            "1338         [[0.0001214526, 3.124052e-05, 0.9998473]]\n",
            "1339        [[0.0009535244, 2.1992078e-05, 0.9990244]]\n",
            "1340       [[0.000114756665, 0.00045725342, 0.999428]]\n",
            "1341       [[0.0038185094, 0.00019526531, 0.99598616]]\n",
            "1342        [[0.0009365935, 2.0795429e-05, 0.9990426]]\n",
            "1343         [[0.9695031, 0.00094573444, 0.029551119]]\n",
            "1344        [[0.011243612, 0.00024698628, 0.98850936]]\n",
            "1345        [[0.000667557, 0.00032862838, 0.99900395]]\n",
            "1346           [[0.023582378, 0.089428276, 0.8869893]]\n",
            "1347         [[0.00052926363, 0.002938426, 0.9965323]]\n",
            "1348         [[0.0006578741, 3.088173e-05, 0.9993113]]\n",
            "1349        [[0.0008075576, 2.755426e-05, 0.99916494]]\n",
            "1350       [[0.00059040525, 0.00016035377, 0.9992493]]\n",
            "1351          [[0.001721964, 0.0014644786, 0.9968136]]\n",
            "1352          [[0.0029176003, 0.020213965, 0.9768685]]\n",
            "1353       [[0.00041844323, 9.658619e-06, 0.99957186]]\n",
            "1354       [[0.00030061867, 1.5922136e-05, 0.9996834]]\n",
            "1355             [[0.02204541, 0.23885839, 0.7390963]]\n",
            "1356          [[0.00036910063, 5.599e-05, 0.99957484]]\n",
            "1357            [[0.005329933, 0.8418306, 0.15283951]]\n",
            "1358       [[0.00075352815, 1.1777291e-05, 0.9992347]]\n",
            "1359       [[0.00042934803, 0.00013326839, 0.9994373]]\n",
            "1360        [[0.00024377309, 6.794108e-06, 0.9997495]]\n",
            "1361          [[0.00040333756, 0.03486734, 0.9647293]]\n",
            "1362            [[0.6424522, 0.30378416, 0.053763647]]\n",
            "1363        [[8.0768266e-05, 0.0012564772, 0.9986628]]\n",
            "1364        [[0.00022022666, 0.95805675, 0.041723013]]\n",
            "1365       [[0.00015301052, 0.0027003558, 0.99714667]]\n",
            "1366          [[0.0014248117, 0.052477404, 0.9460978]]\n",
            "1367       [[7.725266e-05, 1.8767922e-05, 0.99990404]]\n",
            "1368          [[0.00015910064, 0.03166269, 0.9681782]]\n",
            "1369       [[6.453482e-05, 0.00049570465, 0.99943966]]\n",
            "1370          [[0.0024123334, 0.9807273, 0.016860383]]\n",
            "1371          [[0.0013625734, 0.69742006, 0.30121738]]\n",
            "1372        [[0.00021563847, 8.843783e-06, 0.9997756]]\n",
            "1373       [[0.00097638014, 4.2346823e-05, 0.9989812]]\n",
            "1374         [[0.0011348098, 0.024319377, 0.97454584]]\n",
            "1375        [[0.00010132228, 0.9991824, 0.0007162397]]\n",
            "1376          [[0.0002934139, 0.007312554, 0.9923941]]\n",
            "1377        [[9.0968584e-05, 0.0002683425, 0.9996407]]\n",
            "1378       [[8.766129e-05, 0.00011405037, 0.99979824]]\n",
            "1379      [[8.0677084e-05, 0.00022694888, 0.99969244]]\n",
            "1380          [[0.98064923, 0.018260831, 0.001089923]]\n",
            "1381        [[0.00058511173, 8.740395e-06, 0.9994062]]\n",
            "1382        [[0.9973236, 5.9726826e-05, 0.0026167966]]\n",
            "1383            [[0.08300002, 0.9032458, 0.013754148]]\n",
            "1384           [[0.023818491, 0.9609211, 0.015260423]]\n",
            "1385      [[0.00031997578, 7.9739475e-05, 0.99960035]]\n",
            "1386        [[0.0006768138, 5.7615816e-05, 0.9992655]]\n",
            "1387      [[7.0179754e-05, 0.00018871421, 0.99974114]]\n",
            "1388           [[0.0009733951, 0.34852424, 0.6505024]]\n",
            "1389      [[0.00026091936, 2.1588408e-05, 0.99971753]]\n",
            "1390           [[0.001857789, 0.056999464, 0.9411428]]\n",
            "1391       [[0.00018603982, 3.5882436e-05, 0.9997781]]\n",
            "1392           [[0.020109797, 0.051855963, 0.9280342]]\n",
            "1393       [[0.0003891073, 3.2214932e-06, 0.99960774]]\n",
            "1394       [[0.00068034197, 5.715094e-06, 0.99931395]]\n",
            "1395              [[0.010001569, 0.1412094, 0.848789]]\n",
            "1396            [[0.008807151, 0.039718743, 0.951474]]\n",
            "1397            [[0.0019470657, 0.01517892, 0.982874]]\n",
            "1398        [[0.00016507778, 0.0010699352, 0.9987651]]\n",
            "1399            [[0.000977902, 0.7813199, 0.21770217]]\n",
            "1400          [[0.00027659078, 0.9621572, 0.03756617]]\n",
            "1401        [[0.0010095151, 9.158878e-05, 0.99889886]]\n",
            "1402          [[0.00037209602, 0.15192027, 0.8477076]]\n",
            "1403       [[5.8990707e-05, 1.7392676e-05, 0.9999236]]\n",
            "1404            [[0.008208435, 0.7927094, 0.19908218]]\n",
            "1405            [[0.008208435, 0.7927094, 0.19908218]]\n",
            "1406          [[0.0064948075, 0.95845896, 0.03504625]]\n",
            "1407            [[0.008208435, 0.7927094, 0.19908218]]\n",
            "1408            [[0.0040412876, 0.2460951, 0.7498637]]\n",
            "1409         [[0.0024812208, 0.94156903, 0.055949714]]\n",
            "1410        [[0.00039510542, 0.0001025172, 0.9995024]]\n",
            "1411       [[0.00075806916, 0.00048448268, 0.9987575]]\n",
            "1412           [[0.0025324372, 0.12590751, 0.8715601]]\n",
            "1413       [[0.00023267127, 1.630017e-05, 0.99975103]]\n",
            "1414        [[0.0002097484, 1.0784764e-05, 0.9997795]]\n",
            "1415            [[0.0016190937, 0.1746106, 0.8237702]]\n",
            "1416         [[0.000550674, 0.00019308762, 0.9992562]]\n",
            "1417          [[0.00022753859, 0.9966074, 0.00316503]]\n",
            "1418       [[0.00041110066, 1.3860047e-05, 0.9995751]]\n",
            "1419          [[0.0020724167, 0.006970221, 0.9909574]]\n",
            "1420          [[0.009763791, 0.021044085, 0.96919215]]\n",
            "1421        [[0.00036952004, 0.0031281845, 0.9965023]]\n",
            "1422        [[0.00011152176, 8.600721e-05, 0.9998024]]\n",
            "1423          [[0.0010499354, 0.040018264, 0.9589318]]\n",
            "1424          [[0.006083755, 0.030475404, 0.96344084]]\n",
            "1425          [[0.0057122963, 0.090293966, 0.9039937]]\n",
            "1426       [[0.00074428547, 0.0044093905, 0.99484634]]\n",
            "1427         [[0.00037889025, 0.9953176, 0.004303585]]\n",
            "1428         [[0.00072722934, 0.96196127, 0.03731154]]\n",
            "1429             [[0.000989078, 0.834849, 0.16416188]]\n",
            "1430     [[0.00057305704, 0.000116299874, 0.99931073]]\n",
            "1431          [[0.0048851366, 0.008779416, 0.9863355]]\n",
            "1432       [[0.00013966626, 3.3667176e-05, 0.9998267]]\n",
            "1433             [[0.017740233, 0.9122115, 0.0700483]]\n",
            "1434           [[0.0031323435, 0.1025712, 0.89429647]]\n",
            "1435      [[0.000113282666, 0.00011907798, 0.9997676]]\n",
            "1436         [[0.00095343887, 0.015648464, 0.9833981]]\n",
            "1437         [[0.0006116823, 0.003997112, 0.99539125]]\n",
            "1438       [[0.0005179988, 3.6079382e-05, 0.99944586]]\n",
            "1439           [[0.0047568046, 0.40850502, 0.5867381]]\n",
            "1440         [[0.00019309185, 0.003630809, 0.9961761]]\n",
            "1441          [[0.0004855198, 0.057078704, 0.9424357]]\n",
            "1442           [[0.006377933, 0.73473996, 0.25888208]]\n",
            "1443         [[0.00036990343, 0.070958465, 0.9286717]]\n",
            "1444          [[0.0025022812, 0.15277025, 0.84472746]]\n",
            "1445          [[0.00050552253, 0.9328011, 0.06669329]]\n",
            "1446     [[0.000121834404, 1.2520921e-05, 0.99986565]]\n",
            "1447      [[0.00010574153, 2.5367342e-05, 0.99986887]]\n",
            "1448       [[0.0002187219, 0.00031122132, 0.99947006]]\n",
            "1449             [[0.4698346, 0.021861298, 0.5083041]]\n",
            "1450          [[0.003016899, 0.89910793, 0.097875096]]\n",
            "1451          [[0.00020710436, 0.978429, 0.021363853]]\n",
            "1452        [[9.0820016e-05, 0.9990299, 0.0008792598]]\n",
            "1453       [[7.736299e-05, 0.99947923, 0.00044346435]]\n",
            "1454           [[0.0011124306, 0.8696395, 0.12924804]]\n",
            "1455        [[0.00011809885, 0.0024680966, 0.9974138]]\n",
            "1456            [[0.04515711, 0.12876013, 0.82608277]]\n",
            "1457          [[0.0028168154, 0.83801925, 0.15916389]]\n",
            "1458            [[0.13444883, 0.8036226, 0.061928604]]\n",
            "1459       [[0.00041370458, 1.4754369e-05, 0.9995715]]\n",
            "1460        [[0.0005376536, 2.2819335e-05, 0.9994394]]\n",
            "1461           [[0.00030383008, 6.61387e-05, 0.99963]]\n",
            "1462          [[0.0006762167, 0.004812231, 0.9945115]]\n",
            "1463          [[0.003700616, 0.0038197287, 0.9924797]]\n",
            "1464        [[0.00019406769, 0.002236047, 0.99756986]]\n",
            "1465        [[0.0005133969, 0.0028763206, 0.99661034]]\n",
            "1466         [[0.0011543494, 0.021108426, 0.97773725]]\n",
            "1467         [[0.0004855526, 0.005540261, 0.99397415]]\n",
            "1468          [[0.0005514671, 0.0042646215, 0.995184]]\n",
            "1469       [[0.00020740581, 9.315889e-06, 0.99978334]]\n",
            "1470       [[0.00027137075, 0.00061701477, 0.9991117]]\n",
            "1471            [[0.002472568, 0.07434879, 0.9231787]]\n",
            "1472       [[0.00017347092, 0.00045428498, 0.9993723]]\n",
            "1473        [[0.9985084, 0.00013828927, 0.0013532415]]\n",
            "1474      [[0.00062700524, 2.6548516e-05, 0.99934644]]\n",
            "1475       [[0.00044999833, 4.312959e-05, 0.99950683]]\n",
            "1476         [[0.00119632, 0.00049884594, 0.99830484]]\n",
            "1477        [[0.0005822252, 0.00021374061, 0.9992041]]\n",
            "1478        [[0.0010214346, 0.00068477227, 0.9982938]]\n",
            "1479         [[0.96402764, 0.034538988, 0.0014333741]]\n",
            "1480        [[0.00011422302, 0.9997507, 0.0001350962]]\n",
            "1481       [[0.0011212041, 2.7741058e-05, 0.99885106]]\n",
            "1482          [[0.9395909, 0.06012058, 0.00028850962]]\n",
            "1483           [[0.593428, 0.40629175, 0.00028027155]]\n",
            "1484       [[0.0042786603, 5.8648264e-05, 0.99566275]]\n",
            "1485            [[0.39731368, 0.20859669, 0.39408967]]\n",
            "1486            [[0.6793538, 0.28074962, 0.039896585]]\n",
            "1487           [[0.021059493, 0.013231661, 0.9657088]]\n",
            "1488       [[0.0006306002, 0.00013124192, 0.99923813]]\n",
            "1489           [[0.9449124, 0.051582765, 0.003504819]]\n",
            "1490          [[0.97592884, 0.016834095, 0.007236986]]\n",
            "1491         [[0.0004431167, 0.0010383587, 0.9985185]]\n",
            "1492      [[0.00038349838, 4.6609006e-05, 0.99956995]]\n",
            "1493        [[0.00025199034, 0.0009187125, 0.9988293]]\n",
            "1494        [[0.00016632446, 7.732401e-05, 0.9997563]]\n",
            "1495             [[0.0008756157, 0.3248003, 0.674324]]\n",
            "1496          [[0.0051061367, 0.9800133, 0.014880545]]\n",
            "1497          [[0.0051061367, 0.9800133, 0.014880545]]\n",
            "1498          [[0.11150664, 0.8878323, 0.00066110864]]\n",
            "1499           [[0.010324593, 0.14967902, 0.83999646]]\n",
            "1500       [[0.00047257065, 0.0011097147, 0.99841774]]\n",
            "1501       [[0.00014903568, 1.6684384e-05, 0.9998343]]\n",
            "1502         [[0.0005641914, 0.028324151, 0.97111166]]\n",
            "1503        [[0.00024491662, 0.0011344481, 0.9986206]]\n",
            "1504       [[9.4686795e-05, 0.0005283732, 0.99937695]]\n",
            "1505      [[0.00013412545, 0.00010929143, 0.99975663]]\n",
            "1506       [[0.0002516137, 6.6559464e-06, 0.99974173]]\n",
            "1507       [[0.00012760828, 1.1815975e-05, 0.9998605]]\n",
            "1508            [[0.0008793083, 0.02252873, 0.976592]]\n",
            "1509          [[0.000376608, 0.0028386116, 0.9967848]]\n",
            "1510        [[0.00012554387, 0.0014091195, 0.9984653]]\n",
            "1511        [[0.00022271118, 0.0019408892, 0.9978364]]\n",
            "1512        [[0.00032370017, 0.00022329485, 0.999453]]\n",
            "1513      [[0.00019812277, 4.8865717e-05, 0.99975306]]\n",
            "1514          [[0.000376608, 0.0028386116, 0.9967848]]\n",
            "1515          [[0.0018919866, 0.058105867, 0.9400022]]\n",
            "1516         [[0.0009108432, 3.398355e-05, 0.9990552]]\n",
            "1517         [[0.0007858101, 0.0028243428, 0.9963898]]\n",
            "1518        [[0.00050703296, 0.002126842, 0.99736613]]\n",
            "1519        [[0.99069136, 0.00022437332, 0.009084231]]\n",
            "1520            [[0.9190032, 0.03297255, 0.048024192]]\n",
            "1521         [[0.0015652451, 0.0011998671, 0.9972349]]\n",
            "1522            [[0.061198473, 0.46358892, 0.4752126]]\n",
            "1523        [[0.0007800197, 2.9411827e-05, 0.9991905]]\n",
            "1524       [[0.0011038269, 0.00041543116, 0.99848074]]\n",
            "1525          [[0.0004965905, 0.995229, 0.0042743725]]\n",
            "1526            [[0.1635811, 0.0005140568, 0.8359048]]\n",
            "1527        [[0.0010003542, 6.4788655e-05, 0.9989348]]\n",
            "1528         [[0.000655166, 0.0005568879, 0.99878794]]\n",
            "1529          [[0.015832637, 0.040110644, 0.94405675]]\n",
            "1530          [[0.015832637, 0.040110644, 0.94405675]]\n",
            "1531       [[0.00029785556, 0.00020533508, 0.9994968]]\n",
            "1532        [[0.00024098503, 6.187732e-05, 0.9996972]]\n",
            "1533       [[0.00018420097, 0.00010731505, 0.9997085]]\n",
            "1534       [[8.741833e-05, 0.00016691443, 0.99974555]]\n",
            "1535        [[0.00022260347, 0.0017043154, 0.9980731]]\n",
            "1536         [[0.9968341, 0.00023829892, 0.002927604]]\n",
            "1537       [[0.99783796, 0.00024833565, 0.0019136519]]\n",
            "1538        [[0.99702954, 0.00015524763, 0.002815177]]\n",
            "1539          [[0.08338162, 0.00011599516, 0.9165024]]\n",
            "1540         [[0.0012697678, 6.142061e-05, 0.9986688]]\n",
            "1541       [[0.00021731014, 0.00014029969, 0.9996424]]\n",
            "1542       [[0.0001432423, 0.00041527467, 0.99944144]]\n",
            "1543       [[0.00012713188, 1.708106e-05, 0.99985576]]\n",
            "1544         [[0.0002469576, 0.0010571881, 0.9986959]]\n",
            "1545           [[0.0007332939, 0.6120328, 0.38723394]]\n",
            "1546      [[0.00013876392, 1.4152001e-05, 0.99984705]]\n",
            "1547          [[0.0001650051, 0.003783488, 0.9960515]]\n",
            "1548       [[4.9561684e-05, 1.2552889e-05, 0.9999379]]\n",
            "1549             [[0.0011873941, 0.740386, 0.2584266]]\n",
            "1550             [[0.010405108, 0.821246, 0.16834886]]\n",
            "1551      [[0.00040750153, 0.00030327178, 0.99928916]]\n",
            "1552         [[0.00025671275, 0.00047874, 0.99926454]]\n",
            "1553       [[0.00022207484, 6.291037e-06, 0.99977165]]\n",
            "1554        [[7.129652e-05, 4.7773596e-05, 0.9998809]]\n",
            "1555         [[7.880081e-05, 2.4222025e-05, 0.999897]]\n",
            "1556        [[0.00015140005, 0.0030414383, 0.9968072]]\n",
            "1557         [[8.757489e-05, 7.323578e-05, 0.9998392]]\n",
            "1558       [[0.00019456657, 0.00019286199, 0.9996126]]\n",
            "1559        [[0.00010775164, 0.96580964, 0.034082636]]\n",
            "1560           [[0.010056213, 0.87426734, 0.11567647]]\n",
            "1561           [[0.008375251, 0.14934093, 0.84228384]]\n",
            "1562          [[0.0022137237, 0.99511755, 0.00266872]]\n",
            "1563       [[0.0004419348, 0.00048001908, 0.99907804]]\n",
            "1564          [[0.0063649844, 0.9625177, 0.031117387]]\n",
            "1565        [[8.5878535e-05, 0.00012112156, 0.999793]]\n",
            "1566           [[0.0010474671, 0.29900652, 0.6999459]]\n",
            "1567           [[0.016015872, 0.08037351, 0.90361065]]\n",
            "1568        [[4.6676334e-05, 0.9987148, 0.0012385442]]\n",
            "1569        [[9.856793e-05, 0.99342716, 0.0064743385]]\n",
            "1570         [[2.889164e-05, 0.9989623, 0.0010088781]]\n",
            "1571         [[0.00022353965, 0.51874524, 0.48103115]]\n",
            "1572          [[0.001805179, 0.95951647, 0.038678415]]\n",
            "1573              [[0.0015712768, 0.65564, 0.3427887]]\n",
            "1574            [[0.8766679, 0.021092093, 0.10223996]]\n",
            "1575           [[0.6188994, 0.0012452507, 0.37985533]]\n",
            "1576            [[0.84121317, 0.07866974, 0.08011712]]\n",
            "1577            [[0.8766679, 0.021092093, 0.10223996]]\n",
            "1578         [[0.0005031518, 3.957012e-06, 0.9994929]]\n",
            "1579         [[0.0004764521, 9.915324e-06, 0.9995136]]\n",
            "1580        [[0.00032262053, 8.268848e-06, 0.9996692]]\n",
            "1581        [[8.698579e-05, 0.00051185704, 0.9994012]]\n",
            "1582            [[0.002404175, 0.13122363, 0.8663723]]\n",
            "1583          [[0.0033882565, 0.9568029, 0.039808813]]\n",
            "1584          [[0.0081179645, 0.9619421, 0.029939959]]\n",
            "1585              [[0.0816603, 0.04206059, 0.8762792]]\n",
            "1586      [[0.00026073772, 0.00013151226, 0.99960774]]\n",
            "1587         [[0.0027829595, 0.0032803444, 0.9939367]]\n",
            "1588           [[0.0065626935, 0.7050661, 0.28837118]]\n",
            "1589           [[0.0002441941, 0.00235921, 0.9973966]]\n",
            "1590      [[0.00014378587, 5.4778953e-05, 0.99980146]]\n",
            "1591       [[0.00018208296, 0.0005894943, 0.99922836]]\n",
            "1592         [[0.0083367415, 0.96708125, 0.024581993]]\n",
            "1593          [[0.0013172355, 0.053816073, 0.9448666]]\n",
            "1594       [[0.0003732257, 9.6371536e-05, 0.99953043]]\n",
            "1595        [[0.00010849831, 0.0006326107, 0.9992588]]\n",
            "1596         [[0.00020512074, 0.011885141, 0.9879097]]\n",
            "1597         [[0.00044298093, 0.029901193, 0.9696558]]\n",
            "1598         [[0.00048142817, 0.67605007, 0.32346845]]\n",
            "1599        [[0.00029816694, 0.9942221, 0.0054797404]]\n",
            "1600        [[0.00031170796, 0.9946989, 0.0049894117]]\n",
            "1601       [[3.0483305e-05, 0.9996455, 0.00032400992]]\n",
            "1602            [[0.00760509, 0.050529048, 0.9418658]]\n",
            "1603        [[0.00022656555, 0.97259516, 0.027178295]]\n",
            "1604       [[0.00021189377, 2.0430833e-05, 0.9997677]]\n",
            "1605        [[0.00014870778, 8.22273e-05, 0.99976903]]\n",
            "1606       [[0.00020663608, 0.00016803063, 0.9996253]]\n",
            "1607      [[0.00015888528, 0.00020373549, 0.99963737]]\n",
            "1608          [[0.96125424, 0.009412641, 0.029333057]]\n",
            "1609            [[0.65870726, 0.09491242, 0.24638024]]\n",
            "1610            [[0.06640456, 0.00097896, 0.93261653]]\n",
            "1611             [[0.001780325, 0.0855456, 0.9126741]]\n",
            "1612           [[0.0036838679, 0.14143562, 0.8548806]]\n",
            "1613       [[0.00020663608, 0.00016803063, 0.9996253]]\n",
            "1614      [[0.00019053133, 0.00021277354, 0.99959666]]\n",
            "1615        [[0.0001933274, 0.0021556464, 0.99765104]]\n",
            "1616           [[0.0006984142, 0.49803364, 0.5012679]]\n",
            "1617       [[0.00023970523, 0.0002588961, 0.99950135]]\n",
            "1618       [[0.00015392716, 0.0027374618, 0.99710864]]\n",
            "1619       [[0.00016264756, 1.3074053e-05, 0.9998242]]\n",
            "1620       [[0.0022442862, 3.2093845e-05, 0.99772364]]\n",
            "1621            [[0.42993477, 0.027958842, 0.5421064]]\n",
            "1622       [[0.00019716419, 8.4048925e-06, 0.9997944]]\n",
            "1623      [[0.00011880537, 2.4233395e-05, 0.99985695]]\n",
            "1624        [[0.00016828232, 9.500478e-06, 0.9998222]]\n",
            "1625          [[0.0011213875, 0.024865424, 0.9740132]]\n",
            "1626         [[0.000847911, 0.00013253171, 0.9990195]]\n",
            "1627       [[0.0005579926, 0.00035392193, 0.99908805]]\n",
            "1628         [[0.000976793, 4.5456578e-05, 0.9989778]]\n",
            "1629       [[0.00011720477, 1.2516466e-05, 0.9998703]]\n",
            "1630         [[0.00013500237, 7.18864e-05, 0.9997931]]\n",
            "1631       [[0.00015939165, 9.9745615e-05, 0.9997409]]\n",
            "1632      [[0.00015930412, 0.00085091003, 0.99898976]]\n",
            "1633       [[0.00012170985, 0.00031069358, 0.9995677]]\n",
            "1634         [[7.861491e-05, 0.0005092061, 0.9994122]]\n",
            "1635        [[0.0012187688, 0.00047537716, 0.9983058]]\n",
            "1636        [[0.00041661278, 0.041474395, 0.95810896]]\n",
            "1637             [[0.49608672, 0.15036903, 0.3535442]]\n",
            "1638            [[0.002674355, 0.5826993, 0.41462636]]\n",
            "1639          [[0.0003841115, 0.9804428, 0.019173121]]\n",
            "1640       [[0.00093853136, 3.8900056e-05, 0.9990225]]\n",
            "1641        [[4.5771787e-05, 3.855746e-05, 0.9999157]]\n",
            "1642          [[0.0003841115, 0.9804428, 0.019173121]]\n",
            "1643        [[0.0051831673, 0.0076870155, 0.98712987]]\n",
            "1644          [[0.0001534419, 0.0014286606, 0.998418]]\n",
            "1645          [[0.0027561593, 0.016808257, 0.9804356]]\n",
            "1646       [[0.00031596178, 0.00012307243, 0.9995609]]\n",
            "1647              [[0.00901619, 0.7028211, 0.2881628]]\n",
            "1648        [[0.00024190819, 0.0010765131, 0.9986816]]\n",
            "1649         [[0.00028176265, 0.012018006, 0.9877002]]\n",
            "1650       [[0.00016157875, 0.0010321635, 0.99880624]]\n",
            "1651          [[0.0009132796, 0.9660388, 0.033047844]]\n",
            "1652           [[0.00035043148, 0.401284, 0.59836555]]\n",
            "1653       [[0.00014847383, 8.051362e-05, 0.99977094]]\n",
            "1654       [[0.00013156836, 3.563946e-05, 0.99983275]]\n",
            "1655       [[0.00038580113, 5.7563884e-05, 0.9995566]]\n",
            "1656       [[0.00032641005, 5.4990073e-06, 0.9996681]]\n",
            "1657        [[0.0009823957, 0.0049870554, 0.99403054]]\n",
            "1658        [[0.0002883877, 2.1237429e-05, 0.9996904]]\n",
            "1659        [[0.0010280504, 6.5621796e-05, 0.9989064]]\n",
            "1660         [[0.0004458917, 2.455962e-05, 0.9995296]]\n",
            "1661        [[0.0009017063, 0.00014806475, 0.9989503]]\n",
            "1662          [[0.0012414587, 0.020788142, 0.9779703]]\n",
            "1663        [[0.0011689585, 0.0021679671, 0.99666303]]\n",
            "1664        [[0.0011689585, 0.0021679671, 0.99666303]]\n",
            "1665      [[0.00019624065, 1.0397726e-05, 0.99979335]]\n",
            "1666      [[0.00020025078, 2.3291022e-05, 0.99977654]]\n",
            "1667      [[0.00012310894, 2.9961297e-05, 0.99984694]]\n",
            "1668         [[0.0005012279, 0.000299887, 0.99919885]]\n",
            "1669          [[0.0010259559, 0.9490509, 0.049923155]]\n",
            "1670       [[0.00042630354, 7.1438676e-06, 0.9995665]]\n",
            "1671         [[0.000553576, 4.8272224e-05, 0.9993981]]\n",
            "1672           [[0.001579211, 0.034382593, 0.9640382]]\n",
            "1673          [[0.0011252126, 0.107701994, 0.8911727]]\n",
            "1674           [[0.0014124829, 0.12977667, 0.8688108]]\n",
            "1675            [[0.69954455, 0.16661434, 0.13384117]]\n",
            "1676        [[0.00042520676, 0.99421906, 0.005355681]]\n",
            "1677           [[0.03957068, 0.013892133, 0.94653714]]\n",
            "1678         [[0.006258657, 0.99262017, 0.0011211864]]\n",
            "1679            [[0.15650475, 0.7421088, 0.101386465]]\n",
            "1680       [[0.00020992315, 9.8920864e-05, 0.9996911]]\n",
            "1681         [[0.00020070035, 0.0007153739, 0.999084]]\n",
            "1682       [[0.00027818643, 3.688639e-05, 0.99968493]]\n",
            "1683       [[0.0003338042, 1.3918977e-05, 0.99965227]]\n",
            "1684       [[0.0003298052, 1.1226926e-05, 0.99965894]]\n",
            "1685          [[0.997092, 0.0018619747, 0.0010460311]]\n",
            "1686            [[0.061010834, 0.07172445, 0.8672647]]\n",
            "1687           [[0.003901168, 0.03406605, 0.96203274]]\n",
            "1688          [[0.008646824, 0.004373846, 0.98697925]]\n",
            "1689         [[0.004033896, 0.0030336517, 0.99293244]]\n",
            "1690        [[0.0006077669, 1.8837465e-05, 0.9993734]]\n",
            "1691             [[0.0026312813, 0.793198, 0.2041708]]\n",
            "1692             [[0.10774947, 0.872825, 0.019425517]]\n",
            "1693       [[0.0001740672, 0.00023618634, 0.99958974]]\n",
            "1694             [[0.01008455, 0.02377703, 0.9661384]]\n",
            "1695      [[0.00041091864, 1.9035833e-05, 0.99956995]]\n",
            "1696      [[0.00010172564, 1.0367776e-05, 0.99988794]]\n",
            "1697         [[0.0011377624, 0.081373684, 0.91748846]]\n",
            "1698         [[0.00034858883, 0.9622741, 0.037377346]]\n",
            "1699        [[7.309764e-05, 1.7018749e-05, 0.9999099]]\n",
            "1700        [[0.00012720145, 0.0006750762, 0.9991978]]\n",
            "1701          [[9.48886e-05, 0.0013413826, 0.9985637]]\n",
            "1702       [[0.00012661667, 0.99257725, 0.0072960868]]\n",
            "1703        [[2.3889488e-05, 0.999257, 0.00071905926]]\n",
            "1704            [[0.00038872156, 0.711452, 0.2881593]]\n",
            "1705       [[4.4626122e-05, 1.0046477e-05, 0.9999454]]\n",
            "1706         [[0.00091753725, 0.03639811, 0.96268433]]\n",
            "1707           [[0.001177422, 0.096791126, 0.9020314]]\n",
            "1708        [[0.00019434218, 0.98815244, 0.011653184]]\n",
            "1709             [[0.2356331, 0.30026937, 0.46409747]]\n",
            "1710          [[0.032907546, 0.9626765, 0.0044159023]]\n",
            "1711           [[0.73861706, 0.049902894, 0.21148004]]\n",
            "1712              [[0.3315225, 0.6531671, 0.01531034]]\n",
            "1713           [[0.0015326106, 0.03330391, 0.9651634]]\n",
            "1714             [[0.0011231267, 0.831209, 0.1676678]]\n",
            "1715           [[0.8908114, 0.0062627085, 0.10292582]]\n",
            "1716      [[0.00013131606, 0.00010997449, 0.99975866]]\n",
            "1717            [[0.076073796, 0.7759746, 0.14795163]]\n",
            "1718        [[0.0005234376, 6.334785e-05, 0.99941325]]\n",
            "1719         [[0.0020574613, 0.0018898494, 0.9960526]]\n",
            "1720        [[0.99862266, 0.0003351901, 0.0010421438]]\n",
            "1721         [[0.0015816693, 0.002046686, 0.99637175]]\n",
            "1722        [[0.00045946366, 0.0028264464, 0.9967141]]\n",
            "1723        [[0.0001867724, 4.8612957e-05, 0.9997646]]\n",
            "1724          [[0.0020459304, 0.42199868, 0.57595545]]\n",
            "1725        [[0.00013813138, 4.967483e-05, 0.9998122]]\n",
            "1726          [[0.0022511675, 0.008299392, 0.9894493]]\n",
            "1727      [[0.00023795996, 3.3266766e-05, 0.99972874]]\n",
            "1728           [[0.9826462, 0.006002592, 0.011351131]]\n",
            "1729          [[0.01957896, 0.0113880485, 0.96903294]]\n",
            "1730       [[0.00017751365, 4.281519e-05, 0.99977976]]\n",
            "1731      [[0.00010767576, 2.5925443e-05, 0.99986637]]\n",
            "1732        [[0.0010520531, 5.8462892e-06, 0.9989421]]\n",
            "1733           [[0.050744854, 0.9244577, 0.024797425]]\n",
            "1734         [[0.0012246027, 0.0032725655, 0.9955029]]\n",
            "1735           [[0.09041436, 0.90722847, 0.002357229]]\n",
            "1736        [[0.00025034507, 0.0088935895, 0.9908562]]\n",
            "1737        [[0.00015670744, 7.823582e-06, 0.9998354]]\n",
            "1738        [[0.00018458856, 7.645228e-06, 0.9998078]]\n",
            "1739        [[7.1312454e-05, 4.834312e-05, 0.9998803]]\n",
            "1740        [[0.00011435688, 0.009060849, 0.99082476]]\n",
            "1741            [[0.01143866, 0.9654118, 0.023149543]]\n",
            "1742         [[0.0025765833, 0.98988605, 0.007537424]]\n",
            "1743           [[0.013909198, 0.93755215, 0.04853863]]\n",
            "1744         [[0.00018044976, 0.003946323, 0.9958733]]\n",
            "1745        [[0.0003126427, 1.6264754e-05, 0.9996712]]\n",
            "1746      [[0.00044498665, 6.8249083e-06, 0.99954814]]\n",
            "1747       [[0.00042091263, 5.725992e-05, 0.99952173]]\n",
            "1748          [[0.0021225445, 0.002730203, 0.9951473]]\n",
            "1749          [[0.0009686615, 0.000504665, 0.9985266]]\n",
            "1750        [[0.00015716064, 6.639006e-05, 0.9997764]]\n",
            "1751      [[0.00010102728, 0.00028799815, 0.99961096]]\n",
            "1752         [[0.000750993, 1.1145436e-05, 0.9992378]]\n",
            "1753         [[0.016674183, 0.0030950583, 0.98023075]]\n",
            "1754            [[0.06513768, 0.9241126, 0.010749767]]\n",
            "1755           [[0.48762062, 0.47069353, 0.041685894]]\n",
            "1756         [[0.0007467242, 0.00018827981, 0.999065]]\n",
            "1757          [[0.001364789, 0.0035559114, 0.9950793]]\n",
            "1758         [[0.014717467, 2.4740137e-05, 0.9852578]]\n",
            "1759           [[0.022605421, 0.81166583, 0.16572875]]\n",
            "1760           [[0.0006876526, 0.19824296, 0.8010694]]\n",
            "1761         [[0.00045199264, 0.04843895, 0.95110905]]\n",
            "1762            [[0.016606746, 0.069115244, 0.914278]]\n",
            "1763          [[0.027092863, 0.002081162, 0.97082597]]\n",
            "1764        [[0.00013246572, 0.00035650353, 0.999511]]\n",
            "1765       [[0.000110976864, 0.0049013896, 0.9949876]]\n",
            "1766         [[0.00052394095, 0.13095778, 0.86851835]]\n",
            "1767           [[0.004355617, 0.32122496, 0.67441946]]\n",
            "1768        [[0.000520567, 2.3154797e-05, 0.99945635]]\n",
            "1769       [[9.699502e-05, 2.9366078e-05, 0.99987364]]\n",
            "1770       [[4.8348258e-05, 2.2178976e-05, 0.9999294]]\n",
            "1771         [[8.294429e-05, 0.99088013, 0.009036912]]\n",
            "1772         [[0.00070373184, 0.009811053, 0.9894852]]\n",
            "1773          [[0.9813752, 0.0014689151, 0.017155843]]\n",
            "1774         [[0.0003191988, 0.011625603, 0.98805517]]\n",
            "1775     [[0.000101951155, 0.00037252618, 0.99952555]]\n",
            "1776        [[0.0002741723, 0.0007994342, 0.99892646]]\n",
            "1777          [[0.00085426425, 0.6164265, 0.38271928]]\n",
            "1778         [[0.0001264753, 0.0010569822, 0.9988166]]\n",
            "1779           [[0.0023092257, 0.05781744, 0.9398734]]\n",
            "1780          [[0.00021239957, 0.997133, 0.002654606]]\n",
            "1781         [[0.0008406643, 0.9909671, 0.0081921965]]\n",
            "1782          [[0.0024273114, 0.010200832, 0.9873719]]\n",
            "1783        [[0.0004745764, 0.00062006264, 0.9989054]]\n",
            "1784          [[0.00066414, 0.0016878064, 0.99764806]]\n",
            "1785           [[0.0018286603, 0.8569112, 0.14126015]]\n",
            "1786        [[0.00014246996, 0.0015364614, 0.9983211]]\n",
            "1787         [[0.00019672724, 0.0005572722, 0.999246]]\n",
            "1788         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1789         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1790         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1791         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1792         [[0.0003580772, 0.0020136188, 0.9976283]]\n",
            "1793            [[0.002661935, 0.5815063, 0.41583177]]\n",
            "1794           [[0.0005419066, 0.8081762, 0.19128188]]\n",
            "1795         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1796          [[0.0009606096, 0.016101865, 0.9829375]]\n",
            "1797         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1798         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1799         [[0.0025442664, 0.062490664, 0.93496513]]\n",
            "1800          [[0.0001066804, 0.000132108, 0.9997613]]\n",
            "1801         [[0.0002661086, 1.0874842e-05, 0.999723]]\n",
            "1802          [[0.0030259516, 0.61877793, 0.37819615]]\n",
            "1803          [[0.0005814815, 0.017136592, 0.9822819]]\n",
            "1804         [[0.0004716431, 0.97345644, 0.026071977]]\n",
            "1805          [[0.00075515674, 0.6555681, 0.34367666]]\n",
            "1806           [[0.0006285862, 0.9221811, 0.07719027]]\n",
            "1807           [[0.0004244541, 0.8899936, 0.10958195]]\n",
            "1808           [[0.0006279493, 0.6376289, 0.36174312]]\n",
            "1809       [[0.00017668918, 1.9182675e-05, 0.9998042]]\n",
            "1810       [[0.00019529203, 2.4761679e-05, 0.9997799]]\n",
            "1811        [[0.0005641964, 0.9993899, 4.5960292e-05]]\n",
            "1812          [[0.0014960334, 0.01161846, 0.98688555]]\n",
            "1813       [[0.00035897287, 1.5708376e-05, 0.9996253]]\n",
            "1814           [[0.0011519648, 0.06592475, 0.9329234]]\n",
            "1815         [[0.014707306, 6.0792216e-05, 0.9852319]]\n",
            "1816        [[0.0010207805, 2.3677812e-05, 0.9989555]]\n",
            "1817          [[0.0010444861, 1.93513e-05, 0.9989361]]\n",
            "1818         [[0.98308045, 0.0054217386, 0.011497699]]\n",
            "1819             [[0.951281, 0.01858147, 0.030137457]]\n",
            "1820        [[0.0010597978, 3.6002206e-05, 0.9989042]]\n",
            "1821      [[0.00061245984, 0.00013897687, 0.99924845]]\n",
            "1822            [[0.038057983, 0.01042071, 0.9515213]]\n",
            "1823          [[0.0025126874, 0.02869931, 0.96878797]]\n",
            "1824           [[0.8704307, 0.0026765128, 0.12689285]]\n",
            "1825         [[0.00043170532, 0.025170902, 0.9743973]]\n",
            "1826           [[0.005264288, 0.054114994, 0.9406207]]\n",
            "1827           [[0.002848877, 0.117569834, 0.8795813]]\n",
            "1828         [[0.00085257454, 0.9872572, 0.011890233]]\n",
            "1829        [[0.0031157492, 0.00026092003, 0.9966234]]\n",
            "1830          [[0.0024591999, 0.08907031, 0.90847045]]\n",
            "1831       [[0.00023127963, 2.5764115e-05, 0.9997429]]\n",
            "1832       [[0.00021343617, 0.00040473804, 0.9993818]]\n",
            "1833        [[0.00033045854, 0.013040774, 0.98662865]]\n",
            "1834            [[0.001950778, 0.40359837, 0.5944509]]\n",
            "1835        [[0.00064801803, 5.137374e-05, 0.9993006]]\n",
            "1836          [[0.073619075, 0.0027336413, 0.9236473]]\n",
            "1837        [[0.0010670508, 0.00013451224, 0.9987984]]\n",
            "1838           [[0.0011845424, 0.38881072, 0.6100047]]\n",
            "1839           [[0.014850345, 0.98494, 0.00020968112]]\n",
            "1840      [[0.00029304123, 1.6460799e-05, 0.99969053]]\n",
            "1841        [[0.00036369442, 0.0010948852, 0.9985415]]\n",
            "1842        [[0.00020804274, 1.9883246e-05, 0.999772]]\n",
            "1843         [[0.00015525521, 3.85087e-05, 0.9998062]]\n",
            "1844         [[8.708797e-05, 0.00011995409, 0.999793]]\n",
            "1845      [[0.00058265985, 2.0858159e-05, 0.99939644]]\n",
            "1846       [[0.00051069073, 2.053545e-05, 0.99946886]]\n",
            "1847       [[0.0004851163, 0.00042506505, 0.99908984]]\n",
            "1848          [[0.004416209, 0.0065134615, 0.9890703]]\n",
            "1849          [[0.00059629086, 0.02223342, 0.9771703]]\n",
            "1850         [[0.0019378588, 0.0037258035, 0.9943363]]\n",
            "1851        [[0.0005382679, 0.00022024555, 0.9992415]]\n",
            "1852       [[0.0005537303, 0.00049523934, 0.99895096]]\n",
            "1853         [[0.000951803, 1.2479688e-05, 0.9990357]]\n",
            "1854          [[0.002244573, 0.0050307275, 0.9927247]]\n",
            "1855           [[0.7811134, 0.21641898, 0.0024676009]]\n",
            "1856          [[0.9263347, 0.00033895142, 0.07332646]]\n",
            "1857       [[0.00020913228, 1.0937285e-05, 0.9997799]]\n",
            "1858        [[0.000111896945, 3.81943e-05, 0.9998499]]\n",
            "1859       [[7.0119924e-05, 0.00011762458, 0.9998123]]\n",
            "1860        [[0.00018669422, 8.682291e-06, 0.9998047]]\n",
            "1861         [[0.0002598446, 0.003667641, 0.99607253]]\n",
            "1862          [[0.00045087322, 0.13272429, 0.8668249]]\n",
            "1863        [[0.00011050572, 1.5479447e-05, 0.999874]]\n",
            "1864       [[6.149842e-05, 1.8964181e-05, 0.99991953]]\n",
            "1865       [[0.00022060757, 0.0007075052, 0.99907196]]\n",
            "1866           [[9.07039e-05, 0.9887217, 0.011187557]]\n",
            "1867         [[9.095475e-05, 0.005389374, 0.99451977]]\n",
            "1868          [[0.00091207563, 0.6099482, 0.38913965]]\n",
            "1869            [[0.001581605, 0.78819484, 0.2102235]]\n",
            "1870         [[6.980483e-05, 0.9988445, 0.0010856794]]\n",
            "1871        [[0.00036495086, 0.0001715135, 0.9994635]]\n",
            "1872      [[0.00013632048, 0.00017245297, 0.99969125]]\n",
            "1873       [[8.401946e-05, 0.000119790995, 0.9997962]]\n",
            "1874       [[8.271397e-05, 1.0150108e-05, 0.99990714]]\n",
            "1875        [[8.350178e-05, 0.00019147318, 0.9997249]]\n",
            "1876        [[0.00025900203, 0.96541214, 0.034328848]]\n",
            "1877     [[0.00012211605, 0.000113005255, 0.99976486]]\n",
            "1878      [[8.8798944e-05, 0.00030404198, 0.99960726]]\n",
            "1879       [[0.00013150957, 2.8773806e-05, 0.9998398]]\n",
            "1880        [[0.0002076096, 0.00068210013, 0.9991103]]\n",
            "1881        [[0.000222156, 0.000109158704, 0.9996687]]\n",
            "1882        [[9.476871e-05, 0.00015018122, 0.9997551]]\n",
            "1883       [[0.00021507835, 3.9033766e-05, 0.9997458]]\n",
            "1884       [[0.00027833646, 0.00018697644, 0.9995347]]\n",
            "1885        [[0.00031992432, 5.562267e-05, 0.9996244]]\n",
            "1886           [[0.12483695, 0.86156774, 0.013595311]]\n",
            "1887          [[0.0032162645, 0.51879543, 0.47798827]]\n",
            "1888       [[0.0006055348, 5.2312735e-05, 0.99934214]]\n",
            "1889           [[0.93730587, 0.05858145, 0.004112792]]\n",
            "1890           [[0.77648616, 0.15191637, 0.071597524]]\n",
            "1891       [[0.00028003505, 1.598012e-05, 0.99970394]]\n",
            "1892        [[0.0009929393, 0.00036155208, 0.9986455]]\n",
            "1893          [[0.027479818, 0.013229053, 0.95929104]]\n",
            "1894       [[0.00017699994, 0.00040145434, 0.9994215]]\n",
            "1895         [[0.0012373952, 0.0021763176, 0.9965862]]\n",
            "1896       [[0.00027184337, 1.4431085e-05, 0.9997137]]\n",
            "1897        [[0.00093645666, 0.92791885, 0.071144685]]\n",
            "1898           [[0.02540076, 0.9734187, 0.0011805625]]\n",
            "1899         [[0.0022243327, 0.997603, 0.00017268096]]\n",
            "1900           [[0.002015362, 0.9933669, 0.004617722]]\n",
            "1901        [[0.0004779743, 2.5722655e-05, 0.9994962]]\n",
            "1902       [[0.00016040083, 8.4329884e-05, 0.9997552]]\n",
            "1903             [[0.17030449, 0.09419964, 0.7354958]]\n",
            "1904           [[0.18087333, 0.78881043, 0.030316168]]\n",
            "1905            [[0.8710105, 0.12038693, 0.008602568]]\n",
            "1906          [[0.006485394, 0.9907783, 0.0027362474]]\n",
            "1907      [[0.00011468231, 0.00023010264, 0.99965525]]\n",
            "1908          [[9.14167e-05, 5.959435e-06, 0.9999026]]\n",
            "1909            [[0.012498594, 0.16176684, 0.8257345]]\n",
            "1910      [[0.00018891855, 7.1005065e-06, 0.99980396]]\n",
            "1911      [[0.00018652558, 1.3344824e-05, 0.99980015]]\n",
            "1912            [[0.000524294, 0.4844978, 0.51497793]]\n",
            "1913        [[0.00040866257, 3.170929e-05, 0.9995596]]\n",
            "1914        [[0.00017369565, 1.0369609e-05, 0.999816]]\n",
            "1915       [[0.00012149619, 1.0865281e-05, 0.9998677]]\n",
            "1916        [[0.0003111224, 2.9492834e-05, 0.9996594]]\n",
            "1917          [[7.431044e-05, 0.9908433, 0.009082387]]\n",
            "1918        [[7.648194e-05, 0.00065310946, 0.9992704]]\n",
            "1919      [[0.00014303518, 1.2369997e-05, 0.99984455]]\n",
            "1920           [[0.0003431318, 0.09288302, 0.9067739]]\n",
            "1921        [[0.00075267896, 0.016394593, 0.98285276]]\n",
            "1922       [[7.8015204e-05, 0.00021768096, 0.9997042]]\n",
            "1923         [[5.532891e-05, 0.002591843, 0.99735284]]\n",
            "1924      [[9.640168e-05, 0.000117760865, 0.99978584]]\n",
            "1925        [[0.0002730057, 1.246361e-05, 0.99971443]]\n",
            "1926      [[0.00028707107, 1.8012335e-05, 0.99969494]]\n",
            "1927      [[0.00014917404, 1.3574739e-05, 0.99983716]]\n",
            "1928            [[0.0013729011, 0.1331359, 0.8654912]]\n",
            "1929        [[0.00011041234, 0.00094064866, 0.998949]]\n",
            "1930       [[0.00028615084, 0.00031697005, 0.9993968]]\n",
            "1931       [[0.00018873117, 0.0005694141, 0.99924195]]\n",
            "1932        [[0.00011041234, 0.00094064866, 0.998949]]\n",
            "1933           [[0.9258487, 0.026018856, 0.048132364]]\n",
            "1934          [[0.9903752, 0.00053382904, 0.00909085]]\n",
            "1935             [[0.8697491, 0.10913734, 0.02111353]]\n",
            "1936           [[0.96358025, 0.025414318, 0.01100535]]\n",
            "1937       [[0.0009535326, 2.0536962e-05, 0.99902594]]\n",
            "1938             [[0.16382109, 0.22516705, 0.6110119]]\n",
            "1939       [[0.00032303936, 5.4153215e-06, 0.9996716]]\n",
            "1940      [[0.00011008076, 0.00017147383, 0.99971837]]\n",
            "1941        [[0.0009822834, 0.0038432502, 0.99517447]]\n",
            "1942      [[0.000100679135, 0.00083228236, 0.9990671]]\n",
            "1943          [[0.00025640219, 0.04439214, 0.9553515]]\n",
            "1944      [[0.00037542722, 0.000109891465, 0.9995147]]\n",
            "1945           [[0.02539625, 0.0066586095, 0.9679452]]\n",
            "1946       [[0.00039600694, 1.116196e-05, 0.99959284]]\n",
            "1947          [[0.0011414186, 0.008610088, 0.9902485]]\n",
            "1948            [[0.024991857, 0.03330802, 0.9417001]]\n",
            "1949            [[0.000623947, 0.60522825, 0.3941478]]\n",
            "1950       [[0.00018634748, 2.1709331e-05, 0.9997919]]\n",
            "1951       [[0.00015833156, 0.00022401872, 0.9996176]]\n",
            "1952            [[0.010753004, 0.031664025, 0.957583]]\n",
            "1953       [[0.00024540685, 2.4213072e-05, 0.9997304]]\n",
            "1954       [[7.2419076e-05, 0.00017720278, 0.9997503]]\n",
            "1955       [[5.485528e-05, 0.00025894004, 0.99968624]]\n",
            "1956         [[7.3021125e-05, 0.005597272, 0.9943297]]\n",
            "1957          [[0.0004770507, 0.01524109, 0.98428184]]\n",
            "1958           [[0.0007972832, 0.9601355, 0.03906715]]\n",
            "1959            [[0.5514497, 0.43893212, 0.009618199]]\n",
            "1960        [[0.000115718416, 0.999801, 8.330109e-05]]\n",
            "1961         [[4.154834e-05, 0.9967861, 0.0031723685]]\n",
            "1962           [[0.0004252573, 0.15341988, 0.8461548]]\n",
            "1963          [[0.0006862506, 0.024846943, 0.9744667]]\n",
            "1964       [[0.00032349222, 0.00017465682, 0.9995018]]\n",
            "1965       [[0.00032349222, 0.00017465682, 0.9995018]]\n",
            "1966        [[0.00034812154, 0.033199273, 0.96645254]]\n",
            "1967         [[0.00013254766, 0.016956944, 0.9829106]]\n",
            "1968          [[0.00048548987, 0.41643214, 0.5830823]]\n",
            "1969        [[0.0047152736, 0.99376386, 0.0015208601]]\n",
            "1970          [[0.0009399209, 0.16886546, 0.83019465]]\n",
            "1971        [[0.0007496649, 8.339505e-06, 0.99924207]]\n",
            "1972       [[0.00059796945, 1.0838458e-05, 0.9993912]]\n",
            "1973        [[0.0008370749, 0.00015042473, 0.9990125]]\n",
            "1974        [[0.00022710265, 2.5825671e-05, 0.999747]]\n",
            "1975          [[0.0018573016, 0.03993515, 0.95820755]]\n",
            "1976       [[0.00085510645, 9.550374e-05, 0.99904937]]\n",
            "1977            [[0.0006409875, 0.0853127, 0.9140462]]\n",
            "1978        [[0.0004637046, 0.0012253079, 0.99831104]]\n",
            "1979          [[0.00021865097, 0.9576746, 0.04210676]]\n",
            "1980          [[0.001428809, 0.0019256342, 0.9966455]]\n",
            "1981         [[0.0023287663, 0.008009193, 0.98966205]]\n",
            "1982       [[0.00040057953, 0.00074301445, 0.9988564]]\n",
            "1983        [[0.00013790547, 3.784687e-05, 0.9998242]]\n",
            "1984        [[0.00059767824, 6.120274e-06, 0.9993962]]\n",
            "1985       [[0.00030516938, 5.821244e-05, 0.99963665]]\n",
            "1986       [[0.00042460175, 0.00026985057, 0.9993056]]\n",
            "1987      [[0.00011908522, 6.7773035e-05, 0.99981314]]\n",
            "1988          [[0.0013206932, 0.076012775, 0.9226666]]\n",
            "1989            [[0.46652767, 0.12142264, 0.41204965]]\n",
            "1990            [[0.000274112, 0.9301714, 0.06955455]]\n",
            "1991           [[0.0044644163, 0.44154802, 0.5539876]]\n",
            "1992           [[0.000401897, 0.37699455, 0.62260354]]\n",
            "1993      [[0.00013984829, 1.5727981e-05, 0.99984443]]\n",
            "1994        [[0.0005623283, 0.00081424654, 0.9986234]]\n",
            "1995             [[0.002450543, 0.11841144, 0.879138]]\n",
            "1996          [[0.0002168861, 0.9609809, 0.038802255]]\n",
            "1997          [[0.00033730108, 0.09197963, 0.9076831]]\n",
            "1998           [[0.0034908256, 0.9062076, 0.09030151]]\n",
            "1999           [[0.0002055757, 0.00307028, 0.9967242]]\n",
            "2000         [[0.00021244757, 0.007112117, 0.9926755]]\n",
            "2001      [[0.00030641284, 0.00049555936, 0.99919814]]\n",
            "2002             [[0.00335545, 0.8086072, 0.18803735]]\n",
            "2003        [[0.00053104357, 0.9952199, 0.0042490056]]\n",
            "2004        [[0.00044263958, 0.98793715, 0.011620236]]\n",
            "2005       [[6.411271e-05, 0.99971706, 0.00021881999]]\n",
            "2006       [[2.7106293e-05, 0.9995733, 0.00039964725]]\n",
            "2007       [[0.00042869238, 0.00016649114, 0.9994049]]\n",
            "2008         [[0.00018228668, 0.9922464, 0.007571287]]\n",
            "2009           [[0.0033553834, 0.19370103, 0.8029436]]\n",
            "2010          [[0.9051006, 0.0023048772, 0.092594475]]\n",
            "2011           [[0.017810445, 0.93056107, 0.05162843]]\n",
            "2012        [[0.00031954393, 1.4485465e-05, 0.999666]]\n",
            "2013        [[0.00028876684, 0.025185725, 0.97452545]]\n",
            "2014       [[0.00048784056, 3.4545632e-05, 0.9994777]]\n",
            "2015            [[0.64183867, 0.09919242, 0.25896895]]\n",
            "2016        [[0.0007678203, 2.1679045e-05, 0.9992105]]\n",
            "2017         [[0.0002352977, 0.99108034, 0.008684398]]\n",
            "2018            [[0.07900443, 0.73836845, 0.18262708]]\n",
            "2019         [[0.0014133577, 0.011487427, 0.98709923]]\n",
            "2020      [[0.00024058415, 0.00025741814, 0.99950206]]\n",
            "2021          [[0.0009275404, 0.002188118, 0.9968843]]\n",
            "2022        [[0.013194572, 0.00065494067, 0.98615044]]\n",
            "2023         [[0.0012648834, 7.746476e-05, 0.9986576]]\n",
            "2024         [[0.00024260537, 0.004106865, 0.9956506]]\n",
            "2025         [[0.00014797057, 0.0070950864, 0.992757]]\n",
            "2026         [[0.0017583382, 0.0022756017, 0.9959661]]\n",
            "2027       [[0.00029428245, 0.00026692648, 0.9994388]]\n",
            "2028       [[0.00023360697, 0.0016935334, 0.99807286]]\n",
            "2029          [[0.00036738976, 0.7208512, 0.27878144]]\n",
            "2030       [[0.00075033365, 0.0013773459, 0.99787223]]\n",
            "2031       [[0.0017053277, 0.00042040626, 0.99787426]]\n",
            "2032          [[0.0002780036, 0.007960881, 0.9917612]]\n",
            "2033        [[0.00023073735, 0.0017434811, 0.9980259]]\n",
            "2034       [[0.00030964598, 0.00013738676, 0.9995529]]\n",
            "2035           [[0.00078084617, 0.9388227, 0.0603964]]\n",
            "2036       [[5.637293e-05, 0.99970454, 0.00023901634]]\n",
            "2037         [[5.151551e-05, 0.9995739, 0.0003745761]]\n",
            "2038      [[2.9854038e-05, 0.99958044, 0.00038969197]]\n",
            "2039      [[4.8716152e-05, 0.99950767, 0.00044363903]]\n",
            "2040           [[0.004555988, 0.85504293, 0.14040108]]\n",
            "2041         [[0.0004877402, 3.436757e-05, 0.9994779]]\n",
            "2042        [[0.00020226624, 0.012902906, 0.98689485]]\n",
            "2043        [[7.506891e-05, 0.00012560913, 0.9997993]]\n",
            "2044        [[0.00021338454, 0.95297235, 0.046814207]]\n",
            "2045          [[7.513175e-05, 0.9968521, 0.003072776]]\n",
            "2046      [[0.000108546665, 0.99798006, 0.0019113688]]\n",
            "2047        [[0.00032224078, 0.9955745, 0.0041033155]]\n",
            "2048          [[0.98082924, 0.015119517, 0.004051218]]\n",
            "2049          [[0.98737156, 0.004417534, 0.008210902]]\n",
            "2050         [[0.0006030643, 3.210886e-05, 0.9993648]]\n",
            "2051         [[0.00011522759, 0.016099447, 0.9837853]]\n",
            "2052        [[0.00025790714, 0.026215302, 0.97352684]]\n",
            "2053          [[6.5632856e-05, 0.009650367, 0.990284]]\n",
            "2054          [[0.0007207046, 0.85687804, 0.14240122]]\n",
            "2055     [[0.000107157786, 1.05903855e-05, 0.9998822]]\n",
            "2056         [[0.00020210087, 0.005741784, 0.9940561]]\n",
            "2057        [[0.00012094822, 0.0001858095, 0.9996933]]\n",
            "2058         [[0.0003611906, 0.002070284, 0.99756855]]\n",
            "2059          [[0.00015662494, 0.9306602, 0.06918322]]\n",
            "2060        [[0.00044122114, 0.0008767385, 0.9986821]]\n",
            "2061       [[0.00021277992, 9.667089e-05, 0.99969065]]\n",
            "2062       [[0.00027917617, 3.8606802e-05, 0.9996822]]\n",
            "2063       [[0.00044139184, 1.5179415e-05, 0.9995435]]\n",
            "2064       [[0.00032639795, 4.3442844e-05, 0.9996301]]\n",
            "2065      [[0.00030946766, 0.00012429853, 0.99956626]]\n",
            "2066          [[0.060989305, 0.93614227, 0.002868481]]\n",
            "2067           [[0.95162237, 0.0457114, 0.0026662487]]\n",
            "2068        [[0.0036144578, 0.0007078466, 0.99567765]]\n",
            "2069         [[0.0005097465, 0.0125645595, 0.9869257]]\n",
            "2070       [[0.00034276955, 0.0017088952, 0.99794835]]\n",
            "2071        [[0.9985097, 0.00027719798, 0.0012130927]]\n",
            "2072        [[0.00024078687, 6.163212e-05, 0.9996977]]\n",
            "2073         [[0.0004045678, 0.011020949, 0.98857445]]\n",
            "2074             [[0.18135715, 0.11319776, 0.7054451]]\n",
            "2075        [[0.006400347, 0.00071807037, 0.99288154]]\n",
            "2076           [[0.9899939, 0.000659323, 0.009346793]]\n",
            "2077          [[0.9970599, 0.002483898, 0.0004561528]]\n",
            "2078             [[0.008520084, 0.4259444, 0.5655355]]\n",
            "2079         [[0.00014770491, 0.0008253185, 0.999027]]\n",
            "2080       [[6.587552e-05, 0.00013708862, 0.99979705]]\n",
            "2081         [[5.20857e-05, 0.0024651245, 0.99748284]]\n",
            "2082        [[6.94721e-05, 0.00010066169, 0.99982977]]\n",
            "2083        [[0.00023737137, 0.042283636, 0.95747894]]\n",
            "2084         [[6.401143e-05, 0.0014725396, 0.9984634]]\n",
            "2085          [[0.0005520539, 0.003736243, 0.9957117]]\n",
            "2086        [[0.00039354997, 0.00018852875, 0.999418]]\n",
            "2087       [[0.0002392275, 1.3289485e-05, 0.99974746]]\n",
            "2088         [[0.9926925, 0.0041722176, 0.0031352686]]\n",
            "2089            [[0.0008550402, 0.523679, 0.47546595]]\n",
            "2090        [[0.0021477765, 0.0052502383, 0.99260205]]\n",
            "2091       [[0.00026853522, 0.00035019472, 0.9993813]]\n",
            "2092          [[0.0005454785, 0.012048764, 0.9874057]]\n",
            "2093         [[0.0004676682, 0.015547628, 0.98398465]]\n",
            "2094       [[0.00048349096, 2.6017875e-05, 0.9994905]]\n",
            "2095           [[0.0014112998, 0.37258223, 0.6260065]]\n",
            "2096        [[0.00014909648, 0.9967456, 0.0031052956]]\n",
            "2097          [[0.00021773482, 0.9784846, 0.02129764]]\n",
            "2098         [[0.0004676682, 0.015547628, 0.98398465]]\n",
            "2099        [[0.00032684868, 0.005089493, 0.99458367]]\n",
            "2100        [[0.00014047862, 0.0005559514, 0.9993036]]\n",
            "2101       [[0.00016192498, 2.0171456e-05, 0.9998179]]\n",
            "2102        [[0.0002380663, 1.6403219e-05, 0.9997454]]\n",
            "2103         [[0.0005517157, 0.045370847, 0.95407736]]\n",
            "2104      [[0.00042685325, 5.9335565e-05, 0.99951386]]\n",
            "2105       [[3.734848e-05, 3.2568158e-05, 0.99993014]]\n",
            "2106        [[8.5596526e-05, 0.0003960575, 0.9995184]]\n",
            "2107         [[0.9840397, 0.00013152392, 0.015828725]]\n",
            "2108          [[0.9613654, 0.00010191673, 0.03853279]]\n",
            "2109       [[5.1213992e-05, 0.99919134, 0.0007574928]]\n",
            "2110            [[0.021174062, 0.02983955, 0.9489864]]\n",
            "2111            [[0.00068522635, 0.360802, 0.6385128]]\n",
            "2112          [[0.0002458518, 0.020441793, 0.9793123]]\n",
            "2113           [[0.0015032756, 0.08686377, 0.9116329]]\n",
            "2114            [[0.010220732, 0.02259977, 0.9671795]]\n",
            "2115         [[0.00020309731, 0.022021402, 0.9777755]]\n",
            "2116           [[0.0001988944, 0.05859635, 0.9412048]]\n",
            "2117      [[0.00028218463, 0.00022134568, 0.99949646]]\n",
            "2118        [[6.5681015e-05, 0.005402534, 0.99453175]]\n",
            "2119         [[0.00030216257, 0.04528067, 0.95441717]]\n",
            "2120       [[0.00021375273, 9.363277e-05, 0.99969256]]\n",
            "2121         [[0.00022986058, 0.001145401, 0.9986247]]\n",
            "2122       [[0.00024478926, 0.00018977537, 0.9995654]]\n",
            "2123        [[0.00041994036, 0.0029366384, 0.9966434]]\n",
            "2124       [[0.000117394295, 0.0003810773, 0.9995016]]\n",
            "2125         [[0.0018520359, 0.010692207, 0.98745584]]\n",
            "2126      [[7.8807774e-05, 0.00081171456, 0.99910945]]\n",
            "2127        [[0.0001059574, 4.1797543e-05, 0.9998522]]\n",
            "2128      [[0.00015347722, 0.00024687388, 0.99959964]]\n",
            "2129       [[0.00044316798, 1.3851357e-05, 0.9995431]]\n",
            "2130           [[0.9581346, 0.028419156, 0.013446253]]\n",
            "2131          [[0.8918641, 0.101443395, 0.0066924836]]\n",
            "2132      [[0.00012390438, 0.00040243688, 0.99947363]]\n",
            "2133        [[0.00010663229, 0.00018736122, 0.999706]]\n",
            "2134       [[0.00018779187, 0.00021350692, 0.9995987]]\n",
            "2135      [[0.00012390438, 0.00040243688, 0.99947363]]\n",
            "2136         [[0.0023705442, 0.023997048, 0.97363245]]\n",
            "2137         [[0.00040451495, 0.051999804, 0.9475957]]\n",
            "2138        [[0.0016872903, 1.0065752e-05, 0.9983026]]\n",
            "2139       [[0.0014139668, 3.7615217e-05, 0.99854845]]\n",
            "2140             [[0.18490683, 0.26827765, 0.5468155]]\n",
            "2141         [[0.00091559446, 0.62117606, 0.37790835]]\n",
            "2142         [[0.00078298344, 0.8907796, 0.108437434]]\n",
            "2143         [[0.00030837944, 0.076669976, 0.9230216]]\n",
            "2144        [[0.000116044954, 1.34692e-05, 0.9998704]]\n",
            "2145       [[0.0011413586, 0.00028943483, 0.99856925]]\n",
            "2146         [[0.0003049979, 4.446969e-05, 0.9996506]]\n",
            "2147             [[0.13469654, 0.13354994, 0.7317535]]\n",
            "2148           [[0.0005191092, 0.00490432, 0.9945766]]\n",
            "2149        [[0.99785477, 0.0003940653, 0.0017510849]]\n",
            "2150           [[0.9456175, 0.0011395348, 0.05324297]]\n",
            "2151      [[0.00069208746, 3.1425338e-05, 0.99927646]]\n",
            "2152            [[0.004739599, 0.9323203, 0.06294014]]\n",
            "2153        [[0.00022388258, 7.119117e-05, 0.9997049]]\n",
            "2154        [[0.000120482415, 0.011884182, 0.9879953]]\n",
            "2155       [[0.00045715627, 5.6031487e-05, 0.9994868]]\n",
            "2156       [[0.00068284594, 0.0008932662, 0.99842393]]\n",
            "2157      [[0.00027345592, 0.00012186034, 0.99960464]]\n",
            "2158       [[0.00019154492, 0.00020475923, 0.9996038]]\n",
            "2159           [[0.0007645134, 0.03650159, 0.9627339]]\n",
            "2160         [[0.0003367998, 0.0001595176, 0.9995036]]\n",
            "2161       [[0.00076184486, 6.701466e-05, 0.99917114]]\n",
            "2162          [[0.9898085, 8.429975e-05, 0.010107331]]\n",
            "2163       [[0.00097573077, 0.99604404, 0.0029802087]]\n",
            "2164          [[0.0014193302, 0.87567204, 0.12290861]]\n",
            "2165           [[0.0011086289, 0.025648287, 0.973243]]\n",
            "2166       [[0.0019908533, 0.00021442844, 0.99779475]]\n",
            "2167      [[0.00030866417, 0.00019371716, 0.99949753]]\n",
            "2168      [[0.00035695793, 2.1193042e-05, 0.99962175]]\n",
            "2169       [[0.0005540247, 2.9618262e-05, 0.99941635]]\n",
            "2170          [[0.0021738107, 0.31215024, 0.68567586]]\n",
            "2171       [[0.99860066, 0.00032444327, 0.0010749777]]\n",
            "2172        [[0.00022937462, 0.98035496, 0.019415688]]\n",
            "2173          [[0.0021738107, 0.31215024, 0.68567586]]\n",
            "2174          [[0.0021738107, 0.31215024, 0.68567586]]\n",
            "2175       [[0.00080123235, 6.4246015e-05, 0.9991346]]\n",
            "2176       [[0.00034979396, 0.0033681183, 0.99628216]]\n",
            "2177         [[0.0020209881, 0.0011267394, 0.9968522]]\n",
            "2178          [[0.009905864, 0.0027775525, 0.9873166]]\n",
            "2179          [[0.0010987571, 5.99954e-05, 0.9988412]]\n",
            "2180      [[0.00029917792, 0.00016105364, 0.99953973]]\n",
            "2181      [[0.00018491661, 1.7924125e-05, 0.99979717]]\n",
            "2182         [[0.00032022112, 4.17361e-05, 0.9996381]]\n",
            "2183      [[0.000112130205, 0.9989146, 0.00097323704]]\n",
            "2184         [[0.0009994814, 0.94130445, 0.057696044]]\n",
            "2185          [[0.0013097028, 0.043099385, 0.9555909]]\n",
            "2186        [[0.00013049896, 0.0010391541, 0.9988304]]\n",
            "2187         [[0.011338714, 0.00017378862, 0.9884875]]\n",
            "2188         [[0.011338714, 0.00017378862, 0.9884875]]\n",
            "2189      [[0.00010348007, 1.5968819e-05, 0.99988055]]\n",
            "2190      [[0.00011281774, 3.2068536e-05, 0.99985504]]\n",
            "2191         [[9.689976e-05, 8.671847e-06, 0.9998944]]\n",
            "2192       [[0.00017012753, 0.00084536005, 0.9989844]]\n",
            "2193        [[0.00023818713, 0.0003318701, 0.9994299]]\n",
            "2194           [[0.0011880406, 0.26669106, 0.7321209]]\n",
            "2195              [[0.002246768, 0.34875, 0.64900327]]\n",
            "2196        [[0.00010258432, 0.0134015735, 0.9864959]]\n",
            "2197        [[0.00017833422, 0.0007319481, 0.9990897]]\n",
            "2198            [[0.0006638042, 0.5437238, 0.4556124]]\n",
            "2199          [[0.000627818, 0.0071426793, 0.9922295]]\n",
            "2200              [[0.012803652, 0.4317123, 0.555484]]\n",
            "2201         [[0.0023483525, 0.021542283, 0.97610927]]\n",
            "2202           [[0.0006099434, 0.0023799734, 0.99701]]\n",
            "2203       [[0.00047876118, 1.4782702e-05, 0.9995065]]\n",
            "2204        [[0.0002543307, 8.6401415e-06, 0.9997371]]\n",
            "2205      [[0.00025104868, 0.00026963738, 0.99947935]]\n",
            "2206        [[0.0005127513, 0.0024149432, 0.99707234]]\n",
            "2207           [[7.9285e-05, 8.537873e-05, 0.9998354]]\n",
            "2208       [[0.000119104654, 0.9970433, 0.0028376195]]\n",
            "2209         [[0.00010002552, 0.9752059, 0.024694078]]\n",
            "2210        [[0.00044225086, 0.007591092, 0.99196666]]\n",
            "2211          [[0.00013662371, 9.2006e-06, 0.9998542]]\n",
            "2212       [[9.8705474e-05, 3.5403842e-05, 0.9998659]]\n",
            "2213          [[0.00080675137, 0.9762498, 0.02294341]]\n",
            "2214       [[0.000105616455, 0.9988205, 0.0010738341]]\n",
            "2215          [[0.0012033676, 0.73510987, 0.26368675]]\n",
            "2216          [[0.0033982259, 0.9715578, 0.025044011]]\n",
            "2217        [[0.99268615, 0.0014676792, 0.0058461893]]\n",
            "2218          [[0.9836939, 0.0005366974, 0.015769435]]\n",
            "2219        [[0.004012571, 3.3208264e-05, 0.99595416]]\n",
            "2220         [[0.97973216, 0.0023727692, 0.017895108]]\n",
            "2221       [[9.1761984e-05, 2.1868796e-05, 0.9998864]]\n",
            "2222       [[5.3714408e-05, 3.704624e-05, 0.99990916]]\n",
            "2223       [[0.0023600091, 0.00021043011, 0.99742955]]\n",
            "2224          [[9.933902e-05, 7.30153e-06, 0.9998934]]\n",
            "2225         [[7.4629424e-05, 0.0024763332, 0.997449]]\n",
            "2226       [[0.0002450753, 6.1304425e-05, 0.99969375]]\n",
            "2227             [[0.007378759, 0.6252145, 0.3674067]]\n",
            "2228      [[0.00022777515, 0.00013552081, 0.99963677]]\n",
            "2229       [[0.00016492157, 0.00036184178, 0.9994733]]\n",
            "2230        [[7.717571e-05, 0.00013218092, 0.9997906]]\n",
            "2231        [[0.0008199849, 4.4350334e-05, 0.9991358]]\n",
            "2232        [[0.00085819303, 6.559115e-05, 0.9990761]]\n",
            "2233        [[0.00021791195, 0.00047909023, 0.999303]]\n",
            "2234      [[0.00072142214, 0.00012964521, 0.99914896]]\n",
            "2235      [[0.00072142214, 0.00012964521, 0.99914896]]\n",
            "2236         [[0.0005779265, 8.474097e-06, 0.9994136]]\n",
            "2237       [[0.00018591793, 2.4735098e-05, 0.9997893]]\n",
            "2238          [[0.0014804007, 0.0013976536, 0.997122]]\n",
            "2239             [[0.03573967, 0.032874368, 0.931386]]\n",
            "2240          [[0.0023864203, 0.003023194, 0.9945904]]\n",
            "2241         [[0.986014, 0.00067925523, 0.0133067155]]\n",
            "2242       [[0.00053468044, 0.0009388298, 0.99852645]]\n",
            "2243           [[0.0017508672, 0.27126506, 0.7269841]]\n",
            "2244          [[0.0012905858, 0.00501105, 0.99369836]]\n",
            "2245              [[0.07569283, 0.0181261, 0.9061811]]\n",
            "2246        [[0.0002586782, 9.787036e-05, 0.99964345]]\n",
            "2247       [[0.00019393995, 2.329319e-05, 0.99978286]]\n",
            "2248        [[0.00014138338, 1.7694316e-05, 0.999841]]\n",
            "2249       [[8.0041566e-05, 3.549131e-05, 0.99988437]]\n",
            "2250       [[0.00016258183, 3.772468e-05, 0.99979967]]\n",
            "2251          [[0.9575596, 0.00035887206, 0.04208153]]\n",
            "2252      [[0.00026671545, 0.99879706, 0.00093626196]]\n",
            "2253          [[0.0015845536, 0.09049775, 0.90791774]]\n",
            "2254          [[0.0007729555, 0.009504378, 0.9897227]]\n",
            "2255        [[0.0004123629, 8.056088e-05, 0.99950707]]\n",
            "2256           [[0.008550891, 0.036371443, 0.9550777]]\n",
            "2257          [[0.009929122, 0.0001925242, 0.9898783]]\n",
            "2258             [[0.9178375, 0.0090174, 0.073145024]]\n",
            "2259            [[0.007398321, 0.03595533, 0.9566463]]\n",
            "2260       [[0.0006274744, 0.00028895438, 0.99908364]]\n",
            "2261         [[0.0005511449, 0.005860355, 0.99358857]]\n",
            "2262        [[0.00018811946, 0.0018090704, 0.9980028]]\n",
            "2263        [[0.00020369669, 2.1339361e-05, 0.999775]]\n",
            "2264           [[0.0001447788, 0.00783517, 0.9920201]]\n",
            "2265           [[0.053322688, 0.9411625, 0.005514761]]\n",
            "2266           [[0.00948396, 0.0019765433, 0.9885394]]\n",
            "2267            [[0.0010622952, 0.0263304, 0.9726073]]\n",
            "2268        [[0.00017116625, 1.852674e-05, 0.9998104]]\n",
            "2269        [[7.735732e-05, 0.00042421094, 0.9994985]]\n",
            "2270           [[0.0065180636, 0.11621609, 0.8772658]]\n",
            "2271           [[0.0065180636, 0.11621609, 0.8772658]]\n",
            "2272        [[0.00014346286, 0.00013248686, 0.999724]]\n",
            "2273        [[0.00017176846, 0.0002554724, 0.9995727]]\n",
            "2274        [[0.00020058293, 0.0005511285, 0.9992482]]\n",
            "2275            [[0.16707134, 0.18713829, 0.64579034]]\n",
            "2276           [[0.0065180636, 0.11621609, 0.8772658]]\n",
            "2277        [[0.00042412264, 7.573132e-06, 0.9995683]]\n",
            "2278        [[0.0003606323, 7.692117e-06, 0.99963164]]\n",
            "2279          [[0.0031152933, 0.044101167, 0.9527835]]\n",
            "2280         [[0.0012280961, 0.0054952404, 0.9932767]]\n",
            "2281       [[0.0002464311, 2.8522229e-05, 0.99972504]]\n",
            "2282         [[0.00048659756, 3.446361e-05, 0.999479]]\n",
            "2283         [[0.0011343532, 0.0011881368, 0.9976775]]\n",
            "2284       [[0.00022729121, 3.9751798e-05, 0.9997329]]\n",
            "2285        [[0.00022165487, 8.761192e-05, 0.9996908]]\n",
            "2286      [[0.00019046947, 3.4191464e-05, 0.99977535]]\n",
            "2287          [[0.0010065761, 0.057299588, 0.9416938]]\n",
            "2288         [[0.00034371082, 0.00736581, 0.99229044]]\n",
            "2289       [[0.00020089794, 1.2847887e-05, 0.9997862]]\n",
            "2290           [[0.0023035933, 0.13509975, 0.8625967]]\n",
            "2291           [[0.0014831515, 0.5633482, 0.43516868]]\n",
            "2292           [[0.0014831515, 0.5633482, 0.43516868]]\n",
            "2293         [[0.0032473032, 0.028371787, 0.96838087]]\n",
            "2294      [[0.00013144457, 0.00067343726, 0.99919504]]\n",
            "2295         [[0.00054572854, 0.9139147, 0.085539564]]\n",
            "2296             [[0.0014194932, 0.6162935, 0.382287]]\n",
            "2297           [[0.0023035933, 0.13509975, 0.8625967]]\n",
            "2298        [[0.0004954736, 4.0918192e-05, 0.9994636]]\n",
            "2299       [[0.00042606375, 2.3631253e-05, 0.9995503]]\n",
            "2300        [[0.00047512114, 0.008824948, 0.99069995]]\n",
            "2301             [[0.0018613322, 0.2941867, 0.703952]]\n",
            "2302            [[0.023085693, 0.01905323, 0.9578612]]\n",
            "2303       [[0.00013742501, 2.3700468e-05, 0.9998388]]\n",
            "2304       [[0.00028601484, 0.0038226107, 0.99589133]]\n",
            "2305       [[0.00020765336, 1.3163568e-05, 0.9997793]]\n",
            "2306          [[0.84755296, 0.101077355, 0.051369745]]\n",
            "2307       [[0.00033589962, 1.7751576e-05, 0.9996463]]\n",
            "2308          [[0.0030084508, 0.016600141, 0.9803915]]\n",
            "2309        [[7.932624e-05, 1.7329905e-05, 0.9999033]]\n",
            "2310       [[0.00012434002, 5.4880464e-05, 0.9998209]]\n",
            "2311          [[8.9487e-05, 6.151572e-05, 0.99984896]]\n",
            "2312        [[0.0012900631, 0.00056736614, 0.9981426]]\n",
            "2313           [[0.0011562927, 0.13456003, 0.8642837]]\n",
            "2314          [[0.9870094, 0.0028399208, 0.010150545]]\n",
            "2315           [[0.0023277202, 0.9461737, 0.05149857]]\n",
            "2316          [[5.604513e-05, 0.995413, 0.0045309537]]\n",
            "2317       [[6.3928535e-05, 0.99869114, 0.0012449512]]\n",
            "2318         [[0.0024518024, 0.018243596, 0.97930455]]\n",
            "2319        [[0.00020967335, 0.0004265855, 0.9993637]]\n",
            "2320          [[0.00021400995, 0.08843147, 0.9113545]]\n",
            "2321          [[0.0007141226, 0.023897022, 0.9753888]]\n",
            "2322          [[0.0007141226, 0.023897022, 0.9753888]]\n",
            "2323       [[0.00039870935, 1.569637e-05, 0.99958557]]\n",
            "2324        [[0.00017842934, 6.334816e-06, 0.9998153]]\n",
            "2325        [[0.00015357701, 0.0001012104, 0.9997452]]\n",
            "2326            [[0.26402685, 0.013966627, 0.7220065]]\n",
            "2327        [[0.00020832533, 2.9665232e-05, 0.999762]]\n",
            "2328        [[0.00024109786, 0.0001857105, 0.9995732]]\n",
            "2329         [[0.00053161185, 0.025103878, 0.9743645]]\n",
            "2330       [[0.00011500618, 0.00074917387, 0.9991358]]\n",
            "2331       [[0.00017872814, 0.00014194897, 0.9996793]]\n",
            "2332         [[0.0001495947, 8.709881e-06, 0.9998417]]\n",
            "2333       [[0.00012462128, 5.5192773e-05, 0.9998202]]\n",
            "2334       [[0.0010148211, 0.00010470743, 0.99888057]]\n",
            "2335       [[0.00015660317, 0.00015862846, 0.9996848]]\n",
            "2336        [[0.0006922463, 0.00068981585, 0.9986179]]\n",
            "2337      [[0.00030842162, 6.5840227e-06, 0.99968505]]\n",
            "2338       [[0.00048044228, 2.8355991e-05, 0.9994912]]\n",
            "2339        [[0.0007174164, 0.0030541185, 0.99622846]]\n",
            "2340             [[0.012439843, 0.8957887, 0.0917715]]\n",
            "2341        [[0.00010095788, 0.00034300756, 0.999556]]\n",
            "2342        [[0.00016003924, 0.0005656843, 0.9992743]]\n",
            "2343          [[8.884616e-05, 3.76298e-05, 0.9998735]]\n",
            "2344       [[0.00015766975, 0.0007260038, 0.99911624]]\n",
            "2345       [[0.00012502329, 8.083746e-06, 0.99986684]]\n",
            "2346       [[9.7551616e-05, 1.3603966e-05, 0.9998889]]\n",
            "2347       [[9.165863e-05, 1.2105131e-05, 0.99989617]]\n",
            "2348        [[0.0003701147, 6.897121e-06, 0.99962294]]\n",
            "2349      [[0.00031956536, 0.00025929243, 0.99942124]]\n",
            "2350       [[0.00053376955, 0.0017010618, 0.99776506]]\n",
            "2351             [[0.09125786, 0.50218594, 0.4065562]]\n",
            "2352          [[0.0017546826, 0.01053985, 0.98770547]]\n",
            "2353       [[0.00047830463, 9.918965e-06, 0.99951184]]\n",
            "2354      [[0.00028830854, 0.00018996587, 0.99952173]]\n",
            "2355      [[0.0016369827, 0.99825174, 0.000111216345]]\n",
            "2356         [[0.0090061445, 0.9905688, 0.0004250596]]\n",
            "2357       [[0.00012285364, 0.00047528002, 0.9994019]]\n",
            "2358         [[0.00010884935, 3.83273e-05, 0.9998528]]\n",
            "2359       [[0.00015299776, 0.00023953276, 0.9996075]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_raw_know_val_f1_0.8014'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_raw_know_val_f1_0.8014\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "S2YfnJpqFKXL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK27GNT1AojQ"
      },
      "source": [
        "## s3 state_dict/bert_spc_combined_select_know_val_f1_0.7819"
      ],
      "id": "CK27GNT1AojQ"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/z_insert_selected_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "UqERsJWHAojS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UqERsJWHAojS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7709b194-4412-4429-b0d7-9154a7b66fb1",
        "id": "OjtCgxW1AojT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0             [[0.02886212, 0.0012908301, 0.9698471]]\n",
            "1           [[0.0018146863, 0.0013946763, 0.9967906]]\n",
            "2              [[0.1211276, 0.091041036, 0.78783137]]\n",
            "3               [[0.4923091, 0.00084086135, 0.50685]]\n",
            "4           [[0.024383485, 5.2948686e-05, 0.9755636]]\n",
            "5         [[0.0016797542, 1.1709821e-05, 0.99830854]]\n",
            "6             [[0.004719406, 0.47593892, 0.51934165]]\n",
            "7           [[0.0019860275, 0.0005508081, 0.9974632]]\n",
            "8             [[0.0074718003, 0.09825403, 0.8942741]]\n",
            "9           [[0.00062853826, 2.88866e-05, 0.9993426]]\n",
            "10            [[0.000753156, 0.010644267, 0.9886026]]\n",
            "11           [[0.0010932202, 0.9390698, 0.059836984]]\n",
            "12          [[0.0006493546, 0.97925526, 0.020095384]]\n",
            "13        [[0.00014718481, 0.99953616, 0.0003166882]]\n",
            "14          [[0.0006493546, 0.97925526, 0.020095384]]\n",
            "15          [[0.011104198, 0.00066030206, 0.9882355]]\n",
            "16            [[0.9531866, 0.0053411177, 0.04147231]]\n",
            "17        [[0.00059650297, 3.0192983e-05, 0.9993734]]\n",
            "18        [[0.00055376807, 2.7860267e-05, 0.9994184]]\n",
            "19            [[0.001164064, 0.06929311, 0.92954284]]\n",
            "20             [[0.005161996, 0.0012579962, 0.99358]]\n",
            "21         [[0.0020789765, 4.990043e-05, 0.99787116]]\n",
            "22         [[0.0008635657, 2.1509262e-05, 0.9991148]]\n",
            "23             [[0.005161996, 0.0012579962, 0.99358]]\n",
            "24             [[0.005161996, 0.0012579962, 0.99358]]\n",
            "25             [[0.0042291107, 0.7784522, 0.2173187]]\n",
            "26       [[0.00048157288, 5.0833723e-06, 0.99951327]]\n",
            "27        [[0.00074804464, 6.261655e-06, 0.99924564]]\n",
            "28       [[0.00020589877, 1.2460536e-05, 0.99978155]]\n",
            "29       [[0.00011081628, 2.9790035e-05, 0.99985933]]\n",
            "30            [[0.0020964462, 0.17179275, 0.8261108]]\n",
            "31         [[0.0013144861, 1.9064953e-05, 0.9986665]]\n",
            "32           [[0.0023970671, 0.21531776, 0.78228515]]\n",
            "33        [[0.0009284165, 1.9644956e-05, 0.99905187]]\n",
            "34           [[0.0021387609, 0.0044781794, 0.993383]]\n",
            "35             [[0.00403628, 0.16827193, 0.82769185]]\n",
            "36           [[0.0014212192, 0.72232556, 0.27625322]]\n",
            "37            [[0.41645372, 0.5789717, 0.0045746076]]\n",
            "38          [[0.013696052, 0.0008236363, 0.98548025]]\n",
            "39          [[0.0011136837, 1.888535e-05, 0.9988674]]\n",
            "40            [[0.0013512538, 0.13982186, 0.8588269]]\n",
            "41       [[0.00058626244, 3.4002827e-05, 0.99937975]]\n",
            "42        [[0.00075602334, 0.00025525255, 0.9989888]]\n",
            "43           [[0.0015697797, 0.008701559, 0.9897287]]\n",
            "44            [[0.050849922, 0.9194815, 0.029668609]]\n",
            "45             [[0.12352186, 0.8482628, 0.028215367]]\n",
            "46              [[0.08542915, 0.8135986, 0.10097226]]\n",
            "47            [[0.39016342, 0.52687764, 0.082958944]]\n",
            "48          [[0.0019641789, 7.206967e-05, 0.9979638]]\n",
            "49            [[0.018799312, 0.9632605, 0.017940233]]\n",
            "50           [[0.0034457832, 0.00240483, 0.99414945]]\n",
            "51        [[0.0010517132, 0.00013221806, 0.99881613]]\n",
            "52          [[0.0019641789, 7.206967e-05, 0.9979638]]\n",
            "53               [[0.00979253, 0.87645, 0.113757454]]\n",
            "54            [[0.0037148101, 0.7433862, 0.25289902]]\n",
            "55             [[0.078213885, 0.13037778, 0.7914083]]\n",
            "56             [[0.078213885, 0.13037778, 0.7914083]]\n",
            "57             [[0.08063321, 0.032211892, 0.8871549]]\n",
            "58            [[0.002289392, 0.9739498, 0.023760855]]\n",
            "59             [[0.06953745, 0.53112024, 0.39934224]]\n",
            "60         [[0.0020442675, 1.4572402e-05, 0.9979412]]\n",
            "61         [[0.00082078803, 0.0004241241, 0.9987551]]\n",
            "62       [[0.00028770356, 0.00075153983, 0.99896073]]\n",
            "63       [[0.00024357492, 3.8163893e-05, 0.99971825]]\n",
            "64        [[0.0005431527, 2.1523014e-05, 0.99943525]]\n",
            "65         [[0.0022880442, 0.00041036692, 0.9973016]]\n",
            "66        [[0.0005029196, 5.7567628e-05, 0.99943954]]\n",
            "67            [[0.010124122, 0.050960228, 0.9389156]]\n",
            "68           [[0.9369642, 0.00027438343, 0.06276133]]\n",
            "69            [[0.33456966, 0.62232804, 0.043102283]]\n",
            "70          [[0.95682484, 0.040529877, 0.0026451957]]\n",
            "71           [[0.94918185, 0.04925515, 0.0015630875]]\n",
            "72        [[0.00038760575, 0.0010520437, 0.99856037]]\n",
            "73            [[0.0026833618, 0.69354033, 0.3037763]]\n",
            "74          [[0.0016130345, 0.032892033, 0.96549493]]\n",
            "75            [[0.018339803, 0.001154779, 0.9805054]]\n",
            "76         [[0.002435455, 0.00019898752, 0.99736553]]\n",
            "77          [[0.0014732826, 2.442186e-05, 0.9985024]]\n",
            "78          [[0.0012049341, 3.0070063e-05, 0.998765]]\n",
            "79          [[0.0014732826, 2.442186e-05, 0.9985024]]\n",
            "80           [[0.012511917, 0.009822458, 0.97766566]]\n",
            "81         [[0.00014483646, 8.834007e-05, 0.9997669]]\n",
            "82             [[0.006378907, 4.4395e-05, 0.9935767]]\n",
            "83           [[0.5990917, 0.00071162457, 0.40019667]]\n",
            "84        [[0.00037347118, 4.3691696e-05, 0.9995828]]\n",
            "85              [[0.6009244, 0.24510255, 0.15397306]]\n",
            "86             [[0.549032, 0.44549835, 0.0054696137]]\n",
            "87           [[0.0006928146, 9.135763e-06, 0.999298]]\n",
            "88             [[0.034919135, 0.43096447, 0.5341164]]\n",
            "89           [[0.004237377, 0.0010218236, 0.9947408]]\n",
            "90         [[0.0012657851, 2.4505307e-05, 0.9987097]]\n",
            "91           [[0.08821306, 0.91008824, 0.0016987327]]\n",
            "92          [[0.0015745574, 0.086702004, 0.91172343]]\n",
            "93        [[0.0040870905, 0.00014996217, 0.99576294]]\n",
            "94          [[0.0017295236, 4.677893e-05, 0.9982237]]\n",
            "95            [[0.12617321, 0.0050501325, 0.8687767]]\n",
            "96            [[0.49656856, 0.0005977693, 0.5028337]]\n",
            "97        [[0.00064643053, 7.797678e-06, 0.99934584]]\n",
            "98        [[0.00042045963, 8.822891e-06, 0.99957067]]\n",
            "99        [[0.00094649725, 1.168178e-05, 0.99904186]]\n",
            "100        [[0.0006034243, 4.8066054e-06, 0.9993918]]\n",
            "101           [[0.0030374466, 0.8491153, 0.14784724]]\n",
            "102      [[0.00077114796, 3.0762076e-05, 0.99919814]]\n",
            "103         [[0.0005225918, 0.0017616792, 0.9977157]]\n",
            "104       [[0.0014899407, 2.9134502e-05, 0.99848086]]\n",
            "105         [[0.004340944, 6.384752e-05, 0.99559516]]\n",
            "106        [[0.00096428604, 9.538519e-05, 0.9989403]]\n",
            "107           [[0.005320629, 0.43059283, 0.56408656]]\n",
            "108       [[0.00055705634, 2.1253925e-05, 0.9994217]]\n",
            "109        [[0.00016236628, 9.559656e-06, 0.9998281]]\n",
            "110         [[0.0025023439, 0.0035688027, 0.9939289]]\n",
            "111       [[0.00043711695, 5.1186405e-05, 0.9995116]]\n",
            "112        [[0.000544435, 0.00038178262, 0.99907374]]\n",
            "113            [[0.024164887, 0.35750246, 0.6183327]]\n",
            "114            [[0.015811669, 0.8693222, 0.11486617]]\n",
            "115            [[0.015811669, 0.8693222, 0.11486617]]\n",
            "116            [[0.015811669, 0.8693222, 0.11486617]]\n",
            "117        [[0.0011945072, 1.4152706e-05, 0.9987914]]\n",
            "118           [[0.001302381, 0.92648476, 0.07221287]]\n",
            "119            [[0.21532814, 0.45711824, 0.32755363]]\n",
            "120          [[0.0030566962, 0.89209163, 0.10485164]]\n",
            "121         [[0.0019310175, 6.925215e-05, 0.9979997]]\n",
            "122       [[0.00016789258, 1.5073945e-05, 0.9998171]]\n",
            "123       [[0.0020478838, 4.6879384e-05, 0.99790525]]\n",
            "124          [[0.0012620579, 0.000862388, 0.9978756]]\n",
            "125          [[0.0044441978, 0.004481344, 0.9910745]]\n",
            "126           [[0.005539232, 0.006711841, 0.9877489]]\n",
            "127            [[0.008075076, 0.33272186, 0.6592031]]\n",
            "128          [[0.0030547811, 0.58686155, 0.41008374]]\n",
            "129      [[0.00071659294, 1.7459717e-05, 0.99926585]]\n",
            "130        [[0.0009868465, 6.1426406e-05, 0.9989517]]\n",
            "131          [[0.93997693, 0.025829844, 0.034193195]]\n",
            "132           [[0.8712984, 0.0042349114, 0.12446673]]\n",
            "133        [[0.00045198284, 0.0001926574, 0.9993554]]\n",
            "134           [[0.037362542, 0.27192888, 0.69070864]]\n",
            "135            [[0.02479667, 0.9569264, 0.018276937]]\n",
            "136            [[0.023569461, 0.23585813, 0.7405724]]\n",
            "137       [[0.00088688923, 1.0632403e-05, 0.9991026]]\n",
            "138       [[0.00076399936, 3.6084784e-05, 0.9991999]]\n",
            "139             [[0.00037036, 9.26787e-05, 0.999537]]\n",
            "140         [[0.0006203718, 8.589852e-06, 0.9993711]]\n",
            "141        [[0.0028624414, 2.8620356e-05, 0.9971089]]\n",
            "142           [[0.042344477, 0.15093283, 0.80672264]]\n",
            "143         [[0.0018067223, 0.032186426, 0.96600693]]\n",
            "144            [[0.02545864, 0.9698148, 0.004726576]]\n",
            "145         [[0.0021912963, 2.1596195e-05, 0.997787]]\n",
            "146          [[0.0003986155, 0.009979812, 0.9896215]]\n",
            "147             [[0.00636076, 0.6395517, 0.35408753]]\n",
            "148          [[0.020438593, 0.9790936, 0.0004677957]]\n",
            "149             [[0.00636076, 0.6395517, 0.35408753]]\n",
            "150       [[0.00078235794, 4.2788437e-05, 0.9991749]]\n",
            "151          [[0.043441217, 0.94636184, 0.010196975]]\n",
            "152       [[0.00078235794, 4.2788437e-05, 0.9991749]]\n",
            "153            [[0.0641408, 0.9334641, 0.0023950806]]\n",
            "154        [[0.00078219606, 0.008956594, 0.99026126]]\n",
            "155           [[0.0037417002, 0.7712608, 0.22499754]]\n",
            "156             [[0.0033767337, 0.3685493, 0.628074]]\n",
            "157            [[0.006073355, 0.09164063, 0.9022861]]\n",
            "158          [[0.10897608, 0.88346153, 0.0075623346]]\n",
            "159          [[0.18992247, 0.80475944, 0.0053180642]]\n",
            "160             [[0.012165341, 0.15481271, 0.833022]]\n",
            "161        [[0.000872468, 1.7443517e-05, 0.99911016]]\n",
            "162        [[0.0006346616, 1.3731031e-05, 0.9993517]]\n",
            "163        [[0.0009979468, 0.0021305291, 0.99687153]]\n",
            "164        [[0.002419202, 1.8721965e-05, 0.99756217]]\n",
            "165           [[0.14881289, 0.0011254294, 0.8500617]]\n",
            "166              [[0.1941477, 0.0008923339, 0.80496]]\n",
            "167        [[0.0056262794, 4.3336247e-05, 0.9943303]]\n",
            "168            [[0.29205298, 0.54331595, 0.16463108]]\n",
            "169           [[0.011527451, 0.009973755, 0.9784989]]\n",
            "170           [[0.023869157, 0.12897713, 0.84715366]]\n",
            "171       [[0.0006241612, 2.5718111e-05, 0.99935013]]\n",
            "172             [[0.031191634, 0.3300167, 0.6387917]]\n",
            "173            [[0.062841296, 0.8692406, 0.06791814]]\n",
            "174         [[0.0070831454, 0.9891284, 0.0037884829]]\n",
            "175     [[0.00016631743, 1.19182305e-05, 0.99982184]]\n",
            "176            [[0.0030505245, 0.0450853, 0.9518641]]\n",
            "177         [[0.00067301514, 0.003973333, 0.9953537]]\n",
            "178         [[0.0008621889, 0.010103753, 0.98903406]]\n",
            "179          [[0.002057309, 0.98976594, 0.008176716]]\n",
            "180           [[0.9695999, 0.0069532422, 0.02344682]]\n",
            "181         [[0.00047268637, 6.76503e-05, 0.9994597]]\n",
            "182            [[0.014199248, 0.40457308, 0.5812276]]\n",
            "183       [[0.0008398959, 0.00064393744, 0.99851614]]\n",
            "184        [[0.008140478, 1.7474023e-05, 0.99184203]]\n",
            "185       [[0.00090389664, 1.6264314e-05, 0.9990798]]\n",
            "186         [[0.031926636, 0.00021674891, 0.9678565]]\n",
            "187       [[0.00090389664, 1.6264314e-05, 0.9990798]]\n",
            "188         [[0.0014720104, 4.4985325e-05, 0.998483]]\n",
            "189           [[0.004501499, 0.026459156, 0.9690393]]\n",
            "190           [[0.0048037805, 0.19106705, 0.8041291]]\n",
            "191       [[0.0010932928, 0.00071196625, 0.99819475]]\n",
            "192            [[0.0025853845, 0.2146522, 0.7827624]]\n",
            "193         [[0.0008946581, 9.597433e-05, 0.9990094]]\n",
            "194          [[0.0006113295, 3.558134e-05, 0.999353]]\n",
            "195           [[0.06772026, 0.002606598, 0.92967314]]\n",
            "196          [[0.0050537805, 0.993842, 0.0011041866]]\n",
            "197         [[0.00082969863, 0.026375465, 0.9727948]]\n",
            "198          [[0.00057721563, 0.000413741, 0.999009]]\n",
            "199       [[0.00076642446, 0.00013413692, 0.9990995]]\n",
            "200             [[0.34341043, 0.15376545, 0.5028241]]\n",
            "201         [[0.9936248, 0.0007588412, 0.0056163603]]\n",
            "202         [[0.002505778, 3.7015674e-05, 0.9974572]]\n",
            "203         [[0.98303336, 0.0024581528, 0.014508567]]\n",
            "204           [[0.0027388528, 0.7683757, 0.22888549]]\n",
            "205        [[0.00041961536, 0.0017621893, 0.9978181]]\n",
            "206               [[0.00526033, 0.5422407, 0.452499]]\n",
            "207       [[0.00043605297, 5.6528042e-05, 0.9995074]]\n",
            "208         [[0.00083383406, 0.00027624244, 0.99889]]\n",
            "209         [[0.00083383406, 0.00027624244, 0.99889]]\n",
            "210       [[0.00014938145, 0.0021299007, 0.99772066]]\n",
            "211       [[0.0002804371, 1.0483711e-05, 0.99970907]]\n",
            "212        [[0.002090492, 2.2152264e-05, 0.99788743]]\n",
            "213       [[0.0002516713, 1.1286333e-05, 0.99973696]]\n",
            "214         [[0.00096259965, 0.002583278, 0.9964541]]\n",
            "215        [[0.00093324267, 0.0019555488, 0.9971112]]\n",
            "216         [[0.0017496385, 0.020594705, 0.97765577]]\n",
            "217          [[0.0015638523, 0.054724034, 0.9437121]]\n",
            "218            [[0.0032654828, 0.2573658, 0.7393687]]\n",
            "219         [[0.0009341014, 0.007077035, 0.99198884]]\n",
            "220        [[0.00049567973, 2.916983e-05, 0.9994752]]\n",
            "221       [[0.0008830676, 0.00010783614, 0.99900913]]\n",
            "222       [[0.0016109922, 0.00012198301, 0.99826705]]\n",
            "223            [[0.0057378095, 0.87637126, 0.117891]]\n",
            "224       [[0.0016109922, 0.00012198301, 0.99826705]]\n",
            "225         [[0.012227192, 0.0006423677, 0.98713046]]\n",
            "226          [[0.9949362, 0.004274658, 0.0007890667]]\n",
            "227           [[0.0014312521, 0.97333413, 0.0252346]]\n",
            "228        [[6.504479e-05, 0.9995478, 0.00038715926]]\n",
            "229           [[0.0018089727, 0.9397335, 0.05845749]]\n",
            "230         [[0.0021521307, 0.88612616, 0.111721694]]\n",
            "231           [[0.05858269, 0.047854103, 0.89356315]]\n",
            "232            [[0.654771, 0.0013311057, 0.34389797]]\n",
            "233          [[0.0044057705, 0.10955436, 0.88603985]]\n",
            "234          [[0.9961438, 0.00338483, 0.00047135007]]\n",
            "235        [[0.0030224305, 3.6107096e-05, 0.9969414]]\n",
            "236         [[0.0008279933, 2.257568e-05, 0.9991493]]\n",
            "237      [[0.00041019835, 2.9735478e-05, 0.99955994]]\n",
            "238        [[0.999405, 0.00013403929, 0.00046099242]]\n",
            "239       [[0.00081468554, 0.0005663596, 0.99861884]]\n",
            "240        [[0.013549426, 0.00016854484, 0.98628193]]\n",
            "241            [[0.009787786, 0.2828245, 0.70738775]]\n",
            "242           [[0.0064565856, 0.15090194, 0.8426415]]\n",
            "243           [[0.15366879, 0.83257186, 0.013759273]]\n",
            "244        [[0.0075776004, 0.0057057026, 0.98671675]]\n",
            "245        [[0.00022353968, 0.99903286, 0.000743667]]\n",
            "246        [[0.0016290307, 3.2237876e-05, 0.9983387]]\n",
            "247        [[0.0017471695, 0.0027720851, 0.99548066]]\n",
            "248           [[0.0023703685, 0.05552032, 0.9421093]]\n",
            "249         [[0.00040833498, 6.10345e-05, 0.9995307]]\n",
            "250         [[0.00029058696, 4.9500206e-05, 0.99966]]\n",
            "251      [[0.00062710664, 2.0701316e-05, 0.99935216]]\n",
            "252      [[0.00062710664, 2.0701316e-05, 0.99935216]]\n",
            "253       [[0.00033855072, 0.00021771538, 0.9994437]]\n",
            "254           [[0.006247623, 0.042608727, 0.9511437]]\n",
            "255           [[0.012106131, 0.020635214, 0.9672587]]\n",
            "256        [[0.00027968752, 0.9982881, 0.0014321973]]\n",
            "257        [[0.0021224697, 1.8662939e-05, 0.9978588]]\n",
            "258         [[0.000615954, 0.00048920646, 0.9988949]]\n",
            "259            [[0.005043786, 0.20126837, 0.7936878]]\n",
            "260         [[0.0043585445, 0.98566645, 0.009975048]]\n",
            "261        [[0.00026641306, 0.9991806, 0.0005529192]]\n",
            "262        [[0.00027968752, 0.9982881, 0.0014321973]]\n",
            "263            [[0.053277627, 0.02785698, 0.9188654]]\n",
            "264            [[0.7634204, 0.0012409695, 0.2353386]]\n",
            "265           [[0.023307104, 0.06962082, 0.90707207]]\n",
            "266         [[0.0015140802, 0.028926812, 0.96955913]]\n",
            "267         [[0.022819854, 0.00010182461, 0.9770783]]\n",
            "268         [[0.022819854, 0.00010182461, 0.9770783]]\n",
            "269      [[0.0048461095, 0.000113625436, 0.99504024]]\n",
            "270           [[0.16775058, 7.218699e-05, 0.8321773]]\n",
            "271            [[0.8934318, 0.08698741, 0.019580768]]\n",
            "272       [[0.0075799865, 0.00044402314, 0.99197596]]\n",
            "273         [[0.0005323758, 0.0008156999, 0.9986519]]\n",
            "274       [[0.0010277543, 2.7755323e-05, 0.99894446]]\n",
            "275         [[0.0006849872, 0.0006927193, 0.9986223]]\n",
            "276          [[0.00044148063, 0.14512008, 0.8544385]]\n",
            "277        [[0.00013966092, 0.0001404491, 0.9997198]]\n",
            "278        [[0.0016562194, 2.2210905e-05, 0.9983215]]\n",
            "279          [[0.002418443, 0.0012211757, 0.9963605]]\n",
            "280       [[0.0004990996, 5.1934854e-05, 0.99944896]]\n",
            "281         [[0.0009771939, 0.9940941, 0.0049287025]]\n",
            "282       [[0.0009802416, 1.2598757e-05, 0.99900717]]\n",
            "283         [[0.0010499371, 0.005484783, 0.99346536]]\n",
            "284           [[0.0029109935, 0.03656865, 0.9605203]]\n",
            "285         [[0.0012183166, 0.9982743, 0.0005073878]]\n",
            "286           [[0.0019554433, 0.08782911, 0.9102155]]\n",
            "287         [[0.001718618, 0.0018199865, 0.99646145]]\n",
            "288            [[0.42110947, 0.5448575, 0.034032963]]\n",
            "289      [[0.00060265465, 2.3049242e-05, 0.99937433]]\n",
            "290            [[0.42110947, 0.5448575, 0.034032963]]\n",
            "291            [[0.0008664121, 0.0002817, 0.9988519]]\n",
            "292      [[0.00067981926, 0.000121069585, 0.9991992]]\n",
            "293         [[0.0013126113, 8.156821e-05, 0.9986059]]\n",
            "294           [[0.0020299412, 0.9536304, 0.04433959]]\n",
            "295          [[0.0005223525, 0.005234911, 0.9942427]]\n",
            "296        [[0.00076974975, 0.0008815883, 0.9983486]]\n",
            "297         [[0.0006534991, 0.98587716, 0.013469363]]\n",
            "298          [[0.0004424119, 0.96054924, 0.03900839]]\n",
            "299          [[0.9925551, 0.0008788482, 0.006566031]]\n",
            "300        [[0.0023439352, 0.0010568335, 0.99659926]]\n",
            "301             [[0.029805869, 0.2812101, 0.6889841]]\n",
            "302       [[0.0016889302, 0.99796057, 0.00035048934]]\n",
            "303              [[0.02340987, 0.4155003, 0.5610898]]\n",
            "304          [[0.9925551, 0.0008788482, 0.006566031]]\n",
            "305            [[0.046421055, 0.946238, 0.007340893]]\n",
            "306          [[0.000935614, 6.54369e-05, 0.99899906]]\n",
            "307        [[0.00061299355, 6.763834e-05, 0.9993193]]\n",
            "308          [[0.0023985095, 0.9410089, 0.056592528]]\n",
            "309           [[0.009739938, 0.11768038, 0.87257963]]\n",
            "310      [[0.00032620764, 2.6066475e-05, 0.99964774]]\n",
            "311        [[0.00027215274, 0.0003805092, 0.9993474]]\n",
            "312           [[0.0024376595, 0.6045816, 0.39298072]]\n",
            "313        [[0.0006441792, 0.0014340323, 0.99792176]]\n",
            "314        [[0.0008085364, 0.0033296833, 0.99586177]]\n",
            "315             [[0.02269799, 0.19878581, 0.7785162]]\n",
            "316       [[0.00056634215, 1.2730516e-05, 0.9994209]]\n",
            "317        [[0.0004259756, 3.3272474e-05, 0.9995408]]\n",
            "318       [[0.0004887654, 2.7760845e-05, 0.99948347]]\n",
            "319          [[0.0052222093, 0.25314227, 0.74163556]]\n",
            "320         [[0.00043574025, 0.015620056, 0.9839442]]\n",
            "321          [[0.0052222093, 0.25314227, 0.74163556]]\n",
            "322       [[0.00059321127, 3.2986932e-06, 0.9994035]]\n",
            "323      [[0.00064976444, 4.9346854e-06, 0.99934536]]\n",
            "324         [[0.0009071849, 6.053955e-05, 0.9990324]]\n",
            "325        [[0.0013051814, 1.1946098e-05, 0.9986829]]\n",
            "326         [[0.028051661, 0.0020304364, 0.96991783]]\n",
            "327        [[0.0015239723, 1.6474794e-05, 0.9984596]]\n",
            "328            [[0.951663, 0.043146722, 0.005190238]]\n",
            "329            [[0.090767495, 0.7600634, 0.14916904]]\n",
            "330         [[0.95507073, 0.040499285, 0.0044299364]]\n",
            "331            [[0.090767495, 0.7600634, 0.14916904]]\n",
            "332            [[0.951663, 0.043146722, 0.005190238]]\n",
            "333       [[0.0012105365, 0.00026055845, 0.99852884]]\n",
            "334          [[0.9654377, 0.03405453, 0.00050781766]]\n",
            "335            [[0.007125909, 0.04971644, 0.9431576]]\n",
            "336              [[0.331035, 0.27242345, 0.39654163]]\n",
            "337            [[0.1028225, 0.013606811, 0.88357073]]\n",
            "338        [[0.0024266455, 0.0008242403, 0.99674904]]\n",
            "339          [[0.056542225, 0.0002111526, 0.9432466]]\n",
            "340             [[0.3680052, 0.26138204, 0.37061274]]\n",
            "341        [[0.00027485465, 1.960836e-05, 0.9997055]]\n",
            "342        [[0.00076225516, 0.0062507535, 0.9929871]]\n",
            "343         [[8.472515e-05, 0.0005496746, 0.9993656]]\n",
            "344          [[0.036772948, 0.006311565, 0.95691544]]\n",
            "345     [[0.00080996274, 0.000118668904, 0.99907136]]\n",
            "346         [[0.0007380015, 0.0001497421, 0.9991123]]\n",
            "347             [[0.6942971, 0.15389037, 0.15181261]]\n",
            "348       [[0.00054824323, 3.3839526e-05, 0.9994179]]\n",
            "349       [[0.00054824323, 3.3839526e-05, 0.9994179]]\n",
            "350         [[0.8807988, 0.00049624656, 0.118704915]]\n",
            "351        [[0.9983259, 0.00059315516, 0.0010809804]]\n",
            "352       [[0.0006922675, 2.0072508e-05, 0.99928766]]\n",
            "353         [[0.00045408483, 0.9727103, 0.026835578]]\n",
            "354         [[0.003486162, 0.00026309685, 0.9962508]]\n",
            "355        [[0.0030349118, 2.7240469e-05, 0.9969379]]\n",
            "356             [[0.046405118, 0.06039594, 0.893199]]\n",
            "357            [[0.011422382, 0.14098637, 0.8475912]]\n",
            "358           [[0.01208205, 0.95080596, 0.037111968]]\n",
            "359         [[0.0018816935, 0.014191386, 0.98392683]]\n",
            "360          [[0.9721326, 0.0018680383, 0.025999382]]\n",
            "361          [[0.001761631, 0.9953354, 0.0029029874]]\n",
            "362         [[0.0014578573, 0.99529415, 0.003248017]]\n",
            "363        [[0.0017346236, 0.00024874136, 0.9980166]]\n",
            "364         [[0.000445132, 0.99655175, 0.0030031144]]\n",
            "365       [[0.00029171968, 0.99931157, 0.0003966684]]\n",
            "366       [[0.0002081996, 0.99962175, 0.00016997213]]\n",
            "367             [[0.36901325, 0.4086448, 0.22234192]]\n",
            "368        [[0.0022561613, 0.9972524, 0.00049145264]]\n",
            "369         [[0.0013427819, 0.00016323851, 0.998494]]\n",
            "370            [[0.009255903, 0.07208961, 0.9186545]]\n",
            "371         [[0.00094037195, 0.013821814, 0.9852378]]\n",
            "372       [[0.00038324375, 0.99538547, 0.0042313323]]\n",
            "373         [[0.0010536038, 1.043934e-05, 0.9989359]]\n",
            "374            [[0.0016900949, 0.5667178, 0.4315921]]\n",
            "375       [[0.00028778485, 8.705255e-06, 0.99970347]]\n",
            "376         [[0.0015861022, 0.0001226614, 0.9982912]]\n",
            "377        [[0.0022818523, 9.926667e-05, 0.99761885]]\n",
            "378           [[0.006072701, 0.56823504, 0.42569226]]\n",
            "379          [[0.001556163, 0.0007050183, 0.9977387]]\n",
            "380         [[0.00027673604, 0.9985185, 0.001204697]]\n",
            "381        [[0.0020011428, 0.00080062164, 0.9971982]]\n",
            "382            [[0.19407803, 0.7952756, 0.010646324]]\n",
            "383            [[0.009719106, 0.07812995, 0.9121509]]\n",
            "384            [[0.009719106, 0.07812995, 0.9121509]]\n",
            "385             [[0.01657699, 0.8093081, 0.17411491]]\n",
            "386        [[0.0017100157, 1.7762188e-05, 0.9982723]]\n",
            "387          [[0.004175753, 0.0016676828, 0.9941565]]\n",
            "388         [[0.0023587344, 7.052361e-05, 0.9975707]]\n",
            "389              [[0.06623734, 0.2906712, 0.6430915]]\n",
            "390          [[0.9047092, 0.00029491217, 0.09499588]]\n",
            "391       [[0.00041864146, 3.565356e-05, 0.99954575]]\n",
            "392         [[0.0028908006, 0.0022195664, 0.9948896]]\n",
            "393        [[0.0008178988, 9.4551746e-05, 0.9990876]]\n",
            "394        [[0.0014427144, 0.00016072486, 0.9983966]]\n",
            "395            [[0.0036645625, 0.3061372, 0.6901982]]\n",
            "396            [[0.002481864, 0.60775477, 0.3897634]]\n",
            "397           [[0.012674009, 0.85489136, 0.13243459]]\n",
            "398           [[0.001678674, 0.8749396, 0.123381734]]\n",
            "399          [[0.0060965572, 0.026331728, 0.9675716]]\n",
            "400      [[0.00048557232, 0.99932027, 0.00019416884]]\n",
            "401          [[0.00036364823, 0.9916829, 0.00795342]]\n",
            "402          [[0.0070902095, 0.14424102, 0.84866875]]\n",
            "403       [[0.00012410265, 0.99885476, 0.0010211585]]\n",
            "404          [[0.0012240729, 0.9921807, 0.006595266]]\n",
            "405         [[0.0010255895, 0.99317944, 0.005794963]]\n",
            "406      [[5.0917308e-05, 0.99942374, 0.00052536424]]\n",
            "407          [[0.00045028405, 0.9975247, 0.00202501]]\n",
            "408         [[0.00033663574, 0.9950906, 0.004572787]]\n",
            "409          [[0.0071222796, 0.52319634, 0.46968135]]\n",
            "410           [[0.0021665802, 0.09031387, 0.9075196]]\n",
            "411          [[0.00250301, 0.0075976346, 0.98989934]]\n",
            "412           [[0.0024134284, 0.09331238, 0.9042743]]\n",
            "413          [[0.0013941793, 0.9856469, 0.012958901]]\n",
            "414          [[0.0038728432, 0.62223566, 0.37389144]]\n",
            "415         [[0.99919075, 7.10544e-05, 0.0007380883]]\n",
            "416         [[0.001122252, 1.9485342e-05, 0.9988582]]\n",
            "417         [[0.008889266, 0.00016221752, 0.9909485]]\n",
            "418         [[0.043687496, 0.0004820978, 0.95583045]]\n",
            "419             [[0.02283395, 0.038453054, 0.938713]]\n",
            "420             [[0.02283395, 0.038453054, 0.938713]]\n",
            "421        [[0.0006438588, 0.0003567007, 0.99899954]]\n",
            "422           [[0.0064932667, 0.19706053, 0.7964462]]\n",
            "423        [[0.0014759736, 3.0252952e-05, 0.9984938]]\n",
            "424       [[0.0029909543, 0.00011171514, 0.99689734]]\n",
            "425         [[0.9987998, 3.999035e-05, 0.0011602257]]\n",
            "426          [[0.91563594, 0.0011860989, 0.08317795]]\n",
            "427       [[0.0016212772, 0.00073066755, 0.99764806]]\n",
            "428        [[0.0025799538, 0.0022297667, 0.99519026]]\n",
            "429       [[0.0026390012, 0.00012350013, 0.99723744]]\n",
            "430         [[0.0017565297, 5.096207e-05, 0.9981925]]\n",
            "431           [[0.0046797288, 0.024287425, 0.971033]]\n",
            "432        [[0.00069413736, 7.677387e-05, 0.9992291]]\n",
            "433        [[0.0011686016, 0.00012766916, 0.9987037]]\n",
            "434           [[0.04172615, 0.004630103, 0.95364374]]\n",
            "435         [[0.0017222221, 0.99121594, 0.007061827]]\n",
            "436        [[0.0010576466, 7.189778e-05, 0.99887043]]\n",
            "437       [[0.0006395937, 2.5653195e-05, 0.99933475]]\n",
            "438       [[0.00026167431, 5.7449393e-05, 0.9996809]]\n",
            "439          [[0.0006852768, 0.76228803, 0.23702666]]\n",
            "440        [[0.00043891268, 0.9948725, 0.0046886047]]\n",
            "441           [[0.0014098111, 0.03337684, 0.9652133]]\n",
            "442         [[0.0022597099, 0.006834006, 0.99090624]]\n",
            "443        [[0.00041028656, 0.0011470703, 0.9984427]]\n",
            "444           [[0.0014098111, 0.03337684, 0.9652133]]\n",
            "445       [[0.0006159155, 1.9086277e-05, 0.99936503]]\n",
            "446       [[0.0014462768, 2.6840304e-05, 0.99852693]]\n",
            "447        [[0.0006089941, 8.085847e-05, 0.99931014]]\n",
            "448           [[0.0014098111, 0.03337684, 0.9652133]]\n",
            "449        [[0.014748574, 0.98430693, 0.00094456016]]\n",
            "450        [[0.015691176, 0.98355526, 0.00075360894]]\n",
            "451            [[0.013390804, 0.60497075, 0.3816384]]\n",
            "452            [[0.0026145137, 0.9465896, 0.0507959]]\n",
            "453           [[0.021124098, 0.9476811, 0.031194782]]\n",
            "454          [[0.003059707, 0.97299767, 0.023942659]]\n",
            "455         [[0.0029521564, 0.93685895, 0.060188845]]\n",
            "456        [[0.0038570298, 0.00087609416, 0.9952669]]\n",
            "457          [[0.0034861604, 0.0003997766, 0.996114]]\n",
            "458          [[0.0034861604, 0.0003997766, 0.996114]]\n",
            "459        [[0.0014430721, 1.4793192e-05, 0.9985422]]\n",
            "460        [[0.0015983168, 4.2145795e-05, 0.9983595]]\n",
            "461       [[0.0011330321, 2.5464173e-05, 0.99884146]]\n",
            "462         [[0.00049421925, 0.00047573223, 0.99903]]\n",
            "463        [[0.0014430721, 1.4793192e-05, 0.9985422]]\n",
            "464             [[0.0019562, 0.16820617, 0.82983756]]\n",
            "465        [[0.00093824166, 1.767996e-05, 0.9990441]]\n",
            "466        [[0.00015145371, 0.9944246, 0.0054238853]]\n",
            "467       [[0.00042968473, 0.00010449786, 0.9994659]]\n",
            "468            [[0.30160692, 0.55046976, 0.14792332]]\n",
            "469           [[0.0050943475, 0.23596698, 0.7589387]]\n",
            "470             [[0.00136909, 0.5718042, 0.42682666]]\n",
            "471        [[0.95044345, 0.00046936414, 0.049087215]]\n",
            "472          [[0.0032787698, 0.001587958, 0.9951332]]\n",
            "473        [[0.95044345, 0.00046936414, 0.049087215]]\n",
            "474       [[0.0011051368, 0.00035355237, 0.99854136]]\n",
            "475          [[0.0032787698, 0.001587958, 0.9951332]]\n",
            "476          [[0.0032787698, 0.001587958, 0.9951332]]\n",
            "477          [[0.0032787698, 0.001587958, 0.9951332]]\n",
            "478        [[0.0021927976, 0.0065360228, 0.99127126]]\n",
            "479       [[0.0019332237, 6.2568855e-05, 0.99800426]]\n",
            "480          [[0.0040993677, 0.002495953, 0.9934047]]\n",
            "481         [[0.0017045384, 6.759844e-05, 0.9982279]]\n",
            "482         [[0.0077475104, 0.98367786, 0.008574693]]\n",
            "483        [[0.0008385209, 3.584117e-05, 0.99912566]]\n",
            "484        [[0.0010788161, 6.825305e-05, 0.99885297]]\n",
            "485          [[0.0022326326, 8.133763e-05, 0.997686]]\n",
            "486             [[0.011993505, 0.16346547, 0.824541]]\n",
            "487            [[0.008051432, 0.6104091, 0.38153952]]\n",
            "488          [[0.0036089898, 0.033392355, 0.9629986]]\n",
            "489          [[0.0019601386, 0.108272284, 0.8897676]]\n",
            "490         [[0.008057238, 0.0010750069, 0.99086773]]\n",
            "491       [[0.0002956945, 2.4858797e-05, 0.99967945]]\n",
            "492       [[0.0003323892, 1.8626497e-05, 0.99964905]]\n",
            "493        [[0.00045969582, 8.52206e-05, 0.99945515]]\n",
            "494         [[0.004165824, 9.362835e-05, 0.99574053]]\n",
            "495          [[0.0019601386, 0.108272284, 0.8897676]]\n",
            "496            [[0.054794207, 0.7598288, 0.18537702]]\n",
            "497            [[0.47198322, 0.22827396, 0.29974273]]\n",
            "498         [[0.00043914988, 0.00017086811, 0.99939]]\n",
            "499             [[0.01054188, 0.9230219, 0.06643615]]\n",
            "500        [[0.0007455419, 1.4172792e-05, 0.9992403]]\n",
            "501       [[0.0019274865, 0.00050743436, 0.99756515]]\n",
            "502           [[0.0018516061, 0.0730261, 0.92512226]]\n",
            "503        [[0.0012310678, 4.414498e-05, 0.99872476]]\n",
            "504         [[0.010938414, 0.00042544736, 0.9886361]]\n",
            "505         [[0.0057388204, 0.028684197, 0.96557695]]\n",
            "506         [[0.0029494872, 0.015605189, 0.98144525]]\n",
            "507         [[0.0008932658, 0.97768754, 0.021419192]]\n",
            "508           [[0.041744325, 0.83329463, 0.12496101]]\n",
            "509         [[0.0016577839, 0.024050463, 0.97429186]]\n",
            "510       [[0.00017592276, 9.768952e-06, 0.99981433]]\n",
            "511        [[0.0005353267, 4.7437943e-06, 0.9994599]]\n",
            "512        [[0.00073226617, 5.451191e-06, 0.9992623]]\n",
            "513          [[0.000701049, 6.421172e-06, 0.9992925]]\n",
            "514         [[0.0012951611, 5.551443e-06, 0.9986992]]\n",
            "515          [[0.006499955, 0.0026889518, 0.9908111]]\n",
            "516        [[0.0014744947, 0.00033427836, 0.9981913]]\n",
            "517             [[0.012698987, 0.626491, 0.36080998]]\n",
            "518          [[0.0034589332, 0.9948342, 0.001706902]]\n",
            "519        [[0.0021425528, 0.00086234976, 0.9969951]]\n",
            "520         [[0.0012457513, 0.003111687, 0.99564254]]\n",
            "521        [[0.0007134289, 8.043577e-05, 0.99920624]]\n",
            "522        [[0.0008296127, 7.2670715e-05, 0.9990977]]\n",
            "523       [[0.00081637484, 2.0818012e-05, 0.9991628]]\n",
            "524       [[0.0006686853, 1.9327887e-05, 0.99931204]]\n",
            "525      [[0.00049164385, 4.5228666e-05, 0.99946314]]\n",
            "526            [[0.01070591, 0.013590875, 0.9757032]]\n",
            "527        [[0.0006679958, 4.3598084e-05, 0.9992884]]\n",
            "528         [[0.0025594153, 4.395068e-05, 0.9973966]]\n",
            "529            [[0.007950687, 0.032568302, 0.959481]]\n",
            "530             [[0.15101567, 0.00233075, 0.8466536]]\n",
            "531        [[0.0063571827, 0.00020754212, 0.9934354]]\n",
            "532       [[0.00027751614, 1.5107261e-05, 0.9997073]]\n",
            "533       [[0.00039459488, 1.1787714e-05, 0.9995937]]\n",
            "534           [[0.003068113, 0.07535027, 0.92158157]]\n",
            "535          [[0.0005692075, 0.016617058, 0.9828137]]\n",
            "536           [[0.0011466448, 0.31565502, 0.6831983]]\n",
            "537        [[0.0040214323, 7.427121e-05, 0.99590427]]\n",
            "538             [[0.84322, 0.15182146, 0.0049585146]]\n",
            "539            [[0.023208816, 0.9683232, 0.00846802]]\n",
            "540         [[0.013113547, 0.0007002281, 0.98618627]]\n",
            "541             [[0.16527697, 0.7921298, 0.04259321]]\n",
            "542         [[0.004612116, 0.0043483647, 0.99103945]]\n",
            "543        [[0.0017113455, 0.0027101187, 0.99557847]]\n",
            "544         [[0.0007946324, 0.0006895148, 0.9985158]]\n",
            "545       [[0.00064310344, 0.00017580783, 0.9991811]]\n",
            "546        [[0.00030239814, 0.98403406, 0.015663542]]\n",
            "547         [[0.005217526, 2.8880339e-05, 0.9947535]]\n",
            "548        [[0.0051661558, 7.0557035e-05, 0.9947633]]\n",
            "549      [[0.00037675342, 0.00014943816, 0.99947387]]\n",
            "550       [[0.99673814, 0.00014733488, 0.0031145005]]\n",
            "551            [[0.006433828, 0.60154855, 0.3920176]]\n",
            "552         [[0.0010937259, 0.010274227, 0.98863214]]\n",
            "553           [[0.0045459494, 0.4719749, 0.52347916]]\n",
            "554        [[0.00038655385, 0.0024177928, 0.9971956]]\n",
            "555        [[0.00038655385, 0.0024177928, 0.9971956]]\n",
            "556        [[0.0005662878, 4.5032404e-05, 0.9993887]]\n",
            "557         [[0.0001925149, 9.080458e-05, 0.9997167]]\n",
            "558         [[0.0005891751, 9.960343e-05, 0.9993112]]\n",
            "559            [[0.046613593, 0.45508522, 0.4983012]]\n",
            "560           [[0.012054522, 0.12942235, 0.85852313]]\n",
            "561           [[0.019029157, 0.42524272, 0.55572814]]\n",
            "562          [[0.0011049337, 0.006221903, 0.9926732]]\n",
            "563         [[0.0016407018, 0.004493687, 0.99386567]]\n",
            "564       [[0.00079928566, 2.4005063e-05, 0.9991767]]\n",
            "565         [[0.056989104, 0.00027827508, 0.9427326]]\n",
            "566            [[0.03558031, 0.48937774, 0.47504187]]\n",
            "567         [[0.0018072001, 0.0030251548, 0.9951676]]\n",
            "568        [[0.0013104945, 0.0132881645, 0.98540133]]\n",
            "569      [[0.00020011571, 0.00027374364, 0.99952626]]\n",
            "570       [[0.0006819299, 0.00029517614, 0.99902284]]\n",
            "571       [[0.00012073104, 0.00015993213, 0.9997193]]\n",
            "572      [[0.00037533604, 1.5697084e-05, 0.99960893]]\n",
            "573      [[0.00027893952, 5.1657997e-05, 0.99966943]]\n",
            "574          [[0.0004039049, 4.806676e-05, 0.999548]]\n",
            "575            [[0.004967121, 0.26143894, 0.7335939]]\n",
            "576          [[0.0013878136, 0.64510506, 0.35350716]]\n",
            "577           [[0.003176662, 0.79839265, 0.19843064]]\n",
            "578       [[0.99831116, 4.8454403e-05, 0.0016403549]]\n",
            "579       [[0.99831116, 4.8454403e-05, 0.0016403549]]\n",
            "580        [[0.9973099, 0.00012255312, 0.0025675376]]\n",
            "581            [[0.6199453, 0.024183037, 0.35587165]]\n",
            "582      [[0.00082990073, 3.3322867e-05, 0.99913675]]\n",
            "583        [[0.0006833418, 1.8576804e-05, 0.9992981]]\n",
            "584            [[0.058696076, 0.1711214, 0.77018255]]\n",
            "585        [[0.00042010317, 5.2928877e-05, 0.999527]]\n",
            "586           [[0.9943229, 0.003749128, 0.001927909]]\n",
            "587        [[0.006899489, 0.00017033808, 0.99293023]]\n",
            "588          [[0.040933214, 0.013624846, 0.94544196]]\n",
            "589       [[0.0039375816, 0.99584454, 0.00021790338]]\n",
            "590       [[0.00047831642, 1.3949893e-05, 0.9995078]]\n",
            "591         [[0.0030186637, 0.0007814115, 0.9961999]]\n",
            "592         [[0.008794372, 6.0876006e-05, 0.9911447]]\n",
            "593         [[0.04299107, 2.8704446e-05, 0.95698017]]\n",
            "594        [[0.0016940016, 2.001868e-05, 0.99828595]]\n",
            "595           [[0.037177686, 0.47044972, 0.49237254]]\n",
            "596        [[0.0029237359, 5.8097452e-05, 0.9970182]]\n",
            "597       [[0.0026249834, 3.3477965e-05, 0.99734145]]\n",
            "598         [[0.0011371935, 3.830855e-05, 0.9988244]]\n",
            "599            [[0.0036517477, 0.05764331, 0.938705]]\n",
            "600          [[0.00092972355, 8.8706e-06, 0.9990615]]\n",
            "601              [[0.271794, 0.046014942, 0.6821911]]\n",
            "602        [[0.0009879823, 2.783449e-05, 0.99898416]]\n",
            "603         [[0.0004695716, 2.072997e-05, 0.9995097]]\n",
            "604         [[0.012638368, 0.0103985965, 0.97696304]]\n",
            "605        [[0.0015551924, 0.00051265606, 0.9979322]]\n",
            "606            [[0.004118122, 0.0779046, 0.91797733]]\n",
            "607          [[0.15777911, 0.0009907514, 0.84123015]]\n",
            "608        [[0.00035005528, 2.0864207e-05, 0.999629]]\n",
            "609         [[0.0010871368, 0.0049594194, 0.9939534]]\n",
            "610       [[0.00045637295, 4.293808e-05, 0.99950075]]\n",
            "611         [[0.0023863015, 0.0007929847, 0.9968207]]\n",
            "612        [[0.0015224682, 0.00022294925, 0.9982545]]\n",
            "613          [[0.002383034, 9.17744e-05, 0.99752516]]\n",
            "614           [[0.0067633274, 0.8579108, 0.13532588]]\n",
            "615            [[0.9484621, 0.03191344, 0.019624405]]\n",
            "616          [[0.19876143, 0.0033861673, 0.79785246]]\n",
            "617       [[0.0013027419, 0.00024416877, 0.99845314]]\n",
            "618        [[0.00032773026, 3.88466e-05, 0.99963343]]\n",
            "619       [[0.00021988488, 0.99711335, 0.0026667637]]\n",
            "620         [[0.0033615965, 0.99140817, 0.005230184]]\n",
            "621        [[0.00017446009, 0.9992142, 0.0006112992]]\n",
            "622           [[0.0014090177, 0.16980082, 0.8287902]]\n",
            "623           [[0.0014090177, 0.16980082, 0.8287902]]\n",
            "624       [[0.0028695955, 0.99690163, 0.00022885556]]\n",
            "625        [[0.0018952751, 0.9980034, 0.00010124925]]\n",
            "626       [[0.00079799857, 4.6526362e-05, 0.9991554]]\n",
            "627              [[0.05532785, 0.1161085, 0.8285636]]\n",
            "628        [[0.00019168245, 0.98938227, 0.010426079]]\n",
            "629         [[4.206069e-05, 0.9987037, 0.0012541708]]\n",
            "630        [[7.270222e-05, 6.090926e-05, 0.99986637]]\n",
            "631        [[0.00010052063, 7.295993e-05, 0.9998266]]\n",
            "632        [[8.026967e-05, 0.0002916757, 0.99962795]]\n",
            "633        [[0.00015462353, 6.740615e-06, 0.9998386]]\n",
            "634       [[0.00018036539, 6.0805837e-06, 0.9998136]]\n",
            "635        [[0.001568884, 4.6346828e-05, 0.99838483]]\n",
            "636       [[0.0017291562, 3.7796617e-05, 0.99823296]]\n",
            "637           [[0.024445003, 0.06816218, 0.90739274]]\n",
            "638            [[0.99595, 0.0008331975, 0.003216786]]\n",
            "639            [[0.99595, 0.0008331975, 0.003216786]]\n",
            "640       [[0.0017435063, 0.00050979713, 0.99774665]]\n",
            "641         [[0.022284849, 0.9774204, 0.00029477646]]\n",
            "642           [[0.5941352, 0.00015746972, 0.4057073]]\n",
            "643      [[0.00070341805, 2.0690757e-05, 0.99927586]]\n",
            "644         [[0.0033650438, 0.015151121, 0.98148376]]\n",
            "645         [[0.0013853604, 0.0003599741, 0.9982546]]\n",
            "646              [[0.003467574, 0.712683, 0.2838494]]\n",
            "647       [[0.0017435063, 0.00050979713, 0.99774665]]\n",
            "648          [[0.0032611045, 0.79919857, 0.19754033]]\n",
            "649           [[0.0035900655, 0.25905868, 0.7373513]]\n",
            "650         [[0.0033650438, 0.015151121, 0.98148376]]\n",
            "651            [[0.0042473655, 0.519255, 0.47649768]]\n",
            "652           [[0.936884, 0.061347365, 0.0017686926]]\n",
            "653           [[0.92623156, 0.010438133, 0.06333032]]\n",
            "654        [[0.00048930565, 9.55041e-05, 0.99941516]]\n",
            "655        [[0.0012349153, 1.31391735e-05, 0.998752]]\n",
            "656         [[0.010287804, 0.98502976, 0.0046823923]]\n",
            "657          [[0.0005146757, 4.5235556e-05, 0.99944]]\n",
            "658        [[0.0008882512, 8.714575e-06, 0.99910307]]\n",
            "659        [[0.00095702417, 0.043997247, 0.95504576]]\n",
            "660        [[0.00062308414, 7.318505e-05, 0.9993038]]\n",
            "661         [[0.0004298055, 2.936759e-05, 0.9995409]]\n",
            "662        [[0.0011741207, 0.00085859303, 0.9979673]]\n",
            "663       [[0.00062551274, 0.00011344912, 0.9992611]]\n",
            "664         [[0.001874872, 0.00023434973, 0.9978908]]\n",
            "665            [[0.008020349, 0.17341053, 0.8185691]]\n",
            "666            [[0.051047396, 0.0049426532, 0.94401]]\n",
            "667            [[0.10684668, 0.048772812, 0.8443805]]\n",
            "668        [[0.0051081455, 0.00082165084, 0.9940701]]\n",
            "669           [[0.0037494856, 0.01584869, 0.9804018]]\n",
            "670          [[0.0035868662, 0.027079416, 0.9693337]]\n",
            "671        [[0.0016811484, 0.0006860426, 0.99763274]]\n",
            "672            [[0.034796145, 0.7746142, 0.19058965]]\n",
            "673         [[0.003291997, 0.9960671, 0.00064096524]]\n",
            "674         [[0.0012472181, 0.9952614, 0.0034914075]]\n",
            "675           [[0.037040923, 0.37405547, 0.58890355]]\n",
            "676            [[0.3969362, 0.6010945, 0.0019693137]]\n",
            "677             [[0.8863496, 0.09736496, 0.01628546]]\n",
            "678          [[0.06289171, 0.93183523, 0.0052731195]]\n",
            "679           [[0.013608411, 0.9818611, 0.004530445]]\n",
            "680            [[0.08138688, 0.9043482, 0.014264979]]\n",
            "681          [[0.9810699, 0.0067702564, 0.012159762]]\n",
            "682          [[0.9959197, 0.0028901575, 0.001190093]]\n",
            "683        [[0.020072604, 0.97978365, 0.00014368905]]\n",
            "684            [[0.011777827, 0.08769266, 0.9005295]]\n",
            "685       [[0.0022878596, 1.5793737e-05, 0.99769634]]\n",
            "686           [[0.012803074, 0.17033762, 0.81685936]]\n",
            "687         [[0.0018339896, 0.97762007, 0.020545928]]\n",
            "688           [[0.013053508, 0.59145576, 0.39549077]]\n",
            "689       [[0.99937385, 9.385955e-05, 0.00053229806]]\n",
            "690       [[0.0031047913, 1.4050348e-05, 0.99688125]]\n",
            "691          [[0.0022638426, 0.75508684, 0.24264933]]\n",
            "692        [[0.00015894625, 0.9983724, 0.0014686785]]\n",
            "693          [[0.0064111315, 0.83787674, 0.15571217]]\n",
            "694          [[0.0022638426, 0.75508684, 0.24264933]]\n",
            "695         [[0.0013193071, 0.9983463, 0.0003343698]]\n",
            "696            [[0.0012658441, 0.408787, 0.58994716]]\n",
            "697           [[0.000810709, 0.023480799, 0.9757085]]\n",
            "698       [[0.00046570483, 9.3219016e-05, 0.9994411]]\n",
            "699      [[0.00032655188, 2.1909767e-05, 0.99965155]]\n",
            "700          [[0.0014056904, 0.002452869, 0.9961415]]\n",
            "701          [[0.0002779292, 0.000699478, 0.9990226]]\n",
            "702          [[0.0015198042, 0.87183636, 0.12664382]]\n",
            "703       [[0.00049769133, 8.3722545e-05, 0.9994186]]\n",
            "704         [[0.0004407185, 0.0002504647, 0.9993087]]\n",
            "705       [[0.00055235066, 9.060506e-05, 0.99935704]]\n",
            "706           [[0.012355309, 0.39028266, 0.59736204]]\n",
            "707             [[0.7003612, 0.18283004, 0.11680871]]\n",
            "708          [[7.099939e-05, 0.997769, 0.0021600472]]\n",
            "709          [[0.0015198042, 0.87183636, 0.12664382]]\n",
            "710            [[0.022993688, 0.24225046, 0.7347559]]\n",
            "711           [[0.014855718, 0.94517356, 0.03997074]]\n",
            "712            [[0.0061149965, 0.1022428, 0.8916423]]\n",
            "713          [[0.0003770201, 0.9851296, 0.014493391]]\n",
            "714        [[0.0005883214, 4.0907995e-05, 0.9993709]]\n",
            "715         [[0.00045792214, 0.9654655, 0.034076553]]\n",
            "716          [[0.042276658, 0.0093617365, 0.9483616]]\n",
            "717             [[0.7003612, 0.18283004, 0.11680871]]\n",
            "718          [[0.16566305, 0.83010906, 0.0042279274]]\n",
            "719           [[0.07395811, 0.011973845, 0.91406804]]\n",
            "720       [[0.00070413004, 0.9990108, 0.00028504198]]\n",
            "721        [[0.00065783784, 0.99880886, 0.000533297]]\n",
            "722           [[0.023139235, 0.062286615, 0.9145742]]\n",
            "723        [[0.00029410637, 0.00022092558, 0.999485]]\n",
            "724             [[0.27566898, 0.0198699, 0.70446104]]\n",
            "725            [[0.809117, 0.0067657596, 0.18411718]]\n",
            "726          [[0.85795826, 0.0014710228, 0.14057067]]\n",
            "727            [[0.14542943, 0.00619537, 0.84837526]]\n",
            "728           [[0.0022258868, 0.16540548, 0.8323687]]\n",
            "729         [[0.0012406033, 8.584791e-06, 0.9987508]]\n",
            "730         [[0.009334418, 0.0057300637, 0.98493564]]\n",
            "731              [[0.28649104, 0.5021378, 0.2113712]]\n",
            "732          [[0.002216368, 0.00036466846, 0.997419]]\n",
            "733            [[0.053081315, 0.69739115, 0.2495275]]\n",
            "734         [[0.0050487304, 0.0022358492, 0.9927154]]\n",
            "735              [[0.28649104, 0.5021378, 0.2113712]]\n",
            "736          [[0.027252717, 0.94811237, 0.024634931]]\n",
            "737           [[0.014144337, 0.9680416, 0.017814066]]\n",
            "738             [[0.27219495, 0.19151653, 0.5362885]]\n",
            "739              [[0.28649104, 0.5021378, 0.2113712]]\n",
            "740          [[0.012308528, 0.0040261922, 0.9836653]]\n",
            "741           [[0.0036163174, 0.5897908, 0.40659285]]\n",
            "742           [[0.0041925637, 0.7408376, 0.25496992]]\n",
            "743           [[0.0014341992, 0.09196326, 0.9066026]]\n",
            "744          [[0.0024141818, 0.104071364, 0.8935145]]\n",
            "745         [[0.0013431682, 0.98309165, 0.015565162]]\n",
            "746           [[0.0036163174, 0.5897908, 0.40659285]]\n",
            "747       [[0.0024679564, 5.6518948e-05, 0.99747556]]\n",
            "748           [[0.0036163174, 0.5897908, 0.40659285]]\n",
            "749        [[0.0026019262, 0.00018415709, 0.9972139]]\n",
            "750          [[0.0024286567, 0.060349498, 0.9372219]]\n",
            "751        [[0.0070595485, 0.00027931537, 0.9926611]]\n",
            "752         [[0.97868574, 0.0077438946, 0.013570436]]\n",
            "753           [[0.0037585916, 0.10783152, 0.8884098]]\n",
            "754         [[0.0022591297, 0.0018032235, 0.9959377]]\n",
            "755           [[0.0028531563, 0.19508703, 0.8020597]]\n",
            "756         [[0.0004721714, 0.97774637, 0.021781461]]\n",
            "757       [[0.0012109869, 1.9032646e-05, 0.99876994]]\n",
            "758           [[0.002244194, 0.45884788, 0.53890795]]\n",
            "759         [[0.0011681112, 0.00012385707, 0.998708]]\n",
            "760         [[0.0012630919, 8.092901e-05, 0.9986559]]\n",
            "761           [[0.0021961424, 0.97269815, 0.0251057]]\n",
            "762         [[0.0024934458, 0.97937965, 0.018126946]]\n",
            "763         [[0.0049865027, 4.372078e-05, 0.9949698]]\n",
            "764            [[0.16645885, 0.09923108, 0.73431003]]\n",
            "765            [[0.1912742, 0.0022165112, 0.8065093]]\n",
            "766            [[0.052518725, 0.4924832, 0.45499808]]\n",
            "767            [[0.1637177, 0.80483216, 0.031450137]]\n",
            "768            [[0.8781403, 0.0026452548, 0.1192145]]\n",
            "769              [[0.2742042, 0.4749204, 0.25087544]]\n",
            "770       [[0.00074345875, 0.99348444, 0.0057720807]]\n",
            "771            [[0.40903518, 0.25802112, 0.33294365]]\n",
            "772            [[0.02273733, 0.9202792, 0.056983452]]\n",
            "773         [[0.0010314127, 0.97652197, 0.022446621]]\n",
            "774         [[0.00085962366, 0.9742662, 0.024874166]]\n",
            "775            [[0.012118666, 0.42451656, 0.5633648]]\n",
            "776       [[0.00045202483, 0.00023623103, 0.9993118]]\n",
            "777        [[0.0027685591, 2.9508616e-05, 0.9972019]]\n",
            "778         [[0.0007118108, 0.9973592, 0.0019289695]]\n",
            "779        [[0.00072625256, 0.9974548, 0.0018189513]]\n",
            "780         [[0.0021047536, 3.2235115e-05, 0.997863]]\n",
            "781       [[0.0026629788, 0.00025441614, 0.99708265]]\n",
            "782        [[0.0003718218, 0.00079584424, 0.9988323]]\n",
            "783       [[0.00051626307, 2.4068422e-05, 0.9994597]]\n",
            "784       [[0.00075081806, 0.0008351362, 0.99841404]]\n",
            "785           [[0.0140250195, 0.8911488, 0.09482622]]\n",
            "786            [[0.68157876, 0.015456811, 0.3029645]]\n",
            "787          [[0.008643273, 0.038863186, 0.95249355]]\n",
            "788        [[0.0017636861, 1.1056149e-05, 0.9982253]]\n",
            "789       [[0.00054905604, 5.0243045e-05, 0.9994006]]\n",
            "790         [[0.9979119, 7.958103e-05, 0.0020085154]]\n",
            "791           [[0.069757335, 0.42723802, 0.50300467]]\n",
            "792       [[0.9968785, 0.000110774774, 0.0030107428]]\n",
            "793        [[0.0011724571, 0.0028765309, 0.99595106]]\n",
            "794          [[0.0021196792, 0.104872786, 0.8930075]]\n",
            "795         [[0.041397214, 0.95533276, 0.0032699588]]\n",
            "796       [[0.00035667676, 0.9992555, 0.00038782455]]\n",
            "797       [[0.00071355863, 0.9987638, 0.00052262226]]\n",
            "798         [[0.0031794542, 0.9953992, 0.0014214051]]\n",
            "799           [[0.002811862, 0.9191205, 0.078067645]]\n",
            "800        [[0.00043591057, 0.9988399, 0.0007242393]]\n",
            "801          [[0.27775326, 0.72041184, 0.0018348815]]\n",
            "802         [[0.0006836933, 0.9976071, 0.0017091769]]\n",
            "803        [[0.0005672052, 5.5597935e-05, 0.9993772]]\n",
            "804       [[0.00053834333, 4.3067626e-05, 0.9994186]]\n",
            "805            [[0.016151069, 0.31216466, 0.6716843]]\n",
            "806            [[0.36691785, 0.18881844, 0.44426373]]\n",
            "807         [[0.004023308, 0.0007642382, 0.99521244]]\n",
            "808          [[0.0025837317, 0.67812276, 0.31929347]]\n",
            "809           [[0.0018446356, 0.8272234, 0.17093189]]\n",
            "810          [[0.007867336, 2.465951e-05, 0.9921079]]\n",
            "811          [[0.0025151586, 1.287389e-05, 0.997472]]\n",
            "812          [[0.0010375589, 0.9164327, 0.082529716]]\n",
            "813            [[0.007984813, 0.14878595, 0.8432293]]\n",
            "814           [[0.0062141563, 0.8883525, 0.10543334]]\n",
            "815             [[0.05128745, 0.8936765, 0.05503609]]\n",
            "816             [[0.05128745, 0.8936765, 0.05503609]]\n",
            "817          [[0.0074496837, 0.29895365, 0.69359666]]\n",
            "818          [[0.55563927, 0.0009474389, 0.44341332]]\n",
            "819        [[0.0008827992, 1.6886528e-05, 0.9991003]]\n",
            "820         [[0.00036182348, 6.47949e-05, 0.9995734]]\n",
            "821          [[0.0028181386, 0.36926392, 0.62791795]]\n",
            "822         [[0.076652706, 0.0054134345, 0.91793394]]\n",
            "823        [[0.0019926208, 5.825289e-05, 0.99794906]]\n",
            "824         [[0.9928883, 0.0029249087, 0.0041867523]]\n",
            "825         [[0.99247813, 0.0018664018, 0.005655423]]\n",
            "826        [[0.0010018498, 1.0508666e-05, 0.9989876]]\n",
            "827       [[0.0018193583, 2.6757247e-05, 0.99815387]]\n",
            "828       [[0.0014313646, 0.00035561723, 0.99821305]]\n",
            "829        [[0.0009104742, 0.00014471104, 0.9989448]]\n",
            "830        [[0.0012295003, 1.0415827e-05, 0.9987601]]\n",
            "831       [[0.0018193583, 2.6757247e-05, 0.99815387]]\n",
            "832          [[0.0010390895, 4.26873e-05, 0.9989183]]\n",
            "833       [[0.0017135997, 0.00016948416, 0.99811697]]\n",
            "834           [[0.5727736, 0.0012922978, 0.42593417]]\n",
            "835         [[0.001672966, 2.4191711e-05, 0.9983028]]\n",
            "836         [[0.0008984641, 0.0016539326, 0.9974476]]\n",
            "837        [[0.0008639422, 0.0056360774, 0.99349993]]\n",
            "838          [[0.000728901, 0.0029947737, 0.9962763]]\n",
            "839        [[0.0050621796, 0.00017818063, 0.9947596]]\n",
            "840          [[0.042096116, 0.0022892246, 0.9556146]]\n",
            "841         [[0.83818245, 0.00069189334, 0.16112556]]\n",
            "842         [[0.0020326278, 0.0013506315, 0.9966168]]\n",
            "843       [[0.0003635438, 0.00070567685, 0.99893075]]\n",
            "844          [[0.0058575687, 0.9683516, 0.025790835]]\n",
            "845       [[0.00094926334, 4.0342882e-05, 0.9990103]]\n",
            "846       [[0.0009037143, 2.1263579e-05, 0.99907494]]\n",
            "847       [[0.00075403927, 2.2260467e-05, 0.9992237]]\n",
            "848        [[0.0010564603, 0.00037537998, 0.9985682]]\n",
            "849        [[0.0012950993, 0.00066936435, 0.9980356]]\n",
            "850       [[0.0013658057, 0.00018041887, 0.99845374]]\n",
            "851       [[0.00084347575, 1.2894161e-05, 0.9991436]]\n",
            "852        [[0.0012249069, 1.1884602e-05, 0.9987632]]\n",
            "853        [[0.0013675959, 2.2038845e-05, 0.9986104]]\n",
            "854        [[0.0032782145, 0.0064241276, 0.99029773]]\n",
            "855          [[0.003180514, 0.0021169856, 0.9947025]]\n",
            "856           [[0.0038917086, 0.003463183, 0.992645]]\n",
            "857         [[0.0012415692, 6.130782e-05, 0.9986971]]\n",
            "858          [[0.5656033, 0.00081322336, 0.43358347]]\n",
            "859             [[0.08329331, 0.048874754, 0.867832]]\n",
            "860       [[0.99892634, 0.00043821294, 0.0006354484]]\n",
            "861         [[0.0044387607, 0.0019179999, 0.9936433]]\n",
            "862        [[0.00020714766, 0.9978536, 0.0019392632]]\n",
            "863         [[0.97679514, 0.017457267, 0.0057476866]]\n",
            "864             [[0.004171965, 0.28560603, 0.710222]]\n",
            "865        [[0.0004364858, 0.00015011299, 0.9994134]]\n",
            "866            [[0.018573565, 0.6573347, 0.32409176]]\n",
            "867             [[0.0014859979, 0.43237403, 0.56614]]\n",
            "868         [[0.00069783477, 0.000427623, 0.9988746]]\n",
            "869         [[0.22658633, 0.77266085, 0.00075280934]]\n",
            "870         [[0.0028827887, 0.9953165, 0.0018007397]]\n",
            "871              [[0.03557053, 0.9067289, 0.0577006]]\n",
            "872              [[0.03557053, 0.9067289, 0.0577006]]\n",
            "873           [[0.0029201817, 0.28782403, 0.7092558]]\n",
            "874            [[0.6087988, 0.015765147, 0.37543604]]\n",
            "875            [[0.61728925, 0.10328102, 0.27942967]]\n",
            "876            [[0.012821995, 0.9746732, 0.01250478]]\n",
            "877           [[0.004493008, 0.10828533, 0.88722163]]\n",
            "878        [[0.0010905637, 0.00017833515, 0.9987311]]\n",
            "879         [[0.0008300213, 0.0017132681, 0.9974567]]\n",
            "880         [[0.9946313, 0.0041232593, 0.0012454555]]\n",
            "881            [[0.21346606, 0.7818187, 0.004715302]]\n",
            "882         [[0.99549425, 0.003676482, 0.0008292822]]\n",
            "883         [[0.018651955, 0.0037446911, 0.97760344]]\n",
            "884        [[0.0074574007, 0.0068771923, 0.98566544]]\n",
            "885          [[0.004572967, 1.070454e-05, 0.9954164]]\n",
            "886        [[0.0002845706, 1.4267484e-05, 0.9997011]]\n",
            "887          [[0.0011829588, 0.043013886, 0.9558032]]\n",
            "888            [[0.011812313, 0.12872942, 0.8594583]]\n",
            "889          [[0.02390919, 0.0005823441, 0.97550845]]\n",
            "890         [[0.000954959, 0.00018638476, 0.9988587]]\n",
            "891        [[0.0022065067, 0.00018693405, 0.9976065]]\n",
            "892            [[0.00655017, 0.058293503, 0.9351563]]\n",
            "893          [[0.00095550047, 6.445773e-05, 0.99898]]\n",
            "894         [[0.00069175195, 0.998495, 0.0008132638]]\n",
            "895         [[0.0011679342, 0.99490875, 0.003923345]]\n",
            "896         [[0.0009573407, 0.0022970273, 0.9967456]]\n",
            "897        [[0.0005743929, 5.921761e-05, 0.99936646]]\n",
            "898        [[0.00034727892, 2.189315e-05, 0.9996308]]\n",
            "899          [[0.000320394, 4.427342e-05, 0.9996352]]\n",
            "900     [[0.00023656088, 1.40776765e-05, 0.99974936]]\n",
            "901          [[0.004580906, 0.98729646, 0.008122661]]\n",
            "902         [[0.98474115, 0.0039037776, 0.011355073]]\n",
            "903          [[0.8759266, 0.122771576, 0.0013017971]]\n",
            "904          [[0.8759266, 0.122771576, 0.0013017971]]\n",
            "905          [[0.0716391, 0.92747504, 0.00088588096]]\n",
            "906          [[0.018666204, 0.93061763, 0.050716117]]\n",
            "907            [[0.8953531, 0.1033577, 0.0012892286]]\n",
            "908            [[0.16674294, 0.76837134, 0.06488578]]\n",
            "909             [[0.31454954, 0.18237002, 0.5030804]]\n",
            "910           [[0.9568097, 0.034121674, 0.009068599]]\n",
            "911            [[0.038579423, 0.1360536, 0.82536685]]\n",
            "912       [[0.99274325, 0.00045138417, 0.0068054064]]\n",
            "913           [[0.67228836, 0.32514185, 0.002569778]]\n",
            "914            [[0.35114318, 0.023123525, 0.6257333]]\n",
            "915         [[0.0008000223, 0.0010933265, 0.9981066]]\n",
            "916          [[0.99415934, 0.00426813, 0.0015725811]]\n",
            "917          [[0.99415934, 0.00426813, 0.0015725811]]\n",
            "918          [[0.20362641, 0.79314506, 0.0032285315]]\n",
            "919          [[0.0059864563, 0.20692444, 0.78708917]]\n",
            "920        [[0.0010242085, 0.9986388, 0.00033697355]]\n",
            "921         [[0.98093075, 0.018474676, 0.0005945134]]\n",
            "922         [[0.0033145128, 0.9959978, 0.0006877085]]\n",
            "923             [[0.007571194, 0.7259099, 0.2665189]]\n",
            "924            [[0.01886005, 0.52854604, 0.45259386]]\n",
            "925            [[0.01886005, 0.52854604, 0.45259386]]\n",
            "926          [[0.0062566064, 0.8706136, 0.123129845]]\n",
            "927          [[0.0025821459, 0.98923373, 0.00818418]]\n",
            "928         [[0.0026033923, 0.0016636227, 0.9957331]]\n",
            "929            [[0.004081981, 0.08468826, 0.9112297]]\n",
            "930             [[0.00561825, 0.048305664, 0.946076]]\n",
            "931         [[0.0008107133, 6.285326e-05, 0.9991264]]\n",
            "932           [[0.0050529535, 0.8410894, 0.15385765]]\n",
            "933        [[0.0022462222, 0.0076546296, 0.99009913]]\n",
            "934            [[0.850364, 7.383075e-05, 0.14956222]]\n",
            "935            [[0.850364, 7.383075e-05, 0.14956222]]\n",
            "936         [[0.0025306682, 4.661345e-05, 0.9974227]]\n",
            "937              [[0.08145255, 0.109597504, 0.80895]]\n",
            "938        [[0.0010420044, 1.40925185e-05, 0.998944]]\n",
            "939           [[0.017774617, 0.59543645, 0.38678893]]\n",
            "940           [[0.008447049, 0.06724103, 0.92431194]]\n",
            "941           [[0.013563776, 0.18512356, 0.80131257]]\n",
            "942              [[0.08145255, 0.109597504, 0.80895]]\n",
            "943         [[0.0003702128, 2.553466e-05, 0.9996043]]\n",
            "944        [[0.000656781, 1.9265144e-05, 0.99932396]]\n",
            "945         [[0.0015442026, 0.004888608, 0.99356717]]\n",
            "946          [[0.0031643193, 0.005213236, 0.9916225]]\n",
            "947       [[0.0010278112, 0.00016651214, 0.99880576]]\n",
            "948           [[0.0029571848, 0.17650768, 0.8205351]]\n",
            "949        [[0.0013040977, 0.00031867065, 0.9983772]]\n",
            "950          [[0.0031643193, 0.005213236, 0.9916225]]\n",
            "951           [[0.0044379886, 0.38170558, 0.6138564]]\n",
            "952           [[0.0016658008, 0.49701747, 0.5013167]]\n",
            "953          [[0.0006459879, 0.12893853, 0.87041545]]\n",
            "954          [[0.039337873, 0.076904595, 0.88375753]]\n",
            "955        [[0.0008495979, 0.0103685325, 0.98878187]]\n",
            "956      [[0.00035896155, 0.00029076688, 0.99935025]]\n",
            "957         [[0.0005672154, 1.95214e-05, 0.99941325]]\n",
            "958       [[0.0019790158, 0.00056292623, 0.99745816]]\n",
            "959       [[0.0019790158, 0.00056292623, 0.99745816]]\n",
            "960       [[0.0027746044, 0.00010523977, 0.99712026]]\n",
            "961       [[0.00089555746, 2.8309287e-05, 0.9990761]]\n",
            "962          [[0.0016804698, 2.655728e-05, 0.998293]]\n",
            "963       [[0.0022105754, 2.3794646e-05, 0.99776566]]\n",
            "964             [[0.31889758, 0.2850364, 0.39606607]]\n",
            "965       [[0.0027746044, 0.00010523977, 0.99712026]]\n",
            "966             [[0.20117864, 0.7766607, 0.02216067]]\n",
            "967             [[0.20117864, 0.7766607, 0.02216067]]\n",
            "968             [[0.20117864, 0.7766607, 0.02216067]]\n",
            "969         [[0.0017470256, 2.517554e-05, 0.9982278]]\n",
            "970             [[0.20117864, 0.7766607, 0.02216067]]\n",
            "971             [[0.20117864, 0.7766607, 0.02216067]]\n",
            "972          [[0.0006355872, 0.85934323, 0.14002112]]\n",
            "973        [[0.0005380514, 2.540997e-05, 0.99943656]]\n",
            "974       [[0.00024799872, 0.00041271147, 0.9993393]]\n",
            "975       [[0.00024799872, 0.00041271147, 0.9993393]]\n",
            "976        [[0.0010579095, 0.00011786636, 0.9988242]]\n",
            "977           [[0.0073039345, 0.17294796, 0.8197481]]\n",
            "978           [[0.002094428, 0.79162836, 0.20627716]]\n",
            "979           [[0.12484667, 0.0034044574, 0.8717489]]\n",
            "980           [[0.12484667, 0.0034044574, 0.8717489]]\n",
            "981          [[0.9538023, 0.0010704804, 0.045127165]]\n",
            "982           [[0.06302265, 0.91970015, 0.017277205]]\n",
            "983         [[0.0006675205, 0.0019413835, 0.9973911]]\n",
            "984          [[0.9538023, 0.0010704804, 0.045127165]]\n",
            "985          [[0.9538023, 0.0010704804, 0.045127165]]\n",
            "986         [[0.0013447216, 0.0007001629, 0.9979552]]\n",
            "987          [[0.004886987, 2.7101334e-05, 0.995086]]\n",
            "988         [[0.0011582874, 9.201828e-06, 0.9988325]]\n",
            "989        [[0.0017960827, 2.0852713e-05, 0.9981831]]\n",
            "990        [[0.0034334057, 6.199734e-05, 0.99650455]]\n",
            "991        [[0.00027142695, 0.9961254, 0.0036031571]]\n",
            "992         [[0.00028627113, 0.9907827, 0.008931125]]\n",
            "993           [[0.002196211, 0.018273253, 0.9795306]]\n",
            "994        [[0.0010693085, 0.0024064973, 0.99652416]]\n",
            "995       [[0.00025646164, 0.99404436, 0.0056991642]]\n",
            "996          [[0.001320763, 0.97820127, 0.020477977]]\n",
            "997            [[0.038024265, 0.7858306, 0.17614514]]\n",
            "998            [[0.009045369, 0.33637443, 0.6545801]]\n",
            "999           [[0.008562434, 0.14728357, 0.84415406]]\n",
            "1000       [[0.0011835238, 0.0042910795, 0.99452543]]\n",
            "1001         [[0.0050543686, 0.66889244, 0.32605323]]\n",
            "1002       [[0.0014834779, 0.0060945097, 0.99242204]]\n",
            "1003          [[0.030050576, 0.12513545, 0.84481394]]\n",
            "1004      [[0.00051900174, 4.3484044e-05, 0.9994375]]\n",
            "1005          [[0.0012922181, 0.4230871, 0.57562065]]\n",
            "1006       [[0.0012106025, 4.604094e-05, 0.99874336]]\n",
            "1007       [[0.0012106025, 4.604094e-05, 0.99874336]]\n",
            "1008      [[0.00091111107, 7.596938e-06, 0.99908125]]\n",
            "1009        [[0.00093823066, 0.998401, 0.0006608338]]\n",
            "1010      [[0.0017200835, 0.00013900142, 0.99814093]]\n",
            "1011       [[0.0008182802, 0.0010107814, 0.99817085]]\n",
            "1012         [[0.017717205, 0.013741843, 0.96854097]]\n",
            "1013       [[0.00017864522, 2.3327822e-05, 0.999798]]\n",
            "1014       [[0.9987632, 0.0008506286, 0.00038619075]]\n",
            "1015        [[0.037782524, 0.0020369214, 0.96018046]]\n",
            "1016       [[0.00047764461, 1.4241526e-05, 0.999508]]\n",
            "1017          [[0.0013626112, 0.37905356, 0.6195838]]\n",
            "1018        [[0.0016268524, 2.0162312e-05, 0.998353]]\n",
            "1019       [[0.0017735311, 7.3663345e-05, 0.9981528]]\n",
            "1020       [[0.0016409851, 1.9165143e-05, 0.9983399]]\n",
            "1021           [[0.59010196, 0.06606897, 0.34382904]]\n",
            "1022      [[0.0007381434, 0.00016319707, 0.99909866]]\n",
            "1023            [[0.015677702, 0.2657601, 0.7185621]]\n",
            "1024          [[0.0028458214, 0.8506574, 0.14649677]]\n",
            "1025          [[0.9082829, 0.014140259, 0.077576905]]\n",
            "1026           [[0.011674864, 0.8564041, 0.13192095]]\n",
            "1027       [[0.0011263983, 0.00096327206, 0.9979103]]\n",
            "1028       [[0.0011263983, 0.00096327206, 0.9979103]]\n",
            "1029         [[0.00065333, 1.000467e-05, 0.99933666]]\n",
            "1030      [[0.00024277107, 3.2577744e-05, 0.9997247]]\n",
            "1031           [[0.010869285, 0.06188506, 0.9272457]]\n",
            "1032          [[0.0015831196, 0.11613826, 0.8822786]]\n",
            "1033           [[0.11700253, 0.04133415, 0.84166336]]\n",
            "1034     [[0.00055716146, 1.6591941e-05, 0.99942636]]\n",
            "1035     [[0.00042691996, 1.1147338e-05, 0.99956185]]\n",
            "1036       [[0.00057696487, 8.668428e-06, 0.9994143]]\n",
            "1037          [[0.0064687976, 0.00238934, 0.9911419]]\n",
            "1038     [[0.00089094444, 2.3480547e-05, 0.99908555]]\n",
            "1039       [[0.0009431089, 1.503479e-05, 0.99904186]]\n",
            "1040        [[0.0012889337, 4.036749e-05, 0.9986707]]\n",
            "1041           [[0.023575185, 0.8123048, 0.16411999]]\n",
            "1042      [[0.00064463954, 0.9984602, 0.00089520554]]\n",
            "1043          [[0.00631131, 0.94041973, 0.053268954]]\n",
            "1044         [[0.0036584667, 0.13747568, 0.85886586]]\n",
            "1045       [[0.0006490923, 5.803386e-05, 0.99929285]]\n",
            "1046      [[0.00081030687, 2.213656e-05, 0.99916756]]\n",
            "1047       [[0.0005016553, 2.5061529e-05, 0.9994734]]\n",
            "1048         [[0.9940485, 0.0010848126, 0.004866624]]\n",
            "1049         [[0.997584, 0.0007816003, 0.0016344156]]\n",
            "1050       [[0.9981415, 0.0015129904, 0.00034545065]]\n",
            "1051          [[0.002764885, 0.006421822, 0.9908132]]\n",
            "1052          [[0.018061096, 0.02731578, 0.95462316]]\n",
            "1053          [[0.018061096, 0.02731578, 0.95462316]]\n",
            "1054       [[0.0006863191, 0.00019711134, 0.9991166]]\n",
            "1055      [[0.0022897215, 0.00018522324, 0.99752504]]\n",
            "1056       [[0.004266855, 0.00020745408, 0.99552566]]\n",
            "1057            [[0.004010267, 0.00809461, 0.987895]]\n",
            "1058      [[0.0022897215, 0.00018522324, 0.99752504]]\n",
            "1059       [[0.0010358889, 0.0009160382, 0.99804807]]\n",
            "1060       [[0.0007803518, 0.0017505792, 0.99746907]]\n",
            "1061     [[0.00019626225, 0.00025415668, 0.99954957]]\n",
            "1062      [[0.00038502974, 0.00013235664, 0.9994825]]\n",
            "1063        [[0.0018948244, 0.015472543, 0.98263264]]\n",
            "1064        [[0.98974854, 0.0040614004, 0.006190098]]\n",
            "1065      [[0.00062300015, 0.00024695662, 0.9991301]]\n",
            "1066      [[0.00062300015, 0.00024695662, 0.9991301]]\n",
            "1067         [[0.0023615863, 0.048030123, 0.9496083]]\n",
            "1068       [[0.0002946737, 0.00032362988, 0.9993818]]\n",
            "1069       [[0.0010209377, 0.0021329487, 0.99684614]]\n",
            "1070       [[0.00095774326, 0.0017591672, 0.9972831]]\n",
            "1071        [[0.0007749083, 0.0002492527, 0.9989759]]\n",
            "1072       [[0.0010209377, 0.0021329487, 0.99684614]]\n",
            "1073         [[0.015042892, 0.000603779, 0.98435336]]\n",
            "1074         [[0.0039798915, 0.009761686, 0.9862584]]\n",
            "1075         [[0.00874885, 6.8336805e-05, 0.9911828]]\n",
            "1076        [[0.0003021652, 0.99029166, 0.009406176]]\n",
            "1077       [[0.00046276412, 2.047829e-05, 0.9995167]]\n",
            "1078       [[0.00026465114, 0.0001161543, 0.9996191]]\n",
            "1079      [[0.00012024746, 6.0664523e-05, 0.9998191]]\n",
            "1080             [[0.3627656, 0.30437028, 0.3328641]]\n",
            "1081          [[0.0044156625, 0.9720195, 0.02356486]]\n",
            "1082           [[0.007949405, 0.8639946, 0.12805605]]\n",
            "1083       [[0.0013825677, 2.556908e-05, 0.99859184]]\n",
            "1084       [[0.0013446645, 2.6233793e-05, 0.9986292]]\n",
            "1085        [[0.0009393021, 0.0024836662, 0.9965771]]\n",
            "1086           [[0.002678876, 0.6992009, 0.29812023]]\n",
            "1087        [[0.0010283014, 0.0009709923, 0.9980007]]\n",
            "1088         [[0.0074868416, 0.40857708, 0.58393615]]\n",
            "1089         [[0.00085818785, 0.47125533, 0.5278865]]\n",
            "1090        [[0.0009727778, 0.97932774, 0.019699538]]\n",
            "1091           [[0.1912248, 0.8072019, 0.0015732177]]\n",
            "1092       [[0.00034022433, 7.237815e-05, 0.9995875]]\n",
            "1093       [[0.99185467, 0.0054980963, 0.0026472886]]\n",
            "1094           [[0.57686126, 0.12755151, 0.29558727]]\n",
            "1095       [[0.0051946025, 0.0016118593, 0.99319357]]\n",
            "1096      [[0.00033498413, 0.00049423287, 0.9991709]]\n",
            "1097     [[0.00046927383, 3.1050695e-05, 0.99949956]]\n",
            "1098       [[0.0016564396, 0.00014778384, 0.9981958]]\n",
            "1099         [[0.001205539, 1.3405394e-05, 0.998781]]\n",
            "1100      [[0.0004743262, 4.7558602e-05, 0.99947816]]\n",
            "1101       [[0.0016192915, 2.7006301e-05, 0.9983537]]\n",
            "1102       [[0.0011860753, 1.9198136e-05, 0.9987947]]\n",
            "1103        [[0.002714111, 0.00030634477, 0.9969795]]\n",
            "1104        [[0.0020918166, 0.00025418785, 0.997654]]\n",
            "1105           [[0.005414701, 0.18122736, 0.8133579]]\n",
            "1106      [[0.0006775434, 0.00018876238, 0.99913365]]\n",
            "1107        [[0.000787569, 0.00012651604, 0.9990859]]\n",
            "1108       [[0.0020576643, 4.4284498e-05, 0.9978981]]\n",
            "1109       [[0.0009919853, 8.0195554e-05, 0.9989279]]\n",
            "1110      [[0.00069967733, 7.3571275e-05, 0.9992267]]\n",
            "1111        [[0.0015269179, 0.002510666, 0.99596244]]\n",
            "1112        [[0.0030136355, 0.014567187, 0.98241913]]\n",
            "1113        [[0.002259467, 0.00064802484, 0.9970925]]\n",
            "1114        [[0.0015618025, 2.638825e-05, 0.9984118]]\n",
            "1115       [[0.0016578763, 3.345669e-05, 0.99830866]]\n",
            "1116         [[0.038633563, 0.0036140964, 0.9577522]]\n",
            "1117        [[0.0032915138, 0.0052585797, 0.9914499]]\n",
            "1118        [[0.002259467, 0.00064802484, 0.9970925]]\n",
            "1119        [[0.0019041306, 0.0015181777, 0.9965777]]\n",
            "1120            [[0.05629475, 0.69882935, 0.2448759]]\n",
            "1121      [[0.0013231871, 2.3125218e-05, 0.99865365]]\n",
            "1122            [[0.9721234, 0.02098964, 0.00688696]]\n",
            "1123           [[0.2116717, 0.74109393, 0.047234382]]\n",
            "1124        [[0.000931866, 0.0009245816, 0.99814355]]\n",
            "1125    [[0.00085473066, 1.30176695e-05, 0.99913234]]\n",
            "1126      [[0.00062726566, 0.00046475575, 0.9989079]]\n",
            "1127         [[0.0062707295, 0.9001923, 0.093536966]]\n",
            "1128         [[0.0010281866, 0.9954921, 0.003479694]]\n",
            "1129        [[0.002649994, 0.98594254, 0.0114074275]]\n",
            "1130        [[0.0049573095, 0.0015684721, 0.9934742]]\n",
            "1131        [[0.016012922, 0.0035871742, 0.98039985]]\n",
            "1132      [[0.0015120258, 0.00022199495, 0.99826604]]\n",
            "1133       [[0.0008903449, 6.2101455e-05, 0.9990476]]\n",
            "1134            [[0.25589076, 0.12642288, 0.6176864]]\n",
            "1135        [[0.0017062288, 0.0001853752, 0.9981084]]\n",
            "1136       [[0.0008782772, 4.427088e-05, 0.99907744]]\n",
            "1137        [[0.0022169445, 0.0060019502, 0.9917812]]\n",
            "1138       [[0.0008782772, 4.427088e-05, 0.99907744]]\n",
            "1139        [[0.0012577409, 0.0006843219, 0.9980579]]\n",
            "1140      [[0.00088506215, 6.614666e-05, 0.99904877]]\n",
            "1141           [[0.012720041, 0.943046, 0.044234026]]\n",
            "1142        [[0.0023548983, 0.97177315, 0.025872031]]\n",
            "1143        [[0.009688519, 0.0024589475, 0.98785245]]\n",
            "1144             [[0.3433979, 0.17507838, 0.4815237]]\n",
            "1145             [[0.3433979, 0.17507838, 0.4815237]]\n",
            "1146         [[0.0010270864, 5.10633e-05, 0.9989219]]\n",
            "1147        [[0.000477449, 1.5978825e-05, 0.9995066]]\n",
            "1148      [[0.00043525329, 1.035343e-05, 0.99955434]]\n",
            "1149            [[0.0473876, 0.008260519, 0.9443518]]\n",
            "1150       [[0.0008336938, 0.00012720043, 0.9990392]]\n",
            "1151      [[0.0031911638, 0.00062415394, 0.99618465]]\n",
            "1152            [[0.0473876, 0.008260519, 0.9443518]]\n",
            "1153       [[0.00039719435, 5.059111e-05, 0.9995522]]\n",
            "1154           [[0.40420747, 0.014653161, 0.5811394]]\n",
            "1155           [[0.40420747, 0.014653161, 0.5811394]]\n",
            "1156       [[0.00092886965, 6.837849e-06, 0.9990644]]\n",
            "1157      [[0.0013739615, 0.00013485306, 0.99849117]]\n",
            "1158       [[0.0011251817, 5.585335e-05, 0.99881893]]\n",
            "1159            [[0.002247474, 0.0021173, 0.9956352]]\n",
            "1160         [[0.004240475, 0.005109865, 0.99064976]]\n",
            "1161         [[0.0055442485, 0.011461079, 0.9829947]]\n",
            "1162      [[0.00088082225, 8.7759705e-05, 0.9990314]]\n",
            "1163       [[0.0012027237, 0.00012301229, 0.9986743]]\n",
            "1164      [[0.00023246408, 9.488152e-05, 0.99967265]]\n",
            "1165         [[0.0055442485, 0.011461079, 0.9829947]]\n",
            "1166       [[0.0013821631, 0.00088363746, 0.9977342]]\n",
            "1167       [[0.0008729761, 5.7723944e-05, 0.9990693]]\n",
            "1168        [[0.0011334035, 7.120078e-05, 0.9987954]]\n",
            "1169        [[0.0006669046, 6.503471e-05, 0.9992681]]\n",
            "1170       [[0.0016695922, 0.00097656215, 0.9973538]]\n",
            "1171        [[0.0011424999, 6.875955e-05, 0.9987888]]\n",
            "1172         [[0.002588013, 0.008330349, 0.98908174]]\n",
            "1173       [[0.0030184174, 0.0058797603, 0.99110174]]\n",
            "1174        [[0.98568183, 0.008757785, 0.0055603776]]\n",
            "1175            [[0.9124014, 0.0836482, 0.003950409]]\n",
            "1176        [[0.009353491, 0.99031067, 0.0003358418]]\n",
            "1177         [[0.007181916, 0.0009638933, 0.9918542]]\n",
            "1178      [[0.0020307142, 3.9265426e-05, 0.99793005]]\n",
            "1179         [[0.08687899, 0.0023990893, 0.91072184]]\n",
            "1180       [[0.0036882372, 7.879093e-05, 0.99623305]]\n",
            "1181        [[0.003719556, 0.00013344799, 0.9961469]]\n",
            "1182       [[0.0021414694, 5.894685e-05, 0.99779946]]\n",
            "1183      [[0.00074571074, 2.8778295e-05, 0.9992255]]\n",
            "1184     [[0.00034733847, 0.00013218731, 0.99952054]]\n",
            "1185       [[0.0006405462, 3.3322955e-05, 0.9993261]]\n",
            "1186           [[0.00873997, 0.0017040042, 0.989556]]\n",
            "1187              [[0.0986681, 0.034481827, 0.86685]]\n",
            "1188       [[0.0025972151, 0.0002514054, 0.99715143]]\n",
            "1189          [[0.005224852, 0.003447263, 0.9913278]]\n",
            "1190        [[0.0010626866, 0.0012965335, 0.9976407]]\n",
            "1191         [[0.000871164, 0.0009204222, 0.9982084]]\n",
            "1192        [[0.0007392873, 0.0013079714, 0.9979527]]\n",
            "1193       [[0.0036624116, 0.00038105523, 0.9959565]]\n",
            "1194        [[0.006239739, 5.134108e-05, 0.99370897]]\n",
            "1195       [[0.0024390246, 1.3048666e-05, 0.9975479]]\n",
            "1196        [[0.0026378585, 0.025684064, 0.97167814]]\n",
            "1197       [[0.00041834608, 0.0004692916, 0.9991124]]\n",
            "1198         [[0.0022356317, 0.056799296, 0.9409651]]\n",
            "1199          [[0.003095921, 0.041206572, 0.9556975]]\n",
            "1200         [[0.0005461343, 0.9515098, 0.047944132]]\n",
            "1201      [[0.00082584424, 2.0579446e-05, 0.9991535]]\n",
            "1202      [[0.00082584424, 2.0579446e-05, 0.9991535]]\n",
            "1203        [[0.004202041, 0.00012483537, 0.9956731]]\n",
            "1204            [[0.07808434, 0.4412971, 0.48061857]]\n",
            "1205         [[0.019310785, 0.016086103, 0.96460307]]\n",
            "1206          [[0.0017081621, 0.7197021, 0.27858976]]\n",
            "1207       [[0.0015754771, 9.908182e-06, 0.99841464]]\n",
            "1208      [[0.0015252456, 2.8729393e-05, 0.99844605]]\n",
            "1209           [[0.045175713, 0.7239079, 0.23091638]]\n",
            "1210         [[0.050313514, 0.93467593, 0.015010504]]\n",
            "1211           [[0.03878939, 0.86181134, 0.09939929]]\n",
            "1212            [[0.21021235, 0.4990229, 0.29076475]]\n",
            "1213        [[0.0011917658, 6.709272e-05, 0.9987411]]\n",
            "1214        [[0.002664225, 0.0021899939, 0.99514574]]\n",
            "1215        [[0.0015157104, 3.070733e-05, 0.9984536]]\n",
            "1216        [[0.002664225, 0.0021899939, 0.99514574]]\n",
            "1217           [[0.011005558, 0.26697412, 0.7220203]]\n",
            "1218       [[0.0009662881, 8.849683e-06, 0.99902487]]\n",
            "1219      [[0.00017856032, 6.587298e-05, 0.99975556]]\n",
            "1220          [[0.001682175, 3.685687e-05, 0.998281]]\n",
            "1221        [[0.0016297915, 4.839239e-05, 0.9983217]]\n",
            "1222       [[0.002109494, 0.00017944502, 0.99771106]]\n",
            "1223          [[0.081348635, 0.077644095, 0.8410073]]\n",
            "1224         [[0.0018411595, 0.04553987, 0.95261896]]\n",
            "1225         [[0.0002510674, 6.3415e-06, 0.99974257]]\n",
            "1226       [[0.0016048807, 0.00046917683, 0.9979259]]\n",
            "1227      [[0.00039510304, 1.1208809e-05, 0.9995937]]\n",
            "1228        [[0.0017245485, 0.0023715605, 0.9959039]]\n",
            "1229       [[0.0029218337, 3.988945e-05, 0.99703825]]\n",
            "1230       [[0.0029218337, 3.988945e-05, 0.99703825]]\n",
            "1231       [[0.0015258981, 9.5393025e-06, 0.9984646]]\n",
            "1232        [[0.99443275, 0.004839257, 0.0007280137]]\n",
            "1233           [[0.008405688, 0.08800322, 0.9035911]]\n",
            "1234        [[0.0007903432, 9.757318e-06, 0.9991999]]\n",
            "1235           [[0.8174074, 0.16857184, 0.014020675]]\n",
            "1236             [[0.17087808, 0.5711567, 0.2579652]]\n",
            "1237       [[0.00088514946, 9.468612e-06, 0.9991054]]\n",
            "1238      [[0.00061129965, 0.00010226658, 0.9992865]]\n",
            "1239        [[0.007320561, 0.0075093056, 0.98517007]]\n",
            "1240     [[0.00082048913, 1.6467717e-05, 0.99916303]]\n",
            "1241        [[0.00039689316, 2.611539e-05, 0.999577]]\n",
            "1242       [[0.0016613081, 0.00036757463, 0.9979711]]\n",
            "1243        [[0.0019685957, 0.027202735, 0.97082865]]\n",
            "1244         [[0.0059234295, 0.021771649, 0.9723049]]\n",
            "1245      [[0.00023091861, 5.4801916e-05, 0.9997142]]\n",
            "1246         [[0.0015462663, 0.9384136, 0.060040087]]\n",
            "1247         [[0.0013804763, 0.057644013, 0.9409754]]\n",
            "1248      [[0.00023091861, 5.4801916e-05, 0.9997142]]\n",
            "1249            [[0.2350091, 0.7500517, 0.014939211]]\n",
            "1250            [[0.02666214, 0.6009059, 0.37243196]]\n",
            "1251            [[0.25747553, 0.05624805, 0.6862765]]\n",
            "1252         [[0.010053477, 0.0029687118, 0.9869779]]\n",
            "1253         [[0.011399909, 0.0057506347, 0.9828494]]\n",
            "1254        [[0.0009095543, 0.0047512017, 0.9943393]]\n",
            "1255         [[0.011399909, 0.0057506347, 0.9828494]]\n",
            "1256           [[0.0138789015, 0.0644955, 0.9216256]]\n",
            "1257         [[0.0017391059, 0.021171207, 0.9770897]]\n",
            "1258       [[0.0009693429, 0.00039317118, 0.9986374]]\n",
            "1259      [[0.00044188352, 0.00013143192, 0.9994267]]\n",
            "1260        [[0.0014183787, 0.9939283, 0.0046532573]]\n",
            "1261        [[0.0007320064, 4.984942e-05, 0.9992182]]\n",
            "1262       [[0.0017314001, 1.2008502e-05, 0.9982566]]\n",
            "1263             [[0.4196092, 0.05062803, 0.5297628]]\n",
            "1264        [[0.0013431967, 1.487232e-05, 0.9986419]]\n",
            "1265           [[0.008168921, 0.12298838, 0.8688427]]\n",
            "1266      [[0.00038617404, 8.9121364e-05, 0.9995247]]\n",
            "1267         [[0.018008934, 0.011277907, 0.97071314]]\n",
            "1268          [[0.12925585, 0.030799512, 0.83994466]]\n",
            "1269          [[0.03287247, 0.9666099, 0.0005175809]]\n",
            "1270        [[0.9969289, 0.0009864089, 0.0020847297]]\n",
            "1271       [[0.9977812, 0.00018621956, 0.0020324804]]\n",
            "1272        [[0.0012923654, 0.9951141, 0.0035935054]]\n",
            "1273          [[0.010403967, 0.90899837, 0.08059768]]\n",
            "1274      [[0.0008518051, 0.00013703402, 0.99901104]]\n",
            "1275       [[0.00071808056, 5.945233e-05, 0.9992225]]\n",
            "1276              [[0.0576938, 0.6899143, 0.2523919]]\n",
            "1277          [[0.14492786, 0.8491601, 0.0059120865]]\n",
            "1278         [[0.018762872, 0.017600538, 0.96363664]]\n",
            "1279            [[0.04384755, 0.22687174, 0.7292807]]\n",
            "1280         [[0.011286179, 0.015732465, 0.97298145]]\n",
            "1281         [[0.0039374754, 0.008773918, 0.9872886]]\n",
            "1282      [[0.0005101856, 2.9747682e-05, 0.99946004]]\n",
            "1283      [[0.00026053845, 2.3870429e-05, 0.9997156]]\n",
            "1284       [[0.00029295273, 4.017632e-05, 0.9996669]]\n",
            "1285      [[0.00034472372, 0.00026576497, 0.9993894]]\n",
            "1286         [[0.0010711921, 0.12201566, 0.87691313]]\n",
            "1287      [[0.00060822535, 5.945283e-06, 0.99938583]]\n",
            "1288           [[0.006444507, 0.7027596, 0.29079586]]\n",
            "1289           [[0.17339388, 0.67952406, 0.14708202]]\n",
            "1290           [[0.07741801, 0.023836197, 0.8987458]]\n",
            "1291       [[0.0016932914, 0.00011711135, 0.9981896]]\n",
            "1292            [[0.9553894, 0.0404671, 0.004143546]]\n",
            "1293        [[0.004684935, 0.00015788112, 0.9951572]]\n",
            "1294      [[0.0015264235, 0.00049554155, 0.99797803]]\n",
            "1295            [[0.36870658, 0.13757662, 0.4937168]]\n",
            "1296          [[0.003972089, 5.596601e-05, 0.995972]]\n",
            "1297          [[0.008885935, 0.013716572, 0.9773975]]\n",
            "1298         [[0.004575779, 0.99298495, 0.002439239]]\n",
            "1299        [[0.0013570281, 0.0019373829, 0.9967056]]\n",
            "1300            [[0.042786054, 0.008033939, 0.94918]]\n",
            "1301        [[0.0013570281, 0.0019373829, 0.9967056]]\n",
            "1302         [[0.049353812, 0.0010484088, 0.9495979]]\n",
            "1303          [[0.0025717209, 0.8594058, 0.13802248]]\n",
            "1304           [[0.002370179, 0.08041089, 0.9172189]]\n",
            "1305          [[0.0010748892, 0.07781179, 0.9211134]]\n",
            "1306         [[0.0047260225, 0.91272646, 0.08254752]]\n",
            "1307      [[0.0005807406, 2.0951877e-05, 0.99939823]]\n",
            "1308        [[0.0009025143, 2.223997e-05, 0.9990752]]\n",
            "1309      [[0.0014616452, 0.00013024439, 0.99840814]]\n",
            "1310        [[0.0009003296, 1.5723801e-05, 0.999084]]\n",
            "1311          [[0.002424483, 0.009947891, 0.9876276]]\n",
            "1312     [[0.00074818975, 0.00047748454, 0.99877435]]\n",
            "1313        [[0.0004159701, 0.016675629, 0.98290837]]\n",
            "1314       [[0.0003617317, 0.00020308173, 0.9994351]]\n",
            "1315          [[0.0008564666, 0.969081, 0.030062526]]\n",
            "1316       [[0.0009987683, 0.00024809898, 0.9987531]]\n",
            "1317       [[0.0009987683, 0.00024809898, 0.9987531]]\n",
            "1318       [[0.001591795, 2.5623398e-05, 0.99838257]]\n",
            "1319       [[0.0016055361, 9.203004e-05, 0.99830246]]\n",
            "1320      [[0.0020379953, 2.8201484e-05, 0.99793386]]\n",
            "1321       [[0.0017566122, 0.00034512545, 0.9978982]]\n",
            "1322            [[0.0116518885, 0.814102, 0.1742461]]\n",
            "1323         [[0.014281756, 0.88777167, 0.097946584]]\n",
            "1324         [[0.0060502156, 0.9367211, 0.057228725]]\n",
            "1325           [[0.00479348, 0.9557306, 0.039475903]]\n",
            "1326      [[0.00046760743, 0.99876535, 0.0007670575]]\n",
            "1327        [[0.0006528238, 0.0017176471, 0.9976295]]\n",
            "1328       [[0.0006267791, 0.0008172847, 0.99855596]]\n",
            "1329       [[0.0007643992, 0.0012527452, 0.99798286]]\n",
            "1330          [[0.0032104894, 0.8951821, 0.10160746]]\n",
            "1331          [[0.0025876942, 0.113125294, 0.884287]]\n",
            "1332        [[0.008302612, 0.0037859944, 0.98791134]]\n",
            "1333           [[0.009776412, 0.01840624, 0.9718174]]\n",
            "1334           [[0.05217227, 0.8917405, 0.056087308]]\n",
            "1335       [[0.0002976925, 0.0066370065, 0.99306524]]\n",
            "1336            [[0.915856, 0.06437676, 0.019767195]]\n",
            "1337       [[0.0006921262, 0.00011066855, 0.9991972]]\n",
            "1338     [[0.00089957676, 3.0029762e-05, 0.99907047]]\n",
            "1339      [[0.00053168635, 0.00027708945, 0.9991912]]\n",
            "1340      [[0.00027116464, 0.00013940506, 0.9995894]]\n",
            "1341       [[0.0019195473, 4.3139018e-05, 0.9980373]]\n",
            "1342       [[0.0008562997, 0.00012552718, 0.9990182]]\n",
            "1343         [[0.9852701, 0.0050618295, 0.009668021]]\n",
            "1344            [[0.31822065, 0.06109494, 0.6206844]]\n",
            "1345        [[0.0013797275, 0.98353785, 0.015082423]]\n",
            "1346            [[0.03748048, 0.60957134, 0.3529482]]\n",
            "1347      [[0.0008816141, 0.00012684149, 0.99899155]]\n",
            "1348       [[0.0010162066, 4.1575433e-05, 0.9989422]]\n",
            "1349         [[0.0023768647, 9.57261e-05, 0.9975274]]\n",
            "1350       [[0.0009170198, 0.00038637588, 0.9986966]]\n",
            "1351      [[0.0019183364, 0.00024254067, 0.99783915]]\n",
            "1352           [[0.014839613, 0.03862198, 0.9465383]]\n",
            "1353          [[0.0036837426, 5.9447e-05, 0.9962567]]\n",
            "1354       [[0.0012244516, 3.145878e-05, 0.99874413]]\n",
            "1355            [[0.5935468, 0.22310986, 0.18334337]]\n",
            "1356        [[0.0015206009, 0.0001578453, 0.9983216]]\n",
            "1357          [[0.18800975, 0.75193053, 0.060059663]]\n",
            "1358       [[0.0009858801, 1.0418707e-05, 0.9990038]]\n",
            "1359          [[0.003485299, 0.004874613, 0.9916401]]\n",
            "1360      [[0.00055886665, 1.554446e-05, 0.99942565]]\n",
            "1361        [[0.0027596664, 0.000781228, 0.99645907]]\n",
            "1362           [[0.051006544, 0.005414463, 0.943579]]\n",
            "1363      [[0.00076790206, 0.0041993894, 0.99503267]]\n",
            "1364          [[0.0026002694, 0.9068193, 0.09058048]]\n",
            "1365          [[0.0012850451, 0.6793484, 0.31936648]]\n",
            "1366           [[0.02939793, 0.015855554, 0.9547466]]\n",
            "1367       [[0.0009767343, 3.659091e-05, 0.99898666]]\n",
            "1368          [[0.004427151, 0.029660525, 0.9659124]]\n",
            "1369       [[0.001159656, 5.9603066e-05, 0.99878067]]\n",
            "1370          [[0.106758565, 0.67252743, 0.22071406]]\n",
            "1371           [[0.011480923, 0.8745103, 0.11400879]]\n",
            "1372      [[0.0010156182, 2.7788741e-05, 0.99895656]]\n",
            "1373         [[0.030436097, 0.020036291, 0.94952756]]\n",
            "1374        [[0.0113601005, 0.0042785485, 0.9843614]]\n",
            "1375          [[0.016999904, 0.93825555, 0.04474451]]\n",
            "1376           [[0.0033847708, 0.07307623, 0.923539]]\n",
            "1377     [[0.00032622778, 0.00034945138, 0.99932444]]\n",
            "1378       [[0.0004763298, 0.0012030444, 0.99832064]]\n",
            "1379         [[0.0014480698, 0.008454592, 0.9900973]]\n",
            "1380          [[0.91164535, 0.07974969, 0.008604934]]\n",
            "1381       [[0.002663937, 1.4431223e-05, 0.99732167]]\n",
            "1382       [[0.9974956, 0.00013351848, 0.0023707987]]\n",
            "1383           [[0.13551013, 0.85925907, 0.00523074]]\n",
            "1384          [[0.004035938, 0.995233, 0.0007310158]]\n",
            "1385        [[0.0010266133, 8.883331e-05, 0.9988846]]\n",
            "1386        [[0.0053877328, 3.409036e-05, 0.9945781]]\n",
            "1387      [[0.0003644375, 4.8267233e-05, 0.99958736]]\n",
            "1388           [[0.018781312, 0.03176995, 0.9494488]]\n",
            "1389       [[0.001093665, 7.4647537e-06, 0.99889886]]\n",
            "1390         [[0.0072153206, 0.61493593, 0.37784868]]\n",
            "1391      [[0.0010383725, 1.8318831e-05, 0.99894327]]\n",
            "1392            [[0.049719125, 0.3391187, 0.6111622]]\n",
            "1393       [[0.0006324161, 4.5586416e-06, 0.9993631]]\n",
            "1394      [[0.0010897778, 7.0885767e-06, 0.99890304]]\n",
            "1395            [[0.11415095, 0.12039186, 0.7654573]]\n",
            "1396         [[0.005934921, 0.0023294697, 0.9917355]]\n",
            "1397          [[0.011764606, 0.16470884, 0.82352656]]\n",
            "1398          [[0.0050289608, 0.46566826, 0.5293028]]\n",
            "1399          [[0.019506667, 0.82447374, 0.15601958]]\n",
            "1400            [[0.01013163, 0.8341129, 0.15575553]]\n",
            "1401        [[0.0015503851, 6.303845e-05, 0.9983865]]\n",
            "1402        [[0.0005547622, 0.9979984, 0.0014467655]]\n",
            "1403         [[0.00079875364, 9.1045e-05, 0.9991103]]\n",
            "1404        [[0.0145043405, 0.94453853, 0.040957123]]\n",
            "1405        [[0.0145043405, 0.94453853, 0.040957123]]\n",
            "1406        [[0.0145043405, 0.94453853, 0.040957123]]\n",
            "1407        [[0.0145043405, 0.94453853, 0.040957123]]\n",
            "1408       [[0.0017662339, 0.0022344606, 0.99599934]]\n",
            "1409          [[0.046728898, 0.8825479, 0.070723176]]\n",
            "1410        [[0.0065601757, 0.0030376657, 0.9904021]]\n",
            "1411        [[0.003118174, 0.0008493067, 0.99603254]]\n",
            "1412          [[0.010415849, 0.07413946, 0.91544473]]\n",
            "1413       [[0.0011187181, 3.5149038e-05, 0.9988462]]\n",
            "1414        [[0.0013993549, 3.867591e-05, 0.9985619]]\n",
            "1415        [[0.005462992, 0.0053494736, 0.98918754]]\n",
            "1416         [[0.002361258, 6.059347e-05, 0.9975781]]\n",
            "1417             [[0.11056855, 0.3864075, 0.5030239]]\n",
            "1418       [[0.002958343, 0.00011215578, 0.99692947]]\n",
            "1419       [[0.0028657492, 6.239813e-05, 0.99707186]]\n",
            "1420         [[0.00625939, 0.00092652376, 0.9928141]]\n",
            "1421      [[0.001717432, 0.000112384514, 0.99817026]]\n",
            "1422        [[0.0002930517, 3.213049e-05, 0.9996748]]\n",
            "1423          [[0.0047820737, 0.35724247, 0.6379754]]\n",
            "1424          [[0.033747178, 0.012712208, 0.9535407]]\n",
            "1425           [[0.024670374, 0.1385778, 0.83675176]]\n",
            "1426          [[0.01754589, 0.012452221, 0.97000194]]\n",
            "1427           [[0.10939694, 0.15917608, 0.73142695]]\n",
            "1428           [[0.040058445, 0.63917863, 0.3207629]]\n",
            "1429         [[0.015840432, 0.96042454, 0.023735028]]\n",
            "1430          [[0.026978457, 0.007801089, 0.9652205]]\n",
            "1431      [[0.0024476363, 2.4700454e-05, 0.99752766]]\n",
            "1432         [[0.0014962704, 0.001382452, 0.9971213]]\n",
            "1433            [[0.5557685, 0.17626768, 0.26796386]]\n",
            "1434            [[0.19700262, 0.06132969, 0.7416676]]\n",
            "1435         [[0.0014962704, 0.001382452, 0.9971213]]\n",
            "1436        [[0.0013780191, 0.0007936757, 0.9978283]]\n",
            "1437       [[0.0011227002, 0.00025560055, 0.9986217]]\n",
            "1438        [[0.001446231, 4.0224302e-05, 0.9985135]]\n",
            "1439           [[0.048961964, 0.82281345, 0.1282245]]\n",
            "1440        [[0.0035502703, 0.0022612908, 0.9941884]]\n",
            "1441          [[0.011509121, 0.61079854, 0.37769237]]\n",
            "1442         [[0.048674542, 0.077119984, 0.87420547]]\n",
            "1443            [[0.03200569, 0.6909274, 0.27706695]]\n",
            "1444           [[0.09646779, 0.71551955, 0.18801266]]\n",
            "1445        [[0.0015085993, 0.97075754, 0.027733872]]\n",
            "1446       [[0.000707679, 2.0101506e-05, 0.99927217]]\n",
            "1447       [[0.0007472505, 2.1216067e-05, 0.9992316]]\n",
            "1448      [[0.0006839078, 2.4501353e-05, 0.99929154]]\n",
            "1449          [[0.88094467, 0.015564537, 0.10349079]]\n",
            "1450         [[0.002041188, 0.95698816, 0.040970612]]\n",
            "1451       [[0.0010710999, 0.99222374, 0.0067051155]]\n",
            "1452       [[0.0010710999, 0.99222374, 0.0067051155]]\n",
            "1453      [[0.00049451867, 0.99476707, 0.0047383984]]\n",
            "1454          [[0.0047204676, 0.4093359, 0.58594364]]\n",
            "1455        [[0.00051637134, 0.000928767, 0.9985549]]\n",
            "1456           [[0.23791677, 0.66217023, 0.09991306]]\n",
            "1457           [[0.014562867, 0.45966437, 0.5257727]]\n",
            "1458            [[0.009033192, 0.80195785, 0.189009]]\n",
            "1459        [[0.0006738585, 7.661328e-05, 0.9992495]]\n",
            "1460       [[0.0017239753, 0.0006121753, 0.99766386]]\n",
            "1461     [[0.00048400785, 1.2245771e-05, 0.99950373]]\n",
            "1462      [[0.0003737907, 0.00043679003, 0.99918944]]\n",
            "1463        [[0.0007973151, 0.057971384, 0.94123125]]\n",
            "1464        [[0.00014062478, 0.010607452, 0.9892519]]\n",
            "1465        [[0.0034046215, 0.98601055, 0.010584856]]\n",
            "1466            [[0.0014640793, 0.1812169, 0.817319]]\n",
            "1467           [[0.001171894, 0.21779259, 0.7810355]]\n",
            "1468      [[0.00040181942, 1.9725068e-05, 0.9995784]]\n",
            "1469       [[0.00023257852, 1.8464769e-05, 0.999749]]\n",
            "1470         [[0.002295745, 9.74644e-05, 0.99760675]]\n",
            "1471       [[0.0010708943, 0.0013257399, 0.99760336]]\n",
            "1472         [[0.0035736824, 0.060153887, 0.9362724]]\n",
            "1473       [[0.99748105, 0.0009785887, 0.0015403378]]\n",
            "1474       [[0.00074440404, 1.644336e-05, 0.9992392]]\n",
            "1475      [[0.0007643141, 1.2946429e-05, 0.99922264]]\n",
            "1476           [[0.04517342, 0.88715136, 0.06767518]]\n",
            "1477      [[0.00058059534, 3.9990744e-05, 0.9993794]]\n",
            "1478       [[0.0037148532, 0.00055992376, 0.9957253]]\n",
            "1479        [[0.99092567, 0.008620037, 0.0004542776]]\n",
            "1480        [[0.002737848, 0.99682486, 0.0004373565]]\n",
            "1481         [[0.19236615, 9.2841976e-05, 0.8075411]]\n",
            "1482     [[0.99932754, 0.00050968153, 0.00016282742]]\n",
            "1483        [[0.9977126, 0.002158252, 0.00012911187]]\n",
            "1484         [[0.13221557, 0.00042649187, 0.8673579]]\n",
            "1485           [[0.871108, 0.118180946, 0.010710959]]\n",
            "1486          [[0.12703303, 0.8668169, 0.0061501698]]\n",
            "1487         [[0.9906742, 0.008072614, 0.0012532009]]\n",
            "1488           [[0.871108, 0.118180946, 0.010710959]]\n",
            "1489        [[0.9649302, 0.034116108, 0.00095370965]]\n",
            "1490          [[0.9210945, 0.07771131, 0.0011941994]]\n",
            "1491           [[0.04598253, 0.12438942, 0.82962805]]\n",
            "1492          [[0.007917232, 0.0004447715, 0.991638]]\n",
            "1493           [[0.04598253, 0.12438942, 0.82962805]]\n",
            "1494        [[0.0016317484, 5.204229e-05, 0.9983163]]\n",
            "1495            [[0.0049765306, 0.97726, 0.01776354]]\n",
            "1496        [[0.0058744485, 0.97098416, 0.023141362]]\n",
            "1497        [[0.0058744485, 0.97098416, 0.023141362]]\n",
            "1498           [[0.33590412, 0.6615707, 0.002525246]]\n",
            "1499           [[0.09882662, 0.8748231, 0.026350262]]\n",
            "1500       [[0.000889901, 0.00018780802, 0.99892235]]\n",
            "1501        [[0.001461001, 2.3611788e-05, 0.9985154]]\n",
            "1502       [[0.0011923836, 1.640398e-05, 0.99879116]]\n",
            "1503        [[0.000296317, 9.9371486e-05, 0.9996043]]\n",
            "1504     [[0.00065886934, 2.8355524e-05, 0.99931276]]\n",
            "1505       [[0.0009104589, 2.2346007e-05, 0.9990671]]\n",
            "1506       [[0.002160357, 1.9379153e-05, 0.99782026]]\n",
            "1507       [[0.0008581994, 2.2163635e-05, 0.9991197]]\n",
            "1508          [[0.014138516, 0.080925725, 0.9049358]]\n",
            "1509        [[0.0066513144, 0.0065665147, 0.9867821]]\n",
            "1510         [[0.0013420938, 0.0032450003, 0.995413]]\n",
            "1511       [[0.0019522974, 0.00044854323, 0.9975992]]\n",
            "1512      [[0.0012921679, 4.8710965e-05, 0.99865913]]\n",
            "1513        [[0.0020210592, 0.0001268338, 0.9978522]]\n",
            "1514        [[0.0066513144, 0.0065665147, 0.9867821]]\n",
            "1515        [[0.0031926632, 0.022476194, 0.97433114]]\n",
            "1516           [[0.007083297, 7.56985e-05, 0.992841]]\n",
            "1517      [[0.0013821435, 5.2034404e-05, 0.99856585]]\n",
            "1518       [[0.0009987777, 0.00026399834, 0.9987373]]\n",
            "1519       [[0.9935673, 0.00032506062, 0.0061077545]]\n",
            "1520           [[0.890841, 0.029531464, 0.079627566]]\n",
            "1521           [[0.8459685, 0.062276307, 0.09175523]]\n",
            "1522          [[0.91863346, 0.07000757, 0.011358964]]\n",
            "1523        [[0.00794079, 0.00077142095, 0.99128777]]\n",
            "1524           [[0.05113318, 0.023302723, 0.9255641]]\n",
            "1525        [[0.0017607126, 0.98985475, 0.008384596]]\n",
            "1526         [[0.9723255, 0.0002918806, 0.027382605]]\n",
            "1527       [[0.0010956128, 2.1874672e-05, 0.9988825]]\n",
            "1528           [[0.2217012, 0.103833884, 0.67446494]]\n",
            "1529          [[0.020062694, 0.034611158, 0.9453261]]\n",
            "1530          [[0.020062694, 0.034611158, 0.9453261]]\n",
            "1531       [[0.0018628341, 0.00051259826, 0.9976246]]\n",
            "1532       [[0.0018628341, 0.00051259826, 0.9976246]]\n",
            "1533      [[0.0011781019, 0.00018669848, 0.99863523]]\n",
            "1534          [[0.00397401, 0.032991678, 0.96303433]]\n",
            "1535        [[0.0018331863, 0.001189249, 0.99697757]]\n",
            "1536        [[0.058518022, 0.00051244954, 0.9409695]]\n",
            "1537       [[0.9968112, 0.00017116296, 0.0030176495]]\n",
            "1538       [[0.99854386, 6.2999046e-05, 0.001393187]]\n",
            "1539          [[0.07109458, 5.71189e-05, 0.92884827]]\n",
            "1540       [[0.0013598243, 3.5074863e-05, 0.9986051]]\n",
            "1541      [[0.0004012585, 3.9263843e-05, 0.99955946]]\n",
            "1542       [[0.00059932366, 0.0012953781, 0.9981053]]\n",
            "1543       [[0.00071251893, 6.624799e-05, 0.9992212]]\n",
            "1544       [[0.00059932366, 0.0012953781, 0.9981053]]\n",
            "1545          [[0.002084123, 0.41092527, 0.58699065]]\n",
            "1546      [[0.00043388765, 8.563128e-06, 0.99955755]]\n",
            "1547        [[0.00060278224, 0.021181358, 0.9782159]]\n",
            "1548     [[0.00022731439, 2.1733034e-05, 0.99975103]]\n",
            "1549         [[0.96929294, 0.021945326, 0.008761677]]\n",
            "1550            [[0.027670193, 0.266743, 0.70558685]]\n",
            "1551            [[0.027670193, 0.266743, 0.70558685]]\n",
            "1552       [[0.0013472906, 0.0001249814, 0.99852765]]\n",
            "1553       [[0.0010147599, 1.8675979e-05, 0.9989666]]\n",
            "1554      [[0.0007838177, 4.6175173e-05, 0.99916995]]\n",
            "1555       [[0.0010147599, 1.8675979e-05, 0.9989666]]\n",
            "1556         [[0.0076503195, 0.005511837, 0.9868379]]\n",
            "1557       [[0.0005571989, 3.136437e-05, 0.99941146]]\n",
            "1558      [[0.0005059859, 0.00034334222, 0.99915063]]\n",
            "1559            [[0.0042012236, 0.7917178, 0.204081]]\n",
            "1560          [[0.03607416, 0.9590415, 0.0048843473]]\n",
            "1561           [[0.41140276, 0.5772342, 0.011363004]]\n",
            "1562            [[0.027670193, 0.266743, 0.70558685]]\n",
            "1563           [[0.018081024, 0.01548448, 0.9664345]]\n",
            "1564          [[0.060586162, 0.86297864, 0.07643525]]\n",
            "1565     [[0.00086959504, 0.00064233475, 0.99848807]]\n",
            "1566          [[0.060654894, 0.51723325, 0.42211187]]\n",
            "1567            [[0.12615119, 0.6279592, 0.24588963]]\n",
            "1568        [[0.0004062135, 0.9985108, 0.0010830512]]\n",
            "1569         [[0.0003647009, 0.998538, 0.0010973432]]\n",
            "1570        [[0.0016829895, 0.99056387, 0.007753096]]\n",
            "1571            [[0.00290694, 0.10479118, 0.8923019]]\n",
            "1572           [[0.14486662, 0.55780023, 0.29733315]]\n",
            "1573            [[0.36637285, 0.5418168, 0.09181032]]\n",
            "1574        [[0.9873904, 0.00018694859, 0.012422722]]\n",
            "1575         [[0.9970509, 0.0003390658, 0.002609965]]\n",
            "1576            [[0.5651285, 0.35947397, 0.07539754]]\n",
            "1577        [[0.9873904, 0.00018694859, 0.012422722]]\n",
            "1578       [[0.00087601464, 6.172418e-06, 0.9991178]]\n",
            "1579      [[0.00064632116, 4.9052733e-06, 0.9993488]]\n",
            "1580      [[0.00064632116, 4.9052733e-06, 0.9993488]]\n",
            "1581      [[0.00019355754, 0.00017685017, 0.9996296]]\n",
            "1582         [[0.000473795, 0.00030810383, 0.999218]]\n",
            "1583        [[0.0036273245, 0.9949292, 0.0014434604]]\n",
            "1584          [[0.0047564306, 0.987051, 0.008192517]]\n",
            "1585         [[0.91723156, 0.066178806, 0.016589614]]\n",
            "1586        [[0.0019421729, 7.215748e-05, 0.9979856]]\n",
            "1587           [[0.020514878, 0.23439676, 0.7450883]]\n",
            "1588        [[0.00024561133, 0.9990551, 0.000699296]]\n",
            "1589         [[0.003484658, 0.0016658852, 0.9948494]]\n",
            "1590      [[0.00057169644, 5.998539e-05, 0.99936825]]\n",
            "1591        [[0.0017542299, 0.0023555146, 0.9958903]]\n",
            "1592       [[0.99074054, 0.0045213513, 0.0047381776]]\n",
            "1593            [[0.17746976, 0.6451336, 0.17739666]]\n",
            "1594         [[0.0043021305, 0.0005268402, 0.995171]]\n",
            "1595           [[0.043816395, 0.05832647, 0.8978571]]\n",
            "1596         [[0.003362322, 0.010283619, 0.98635405]]\n",
            "1597             [[0.05422725, 0.5824197, 0.3633531]]\n",
            "1598            [[0.03373212, 0.9391501, 0.02711773]]\n",
            "1599       [[0.00019053977, 0.9974982, 0.0023112674]]\n",
            "1600        [[0.00017745982, 0.9979013, 0.001921271]]\n",
            "1601       [[0.00012476866, 0.9986131, 0.0012620467]]\n",
            "1602        [[0.012322853, 0.00027800517, 0.9873991]]\n",
            "1603       [[0.00081234885, 0.084997885, 0.91418976]]\n",
            "1604      [[0.0016150916, 2.0816651e-05, 0.99836403]]\n",
            "1605         [[0.006728811, 0.0008131316, 0.9924581]]\n",
            "1606       [[0.0040997183, 0.00014488181, 0.9957553]]\n",
            "1607       [[0.001035829, 0.00016589716, 0.99879825]]\n",
            "1608       [[0.99154156, 0.0011502822, 0.0073080733]]\n",
            "1609        [[0.98538905, 0.0019264601, 0.012684529]]\n",
            "1610        [[0.9855192, 0.00063508976, 0.013845785]]\n",
            "1611       [[0.99154156, 0.0011502822, 0.0073080733]]\n",
            "1612          [[0.017473925, 0.039369617, 0.9431565]]\n",
            "1613       [[0.0040997183, 0.00014488181, 0.9957553]]\n",
            "1614      [[0.0017651472, 0.00011017403, 0.99812466]]\n",
            "1615      [[0.0011524182, 0.00014533773, 0.99870217]]\n",
            "1616         [[0.0031947694, 0.11199115, 0.88481414]]\n",
            "1617        [[0.0041404236, 0.0016597484, 0.9941999]]\n",
            "1618       [[0.0007001948, 0.00035256086, 0.9989472]]\n",
            "1619       [[0.0026911004, 6.585517e-05, 0.99724305]]\n",
            "1620         [[0.066009976, 0.0022683477, 0.9317217]]\n",
            "1621           [[0.14203161, 0.001985028, 0.8559834]]\n",
            "1622       [[0.0006722147, 9.959881e-06, 0.99931777]]\n",
            "1623     [[0.00045278485, 1.1768214e-05, 0.99953544]]\n",
            "1624      [[0.0003679702, 1.4087657e-05, 0.99961793]]\n",
            "1625          [[0.0010572311, 0.05604607, 0.9428967]]\n",
            "1626        [[0.01741627, 0.00031905202, 0.98226464]]\n",
            "1627        [[0.001667757, 2.7521139e-05, 0.9983047]]\n",
            "1628        [[0.001367805, 1.7305825e-05, 0.9986149]]\n",
            "1629      [[0.0006250773, 1.01047535e-05, 0.9993648]]\n",
            "1630         [[0.001135238, 1.588853e-05, 0.9988489]]\n",
            "1631       [[0.0011270124, 5.2821582e-05, 0.9988201]]\n",
            "1632      [[0.00093712594, 2.8007335e-05, 0.9990349]]\n",
            "1633       [[9.2143884e-05, 0.0001712774, 0.9997366]]\n",
            "1634        [[0.00014014107, 0.016640453, 0.9832193]]\n",
            "1635           [[0.0107674, 8.171432e-05, 0.9891509]]\n",
            "1636         [[0.0034606957, 0.66879123, 0.32774806]]\n",
            "1637          [[0.9093334, 0.078024685, 0.012641917]]\n",
            "1638           [[0.005217809, 0.51991725, 0.4748649]]\n",
            "1639         [[0.00035808122, 0.974006, 0.025635956]]\n",
            "1640     [[0.00033129088, 4.5065593e-05, 0.99962366]]\n",
            "1641        [[0.0009784837, 0.0024928425, 0.9965287]]\n",
            "1642         [[0.00035808122, 0.974006, 0.025635956]]\n",
            "1643        [[0.022224333, 0.0050394456, 0.97273624]]\n",
            "1644            [[0.01059397, 0.7916007, 0.19780529]]\n",
            "1645              [[0.0702959, 0.680319, 0.24938513]]\n",
            "1646          [[0.007911118, 0.002254251, 0.9898346]]\n",
            "1647             [[0.22910081, 0.570628, 0.20027125]]\n",
            "1648        [[0.0008870451, 6.964953e-05, 0.9990433]]\n",
            "1649         [[0.006539564, 0.014821103, 0.97863936]]\n",
            "1650            [[0.01045009, 0.0339452, 0.95560473]]\n",
            "1651          [[0.0025916398, 0.9181145, 0.07929391]]\n",
            "1652           [[0.0016909898, 0.5846617, 0.4136473]]\n",
            "1653       [[0.0008442318, 2.5544663e-05, 0.9991303]]\n",
            "1654      [[0.0007813653, 1.9070672e-05, 0.99919957]]\n",
            "1655           [[0.45152667, 0.16708021, 0.38139313]]\n",
            "1656     [[0.00023018317, 4.6056877e-05, 0.99972385]]\n",
            "1657            [[0.8234398, 0.1415215, 0.035038766]]\n",
            "1658     [[0.00026477806, 3.5146353e-05, 0.99970007]]\n",
            "1659       [[0.0006077399, 1.2336804e-05, 0.9993799]]\n",
            "1660        [[0.0006547897, 1.65514e-05, 0.99932873]]\n",
            "1661      [[0.0008940916, 0.00019668626, 0.99890924]]\n",
            "1662          [[0.006021028, 0.76043576, 0.23354323]]\n",
            "1663        [[0.0005829538, 0.0018856261, 0.9975314]]\n",
            "1664        [[0.0005829538, 0.0018856261, 0.9975314]]\n",
            "1665      [[0.0020016094, 4.4263634e-05, 0.99795413]]\n",
            "1666        [[0.0024774745, 4.866086e-05, 0.9974739]]\n",
            "1667      [[0.0007843055, 0.00014977773, 0.99906594]]\n",
            "1668           [[0.5549057, 0.023348814, 0.42174548]]\n",
            "1669           [[0.5549057, 0.023348814, 0.42174548]]\n",
            "1670      [[0.0007588342, 2.9581794e-05, 0.99921155]]\n",
            "1671       [[0.0010980286, 0.00012614492, 0.9987759]]\n",
            "1672         [[0.0035904339, 0.019581921, 0.9768276]]\n",
            "1673        [[0.0105417585, 0.89544934, 0.094008915]]\n",
            "1674          [[0.026273625, 0.9374557, 0.036270585]]\n",
            "1675        [[0.96048325, 0.032595474, 0.0069213742]]\n",
            "1676         [[0.0023739717, 0.03467663, 0.96294934]]\n",
            "1677         [[0.005840835, 0.0045070536, 0.9896521]]\n",
            "1678       [[0.0008768086, 0.99800867, 0.0011145686]]\n",
            "1679            [[0.012403592, 0.24434443, 0.743252]]\n",
            "1680          [[0.001382375, 0.000590161, 0.9980275]]\n",
            "1681        [[0.0042342427, 0.0069892695, 0.9887764]]\n",
            "1682       [[0.00072227773, 0.0001055175, 0.9991722]]\n",
            "1683          [[0.001382375, 0.000590161, 0.9980275]]\n",
            "1684          [[0.002491516, 3.19336e-05, 0.9974765]]\n",
            "1685         [[0.9529382, 0.045702897, 0.0013588661]]\n",
            "1686        [[0.0046639894, 0.0004489376, 0.9948872]]\n",
            "1687         [[0.005987016, 0.105739765, 0.88827324]]\n",
            "1688           [[0.13757692, 0.18304127, 0.67938185]]\n",
            "1689          [[0.006489565, 0.028397715, 0.9651128]]\n",
            "1690         [[0.008313993, 0.0001683838, 0.9915176]]\n",
            "1691           [[0.2580595, 0.73306775, 0.008872752]]\n",
            "1692            [[0.932452, 0.06082076, 0.006727257]]\n",
            "1693       [[0.0008261456, 0.00027996989, 0.9988939]]\n",
            "1694          [[0.9690412, 0.02966971, 0.0012891291]]\n",
            "1695        [[0.00039888607, 7.16447e-05, 0.9995295]]\n",
            "1696      [[0.0004592472, 1.5860529e-05, 0.99952495]]\n",
            "1697        [[0.9891916, 0.0033764176, 0.0074319174]]\n",
            "1698           [[0.003920182, 0.9299204, 0.06615947]]\n",
            "1699         [[0.000597582, 7.48426e-05, 0.99932766]]\n",
            "1700          [[0.008496702, 0.07620921, 0.91529405]]\n",
            "1701       [[0.0005415495, 1.899411e-05, 0.99943954]]\n",
            "1702      [[0.00054796913, 0.0013123589, 0.99813974]]\n",
            "1703          [[0.0065156333, 0.9608498, 0.03263455]]\n",
            "1704          [[0.0014435377, 0.8635782, 0.13497825]]\n",
            "1705       [[0.00030218807, 4.235553e-05, 0.9996555]]\n",
            "1706         [[0.0075041703, 0.015366839, 0.9771289]]\n",
            "1707         [[0.012796016, 0.008118214, 0.97908574]]\n",
            "1708         [[0.002690386, 0.97792166, 0.019388001]]\n",
            "1709          [[0.05469431, 0.9383299, 0.0069758683]]\n",
            "1710           [[0.12434671, 0.8695729, 0.006080377]]\n",
            "1711          [[0.9820779, 0.009385582, 0.008536485]]\n",
            "1712           [[0.4521919, 0.54124784, 0.006560267]]\n",
            "1713          [[0.0064559686, 0.8597342, 0.13380983]]\n",
            "1714          [[0.0010633876, 0.991757, 0.007179637]]\n",
            "1715          [[0.98756427, 0.004519064, 0.00791671]]\n",
            "1716       [[0.00079513306, 9.999655e-05, 0.9991048]]\n",
            "1717           [[0.70616317, 0.12730889, 0.16652797]]\n",
            "1718         [[0.0025084638, 1.68536e-05, 0.9974746]]\n",
            "1719         [[0.0026590442, 7.94438e-05, 0.9972615]]\n",
            "1720      [[0.9994636, 0.00014908276, 0.00038735857]]\n",
            "1721               [[0.293263, 0.3813937, 0.3253433]]\n",
            "1722            [[0.0011936799, 0.8172834, 0.181523]]\n",
            "1723       [[0.0056635304, 0.00012066594, 0.9942158]]\n",
            "1724          [[0.0076948865, 0.8134035, 0.17890163]]\n",
            "1725       [[0.0024552902, 2.325276e-05, 0.99752134]]\n",
            "1726        [[0.018505612, 0.0041794195, 0.97731495]]\n",
            "1727       [[0.0010930867, 8.560908e-06, 0.99889827]]\n",
            "1728         [[0.9945261, 0.003138426, 0.0023355056]]\n",
            "1729       [[0.98201466, 0.00066571095, 0.017319616]]\n",
            "1730        [[0.00051356823, 9.84171e-06, 0.9994766]]\n",
            "1731     [[0.0003518168, 1.27106705e-05, 0.99963546]]\n",
            "1732       [[0.0032035604, 3.583888e-05, 0.99676055]]\n",
            "1733       [[0.0041638664, 0.00046298312, 0.9953732]]\n",
            "1734       [[0.0041638664, 0.00046298312, 0.9953732]]\n",
            "1735          [[0.0269112, 0.97083604, 0.0022527913]]\n",
            "1736       [[0.00015039589, 0.0010362236, 0.9988134]]\n",
            "1737       [[0.0002594514, 5.1136212e-06, 0.9997354]]\n",
            "1738      [[0.00025306694, 1.1114204e-05, 0.9997359]]\n",
            "1739     [[0.00014203585, 1.41922155e-05, 0.9998437]]\n",
            "1740       [[0.00012799968, 0.98532027, 0.014551768]]\n",
            "1741          [[0.024840193, 0.9565024, 0.018657455]]\n",
            "1742           [[0.051007178, 0.86131155, 0.0876813]]\n",
            "1743             [[0.1418721, 0.7737971, 0.08433086]]\n",
            "1744      [[0.00014870509, 0.00051510514, 0.9993362]]\n",
            "1745      [[0.00058115827, 8.827171e-06, 0.99941003]]\n",
            "1746       [[0.0007610976, 9.273016e-06, 0.99922967]]\n",
            "1747     [[0.00050221157, 1.8008048e-05, 0.99947983]]\n",
            "1748           [[0.22253889, 0.46629655, 0.31116456]]\n",
            "1749          [[0.08730285, 0.007940201, 0.90475696]]\n",
            "1750         [[0.0037418976, 0.000611632, 0.9956464]]\n",
            "1751           [[0.023029257, 0.9005444, 0.07642635]]\n",
            "1752         [[0.002346517, 2.800599e-05, 0.9976255]]\n",
            "1753           [[0.15819028, 0.35846496, 0.48334482]]\n",
            "1754            [[0.297437, 0.7007374, 0.0018256089]]\n",
            "1755           [[0.3124927, 0.6857929, 0.0017144202]]\n",
            "1756       [[0.0094546275, 0.00024119887, 0.9903042]]\n",
            "1757          [[0.010898898, 0.001517491, 0.9875836]]\n",
            "1758        [[0.0037889662, 1.4145712e-05, 0.996197]]\n",
            "1759          [[0.0027656832, 0.5131683, 0.48406604]]\n",
            "1760           [[0.009328808, 0.41345167, 0.5772195]]\n",
            "1761           [[0.009328808, 0.41345167, 0.5772195]]\n",
            "1762             [[0.21739438, 0.371276, 0.41132963]]\n",
            "1763             [[0.15423572, 0.5361959, 0.3095684]]\n",
            "1764      [[0.0010888225, 0.000118542586, 0.9987925]]\n",
            "1765           [[0.016300479, 0.12305884, 0.8606407]]\n",
            "1766       [[0.00040403215, 0.023156604, 0.97643936]]\n",
            "1767          [[0.008886365, 0.16722585, 0.82388777]]\n",
            "1768          [[0.11421648, 0.029689554, 0.85609394]]\n",
            "1769     [[0.00037746888, 3.7743557e-05, 0.99958473]]\n",
            "1770     [[0.00018137625, 1.9007424e-05, 0.99979967]]\n",
            "1771       [[0.00048407036, 0.9965313, 0.0029846397]]\n",
            "1772           [[0.0063936063, 0.19978246, 0.793824]]\n",
            "1773        [[0.9842202, 0.0077769165, 0.0080029275]]\n",
            "1774        [[0.0017366088, 0.0036755155, 0.9945879]]\n",
            "1775          [[0.0015043202, 0.013826607, 0.984669]]\n",
            "1776          [[0.0015043202, 0.013826607, 0.984669]]\n",
            "1777         [[0.001498586, 0.023148663, 0.97535276]]\n",
            "1778        [[0.0009858634, 0.118114956, 0.88089925]]\n",
            "1779           [[0.0057739834, 0.17346197, 0.820764]]\n",
            "1780            [[0.01799579, 0.6332605, 0.34874374]]\n",
            "1781            [[0.5443263, 0.3948369, 0.060836785]]\n",
            "1782       [[0.0010148869, 0.0002988056, 0.99868625]]\n",
            "1783         [[0.003388195, 0.00085092743, 0.995761]]\n",
            "1784          [[0.027489802, 0.58873206, 0.38377815]]\n",
            "1785        [[0.0116773825, 0.0019339402, 0.9863886]]\n",
            "1786      [[0.00028089646, 0.0014856085, 0.99823356]]\n",
            "1787         [[0.003577707, 0.0038934078, 0.9925289]]\n",
            "1788           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1789           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1790           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1791           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1792            [[0.009796006, 0.2314078, 0.7587963]]\n",
            "1793           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1794           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1795           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1796           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1797           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1798           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1799           [[0.012032163, 0.25695014, 0.7310177]]\n",
            "1800     [[0.00029156986, 0.00014389555, 0.99956447]]\n",
            "1801        [[0.004095187, 4.5115998e-05, 0.9958597]]\n",
            "1802            [[0.24663143, 0.5283813, 0.22498728]]\n",
            "1803          [[0.0015073521, 0.02145678, 0.9770358]]\n",
            "1804         [[0.0013131249, 0.9900878, 0.008599062]]\n",
            "1805          [[0.0016738556, 0.5819658, 0.41636026]]\n",
            "1806         [[0.0025323383, 0.83661664, 0.16085097]]\n",
            "1807        [[0.0018720778, 0.92152745, 0.076600514]]\n",
            "1808           [[0.011870315, 0.6641622, 0.32396746]]\n",
            "1809       [[0.003532726, 3.0309433e-05, 0.99643695]]\n",
            "1810      [[0.00093437947, 3.1251697e-05, 0.9990344]]\n",
            "1811          [[0.3300326, 0.66462475, 0.0053426255]]\n",
            "1812         [[0.0074609695, 0.01288372, 0.97965527]]\n",
            "1813       [[0.0006869646, 8.340982e-06, 0.99930465]]\n",
            "1814        [[0.0028008877, 0.010777786, 0.98642135]]\n",
            "1815          [[0.52556497, 0.0017916193, 0.4726434]]\n",
            "1816      [[0.0029462697, 2.8739107e-05, 0.99702495]]\n",
            "1817      [[0.0044536544, 0.00043638135, 0.99510986]]\n",
            "1818          [[0.969104, 0.029022895, 0.0018731138]]\n",
            "1819           [[0.13011134, 0.017604839, 0.8522838]]\n",
            "1820       [[0.0045719803, 0.00027886574, 0.9951491]]\n",
            "1821      [[0.0016051849, 7.6969554e-05, 0.99831784]]\n",
            "1822          [[0.06260353, 0.0027645468, 0.9346319]]\n",
            "1823           [[0.046477884, 0.22718686, 0.7263353]]\n",
            "1824         [[0.03892109, 0.00035482625, 0.9607241]]\n",
            "1825          [[0.0014397816, 0.24569474, 0.7528655]]\n",
            "1826          [[0.017971134, 0.72030926, 0.26171955]]\n",
            "1827           [[0.01470141, 0.75181776, 0.23348086]]\n",
            "1828          [[0.013404422, 0.80630094, 0.18029469]]\n",
            "1829           [[0.046477884, 0.22718686, 0.7263353]]\n",
            "1830            [[0.19208296, 0.6830367, 0.12488034]]\n",
            "1831       [[0.0012817283, 2.4834915e-05, 0.9986934]]\n",
            "1832       [[0.0010606459, 3.195545e-05, 0.99890745]]\n",
            "1833        [[0.0013962144, 0.0011715924, 0.9974323]]\n",
            "1834        [[0.0020118952, 0.0067734923, 0.9912145]]\n",
            "1835          [[0.8541136, 0.0012407146, 0.14464566]]\n",
            "1836          [[0.8541136, 0.0012407146, 0.14464566]]\n",
            "1837        [[0.0126868365, 0.0002054503, 0.9871077]]\n",
            "1838          [[0.045332655, 0.86385906, 0.09080832]]\n",
            "1839         [[0.31275645, 0.68581706, 0.0014264574]]\n",
            "1840      [[0.0012630224, 2.9246556e-05, 0.99870765]]\n",
            "1841           [[0.018378563, 0.01606756, 0.9655538]]\n",
            "1842       [[0.0037071998, 1.9503635e-05, 0.9962733]]\n",
            "1843       [[0.0007222789, 2.922154e-05, 0.99924856]]\n",
            "1844       [[0.0014015769, 0.00050183997, 0.9980965]]\n",
            "1845        [[0.001974389, 6.028866e-05, 0.99796534]]\n",
            "1846        [[0.0064366576, 7.94915e-05, 0.99348384]]\n",
            "1847       [[0.0071788104, 0.0063510854, 0.98647016]]\n",
            "1848        [[0.0041432315, 0.0020689543, 0.9937878]]\n",
            "1849        [[0.0012687806, 0.0015636139, 0.9971675]]\n",
            "1850        [[0.007311155, 0.0017215963, 0.99096733]]\n",
            "1851      [[0.00085194584, 0.00011228335, 0.9990357]]\n",
            "1852        [[0.0005796494, 8.140249e-05, 0.9993389]]\n",
            "1853        [[0.003271293, 2.3060746e-05, 0.9967057]]\n",
            "1854         [[0.009767445, 0.0055691027, 0.9846635]]\n",
            "1855         [[0.96032614, 0.038047314, 0.001626488]]\n",
            "1856         [[0.9899132, 0.0002662683, 0.009820579]]\n",
            "1857      [[0.0005009419, 1.12097505e-05, 0.9994879]]\n",
            "1858      [[0.00047786254, 4.0551113e-05, 0.9994816]]\n",
            "1859        [[0.0003245407, 8.392251e-05, 0.9995915]]\n",
            "1860      [[0.0005009419, 1.12097505e-05, 0.9994879]]\n",
            "1861       [[0.00064808654, 0.027596423, 0.97175545]]\n",
            "1862          [[0.0024936947, 0.5286175, 0.46888882]]\n",
            "1863        [[0.00081055576, 3.147329e-05, 0.999158]]\n",
            "1864        [[0.0003245407, 8.392251e-05, 0.9995915]]\n",
            "1865         [[0.008113466, 0.014037615, 0.97784895]]\n",
            "1866          [[0.0009949756, 0.9598167, 0.03918837]]\n",
            "1867          [[0.0029670733, 0.6582099, 0.33882302]]\n",
            "1868          [[0.0020784151, 0.987997, 0.009924562]]\n",
            "1869         [[0.0017982627, 0.9930179, 0.005183817]]\n",
            "1870         [[0.0005619874, 0.9946306, 0.004807401]]\n",
            "1871        [[0.0015798835, 9.9137986e-05, 0.998321]]\n",
            "1872          [[0.004770759, 0.011644829, 0.9835844]]\n",
            "1873         [[0.0030367982, 0.00626111, 0.99070203]]\n",
            "1874       [[0.0012097125, 4.5145123e-05, 0.9987451]]\n",
            "1875        [[0.0012198333, 0.0010658668, 0.9977143]]\n",
            "1876           [[0.013331344, 0.8919187, 0.09474991]]\n",
            "1877       [[0.00093986903, 0.0094925575, 0.9895676]]\n",
            "1878      [[0.0011013639, 0.00034956142, 0.99854904]]\n",
            "1879     [[0.00058103335, 5.3276934e-05, 0.99936575]]\n",
            "1880      [[0.0011013639, 0.00034956142, 0.99854904]]\n",
            "1881       [[0.0010243725, 0.0001968058, 0.99877876]]\n",
            "1882       [[0.0028287286, 0.0033826195, 0.99378866]]\n",
            "1883      [[0.0012810697, 0.00010944477, 0.99860954]]\n",
            "1884      [[0.0036247217, 0.00072149845, 0.99565375]]\n",
            "1885        [[0.0049779457, 0.0007632016, 0.9942589]]\n",
            "1886         [[0.9300584, 0.066288576, 0.0036530036]]\n",
            "1887          [[0.007902591, 0.009053261, 0.9830442]]\n",
            "1888         [[0.006688665, 7.57013e-05, 0.99323565]]\n",
            "1889         [[0.9913685, 0.007026885, 0.0016046742]]\n",
            "1890           [[0.9222632, 0.028168205, 0.04956862]]\n",
            "1891      [[0.00047389526, 2.1329974e-05, 0.9995048]]\n",
            "1892          [[0.0070789843, 0.80084544, 0.1920755]]\n",
            "1893           [[0.099882536, 0.01361029, 0.8865072]]\n",
            "1894       [[0.0002487649, 2.1697133e-05, 0.9997296]]\n",
            "1895           [[0.07647799, 0.55703896, 0.36648303]]\n",
            "1896      [[0.00026183747, 1.0948646e-05, 0.9997272]]\n",
            "1897         [[0.0030237853, 0.85145986, 0.14551634]]\n",
            "1898            [[0.23881426, 0.6989725, 0.06221327]]\n",
            "1899            [[0.02395423, 0.7814577, 0.19458808]]\n",
            "1900         [[0.016792065, 0.96198815, 0.021219809]]\n",
            "1901       [[0.0006199377, 7.423912e-06, 0.99937266]]\n",
            "1902     [[0.00055324216, 1.3942037e-05, 0.99943274]]\n",
            "1903          [[0.005742356, 0.003099267, 0.9911584]]\n",
            "1904       [[0.99581134, 0.0037073914, 0.0004812731]]\n",
            "1905        [[0.9967824, 0.0018970616, 0.0013204553]]\n",
            "1906        [[0.002723368, 0.9968946, 0.00038202773]]\n",
            "1907         [[0.0007686794, 0.0014062962, 0.997825]]\n",
            "1908      [[0.0005752059, 0.00027464563, 0.99915016]]\n",
            "1909         [[0.061745804, 0.0012774742, 0.9369767]]\n",
            "1910       [[0.002279926, 1.2234429e-05, 0.99770784]]\n",
            "1911        [[0.0008406057, 9.013653e-06, 0.9991503]]\n",
            "1912          [[0.00077248085, 0.3256276, 0.6735999]]\n",
            "1913       [[0.0010616732, 8.4633546e-05, 0.9988537]]\n",
            "1914      [[0.00084729725, 2.4798306e-05, 0.9991279]]\n",
            "1915      [[0.00067799044, 8.151725e-06, 0.99931395]]\n",
            "1916        [[0.0012621963, 7.446085e-05, 0.9986634]]\n",
            "1917       [[0.00048137733, 0.94313186, 0.056386758]]\n",
            "1918       [[0.0014625539, 0.0015974134, 0.99694014]]\n",
            "1919        [[0.0008385882, 7.852454e-06, 0.9991535]]\n",
            "1920         [[0.0010994101, 0.003907009, 0.9949936]]\n",
            "1921          [[0.039264224, 0.027032515, 0.9337033]]\n",
            "1922       [[0.004636302, 0.00012337088, 0.99524033]]\n",
            "1923        [[0.0015763636, 0.0055439076, 0.9928798]]\n",
            "1924      [[6.894362e-05, 0.00031751228, 0.99961346]]\n",
            "1925      [[0.00037685005, 2.5067404e-05, 0.9995981]]\n",
            "1926      [[0.0004567002, 1.6612008e-05, 0.99952674]]\n",
            "1927      [[0.00013218785, 1.9205203e-05, 0.9998486]]\n",
            "1928       [[0.00013227481, 0.0026742746, 0.9971934]]\n",
            "1929      [[0.00022689006, 0.00076295267, 0.9990102]]\n",
            "1930         [[0.0024542683, 0.002972487, 0.9945733]]\n",
            "1931      [[0.00027157034, 3.7285463e-05, 0.9996911]]\n",
            "1932      [[0.00022689006, 0.00076295267, 0.9990102]]\n",
            "1933          [[0.8668102, 0.030148555, 0.103041254]]\n",
            "1934       [[0.9987413, 0.00012707293, 0.0011316816]]\n",
            "1935           [[0.16165408, 0.8265434, 0.011802507]]\n",
            "1936             [[0.5342128, 0.451587, 0.014200176]]\n",
            "1937       [[0.0011693996, 7.4771897e-06, 0.9988231]]\n",
            "1938         [[0.0017765675, 0.16002281, 0.83820057]]\n",
            "1939       [[0.0005164178, 3.676942e-06, 0.99947995]]\n",
            "1940        [[0.0015326208, 0.031321235, 0.96714616]]\n",
            "1941             [[0.13547389, 0.2864758, 0.5780503]]\n",
            "1942       [[0.00024072765, 8.637366e-05, 0.9996729]]\n",
            "1943          [[0.0015785524, 0.17602329, 0.8223981]]\n",
            "1944         [[0.0057016844, 0.19615053, 0.79814774]]\n",
            "1945         [[0.00393777, 0.00027513521, 0.9957871]]\n",
            "1946        [[0.002401263, 5.605973e-05, 0.99754274]]\n",
            "1947        [[0.0034439876, 0.0009179111, 0.9956381]]\n",
            "1948          [[0.73230433, 0.043084845, 0.22461087]]\n",
            "1949          [[0.019561423, 0.69457304, 0.28586558]]\n",
            "1950          [[0.006045562, 0.011899242, 0.9820551]]\n",
            "1951         [[0.0031941794, 0.05233586, 0.94447005]]\n",
            "1952           [[0.8493763, 0.077561386, 0.07306223]]\n",
            "1953       [[0.0008041611, 3.0009009e-05, 0.9991659]]\n",
            "1954       [[0.0018658863, 0.00038392775, 0.9977502]]\n",
            "1955     [[0.00028490872, 0.00013093602, 0.99958414]]\n",
            "1956        [[0.0002722682, 0.0006835709, 0.9990441]]\n",
            "1957         [[0.001093413, 0.0007391805, 0.9981674]]\n",
            "1958         [[0.0026253487, 0.9590204, 0.038354304]]\n",
            "1959          [[0.66927594, 0.32585523, 0.004868816]]\n",
            "1960        [[0.0020685694, 0.9978619, 6.957169e-05]]\n",
            "1961       [[0.00034632438, 0.98824894, 0.011404671]]\n",
            "1962       [[0.0005080167, 0.0035825344, 0.99590945]]\n",
            "1963         [[0.004964774, 0.089512795, 0.90552247]]\n",
            "1964         [[0.020017045, 0.0004220283, 0.9795609]]\n",
            "1965         [[0.020017045, 0.0004220283, 0.9795609]]\n",
            "1966           [[0.0074335784, 0.0988741, 0.8936923]]\n",
            "1967           [[0.026917089, 0.33997265, 0.6331102]]\n",
            "1968        [[0.024209058, 0.00029388515, 0.9754971]]\n",
            "1969          [[0.9276366, 0.051303837, 0.021059515]]\n",
            "1970          [[0.0031140803, 0.71632457, 0.2805613]]\n",
            "1971        [[0.0008106508, 3.0412295e-05, 0.999159]]\n",
            "1972     [[0.00036365952, 1.0091716e-05, 0.99962616]]\n",
            "1973       [[0.0006520624, 3.1715204e-05, 0.9993162]]\n",
            "1974       [[0.00056818407, 8.137456e-05, 0.9993505]]\n",
            "1975       [[0.0005324219, 0.00027287492, 0.9991947]]\n",
            "1976         [[0.000319555, 0.00047642805, 0.999204]]\n",
            "1977            [[0.021017607, 0.6600409, 0.3189415]]\n",
            "1978          [[0.009079069, 0.007263095, 0.9836579]]\n",
            "1979          [[0.0016178202, 0.94578755, 0.0525946]]\n",
            "1980          [[0.026759388, 0.020963373, 0.9522773]]\n",
            "1981         [[0.0020731688, 0.9065456, 0.091381274]]\n",
            "1982       [[0.0013799918, 0.00024339215, 0.9983766]]\n",
            "1983       [[0.0005729585, 3.5239816e-05, 0.9993918]]\n",
            "1984       [[0.0012132911, 1.0343419e-05, 0.9987764]]\n",
            "1985       [[0.0017928319, 1.0221895e-05, 0.9981969]]\n",
            "1986       [[0.0030373267, 0.0037443526, 0.99321836]]\n",
            "1987          [[0.003860203, 0.007823549, 0.9883161]]\n",
            "1988          [[0.002250376, 0.03846913, 0.95928043]]\n",
            "1989       [[0.0030373267, 0.0037443526, 0.99321836]]\n",
            "1990             [[0.02535497, 0.19958903, 0.775056]]\n",
            "1991          [[0.046451174, 0.28729498, 0.66625386]]\n",
            "1992          [[0.0021981695, 0.015977839, 0.981824]]\n",
            "1993        [[0.002259329, 1.8568353e-05, 0.9977221]]\n",
            "1994          [[0.0012124632, 0.8621911, 0.13659647]]\n",
            "1995          [[0.0018489651, 0.27376056, 0.7243905]]\n",
            "1996        [[0.00016986152, 0.9966114, 0.003218686]]\n",
            "1997           [[0.008986409, 0.029736629, 0.961277]]\n",
            "1998          [[0.010310801, 0.39767218, 0.59201705]]\n",
            "1999          [[0.007515414, 0.9270073, 0.065477245]]\n",
            "2000        [[0.0017342189, 0.0019899819, 0.9962758]]\n",
            "2001        [[0.003466202, 0.0011010676, 0.99543273]]\n",
            "2002            [[0.0158272, 0.9617808, 0.022391967]]\n",
            "2003       [[0.0005474543, 0.99904615, 0.0004063573]]\n",
            "2004          [[0.0058763325, 0.8644193, 0.12970442]]\n",
            "2005       [[0.0031394926, 0.99519664, 0.0016639145]]\n",
            "2006        [[0.00026101744, 0.9961981, 0.003540786]]\n",
            "2007       [[0.0013988896, 0.00040126336, 0.9981998]]\n",
            "2008       [[0.0064353268, 0.99108934, 0.0024753616]]\n",
            "2009         [[0.0057447515, 0.011062585, 0.9831927]]\n",
            "2010       [[0.99607193, 0.0015217692, 0.0024063461]]\n",
            "2011          [[0.0029446608, 0.46526903, 0.5317863]]\n",
            "2012      [[0.00041897877, 2.4292747e-05, 0.9995567]]\n",
            "2013         [[0.0047329185, 0.50621986, 0.48904723]]\n",
            "2014      [[0.0029588693, 6.5537635e-05, 0.99697566]]\n",
            "2015            [[0.5900057, 0.11453214, 0.29546213]]\n",
            "2016       [[0.0041258545, 7.4637566e-05, 0.9957995]]\n",
            "2017         [[0.036113393, 0.95260054, 0.011286107]]\n",
            "2018             [[0.41677165, 0.18303636, 0.400192]]\n",
            "2019         [[0.004884244, 8.820735e-05, 0.9950275]]\n",
            "2020       [[0.0011440844, 0.0022381947, 0.99661773]]\n",
            "2021        [[0.0012468961, 0.0016912667, 0.9970618]]\n",
            "2022          [[0.063446425, 0.0013575078, 0.935196]]\n",
            "2023       [[0.0011023792, 1.1181049e-05, 0.9988864]]\n",
            "2024         [[0.0027302597, 0.029411986, 0.9678578]]\n",
            "2025         [[0.0047413413, 0.17799631, 0.81726235]]\n",
            "2026         [[0.0014389097, 0.00038354, 0.99817765]]\n",
            "2027         [[0.002948957, 0.0002271682, 0.9968239]]\n",
            "2028        [[0.0012473398, 0.005050739, 0.99370193]]\n",
            "2029           [[0.00197766, 0.019272795, 0.9787496]]\n",
            "2030       [[0.0012540704, 8.055093e-05, 0.99866533]]\n",
            "2031        [[0.04857201, 0.00046897735, 0.95095897]]\n",
            "2032       [[0.0033401125, 0.0036979716, 0.99296194]]\n",
            "2033         [[0.0011927355, 0.003971954, 0.9948354]]\n",
            "2034       [[0.0010837032, 0.0002815563, 0.99863476]]\n",
            "2035          [[0.0051938733, 0.5837847, 0.41102147]]\n",
            "2036      [[0.00012065073, 0.9995633, 0.00031609635]]\n",
            "2037      [[0.00010366276, 0.99952257, 0.0003737884]]\n",
            "2038         [[0.00014164604, 0.998831, 0.001027375]]\n",
            "2039       [[8.631594e-05, 0.99952984, 0.0003838926]]\n",
            "2040          [[0.15375055, 0.007036537, 0.83921283]]\n",
            "2041          [[0.08498165, 0.0021607892, 0.9128576]]\n",
            "2042          [[0.15375055, 0.007036537, 0.83921283]]\n",
            "2043      [[0.0050825956, 3.4551314e-05, 0.99488294]]\n",
            "2044           [[0.0022428, 0.9950558, 0.0027014194]]\n",
            "2045       [[0.00092280324, 0.9966785, 0.0023986916]]\n",
            "2046       [[0.00077627524, 0.9974443, 0.0017794147]]\n",
            "2047          [[0.004960133, 0.9463272, 0.048712622]]\n",
            "2048         [[0.9668305, 0.030470885, 0.0026985514]]\n",
            "2049        [[0.99580306, 0.0006219909, 0.003574867]]\n",
            "2050       [[0.0028971785, 0.00026357005, 0.9968393]]\n",
            "2051          [[0.005234268, 0.47527397, 0.51949173]]\n",
            "2052       [[0.0012154676, 0.0011097861, 0.99767476]]\n",
            "2053          [[0.005234268, 0.47527397, 0.51949173]]\n",
            "2054         [[0.0011448823, 0.9817842, 0.017070925]]\n",
            "2055     [[0.00037458612, 1.0663126e-05, 0.99961483]]\n",
            "2056         [[0.0020021163, 0.018112665, 0.9798852]]\n",
            "2057       [[0.00044731077, 6.098517e-05, 0.9994917]]\n",
            "2058       [[0.0002985637, 3.380434e-05, 0.99966764]]\n",
            "2059        [[0.00032400968, 0.21289451, 0.78678143]]\n",
            "2060        [[0.0011358929, 8.826901e-05, 0.9987759]]\n",
            "2061       [[0.0015462588, 1.5518975e-05, 0.9984383]]\n",
            "2062        [[0.001766769, 1.5378226e-05, 0.9982179]]\n",
            "2063        [[0.001864874, 1.6556616e-05, 0.9981186]]\n",
            "2064        [[0.001373567, 5.3770706e-05, 0.9985726]]\n",
            "2065        [[0.0040966426, 3.695372e-05, 0.9958664]]\n",
            "2066           [[0.7097426, 0.28909883, 0.001158497]]\n",
            "2067         [[0.9753618, 0.021154406, 0.0034837644]]\n",
            "2068      [[0.0036585066, 0.00019145067, 0.99615014]]\n",
            "2069         [[0.0021893736, 0.012029797, 0.9857808]]\n",
            "2070           [[0.00881385, 0.027220506, 0.9639656]]\n",
            "2071         [[0.9929531, 0.005168729, 0.0018781142]]\n",
            "2072        [[0.0005916413, 5.529852e-05, 0.9993531]]\n",
            "2073        [[0.0017959591, 0.00029910821, 0.997905]]\n",
            "2074        [[0.95036286, 0.0045328247, 0.045104243]]\n",
            "2075            [[0.7094116, 0.044593085, 0.2459953]]\n",
            "2076             [[0.766785, 0.10128191, 0.13193302]]\n",
            "2077       [[0.9992648, 0.0005947393, 0.00014041837]]\n",
            "2078        [[0.0006988622, 0.0008597347, 0.9984414]]\n",
            "2079      [[0.00091650436, 0.00020394305, 0.9988795]]\n",
            "2080        [[0.0006095692, 6.870955e-05, 0.9993217]]\n",
            "2081      [[0.00085145386, 0.00025093084, 0.9988977]]\n",
            "2082         [[0.002238924, 0.0004948928, 0.9972662]]\n",
            "2083           [[0.005214749, 0.22907087, 0.7657144]]\n",
            "2084        [[0.0009977599, 0.0007255843, 0.9982767]]\n",
            "2085       [[0.00040715066, 0.0012151783, 0.9983777]]\n",
            "2086           [[0.000821699, 0.8634428, 0.13573553]]\n",
            "2087        [[0.0017188109, 1.670117e-05, 0.9982646]]\n",
            "2088        [[0.99150217, 0.006136359, 0.0023614503]]\n",
            "2089          [[0.0012550338, 0.14228082, 0.8564642]]\n",
            "2090       [[0.00070389966, 3.617164e-05, 0.9992599]]\n",
            "2091       [[0.0020254718, 0.0053775692, 0.99259686]]\n",
            "2092       [[0.00075663364, 0.0004349069, 0.9988084]]\n",
            "2093         [[0.008126392, 0.0032891275, 0.9885845]]\n",
            "2094        [[0.0035778966, 3.928831e-05, 0.9963827]]\n",
            "2095          [[0.00485306, 0.96881986, 0.026327154]]\n",
            "2096      [[0.00053009286, 0.9990069, 0.00046305507]]\n",
            "2097          [[0.004242115, 0.992172, 0.0035858431]]\n",
            "2098         [[0.008126392, 0.0032891275, 0.9885845]]\n",
            "2099      [[0.00046516844, 0.0011738904, 0.99836093]]\n",
            "2100         [[0.00060455414, 5.2747e-05, 0.9993426]]\n",
            "2101       [[0.0004178747, 2.1286827e-05, 0.9995608]]\n",
            "2102      [[0.00084405567, 2.2614231e-05, 0.9991333]]\n",
            "2103        [[0.0035875528, 0.009824937, 0.98658746]]\n",
            "2104       [[0.0015271595, 1.3584568e-05, 0.9984592]]\n",
            "2105      [[0.00027845168, 8.661768e-05, 0.99963486]]\n",
            "2106       [[0.00045946785, 0.0002637058, 0.9992768]]\n",
            "2107       [[0.99751943, 0.00010280931, 0.002377637]]\n",
            "2108        [[0.96181047, 1.9208343e-05, 0.03817021]]\n",
            "2109      [[0.0007486033, 0.99919254, 5.8878584e-05]]\n",
            "2110         [[0.9464362, 0.0017496443, 0.051814057]]\n",
            "2111        [[0.0077939513, 0.93241817, 0.059787884]]\n",
            "2112          [[0.010590142, 0.12548788, 0.86392194]]\n",
            "2113            [[0.0028593666, 0.392362, 0.6047786]]\n",
            "2114        [[0.0025650372, 0.0006717863, 0.9967631]]\n",
            "2115         [[0.00015795282, 0.00185639, 0.9979856]]\n",
            "2116         [[0.000560546, 0.027496243, 0.97194326]]\n",
            "2117        [[0.0035266925, 0.002120393, 0.99435294]]\n",
            "2118        [[0.0004612186, 0.0013974375, 0.9981414]]\n",
            "2119         [[0.0011960892, 0.40616938, 0.59263456]]\n",
            "2120       [[0.0008154785, 0.00011358871, 0.9990709]]\n",
            "2121       [[0.0007547174, 0.0007882784, 0.99845695]]\n",
            "2122           [[0.002468231, 0.39455566, 0.6029761]]\n",
            "2123           [[0.003963219, 0.4652071, 0.53082967]]\n",
            "2124        [[0.0027351251, 0.029657613, 0.96760726]]\n",
            "2125           [[0.43931457, 0.18856679, 0.37211865]]\n",
            "2126       [[0.00053640356, 0.0017643713, 0.9976992]]\n",
            "2127       [[0.0004537962, 4.0714644e-05, 0.9995054]]\n",
            "2128      [[0.00045396932, 0.0006782228, 0.99886787]]\n",
            "2129       [[0.0036953867, 5.0965922e-05, 0.9962536]]\n",
            "2130          [[0.33252203, 0.6596943, 0.0077837063]]\n",
            "2131          [[0.33252203, 0.6596943, 0.0077837063]]\n",
            "2132         [[0.00031399418, 0.00113147, 0.9985545]]\n",
            "2133      [[0.00044769185, 0.00019070973, 0.9993616]]\n",
            "2134       [[0.0005006473, 0.0002889486, 0.99921036]]\n",
            "2135         [[0.00031399418, 0.00113147, 0.9985545]]\n",
            "2136           [[0.10956067, 0.8779576, 0.012481779]]\n",
            "2137          [[0.000759587, 0.089246035, 0.9099944]]\n",
            "2138        [[0.003982285, 2.7143644e-05, 0.9959906]]\n",
            "2139        [[0.003982285, 2.7143644e-05, 0.9959906]]\n",
            "2140          [[0.9468938, 0.014094663, 0.039011497]]\n",
            "2141        [[0.0060826447, 0.94196373, 0.051953677]]\n",
            "2142        [[0.00087663863, 0.9927921, 0.006331189]]\n",
            "2143         [[0.0016677757, 0.23046945, 0.76786274]]\n",
            "2144       [[0.0006857757, 1.6004406e-05, 0.9992982]]\n",
            "2145       [[0.0045911977, 3.8501923e-05, 0.9953703]]\n",
            "2146          [[0.19665982, 0.0002393232, 0.8031008]]\n",
            "2147             [[0.2623842, 0.20775454, 0.5298613]]\n",
            "2148        [[0.0031104062, 0.005738707, 0.99115086]]\n",
            "2149       [[0.99833304, 0.0002629675, 0.0014039915]]\n",
            "2150          [[0.19665982, 0.0002393232, 0.8031008]]\n",
            "2151        [[0.0015891285, 4.647149e-05, 0.9983645]]\n",
            "2152          [[0.078699745, 0.9022663, 0.019033931]]\n",
            "2153       [[0.0011701774, 2.9960933e-05, 0.9987998]]\n",
            "2154          [[0.017375657, 0.08542863, 0.89719576]]\n",
            "2155        [[0.15676461, 0.00045962125, 0.84277576]]\n",
            "2156        [[0.0013330661, 0.0005792312, 0.9980877]]\n",
            "2157       [[0.0016843786, 0.00047268835, 0.9978429]]\n",
            "2158      [[0.00075666065, 0.00034227784, 0.9989011]]\n",
            "2159          [[0.0021253908, 0.01480014, 0.9830745]]\n",
            "2160        [[0.0008256719, 0.0002835873, 0.9988907]]\n",
            "2161           [[0.3939494, 0.031205049, 0.57484555]]\n",
            "2162            [[0.68966436, 0.04008405, 0.2702516]]\n",
            "2163           [[0.7164527, 0.049832206, 0.23371512]]\n",
            "2164         [[0.0064082067, 0.9894944, 0.004097417]]\n",
            "2165           [[0.050923306, 0.7488533, 0.20022334]]\n",
            "2166         [[0.0014798895, 5.411941e-05, 0.998466]]\n",
            "2167      [[0.0005884586, 0.00032419796, 0.99908733]]\n",
            "2168       [[0.0009902213, 5.278189e-05, 0.99895704]]\n",
            "2169       [[0.0013735493, 2.6739091e-05, 0.9985997]]\n",
            "2170          [[0.012870609, 0.52784544, 0.45928395]]\n",
            "2171     [[0.99956745, 0.00024927215, 0.00018328732]]\n",
            "2172           [[0.007059964, 0.9332836, 0.05965637]]\n",
            "2173          [[0.012870609, 0.52784544, 0.45928395]]\n",
            "2174          [[0.012870609, 0.52784544, 0.45928395]]\n",
            "2175       [[0.0032511645, 2.022437e-05, 0.99672866]]\n",
            "2176          [[0.0047987327, 0.04668803, 0.9485132]]\n",
            "2177       [[0.0032511645, 2.022437e-05, 0.99672866]]\n",
            "2178       [[0.0032511645, 2.022437e-05, 0.99672866]]\n",
            "2179       [[0.0077348547, 9.8339944e-05, 0.9921669]]\n",
            "2180     [[0.00083383854, 0.00021272972, 0.99895346]]\n",
            "2181      [[0.00060822105, 2.6894306e-05, 0.9993649]]\n",
            "2182     [[0.00079332944, 0.00013161078, 0.99907506]]\n",
            "2183          [[0.023474362, 0.9667309, 0.009794784]]\n",
            "2184          [[0.040028915, 0.9396409, 0.020330288]]\n",
            "2185           [[0.010507348, 0.9202692, 0.06922348]]\n",
            "2186      [[0.00017794536, 4.2136136e-05, 0.9997799]]\n",
            "2187         [[0.012570178, 6.133505e-05, 0.9873685]]\n",
            "2188         [[0.012570178, 6.133505e-05, 0.9873685]]\n",
            "2189      [[0.0005549543, 1.3528927e-05, 0.99943143]]\n",
            "2190      [[0.0003589438, 1.1888682e-05, 0.99962914]]\n",
            "2191      [[0.0005549543, 1.3528927e-05, 0.99943143]]\n",
            "2192        [[0.0009647922, 0.0004490416, 0.9985862]]\n",
            "2193         [[0.026266353, 0.004000044, 0.96973366]]\n",
            "2194          [[0.0016217798, 0.07068504, 0.9276932]]\n",
            "2195             [[0.013848647, 0.358915, 0.6272363]]\n",
            "2196       [[0.00014761694, 0.0017068117, 0.9981456]]\n",
            "2197       [[0.0011460473, 0.00063543965, 0.9982185]]\n",
            "2198          [[0.0021711974, 0.9181807, 0.07964815]]\n",
            "2199          [[0.0031209926, 0.000333962, 0.996545]]\n",
            "2200        [[0.0031523488, 0.0020893763, 0.9947583]]\n",
            "2201        [[0.002150085, 0.0026479822, 0.99520195]]\n",
            "2202           [[0.06618637, 0.008427489, 0.9253862]]\n",
            "2203         [[0.0011217966, 1.8252853e-05, 0.99886]]\n",
            "2204       [[0.0013410827, 2.0051713e-05, 0.9986389]]\n",
            "2205        [[0.0009254464, 8.646765e-05, 0.9989881]]\n",
            "2206         [[0.029777402, 0.0035508352, 0.9666717]]\n",
            "2207      [[0.0010322556, 2.7610924e-05, 0.99894017]]\n",
            "2208           [[0.11430829, 0.7641425, 0.121549256]]\n",
            "2209        [[0.00066519674, 0.9805611, 0.018773692]]\n",
            "2210           [[0.11430829, 0.7641425, 0.121549256]]\n",
            "2211      [[0.0006650131, 2.2401884e-05, 0.99931264]]\n",
            "2212      [[0.00060306425, 9.3211725e-05, 0.9993038]]\n",
            "2213         [[0.0031906962, 0.9277632, 0.069046065]]\n",
            "2214       [[0.00021312558, 0.9979055, 0.0018814356]]\n",
            "2215          [[0.015091505, 0.9797966, 0.005111872]]\n",
            "2216        [[0.003320719, 0.99590564, 0.0007735802]]\n",
            "2217         [[0.9940978, 0.003985016, 0.0019171342]]\n",
            "2218         [[0.994476, 7.816853e-05, 0.0054458575]]\n",
            "2219       [[0.001110909, 1.7211623e-05, 0.99887174]]\n",
            "2220           [[0.919211, 0.0012716935, 0.07951734]]\n",
            "2221      [[0.00047825038, 1.7495357e-05, 0.9995042]]\n",
            "2222      [[0.00046920616, 2.571827e-05, 0.99950504]]\n",
            "2223         [[0.036116462, 9.950817e-05, 0.9637841]]\n",
            "2224      [[0.00047825038, 1.7495357e-05, 0.9995042]]\n",
            "2225     [[0.00044324916, 4.8057118e-05, 0.99950874]]\n",
            "2226     [[0.00044324916, 4.8057118e-05, 0.99950874]]\n",
            "2227         [[0.008870127, 0.004855839, 0.98627394]]\n",
            "2228      [[0.00044770696, 5.0677587e-05, 0.9995016]]\n",
            "2229        [[0.0003535168, 7.564255e-05, 0.9995708]]\n",
            "2230     [[0.00044324916, 4.8057118e-05, 0.99950874]]\n",
            "2231       [[0.004402631, 0.000109177105, 0.9954882]]\n",
            "2232       [[0.0021268409, 3.2665343e-05, 0.9978404]]\n",
            "2233          [[0.005637966, 0.023817394, 0.9705447]]\n",
            "2234      [[0.0010694369, 0.00080529065, 0.99812526]]\n",
            "2235      [[0.0010694369, 0.00080529065, 0.99812526]]\n",
            "2236        [[0.0018943843, 7.358204e-06, 0.9980982]]\n",
            "2237       [[0.00084950385, 2.094425e-05, 0.9991296]]\n",
            "2238       [[0.004848071, 2.5957304e-05, 0.99512595]]\n",
            "2239        [[0.025219502, 0.00013840887, 0.9746421]]\n",
            "2240       [[0.0026058129, 0.00018550051, 0.9972088]]\n",
            "2241            [[0.8751546, 0.04162931, 0.08321606]]\n",
            "2242            [[0.48649108, 0.02489564, 0.4886132]]\n",
            "2243         [[0.0009694126, 0.8882611, 0.110769495]]\n",
            "2244         [[0.0067989966, 0.023961851, 0.9692392]]\n",
            "2245           [[0.009764309, 0.03100525, 0.9592305]]\n",
            "2246      [[0.0034498044, 3.0185292e-05, 0.99652004]]\n",
            "2247        [[0.0021154077, 0.000127369, 0.99775726]]\n",
            "2248      [[0.002076421, 0.000113642855, 0.99780995]]\n",
            "2249      [[0.0008621879, 0.00022101887, 0.99891686]]\n",
            "2250      [[0.00077828503, 2.2471208e-05, 0.9991992]]\n",
            "2251        [[0.94915056, 9.191957e-05, 0.050757587]]\n",
            "2252           [[0.1278131, 0.8690623, 0.0031245702]]\n",
            "2253           [[0.010424391, 0.054371536, 0.935204]]\n",
            "2254        [[0.0048461473, 0.0066519515, 0.9885019]]\n",
            "2255       [[0.000868633, 2.4275569e-05, 0.99910706]]\n",
            "2256          [[0.007368028, 0.0030899486, 0.989542]]\n",
            "2257        [[0.94915056, 9.191957e-05, 0.050757587]]\n",
            "2258           [[0.7218778, 0.0019296273, 0.2761926]]\n",
            "2259             [[0.54353607, 0.09788199, 0.358582]]\n",
            "2260       [[0.0010650951, 3.5745157e-05, 0.9988991]]\n",
            "2261          [[0.061230715, 0.17365767, 0.76511157]]\n",
            "2262       [[0.0010267542, 0.0004093147, 0.99856395]]\n",
            "2263      [[0.00081402564, 2.4855955e-05, 0.9991611]]\n",
            "2264          [[0.012235649, 0.50402117, 0.48374313]]\n",
            "2265          [[0.72407407, 0.2723218, 0.0036041464]]\n",
            "2266            [[0.2570606, 0.011291295, 0.7316481]]\n",
            "2267            [[0.037162665, 0.0606893, 0.9021481]]\n",
            "2268      [[0.00042328774, 1.3873671e-05, 0.9995629]]\n",
            "2269       [[0.00015727463, 0.0009047544, 0.9989379]]\n",
            "2270             [[0.05720677, 0.6314088, 0.3113844]]\n",
            "2271             [[0.05720677, 0.6314088, 0.3113844]]\n",
            "2272        [[0.0026581965, 0.0007922565, 0.9965495]]\n",
            "2273       [[0.0023742905, 0.00017878946, 0.9974469]]\n",
            "2274         [[0.004429668, 0.013554059, 0.98201627]]\n",
            "2275           [[0.66249543, 0.24114281, 0.09636181]]\n",
            "2276             [[0.05720677, 0.6314088, 0.3113844]]\n",
            "2277      [[0.0017098115, 1.43203215e-05, 0.9982759]]\n",
            "2278       [[0.0024242932, 1.4067651e-05, 0.9975617]]\n",
            "2279           [[0.053467188, 0.6600401, 0.28649276]]\n",
            "2280        [[0.0015664357, 0.006285718, 0.99214786]]\n",
            "2281       [[0.0006964516, 5.5219836e-05, 0.9992482]]\n",
            "2282      [[0.00097414246, 0.00017321216, 0.9988526]]\n",
            "2283         [[0.0010454534, 8.63509e-05, 0.9988682]]\n",
            "2284      [[0.0007294321, 2.8507902e-05, 0.99924207]]\n",
            "2285        [[0.0011644728, 1.678879e-05, 0.9988187]]\n",
            "2286     [[0.00067185494, 2.8302204e-05, 0.99929976]]\n",
            "2287         [[0.0013271421, 0.001908451, 0.9967644]]\n",
            "2288        [[0.001477736, 0.0013208019, 0.99720144]]\n",
            "2289       [[0.0004983141, 1.1306148e-05, 0.9994904]]\n",
            "2290           [[0.09024999, 0.44136077, 0.46838924]]\n",
            "2291       [[0.0004663213, 0.9990978, 0.00043582273]]\n",
            "2292       [[0.0004663213, 0.9990978, 0.00043582273]]\n",
            "2293          [[0.020806579, 0.9284376, 0.050755855]]\n",
            "2294         [[0.0023288801, 0.016327817, 0.9813433]]\n",
            "2295        [[0.00094364444, 0.92186636, 0.07718992]]\n",
            "2296     [[0.00039674708, 0.99922967, 0.00037355986]]\n",
            "2297           [[0.09024999, 0.44136077, 0.46838924]]\n",
            "2298        [[0.0012871334, 4.705514e-05, 0.9986658]]\n",
            "2299       [[0.002888493, 1.0904333e-05, 0.99710053]]\n",
            "2300           [[0.013921452, 0.3511225, 0.63495606]]\n",
            "2301          [[0.011693412, 0.93242157, 0.05588506]]\n",
            "2302          [[0.011693412, 0.93242157, 0.05588506]]\n",
            "2303      [[0.00075803994, 2.3846334e-05, 0.9992181]]\n",
            "2304      [[0.0005713819, 0.00017205458, 0.99925655]]\n",
            "2305      [[0.00075803994, 2.3846334e-05, 0.9992181]]\n",
            "2306               [[0.83258164, 0.05431833, 0.1131]]\n",
            "2307      [[0.0011137892, 2.7718044e-05, 0.99885845]]\n",
            "2308       [[0.0015267137, 0.00015891093, 0.9983144]]\n",
            "2309      [[0.00036246376, 1.2809136e-05, 0.9996247]]\n",
            "2310      [[0.00037102523, 2.7562066e-05, 0.9996014]]\n",
            "2311        [[0.0005628788, 4.777812e-05, 0.9993893]]\n",
            "2312       [[0.0022532868, 6.711429e-05, 0.99767965]]\n",
            "2313           [[0.009484926, 0.45114195, 0.5393731]]\n",
            "2314         [[0.9957522, 0.001269613, 0.0029781142]]\n",
            "2315         [[0.0010348645, 0.9766619, 0.022303196]]\n",
            "2316       [[0.0002037924, 0.99656564, 0.0032305496]]\n",
            "2317         [[0.00089647115, 0.985913, 0.013190532]]\n",
            "2318        [[0.0036075518, 0.003040837, 0.99335164]]\n",
            "2319         [[0.010598293, 0.0063848407, 0.9830169]]\n",
            "2320        [[0.0023155014, 0.89708954, 0.100594975]]\n",
            "2321             [[0.01565211, 0.920868, 0.06347996]]\n",
            "2322             [[0.01565211, 0.920868, 0.06347996]]\n",
            "2323        [[0.0034859905, 6.665777e-05, 0.9964474]]\n",
            "2324       [[0.0015605709, 2.349701e-05, 0.99841595]]\n",
            "2325        [[0.0009304742, 9.740847e-05, 0.9989722]]\n",
            "2326          [[0.017700879, 0.003964803, 0.9783343]]\n",
            "2327     [[0.00021316657, 0.00028728033, 0.99949956]]\n",
            "2328       [[0.0011258515, 0.0016821742, 0.99719197]]\n",
            "2329        [[0.0035023286, 0.058829796, 0.93766785]]\n",
            "2330       [[0.0004865392, 0.00072217704, 0.9987914]]\n",
            "2331       [[0.0011258515, 0.0016821742, 0.99719197]]\n",
            "2332       [[0.0011040822, 1.6594378e-05, 0.9988794]]\n",
            "2333          [[0.0008893882, 0.00076397, 0.9983467]]\n",
            "2334       [[0.0039940206, 6.738817e-05, 0.99593854]]\n",
            "2335       [[0.0011258515, 0.0016821742, 0.99719197]]\n",
            "2336       [[0.0016658546, 8.339908e-05, 0.99825066]]\n",
            "2337        [[0.0008665999, 9.246834e-06, 0.9991241]]\n",
            "2338         [[0.0016814165, 7.554949e-05, 0.998243]]\n",
            "2339        [[0.0011662624, 0.00015575648, 0.998678]]\n",
            "2340          [[0.024212215, 0.002113504, 0.9736743]]\n",
            "2341       [[0.0016658546, 8.339908e-05, 0.99825066]]\n",
            "2342       [[0.00064814254, 4.509772e-05, 0.9993067]]\n",
            "2343      [[0.00023276362, 0.00011532254, 0.9996519]]\n",
            "2344        [[0.0004218571, 0.0008776273, 0.9987005]]\n",
            "2345      [[0.0002625216, 1.1045311e-05, 0.99972636]]\n",
            "2346    [[0.00035485366, 1.34395805e-05, 0.99963164]]\n",
            "2347     [[0.00028745455, 9.2349355e-06, 0.99970335]]\n",
            "2348        [[0.002447128, 1.3941015e-05, 0.9975389]]\n",
            "2349      [[0.0012821169, 0.00078729546, 0.99793065]]\n",
            "2350         [[0.0028389983, 0.017179053, 0.9799819]]\n",
            "2351           [[0.113085486, 0.4904038, 0.39651075]]\n",
            "2352           [[0.037117854, 0.5302217, 0.43266046]]\n",
            "2353        [[0.0013133909, 2.204168e-05, 0.9986646]]\n",
            "2354     [[0.00091324945, 0.00013922801, 0.99894756]]\n",
            "2355       [[0.076860406, 0.92299473, 0.00014482145]]\n",
            "2356          [[0.83560735, 0.1636386, 0.0007540582]]\n",
            "2357       [[0.00035890084, 0.0050925375, 0.9945486]]\n",
            "2358      [[0.00021842678, 0.0005439124, 0.99923766]]\n",
            "2359       [[0.00022425975, 0.0001413349, 0.9996344]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_select_know_val_f1_0.7819'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_select_know_val_f1_0.7819\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "OjtCgxW1AojT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNy7_84NIR-Z"
      },
      "source": [
        "## s4 state_dict/bert_spc_combined_padanan_know_val_f1_0.7972"
      ],
      "id": "JNy7_84NIR-Z"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/j_insert_padanan_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "jH5eFkPSIR-q"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jH5eFkPSIR-q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "59c73229-d7e6-4d95-c8df-0601c9234ec3",
        "id": "eGsS2it6IR-q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0               [[0.14862712, 0.16988836, 0.6814845]]\n",
            "1         [[0.0013034673, 0.00032755398, 0.99836904]]\n",
            "2               [[0.2868552, 0.6871703, 0.025974462]]\n",
            "3              [[0.30023378, 0.43507147, 0.26469478]]\n",
            "4            [[0.85921675, 0.0015320181, 0.13925128]]\n",
            "5           [[0.0045743133, 0.0013353477, 0.9940904]]\n",
            "6         [[0.0008404458, 0.00040026198, 0.99875927]]\n",
            "7              [[0.001584011, 0.04136923, 0.9570468]]\n",
            "8           [[0.00040843178, 0.041062962, 0.9585287]]\n",
            "9             [[0.0118581625, 0.10351412, 0.8846277]]\n",
            "10           [[0.0005740102, 0.94914466, 0.05028136]]\n",
            "11           [[0.0005198844, 0.76821816, 0.23126194]]\n",
            "12         [[4.7096768e-05, 0.9961653, 0.0037876463]]\n",
            "13        [[2.3558541e-05, 0.99828005, 0.0016964213]]\n",
            "14            [[0.00016359435, 0.8253025, 0.1745339]]\n",
            "15           [[0.00804436, 0.00026518165, 0.9916905]]\n",
            "16            [[0.9832608, 0.01207113, 0.0046680104]]\n",
            "17         [[0.0013989145, 6.0561186e-05, 0.9985405]]\n",
            "18        [[0.00054542074, 1.927249e-05, 0.99943525]]\n",
            "19         [[0.00046690117, 0.051626913, 0.94790626]]\n",
            "20        [[0.00034886244, 5.9944614e-05, 0.9995912]]\n",
            "21           [[0.00037146127, 3.2745e-05, 0.9995958]]\n",
            "22        [[0.00029558665, 1.7940592e-05, 0.9996865]]\n",
            "23            [[0.15766859, 0.016664844, 0.82566667]]\n",
            "24        [[0.000113223025, 0.0063591395, 0.9935276]]\n",
            "25           [[0.0005295462, 0.05223406, 0.94723636]]\n",
            "26            [[0.00354531, 9.630279e-06, 0.9964451]]\n",
            "27         [[0.0020098519, 2.315942e-05, 0.99796695]]\n",
            "28         [[0.00016885994, 6.804196e-05, 0.9997631]]\n",
            "29          [[8.128743e-05, 9.280917e-05, 0.9998259]]\n",
            "30           [[0.00021974502, 0.39840537, 0.6013749]]\n",
            "31             [[0.03179682, 0.32360587, 0.64459735]]\n",
            "32        [[0.00019834402, 0.00012558098, 0.9996761]]\n",
            "33        [[0.00070416345, 0.00011945454, 0.9991763]]\n",
            "34          [[0.0008043542, 0.0004172266, 0.9987784]]\n",
            "35        [[0.00040062584, 0.00084413704, 0.9987552]]\n",
            "36           [[0.00059684785, 0.3007953, 0.69860786]]\n",
            "37           [[0.9792259, 0.016596224, 0.0041778865]]\n",
            "38         [[0.0033055802, 0.0007809238, 0.99591345]]\n",
            "39         [[0.0011517558, 1.2181095e-05, 0.9988361]]\n",
            "40         [[0.0002492447, 3.4056095e-05, 0.9997167]]\n",
            "41        [[0.00039633652, 1.5396048e-05, 0.9995883]]\n",
            "42         [[0.00029903103, 8.4059066e-05, 0.999617]]\n",
            "43       [[0.00022291897, 0.00020460426, 0.99957246]]\n",
            "44            [[0.015581648, 0.90929437, 0.07512393]]\n",
            "45             [[0.019993767, 0.8103303, 0.16967593]]\n",
            "46             [[0.01039963, 0.027421009, 0.9621793]]\n",
            "47             [[0.0045809965, 0.8566227, 0.1387963]]\n",
            "48             [[0.03179682, 0.32360587, 0.64459735]]\n",
            "49             [[0.014537605, 0.27765232, 0.7078101]]\n",
            "50        [[0.0002901832, 0.00022709352, 0.99948275]]\n",
            "51       [[0.00074473605, 0.00015551048, 0.99909973]]\n",
            "52          [[0.0007577999, 0.009344301, 0.98989785]]\n",
            "53            [[0.008470069, 0.86844546, 0.12308452]]\n",
            "54           [[0.0015038657, 0.55283344, 0.44566268]]\n",
            "55           [[0.0012975208, 0.022445455, 0.9762571]]\n",
            "56        [[0.00079286384, 2.8377855e-05, 0.9991788]]\n",
            "57             [[0.075371996, 0.3135849, 0.61104316]]\n",
            "58           [[0.0011323711, 0.64751136, 0.35135624]]\n",
            "59             [[0.005412769, 0.7836896, 0.21089761]]\n",
            "60         [[0.0003848147, 2.5713382e-05, 0.9995895]]\n",
            "61            [[0.0006099046, 0.22957799, 0.7698121]]\n",
            "62        [[0.00029196645, 0.0001881869, 0.99951994]]\n",
            "63          [[0.0003863774, 0.009282521, 0.99033105]]\n",
            "64        [[0.00025984328, 7.370979e-05, 0.99966645]]\n",
            "65            [[0.072479025, 0.013538695, 0.9139823]]\n",
            "66            [[0.5261227, 0.00012948648, 0.4737478]]\n",
            "67           [[0.94991624, 0.009180862, 0.040902853]]\n",
            "68         [[0.0023323186, 0.0019783308, 0.99568933]]\n",
            "69            [[0.009813525, 0.38518488, 0.60500157]]\n",
            "70           [[0.9898929, 0.007114716, 0.0029923706]]\n",
            "71            [[0.91897964, 0.059841692, 0.02117868]]\n",
            "72        [[0.00025997427, 0.0098031005, 0.98993695]]\n",
            "73           [[3.8792525e-05, 0.9850889, 0.01487232]]\n",
            "74            [[0.0008132425, 0.7387832, 0.26040354]]\n",
            "75             [[0.12642224, 0.007887598, 0.8656902]]\n",
            "76           [[0.0007048274, 0.013896834, 0.9853984]]\n",
            "77            [[0.5449874, 0.0004933428, 0.45451924]]\n",
            "78        [[0.0014427917, 2.5285635e-05, 0.99853194]]\n",
            "79        [[0.0016911144, 3.8201386e-05, 0.99827063]]\n",
            "80        [[0.00016982075, 0.0005279768, 0.99930215]]\n",
            "81        [[0.00013221103, 2.6093921e-05, 0.9998417]]\n",
            "82          [[0.009813601, 0.00013323915, 0.9900531]]\n",
            "83            [[0.90281844, 0.027356189, 0.06982544]]\n",
            "84         [[0.00047373338, 0.0013248906, 0.9982014]]\n",
            "85          [[0.009358157, 0.98420554, 0.0064362995]]\n",
            "86          [[0.91453063, 0.072601885, 0.0128674265]]\n",
            "87       [[0.00056012557, 1.4448597e-05, 0.99942553]]\n",
            "88           [[0.00067709596, 0.7291474, 0.27017555]]\n",
            "89          [[0.0017739473, 0.0034624059, 0.9947636]]\n",
            "90        [[0.00050666224, 2.156255e-05, 0.99947184]]\n",
            "91         [[0.00076204684, 0.9976277, 0.0016103426]]\n",
            "92        [[0.00012350034, 0.0033873806, 0.99648905]]\n",
            "93             [[0.005220396, 0.004504507, 0.990275]]\n",
            "94        [[0.99802667, 0.00038348278, 0.0015898921]]\n",
            "95           [[0.88215816, 0.0018428789, 0.11599898]]\n",
            "96        [[0.00049727014, 0.0059614265, 0.99354124]]\n",
            "97        [[0.0006273404, 1.3121049e-05, 0.99935955]]\n",
            "98        [[0.00029281335, 1.2646828e-05, 0.9996946]]\n",
            "99          [[0.0029488516, 6.754502e-05, 0.9969836]]\n",
            "100       [[0.0008080757, 1.7968747e-05, 0.99917394]]\n",
            "101           [[0.0011876244, 0.46410918, 0.5347032]]\n",
            "102       [[0.00036146503, 1.934364e-05, 0.99961925]]\n",
            "103          [[0.00025474394, 0.00704481, 0.9927004]]\n",
            "104          [[0.00052508013, 4.19401e-05, 0.999433]]\n",
            "105          [[0.00067023723, 0.05140002, 0.9479298]]\n",
            "106       [[0.00030896426, 0.0132886795, 0.98640233]]\n",
            "107        [[0.00012538738, 0.008129004, 0.99174553]]\n",
            "108       [[0.0018274002, 5.5216664e-05, 0.99811745]]\n",
            "109        [[0.00012506018, 0.00045092482, 0.999424]]\n",
            "110          [[0.0011245527, 0.011221717, 0.9876538]]\n",
            "111      [[0.00030050968, 2.5045088e-05, 0.99967444]]\n",
            "112            [[0.003262506, 0.9281717, 0.06856576]]\n",
            "113        [[0.0006027651, 3.1726206e-05, 0.9993655]]\n",
            "114             [[0.2942946, 0.6707835, 0.034921918]]\n",
            "115          [[0.00024474243, 0.80865353, 0.1911017]]\n",
            "116          [[0.00010941684, 0.991471, 0.008419566]]\n",
            "117         [[0.0007868736, 1.963442e-05, 0.9991935]]\n",
            "118           [[0.0013324282, 0.74807096, 0.2505966]]\n",
            "119        [[0.00087502727, 0.99595934, 0.003165635]]\n",
            "120         [[7.9613514e-05, 0.9780862, 0.021834163]]\n",
            "121       [[0.00027649486, 0.00037279114, 0.9993507]]\n",
            "122       [[0.00030740892, 0.0003732058, 0.99931943]]\n",
            "123       [[0.0003642197, 8.1951985e-05, 0.99955374]]\n",
            "124         [[0.0006855059, 0.0054788273, 0.9938356]]\n",
            "125            [[0.0018078439, 0.1835396, 0.8146525]]\n",
            "126          [[0.0013822567, 0.012525847, 0.9860919]]\n",
            "127            [[0.0011113053, 0.0310544, 0.9678343]]\n",
            "128         [[0.00021242289, 0.000379114, 0.9994085]]\n",
            "129       [[0.0011181236, 1.3086434e-05, 0.99886876]]\n",
            "130              [[0.1793051, 0.5104034, 0.31029156]]\n",
            "131        [[0.98881793, 0.0037521073, 0.0074299807]]\n",
            "132           [[0.1773045, 0.0044783195, 0.81821716]]\n",
            "133        [[0.0009361416, 0.0044967635, 0.99456704]]\n",
            "134             [[0.33213297, 0.5964083, 0.07145871]]\n",
            "135            [[0.3625282, 0.62234247, 0.015129323]]\n",
            "136          [[0.0009773488, 0.21910933, 0.77991337]]\n",
            "137        [[0.0003537727, 2.130639e-05, 0.99962485]]\n",
            "138        [[0.0010507797, 2.4305376e-05, 0.9989249]]\n",
            "139         [[0.0009109002, 7.0006376e-05, 0.999019]]\n",
            "140       [[0.00039982135, 1.4293022e-05, 0.9995859]]\n",
            "141          [[0.67044467, 0.00052051473, 0.3290348]]\n",
            "142         [[0.9886342, 0.0071913414, 0.0041744257]]\n",
            "143          [[9.29753e-05, 0.0015700674, 0.9983369]]\n",
            "144       [[0.00056942285, 0.0012609933, 0.99816966]]\n",
            "145        [[0.0009026842, 1.0801158e-05, 0.9990865]]\n",
            "146        [[0.00031826086, 0.014453752, 0.98522794]]\n",
            "147           [[0.0007935182, 0.8992027, 0.10000379]]\n",
            "148              [[0.022203896, 0.2545351, 0.723261]]\n",
            "149        [[0.00027941953, 0.0012269208, 0.9984937]]\n",
            "150        [[0.0004893647, 7.0215014e-05, 0.9994405]]\n",
            "151          [[0.039132994, 0.9546225, 0.0062444196]]\n",
            "152       [[0.0003088685, 4.0195915e-05, 0.99965096]]\n",
            "153          [[0.0022104445, 0.9879161, 0.009873491]]\n",
            "154        [[0.00012913147, 0.0006754549, 0.9991954]]\n",
            "155            [[0.007396712, 0.40434304, 0.5882603]]\n",
            "156           [[0.00073514594, 0.4730087, 0.5262562]]\n",
            "157          [[0.0032710698, 0.19897617, 0.79775274]]\n",
            "158        [[0.0031105825, 0.99535465, 0.0015348175]]\n",
            "159           [[0.054629467, 0.9081216, 0.037248943]]\n",
            "160         [[0.00094977836, 0.9442507, 0.054799497]]\n",
            "161        [[0.0017581582, 0.0017289314, 0.99651295]]\n",
            "162          [[0.0009483071, 9.643322e-06, 0.999042]]\n",
            "163          [[0.011600612, 0.006314347, 0.98208505]]\n",
            "164         [[0.0012492584, 0.003236994, 0.99551374]]\n",
            "165         [[0.008297704, 0.00017044554, 0.9915318]]\n",
            "166           [[0.0023955437, 0.986764, 0.010840469]]\n",
            "167      [[0.00071276916, 6.0156275e-05, 0.99922705]]\n",
            "168          [[0.0015924291, 0.16184153, 0.83656603]]\n",
            "169             [[0.08510096, 0.40993133, 0.5049677]]\n",
            "170          [[0.00053191104, 0.05721123, 0.9422569]]\n",
            "171       [[0.0022071977, 0.00050497655, 0.99728775]]\n",
            "172           [[0.001155242, 0.004136591, 0.9947082]]\n",
            "173          [[0.000171636, 0.0019500342, 0.9978783]]\n",
            "174        [[0.00094067294, 0.98482645, 0.014232858]]\n",
            "175      [[0.00085673993, 2.0858228e-05, 0.99912244]]\n",
            "176          [[0.0005262784, 0.014252602, 0.9852211]]\n",
            "177           [[0.00012984, 0.0014599655, 0.9984101]]\n",
            "178         [[0.0002647216, 0.002581058, 0.99715424]]\n",
            "179            [[0.0020357259, 0.222828, 0.77513623]]\n",
            "180         [[0.9985411, 0.0003669168, 0.0010919786]]\n",
            "181      [[0.00038677905, 0.00017919898, 0.99943405]]\n",
            "182       [[0.00035798852, 0.0008492972, 0.99879265]]\n",
            "183        [[0.00031889832, 0.0011619751, 0.9985191]]\n",
            "184       [[0.0013182542, 1.8084109e-05, 0.99866366]]\n",
            "185      [[0.00031305983, 1.07522565e-05, 0.9996762]]\n",
            "186      [[0.00026919408, 2.6790523e-05, 0.99970394]]\n",
            "187         [[0.000166411, 3.2084317e-05, 0.9998016]]\n",
            "188       [[0.00054989563, 2.5888487e-05, 0.9994242]]\n",
            "189           [[0.0018912201, 0.26524287, 0.7328659]]\n",
            "190          [[0.0011079309, 0.35175818, 0.64713395]]\n",
            "191           [[0.0011840168, 0.42572933, 0.5730867]]\n",
            "192             [[0.001369698, 0.8525848, 0.1460455]]\n",
            "193       [[0.00035553068, 3.357309e-05, 0.99961084]]\n",
            "194      [[0.00015496367, 3.1922376e-05, 0.99981314]]\n",
            "195           [[0.01191063, 0.005919961, 0.98216945]]\n",
            "196       [[6.9874484e-05, 0.9990025, 0.00092761667]]\n",
            "197          [[0.00083893386, 0.4796829, 0.51947814]]\n",
            "198         [[0.0057869484, 0.012621007, 0.98159206]]\n",
            "199      [[0.00025737443, 0.00017761401, 0.99956495]]\n",
            "200           [[0.23486494, 0.0012175097, 0.7639175]]\n",
            "201           [[0.4228417, 0.0038240221, 0.57333434]]\n",
            "202       [[0.00030237256, 1.3625483e-05, 0.9996841]]\n",
            "203          [[0.95343053, 0.03519889, 0.0113705285]]\n",
            "204         [[0.0003463475, 0.0045135603, 0.9951401]]\n",
            "205        [[0.00036479015, 0.00012617695, 0.999509]]\n",
            "206          [[0.00010170754, 0.9951669, 0.00473141]]\n",
            "207         [[0.0014350271, 0.0004308998, 0.9981342]]\n",
            "208           [[0.013511971, 0.001033027, 0.9854549]]\n",
            "209        [[0.0007079134, 9.6840704e-05, 0.9991953]]\n",
            "210         [[0.00014374762, 0.036955535, 0.9629007]]\n",
            "211        [[0.0003361419, 3.467108e-05, 0.99962914]]\n",
            "212       [[0.0017282186, 1.2371496e-05, 0.99825937]]\n",
            "213          [[0.0013624913, 0.0021905864, 0.996447]]\n",
            "214          [[0.0006078374, 0.08547834, 0.91391385]]\n",
            "215          [[9.025482e-05, 0.00106552, 0.99884415]]\n",
            "216           [[0.0010615636, 0.010097442, 0.988841]]\n",
            "217      [[0.00059632654, 0.00020970212, 0.99919397]]\n",
            "218       [[0.00027307312, 5.1567687e-05, 0.9996754]]\n",
            "219        [[0.0003129361, 0.00012375298, 0.9995633]]\n",
            "220      [[0.00030535058, 0.00029386822, 0.99940073]]\n",
            "221       [[0.00025111117, 2.4725823e-05, 0.9997242]]\n",
            "222        [[0.00028144373, 7.413128e-05, 0.9996444]]\n",
            "223          [[0.0003042867, 0.9956204, 0.004075281]]\n",
            "224      [[0.00033150322, 0.00020032808, 0.99946827]]\n",
            "225           [[0.0025322929, 0.0067187, 0.99074894]]\n",
            "226         [[0.9941671, 0.0019059764, 0.0039269305]]\n",
            "227           [[0.023500146, 0.55810344, 0.41839644]]\n",
            "228         [[2.8409382e-05, 0.998798, 0.0011735614]]\n",
            "229           [[0.002688806, 0.9352057, 0.062105544]]\n",
            "230         [[0.0016175639, 0.009971507, 0.98841095]]\n",
            "231              [[0.0450449, 0.7882494, 0.16670573]]\n",
            "232            [[0.0021506494, 0.1499569, 0.8478925]]\n",
            "233         [[0.0013749803, 0.024308937, 0.97431606]]\n",
            "234            [[0.7205715, 0.073534146, 0.20589441]]\n",
            "235        [[0.0013080474, 9.953653e-05, 0.99859244]]\n",
            "236        [[0.00019073336, 4.362603e-05, 0.9997657]]\n",
            "237        [[0.00023492615, 9.4131414e-05, 0.999671]]\n",
            "238         [[0.9816691, 0.00020558236, 0.018125271]]\n",
            "239         [[0.004477064, 0.00030372114, 0.9952192]]\n",
            "240        [[0.0020538012, 0.00017883684, 0.9977673]]\n",
            "241         [[0.0008471877, 0.0011763073, 0.9979765]]\n",
            "242          [[0.0005264784, 0.01163326, 0.98784024]]\n",
            "243            [[0.00900407, 0.9690915, 0.021904439]]\n",
            "244      [[0.00019217213, 3.2630258e-05, 0.99977523]]\n",
            "245         [[6.651212e-05, 0.99678135, 0.003152112]]\n",
            "246          [[0.002192863, 5.91512e-05, 0.99774796]]\n",
            "247          [[0.001918281, 0.0058942568, 0.9921875]]\n",
            "248          [[0.010830606, 0.022211676, 0.96695775]]\n",
            "249      [[0.00036662052, 3.6163638e-05, 0.99959725]]\n",
            "250        [[0.0002548591, 6.5911314e-05, 0.9996792]]\n",
            "251        [[0.0023777934, 3.4307883e-05, 0.9975879]]\n",
            "252         [[0.00061473023, 6.06084e-05, 0.9993247]]\n",
            "253        [[0.00028474478, 8.318224e-05, 0.9996321]]\n",
            "254         [[0.0012326678, 0.0042486284, 0.9945187]]\n",
            "255           [[0.0015522629, 0.04677029, 0.9516775]]\n",
            "256          [[9.484142e-05, 0.9935516, 0.006353501]]\n",
            "257       [[0.0013177649, 0.00016540622, 0.99851674]]\n",
            "258       [[0.00030131382, 2.2188575e-05, 0.9996766]]\n",
            "259          [[0.00024924954, 0.02768756, 0.9720632]]\n",
            "260        [[0.0010402288, 0.99804115, 0.0009185889]]\n",
            "261       [[2.4282595e-05, 0.99947256, 0.0005032131]]\n",
            "262           [[7.033022e-05, 0.9644885, 0.03544121]]\n",
            "263           [[0.0049317894, 0.9286242, 0.06644405]]\n",
            "264         [[0.96593493, 0.0010032956, 0.033061706]]\n",
            "265          [[0.0071961535, 0.01243158, 0.98037237]]\n",
            "266          [[0.00034899154, 0.8577172, 0.14193378]]\n",
            "267          [[0.77283484, 0.0011351472, 0.22603008]]\n",
            "268          [[0.77283484, 0.0011351472, 0.22603008]]\n",
            "269        [[0.0011251757, 8.2551414e-05, 0.9987923]]\n",
            "270            [[0.20167372, 0.003346522, 0.7949798]]\n",
            "271            [[0.9362154, 0.0008413793, 0.0629432]]\n",
            "272         [[0.0009024321, 0.013439251, 0.98565835]]\n",
            "273        [[0.0003565002, 7.0820715e-05, 0.9995727]]\n",
            "274        [[0.0006118871, 2.8184046e-05, 0.9993599]]\n",
            "275       [[0.00030509869, 0.0005680106, 0.99912685]]\n",
            "276          [[0.00018933526, 0.24807186, 0.7517388]]\n",
            "277       [[0.00031413996, 1.9665527e-05, 0.9996662]]\n",
            "278         [[0.0010525872, 8.127432e-05, 0.9988661]]\n",
            "279        [[0.00059312367, 0.0010834935, 0.9983234]]\n",
            "280         [[0.0006119821, 0.035300806, 0.96408725]]\n",
            "281        [[0.00018505634, 0.98917025, 0.010644734]]\n",
            "282       [[0.00027311163, 1.6278507e-05, 0.9997105]]\n",
            "283        [[0.00017996051, 0.0016475392, 0.9981725]]\n",
            "284        [[0.0004135652, 0.0007818759, 0.99880457]]\n",
            "285          [[9.215548e-05, 0.9985056, 0.001402227]]\n",
            "286        [[9.6929274e-05, 0.99577326, 0.004129773]]\n",
            "287          [[0.0027327691, 0.006031708, 0.9912355]]\n",
            "288            [[0.011790914, 0.20039913, 0.7878099]]\n",
            "289      [[0.00044428205, 1.1101697e-05, 0.99954456]]\n",
            "290            [[0.011790914, 0.20039913, 0.7878099]]\n",
            "291        [[0.0010205158, 0.00091427035, 0.9980653]]\n",
            "292       [[0.00020825092, 0.00044407466, 0.9993476]]\n",
            "293        [[0.00059670286, 4.344419e-05, 0.9993598]]\n",
            "294          [[0.0002530407, 0.87859976, 0.12114715]]\n",
            "295         [[0.00034435096, 0.02959371, 0.97006184]]\n",
            "296         [[0.0021915857, 0.025798216, 0.97201014]]\n",
            "297         [[0.00021515662, 0.99173063, 0.00805424]]\n",
            "298           [[0.00080132124, 0.612213, 0.38698566]]\n",
            "299           [[0.004839905, 0.0010980091, 0.994062]]\n",
            "300       [[0.0023382588, 0.00012021945, 0.99754155]]\n",
            "301          [[0.0034903248, 0.011501203, 0.9850085]]\n",
            "302          [[0.0024633955, 0.9507418, 0.046794765]]\n",
            "303            [[0.003929796, 0.8313573, 0.16471294]]\n",
            "304       [[0.00043983452, 6.1148276e-05, 0.9994991]]\n",
            "305            [[0.010464384, 0.6696759, 0.31985968]]\n",
            "306       [[0.00054577505, 0.0005055172, 0.99894875]]\n",
            "307         [[0.0005684428, 0.0029009709, 0.9965306]]\n",
            "308           [[0.0009999671, 0.7474933, 0.25150666]]\n",
            "309           [[0.0021979385, 0.58664155, 0.4111605]]\n",
            "310        [[0.0005834028, 0.0004401461, 0.99897647]]\n",
            "311        [[0.0006063071, 7.097878e-05, 0.99932265]]\n",
            "312          [[0.0006080365, 0.11295779, 0.88643414]]\n",
            "313         [[0.00085719855, 0.033665232, 0.9654776]]\n",
            "314          [[0.0002444394, 0.009477909, 0.9902776]]\n",
            "315             [[0.01390619, 0.64943916, 0.3366547]]\n",
            "316      [[0.00043921758, 3.3971173e-05, 0.99952686]]\n",
            "317      [[0.00013577234, 3.4510274e-05, 0.99982965]]\n",
            "318      [[0.00020741991, 0.00019104662, 0.99960154]]\n",
            "319             [[0.012759584, 0.4746395, 0.5126009]]\n",
            "320         [[0.00055116846, 0.16114612, 0.83830273]]\n",
            "321         [[0.004053594, 0.0002271607, 0.99571925]]\n",
            "322        [[0.0006185473, 1.2167228e-05, 0.9993693]]\n",
            "323        [[0.00077150675, 8.598485e-06, 0.9992199]]\n",
            "324         [[0.00065061986, 0.0012573863, 0.998092]]\n",
            "325         [[0.0052810716, 2.6928814e-05, 0.994692]]\n",
            "326          [[0.014780703, 0.015129941, 0.97008944]]\n",
            "327          [[0.0021656486, 0.001498041, 0.9963362]]\n",
            "328        [[0.9954561, 0.0041813967, 0.00036255852]]\n",
            "329        [[0.99555343, 0.0033893553, 0.0010572046]]\n",
            "330             [[0.151177, 0.8451471, 0.0036759279]]\n",
            "331          [[0.0014570875, 0.9936308, 0.004912142]]\n",
            "332           [[0.053717695, 0.67614424, 0.27013808]]\n",
            "333       [[0.0013174103, 0.000105153624, 0.9985775]]\n",
            "334           [[0.41441345, 0.57751805, 0.008068471]]\n",
            "335         [[8.786968e-05, 0.9922881, 0.0076240716]]\n",
            "336        [[0.0040252814, 0.99160224, 0.0043724305]]\n",
            "337       [[0.0009775828, 0.000102973245, 0.9989195]]\n",
            "338       [[0.0024161846, 1.8778057e-05, 0.99756503]]\n",
            "339          [[0.47880554, 0.0025908523, 0.51860356]]\n",
            "340            [[0.5486174, 0.4446881, 0.0066944715]]\n",
            "341          [[0.0009417343, 0.025523033, 0.9735352]]\n",
            "342         [[0.0003629937, 0.009924027, 0.98971295]]\n",
            "343       [[9.685297e-05, 3.3135493e-05, 0.99986994]]\n",
            "344          [[0.008974217, 0.0007857449, 0.9902401]]\n",
            "345         [[0.0010741432, 3.933167e-05, 0.9988865]]\n",
            "346         [[0.0005900789, 2.6913882e-05, 0.999383]]\n",
            "347            [[0.9215664, 0.045183454, 0.03325016]]\n",
            "348       [[0.0075001842, 6.8581816e-05, 0.99243116]]\n",
            "349        [[0.0010053358, 5.1108847e-05, 0.9989436]]\n",
            "350             [[0.6427994, 0.13159716, 0.22560349]]\n",
            "351          [[0.9503658, 0.047267746, 0.0023664348]]\n",
            "352          [[0.002969539, 0.0039062663, 0.9931242]]\n",
            "353          [[0.0022626137, 0.19180168, 0.80593574]]\n",
            "354        [[0.00073895283, 5.398955e-05, 0.9992071]]\n",
            "355        [[0.00069992116, 2.399818e-05, 0.9992761]]\n",
            "356            [[0.0042363107, 0.0617011, 0.9340626]]\n",
            "357         [[0.0017243492, 0.033978734, 0.96429694]]\n",
            "358           [[0.008531231, 0.76119626, 0.23027247]]\n",
            "359            [[0.001211757, 0.05809044, 0.9406977]]\n",
            "360           [[0.9667045, 0.006315122, 0.026980417]]\n",
            "361        [[0.00016257272, 0.99272823, 0.007109182]]\n",
            "362          [[9.35909e-05, 0.9993856, 0.0005208137]]\n",
            "363        [[0.0011120874, 0.0031341552, 0.99575377]]\n",
            "364        [[5.4302953e-05, 0.99574465, 0.004201104]]\n",
            "365      [[5.1866482e-05, 0.99981564, 0.00013249877]]\n",
            "366      [[2.0290569e-05, 0.9998766, 0.000103107115]]\n",
            "367           [[0.0038257404, 0.6866017, 0.30957255]]\n",
            "368         [[0.0006366305, 0.95311075, 0.046252575]]\n",
            "369            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "370           [[0.002230988, 0.001115378, 0.9966536]]\n",
            "371        [[0.0013252102, 0.00020293202, 0.9984718]]\n",
            "372          [[0.0012696949, 0.49125856, 0.50747174]]\n",
            "373       [[0.0012624577, 1.6481074e-05, 0.99872106]]\n",
            "374       [[0.00019916716, 0.00033470496, 0.9994661]]\n",
            "375       [[0.00055637286, 0.00016085156, 0.9992828]]\n",
            "376          [[0.001784605, 8.170828e-05, 0.9981337]]\n",
            "377        [[0.0060463636, 7.358083e-05, 0.99388003]]\n",
            "378          [[0.0034749736, 0.11799563, 0.87852937]]\n",
            "379       [[0.00047582592, 0.0035265023, 0.99599767]]\n",
            "380          [[0.00022086092, 0.9946366, 0.00514248]]\n",
            "381          [[0.0035810166, 7.51347e-05, 0.9963438]]\n",
            "382          [[0.9760258, 0.0057474826, 0.018226635]]\n",
            "383          [[0.0068996195, 0.004139079, 0.9889613]]\n",
            "384       [[0.00044635005, 0.99793637, 0.0016172575]]\n",
            "385           [[0.010323427, 0.95434225, 0.03533437]]\n",
            "386       [[0.0015680679, 2.3784482e-05, 0.99840814]]\n",
            "387         [[0.002554245, 0.0005722744, 0.99687344]]\n",
            "388          [[0.003503272, 6.562589e-05, 0.9964311]]\n",
            "389           [[0.005332409, 0.011056198, 0.9836114]]\n",
            "390            [[0.00518049, 0.006873783, 0.9879458]]\n",
            "391            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "392           [[0.0020649927, 0.026180968, 0.971754]]\n",
            "393        [[0.0016692171, 0.00014444927, 0.9981863]]\n",
            "394       [[0.0034777462, 0.00093243306, 0.99558985]]\n",
            "395          [[0.0009913171, 0.9863013, 0.012707327]]\n",
            "396           [[0.005088809, 0.73930895, 0.25560227]]\n",
            "397         [[0.00042538933, 0.9901466, 0.009428018]]\n",
            "398           [[0.0008745717, 0.5555229, 0.44360256]]\n",
            "399            [[0.004271561, 0.52176833, 0.4739601]]\n",
            "400         [[9.970115e-05, 0.9987551, 0.0011451694]]\n",
            "401         [[0.00013706263, 0.9744942, 0.025368681]]\n",
            "402       [[0.00038126754, 0.0117387045, 0.98787993]]\n",
            "403        [[1.5827882e-05, 0.9975751, 0.0024090628]]\n",
            "404             [[0.00331822, 0.81396323, 0.1827186]]\n",
            "405         [[0.0010971418, 0.97821885, 0.020684034]]\n",
            "406         [[6.226101e-05, 0.9980196, 0.0019181464]]\n",
            "407       [[0.00053200015, 0.99879634, 0.0006715905]]\n",
            "408        [[6.793192e-05, 0.99894243, 0.0009896563]]\n",
            "409         [[0.0009055297, 0.0024135604, 0.9966809]]\n",
            "410          [[0.0016444004, 0.018700818, 0.9796547]]\n",
            "411            [[0.004742953, 0.23735985, 0.7578972]]\n",
            "412          [[0.00017722766, 0.7955078, 0.20431499]]\n",
            "413          [[0.0001411839, 0.9940865, 0.005772352]]\n",
            "414        [[3.7249138e-05, 0.9987704, 0.0011923232]]\n",
            "415         [[0.007872649, 0.0134692965, 0.97865796]]\n",
            "416         [[0.00050380477, 3.523399e-05, 0.999461]]\n",
            "417           [[0.0031938925, 0.014692089, 0.982114]]\n",
            "418        [[0.012529085, 0.00039952874, 0.98707145]]\n",
            "419        [[0.0026606857, 0.00082542317, 0.9965139]]\n",
            "420         [[0.0020896653, 0.0058586635, 0.9920516]]\n",
            "421        [[0.0009101785, 1.3182194e-05, 0.9990766]]\n",
            "422           [[0.0063096206, 0.20072344, 0.7929669]]\n",
            "423          [[0.010547703, 0.0020394174, 0.9874129]]\n",
            "424          [[0.0013643865, 0.02496259, 0.97367305]]\n",
            "425           [[0.80280846, 0.024534317, 0.17265724]]\n",
            "426         [[0.88434225, 0.0067258724, 0.108931825]]\n",
            "427      [[0.00020999409, 0.00010058825, 0.99968946]]\n",
            "428          [[0.0011031368, 0.16760589, 0.83129096]]\n",
            "429        [[0.0020469853, 0.00092484924, 0.9970282]]\n",
            "430            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "431        [[0.0014736925, 0.0015571463, 0.99696916]]\n",
            "432         [[0.0013911644, 0.0002511767, 0.9983577]]\n",
            "433         [[0.0005168398, 0.0001609512, 0.9993222]]\n",
            "434         [[0.004872635, 0.00017560826, 0.9949517]]\n",
            "435        [[0.00014069401, 0.9960377, 0.0038215157]]\n",
            "436       [[0.0006406446, 4.2145723e-05, 0.99931717]]\n",
            "437             [[0.00659986, 0.17039913, 0.8230011]]\n",
            "438        [[0.0012660044, 0.0022858735, 0.99644804]]\n",
            "439        [[3.7892885e-05, 0.9972114, 0.0027506775]]\n",
            "440         [[0.0004547945, 0.9957475, 0.0037976804]]\n",
            "441         [[0.0005088005, 0.00041723606, 0.999074]]\n",
            "442         [[0.0022553601, 0.96766603, 0.030078571]]\n",
            "443         [[0.00060824945, 0.034060366, 0.9653314]]\n",
            "444        [[0.00014646238, 0.047960754, 0.95189273]]\n",
            "445         [[0.00028083922, 3.61805e-05, 0.9996829]]\n",
            "446         [[0.000596646, 7.830428e-05, 0.99932516]]\n",
            "447        [[0.0001850605, 7.239973e-05, 0.99974257]]\n",
            "448           [[0.0005940852, 0.19148284, 0.8079231]]\n",
            "449         [[0.0002024765, 0.99528754, 0.004509937]]\n",
            "450         [[0.00023485081, 0.993912, 0.0058532134]]\n",
            "451           [[0.0018628574, 0.22853346, 0.7696037]]\n",
            "452           [[0.0014558163, 0.6454816, 0.35306263]]\n",
            "453          [[0.0047278814, 0.13464388, 0.86062825]]\n",
            "454         [[0.00050344074, 0.92916095, 0.07033561]]\n",
            "455         [[0.0017849592, 0.029179746, 0.96903527]]\n",
            "456        [[0.000476238, 3.0961775e-05, 0.99949276]]\n",
            "457         [[0.0011376112, 0.026043234, 0.97281903]]\n",
            "458           [[0.013764495, 0.028472025, 0.9577635]]\n",
            "459            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "460        [[0.000626932, 4.6110563e-05, 0.99932694]]\n",
            "461         [[0.000814013, 5.185793e-05, 0.99913424]]\n",
            "462      [[0.00052530755, 0.00051147956, 0.99896324]]\n",
            "463          [[0.001366211, 0.002914675, 0.99571913]]\n",
            "464         [[0.0004123035, 0.0009224681, 0.9986652]]\n",
            "465        [[0.0007598559, 1.7238803e-05, 0.9992229]]\n",
            "466        [[0.00013438337, 0.0032224418, 0.9966432]]\n",
            "467        [[0.000329428, 0.00011725334, 0.99955326]]\n",
            "468          [[0.016863868, 0.0055848444, 0.9775513]]\n",
            "469        [[0.00016096124, 0.001700468, 0.99813855]]\n",
            "470             [[0.12498128, 0.3587615, 0.51625717]]\n",
            "471            [[0.5357677, 0.0024044504, 0.4618279]]\n",
            "472        [[0.0074693128, 0.0027605677, 0.98977005]]\n",
            "473            [[0.5357677, 0.0024044504, 0.4618279]]\n",
            "474           [[0.0022635346, 0.01725285, 0.9804836]]\n",
            "475             [[0.029486995, 0.08646991, 0.884043]]\n",
            "476      [[0.00033659016, 0.00029700773, 0.99936646]]\n",
            "477        [[0.00036673152, 0.0005469508, 0.9990864]]\n",
            "478            [[0.0156707, 0.003276399, 0.98105294]]\n",
            "479       [[0.0019689745, 0.00016707694, 0.99786395]]\n",
            "480          [[0.0005563634, 0.8763421, 0.123101555]]\n",
            "481          [[0.0002713554, 8.43178e-05, 0.9996443]]\n",
            "482        [[0.00022962975, 0.96183485, 0.037935518]]\n",
            "483        [[0.00032960557, 0.0001238481, 0.9995466]]\n",
            "484        [[0.00090236194, 0.0066925376, 0.9924051]]\n",
            "485         [[0.0013303215, 4.694926e-05, 0.9986228]]\n",
            "486         [[0.0005902592, 0.011539764, 0.98787004]]\n",
            "487            [[0.001199724, 0.08023256, 0.9185678]]\n",
            "488          [[0.0008408961, 0.06239605, 0.93676305]]\n",
            "489          [[0.00035575544, 0.08759913, 0.9120451]]\n",
            "490         [[0.0001608796, 0.0018803935, 0.9979588]]\n",
            "491        [[0.0016776394, 0.0047584954, 0.99356383]]\n",
            "492           [[0.002035151, 0.005148414, 0.9928163]]\n",
            "493        [[0.00055959815, 5.2462725e-05, 0.999388]]\n",
            "494         [[0.000595371, 6.2004205e-05, 0.9993426]]\n",
            "495           [[0.0002507613, 0.26157084, 0.7381784]]\n",
            "496            [[0.0006081584, 0.08126573, 0.918126]]\n",
            "497           [[0.67803985, 0.052258894, 0.26970124]]\n",
            "498        [[0.003632208, 0.00059763575, 0.99577004]]\n",
            "499           [[0.001687146, 0.08454695, 0.91376597]]\n",
            "500          [[0.001591809, 0.0010490177, 0.9973592]]\n",
            "501       [[0.0008113997, 0.00019516298, 0.99899346]]\n",
            "502           [[0.0021114897, 0.058249563, 0.939639]]\n",
            "503         [[0.018916793, 0.0006941673, 0.98038894]]\n",
            "504        [[0.0011441648, 0.00028238015, 0.9985734]]\n",
            "505            [[0.0054300954, 0.8739172, 0.1206527]]\n",
            "506        [[0.00072810776, 0.012827749, 0.98644406]]\n",
            "507          [[0.0015230168, 0.97638595, 0.02209111]]\n",
            "508           [[0.019100146, 0.78816485, 0.19273503]]\n",
            "509        [[8.892553e-05, 0.00015146578, 0.9997596]]\n",
            "510         [[7.772802e-05, 0.0017261121, 0.9981962]]\n",
            "511        [[0.0009186454, 0.0048120157, 0.99426925]]\n",
            "512       [[0.00039626492, 2.426762e-05, 0.99957937]]\n",
            "513          [[0.000577608, 4.978235e-06, 0.9994174]]\n",
            "514        [[0.00028154676, 3.313642e-05, 0.9996853]]\n",
            "515            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "516          [[0.0005872508, 0.002289659, 0.9971232]]\n",
            "517          [[0.0008420024, 0.19258013, 0.80657786]]\n",
            "518        [[0.00021257931, 0.99106264, 0.008724762]]\n",
            "519         [[0.0007804956, 0.010203292, 0.98901623]]\n",
            "520            [[0.001205817, 0.2299525, 0.76884174]]\n",
            "521          [[0.0010566681, 0.059942745, 0.9390005]]\n",
            "522      [[0.00029653628, 3.0918953e-05, 0.99967265]]\n",
            "523       [[0.00029717846, 1.659879e-05, 0.99968624]]\n",
            "524        [[0.0010163855, 0.00014958295, 0.9988341]]\n",
            "525      [[0.00054496754, 0.00012798063, 0.99932706]]\n",
            "526            [[0.0010245767, 0.02200845, 0.976967]]\n",
            "527       [[0.00040386134, 0.00037139724, 0.9992248]]\n",
            "528            [[0.003578743, 0.05016414, 0.9462571]]\n",
            "529           [[0.0012716177, 0.1173201, 0.88140833]]\n",
            "530         [[0.012702298, 0.0022201594, 0.98507756]]\n",
            "531         [[0.0010686509, 6.895663e-05, 0.9988624]]\n",
            "532       [[0.00037128755, 6.620769e-05, 0.99956244]]\n",
            "533       [[0.00053784694, 1.0044978e-05, 0.9994522]]\n",
            "534          [[0.0004964953, 0.055579375, 0.9439242]]\n",
            "535           [[0.0010830284, 0.02994047, 0.9689765]]\n",
            "536       [[0.00013213824, 0.0029590533, 0.99690884]]\n",
            "537        [[0.0011677203, 0.00014098304, 0.9986914]]\n",
            "538           [[0.15519753, 0.83616036, 0.008642164]]\n",
            "539            [[0.033172213, 0.68896586, 0.2778619]]\n",
            "540        [[0.0018176675, 0.00046663336, 0.9977157]]\n",
            "541         [[0.99268085, 0.0026736427, 0.004645454]]\n",
            "542           [[0.003876114, 0.015985804, 0.9801381]]\n",
            "543       [[0.00063963386, 0.00022058659, 0.9991398]]\n",
            "544       [[0.00016972807, 0.0006018444, 0.99922836]]\n",
            "545      [[0.00012034319, 0.000112545946, 0.9997671]]\n",
            "546        [[3.0549094e-05, 0.9962399, 0.0037295863]]\n",
            "547          [[0.003477311, 3.116972e-05, 0.9964916]]\n",
            "548       [[0.00041514524, 1.6438804e-05, 0.9995684]]\n",
            "549       [[0.0011129817, 0.00013280545, 0.99875426]]\n",
            "550        [[0.99307114, 6.697465e-05, 0.0068617933]]\n",
            "551           [[0.00052359, 0.042469706, 0.95700663]]\n",
            "552           [[0.003598514, 0.039916947, 0.9564845]]\n",
            "553        [[0.00020421094, 0.0016454333, 0.9981504]]\n",
            "554          [[7.139009e-05, 0.004766835, 0.9951617]]\n",
            "555          [[0.0002175835, 0.10145906, 0.89832336]]\n",
            "556         [[0.0002202631, 3.630685e-05, 0.9997434]]\n",
            "557       [[0.00014340672, 0.00011113585, 0.9997454]]\n",
            "558       [[0.0003545345, 3.0458574e-05, 0.99961495]]\n",
            "559           [[0.53873956, 0.031608865, 0.42965156]]\n",
            "560            [[0.006493581, 0.011303448, 0.982203]]\n",
            "561           [[0.000504094, 0.025728555, 0.9737673]]\n",
            "562          [[0.0004962228, 0.014940903, 0.9845628]]\n",
            "563           [[0.0012015493, 0.1813198, 0.81747866]]\n",
            "564        [[0.00021073104, 6.139247e-05, 0.9997279]]\n",
            "565        [[0.0001556219, 0.0016295207, 0.99821484]]\n",
            "566           [[0.00035848736, 0.8678433, 0.1317982]]\n",
            "567         [[0.0002347745, 0.0032459453, 0.9965193]]\n",
            "568         [[0.00020669078, 0.042521823, 0.9572716]]\n",
            "569         [[7.16346e-05, 0.00011284319, 0.9998155]]\n",
            "570      [[0.000113986775, 0.00022493016, 0.9996611]]\n",
            "571       [[0.00010341164, 0.00039123607, 0.9995053]]\n",
            "572        [[0.0003350129, 2.4205292e-05, 0.9996408]]\n",
            "573        [[0.00021312453, 0.00041292695, 0.999374]]\n",
            "574         [[0.0004472838, 0.0002921987, 0.9992605]]\n",
            "575           [[0.0005727579, 0.00224059, 0.9971867]]\n",
            "576          [[0.0015994898, 0.74965405, 0.24874648]]\n",
            "577         [[0.0005716082, 0.0037915735, 0.9956369]]\n",
            "578            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "579         [[0.92271614, 0.00060079596, 0.07668304]]\n",
            "580         [[0.93765116, 0.0058602947, 0.056488443]]\n",
            "581          [[0.019162523, 0.002340311, 0.97849727]]\n",
            "582            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "583      [[0.00023922008, 2.3358443e-05, 0.99973744]]\n",
            "584              [[0.13850208, 0.2286933, 0.6328047]]\n",
            "585       [[0.00033730836, 0.00018184105, 0.9994809]]\n",
            "586            [[0.70128036, 0.25518754, 0.04353213]]\n",
            "587          [[0.005144649, 0.0005002805, 0.9943552]]\n",
            "588          [[0.090033546, 0.87121356, 0.038752872]]\n",
            "589        [[0.0015912934, 0.99716836, 0.0012403375]]\n",
            "590         [[0.00076994917, 5.12892e-05, 0.9991787]]\n",
            "591       [[0.0005090625, 0.00017526865, 0.99931574]]\n",
            "592        [[0.0006396003, 0.00019388678, 0.9991665]]\n",
            "593        [[0.030455498, 3.0984258e-05, 0.96951354]]\n",
            "594           [[0.001360213, 1.875852e-05, 0.998621]]\n",
            "595         [[0.00013946858, 0.9896645, 0.010196041]]\n",
            "596       [[0.0014900826, 0.00023053662, 0.99827945]]\n",
            "597       [[0.00092598185, 1.6477257e-05, 0.9990576]]\n",
            "598       [[0.00028702704, 0.00046869775, 0.9992442]]\n",
            "599        [[0.00073506305, 0.0011905592, 0.9980744]]\n",
            "600        [[0.0013691236, 5.0321847e-05, 0.9985806]]\n",
            "601             [[0.04980724, 0.24021213, 0.7099806]]\n",
            "602         [[0.0037534386, 0.001091904, 0.99515474]]\n",
            "603        [[0.00034892643, 6.399431e-05, 0.9995871]]\n",
            "604          [[0.0028422389, 0.88708365, 0.11007412]]\n",
            "605         [[0.0037575846, 0.001103609, 0.99513876]]\n",
            "606          [[0.010131756, 0.0047755353, 0.9850928]]\n",
            "607         [[0.0011913162, 4.441971e-05, 0.9987643]]\n",
            "608       [[0.0003557413, 5.0170558e-05, 0.99959415]]\n",
            "609          [[0.0040780986, 0.068991646, 0.9269303]]\n",
            "610          [[0.001199379, 4.733712e-05, 0.9987532]]\n",
            "611         [[0.003426474, 3.5806006e-05, 0.9965378]]\n",
            "612           [[0.0063385447, 0.34903085, 0.6446306]]\n",
            "613       [[0.0022946817, 2.2280348e-05, 0.99768305]]\n",
            "614          [[0.0016590569, 0.9903239, 0.008017073]]\n",
            "615          [[0.87117195, 0.006604534, 0.122223444]]\n",
            "616           [[0.17904432, 0.022335393, 0.79862034]]\n",
            "617         [[0.0067119393, 0.0016446118, 0.9916435]]\n",
            "618       [[0.00079695234, 4.3951615e-05, 0.9991591]]\n",
            "619        [[2.3420089e-05, 0.9992034, 0.0007732169]]\n",
            "620           [[0.0011763049, 0.7730083, 0.22581539]]\n",
            "621        [[1.7473656e-05, 0.9983864, 0.0015961701]]\n",
            "622      [[0.00021879168, 0.00046794783, 0.99931324]]\n",
            "623        [[3.8849343e-05, 0.99039197, 0.009569242]]\n",
            "624        [[0.00013012168, 0.96628356, 0.033586346]]\n",
            "625        [[0.00034028915, 0.94792205, 0.051737666]]\n",
            "626        [[0.0088965995, 0.0006998582, 0.99040353]]\n",
            "627        [[0.00061797607, 0.99248874, 0.006893341]]\n",
            "628       [[4.2415268e-05, 0.99611145, 0.0038461608]]\n",
            "629         [[3.925579e-05, 0.9961629, 0.0037978974]]\n",
            "630       [[0.00017655942, 0.00086773594, 0.9989556]]\n",
            "631        [[0.00012463804, 0.0001143613, 0.9997609]]\n",
            "632       [[5.8580084e-05, 5.543068e-05, 0.99988604]]\n",
            "633       [[0.00026306047, 1.0347475e-05, 0.9997266]]\n",
            "634          [[0.0014729885, 0.052277666, 0.9462494]]\n",
            "635        [[0.0011607272, 1.7032822e-05, 0.9988223]]\n",
            "636         [[0.0003476382, 3.9412032e-05, 0.999613]]\n",
            "637         [[0.0012362822, 0.0014925998, 0.9972711]]\n",
            "638        [[0.9984983, 0.00011597283, 0.0013857594]]\n",
            "639         [[0.9985261, 8.536928e-05, 0.0013885377]]\n",
            "640        [[0.00042619288, 1.609677e-05, 0.9995577]]\n",
            "641            [[0.014741848, 0.98395985, 0.0012983]]\n",
            "642         [[0.0004089263, 0.0001072177, 0.9994838]]\n",
            "643       [[0.00019641039, 2.4088686e-05, 0.9997795]]\n",
            "644      [[0.00047229233, 6.5606786e-05, 0.99946207]]\n",
            "645       [[0.00074580417, 0.00017454775, 0.9990796]]\n",
            "646        [[0.00035587713, 0.015570364, 0.98407364]]\n",
            "647          [[0.00019004164, 0.071170874, 0.928639]]\n",
            "648         [[0.00035229244, 0.92906463, 0.07058308]]\n",
            "649          [[0.00043063355, 0.29919177, 0.7003776]]\n",
            "650           [[0.0008870336, 0.5231984, 0.47591457]]\n",
            "651        [[0.0015226526, 0.00020149097, 0.9982759]]\n",
            "652             [[0.83236545, 0.13823135, 0.0294033]]\n",
            "653             [[0.08111908, 0.38826343, 0.5306175]]\n",
            "654        [[0.0017335138, 1.4347129e-05, 0.9982521]]\n",
            "655       [[0.00053347426, 1.7828374e-05, 0.9994486]]\n",
            "656            [[0.009597695, 0.7759908, 0.21441151]]\n",
            "657       [[0.0006509368, 1.6777667e-05, 0.99933225]]\n",
            "658        [[0.0023396793, 1.1428608e-05, 0.9976489]]\n",
            "659           [[0.0005104662, 0.12666008, 0.8728295]]\n",
            "660         [[0.0005200411, 0.0014523327, 0.9980276]]\n",
            "661         [[0.00039018027, 0.002887914, 0.9967219]]\n",
            "662           [[0.0009959856, 0.008285036, 0.990719]]\n",
            "663        [[0.00047894375, 0.001027462, 0.99849355]]\n",
            "664       [[0.00034173272, 0.00036189263, 0.9992963]]\n",
            "665       [[0.0004258168, 0.00021395758, 0.99936026]]\n",
            "666        [[0.00096478115, 0.0014364208, 0.9975987]]\n",
            "667            [[0.0038182347, 0.13513568, 0.861046]]\n",
            "668        [[0.0039644153, 0.0007774828, 0.99525815]]\n",
            "669            [[0.021337515, 0.5958911, 0.38277134]]\n",
            "670            [[0.009869235, 0.20453815, 0.7855927]]\n",
            "671      [[0.00024114695, 5.3764685e-05, 0.99970514]]\n",
            "672         [[0.00061629736, 0.98265314, 0.01673053]]\n",
            "673        [[0.00067464774, 0.98841023, 0.010915123]]\n",
            "674        [[9.813186e-05, 0.99736553, 0.0025363131]]\n",
            "675             [[0.16330329, 0.07466618, 0.7620306]]\n",
            "676              [[0.8897039, 0.07889689, 0.0313992]]\n",
            "677            [[0.8512249, 0.13593332, 0.012841687]]\n",
            "678          [[0.010599981, 0.97867537, 0.010724717]]\n",
            "679           [[0.023257194, 0.9658428, 0.010900043]]\n",
            "680                [[0.533619, 0.4217766, 0.0446044]]\n",
            "681            [[0.5734724, 0.013833963, 0.41269362]]\n",
            "682             [[0.650529, 0.32342514, 0.026045868]]\n",
            "683            [[0.71972543, 0.27226144, 0.00801313]]\n",
            "684           [[0.0022519235, 0.24482617, 0.7529218]]\n",
            "685         [[0.002993882, 4.561519e-05, 0.99696046]]\n",
            "686         [[0.0024597938, 0.0009178929, 0.9966223]]\n",
            "687        [[0.0011586369, 0.0008517144, 0.99798965]]\n",
            "688         [[0.0093917595, 0.0014477707, 0.9891605]]\n",
            "689          [[0.990359, 0.00094530045, 0.008695682]]\n",
            "690       [[0.00097049074, 1.3048872e-05, 0.9990164]]\n",
            "691         [[0.0012143148, 0.0010241787, 0.9977615]]\n",
            "692         [[7.728733e-05, 0.9953349, 0.0045878175]]\n",
            "693          [[0.0015742461, 0.12684827, 0.87157744]]\n",
            "694            [[0.0003731558, 0.848346, 0.15128088]]\n",
            "695        [[8.946286e-05, 0.9990798, 0.00083069754]]\n",
            "696          [[0.00017891925, 0.968814, 0.031007042]]\n",
            "697       [[0.00066624675, 5.0254454e-05, 0.9992835]]\n",
            "698       [[0.0005104208, 6.8261026e-05, 0.99942136]]\n",
            "699            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "700        [[0.000225265, 5.9621296e-05, 0.99971515]]\n",
            "701        [[0.00054105517, 0.0031395848, 0.9963194]]\n",
            "702          [[0.0027141778, 0.03696612, 0.96031976]]\n",
            "703       [[0.0005956325, 0.00012614374, 0.99927825]]\n",
            "704          [[0.0003045967, 0.012888117, 0.9868073]]\n",
            "705        [[0.0006308273, 0.0004354427, 0.99893373]]\n",
            "706           [[0.0038348322, 0.19945776, 0.7967075]]\n",
            "707        [[0.00046564417, 0.9946696, 0.0048646796]]\n",
            "708           [[0.0004313567, 0.8889045, 0.11066409]]\n",
            "709          [[0.0002483752, 0.9932153, 0.006536387]]\n",
            "710           [[0.002592401, 0.26853594, 0.72887164]]\n",
            "711         [[0.0002665095, 0.99408203, 0.005651407]]\n",
            "712          [[0.0022501373, 0.65941304, 0.33833683]]\n",
            "713          [[0.00043163268, 0.979981, 0.019587403]]\n",
            "714         [[0.0030539331, 0.00011702981, 0.996829]]\n",
            "715        [[0.00084805314, 0.88268346, 0.116468444]]\n",
            "716       [[0.0013741815, 0.00013044299, 0.99849534]]\n",
            "717              [[0.02711454, 0.15642844, 0.816457]]\n",
            "718            [[0.010175931, 0.8104469, 0.17937717]]\n",
            "719            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "720          [[0.0012835118, 0.9482539, 0.050462548]]\n",
            "721        [[0.00020848667, 0.9968817, 0.0029098194]]\n",
            "722       [[0.0051573147, 0.000116810756, 0.9947259]]\n",
            "723      [[0.00033036474, 0.00013768762, 0.99953187]]\n",
            "724        [[0.99005204, 2.5440075e-05, 0.009922492]]\n",
            "725         [[0.98987585, 3.426571e-05, 0.010089937]]\n",
            "726           [[0.038566545, 0.0004954002, 0.960938]]\n",
            "727          [[0.008505927, 0.0014409143, 0.9900531]]\n",
            "728             [[0.026612945, 0.698571, 0.27481604]]\n",
            "729        [[0.0063498504, 4.5700894e-05, 0.9936045]]\n",
            "730        [[0.0013286384, 0.0033269378, 0.99534434]]\n",
            "731         [[0.0010820929, 0.0045475774, 0.9943703]]\n",
            "732      [[0.00019628982, 5.2678548e-05, 0.99975103]]\n",
            "733           [[0.0067968145, 0.5617812, 0.43142194]]\n",
            "734         [[0.001254762, 0.0004481461, 0.99829704]]\n",
            "735          [[0.012927514, 0.0024991725, 0.9845733]]\n",
            "736            [[0.8844432, 0.028096957, 0.08745978]]\n",
            "737            [[0.66659963, 0.15632606, 0.17707424]]\n",
            "738            [[0.006133809, 0.25287607, 0.7409901]]\n",
            "739          [[0.012927514, 0.0024991725, 0.9845733]]\n",
            "740           [[0.0037941143, 0.49476525, 0.5014406]]\n",
            "741           [[0.002077616, 0.009346991, 0.9885754]]\n",
            "742         [[0.00035741492, 0.009706831, 0.9899357]]\n",
            "743        [[0.0001267529, 0.0025939886, 0.99727935]]\n",
            "744         [[0.00046392504, 0.005027183, 0.9945089]]\n",
            "745          [[0.0003200144, 0.84303486, 0.15664515]]\n",
            "746           [[0.0002396293, 0.33319053, 0.6665698]]\n",
            "747           [[0.7132745, 0.0013485951, 0.28537697]]\n",
            "748       [[0.00011849953, 9.687786e-05, 0.99978465]]\n",
            "749           [[0.011953655, 0.0029332354, 0.985113]]\n",
            "750         [[0.0013145098, 0.0028367399, 0.9958488]]\n",
            "751             [[0.16752954, 0.04572221, 0.7867482]]\n",
            "752          [[0.93011504, 0.051364493, 0.018520452]]\n",
            "753          [[0.0006074717, 0.050470904, 0.9489217]]\n",
            "754           [[0.0002818328, 0.8097402, 0.18997802]]\n",
            "755          [[0.0007749341, 0.062053584, 0.9371715]]\n",
            "756        [[0.000109973036, 0.9778371, 0.022052953]]\n",
            "757            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "758         [[0.0001621636, 0.88211495, 0.117722906]]\n",
            "759        [[0.0004929538, 0.00010713553, 0.9993999]]\n",
            "760       [[0.00051895546, 0.00013031553, 0.9993507]]\n",
            "761         [[0.00070340215, 0.9829159, 0.016380744]]\n",
            "762          [[0.0008489022, 0.9840206, 0.015130577]]\n",
            "763        [[0.0034252827, 1.7114966e-05, 0.9965576]]\n",
            "764         [[0.0019305039, 0.0022037711, 0.9958658]]\n",
            "765            [[0.1505889, 0.039299853, 0.81011134]]\n",
            "766         [[0.0036904844, 0.0098390635, 0.9864704]]\n",
            "767             [[0.00476898, 0.29775816, 0.6974729]]\n",
            "768            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "769            [[0.5370579, 0.040071353, 0.42287078]]\n",
            "770          [[0.0018165399, 0.9522288, 0.045954626]]\n",
            "771          [[0.013751931, 0.0072201993, 0.9790278]]\n",
            "772        [[0.0023685235, 0.00021361849, 0.9974178]]\n",
            "773         [[0.00020831432, 0.9348702, 0.064921506]]\n",
            "774          [[0.0014974665, 0.89241594, 0.10608665]]\n",
            "775          [[0.0028361876, 0.042253137, 0.9549107]]\n",
            "776        [[0.00017482566, 0.00084920076, 0.998976]]\n",
            "777        [[0.0013298413, 0.00079334393, 0.9978769]]\n",
            "778       [[3.9882707e-05, 0.99780744, 0.0021526818]]\n",
            "779        [[0.00049980934, 0.0026223112, 0.9968779]]\n",
            "780        [[0.0004679759, 1.9608402e-05, 0.9995123]]\n",
            "781       [[0.00067860424, 0.0038234065, 0.99549806]]\n",
            "782         [[0.00015898858, 0.29102954, 0.70881146]]\n",
            "783       [[0.00044876742, 2.2784528e-05, 0.9995285]]\n",
            "784       [[0.00012412244, 0.00035864403, 0.9995172]]\n",
            "785         [[0.00025880386, 0.0038521986, 0.995889]]\n",
            "786        [[0.00081914564, 0.014272931, 0.98490787]]\n",
            "787      [[0.00038617948, 0.00057958916, 0.99903417]]\n",
            "788        [[0.0009264314, 0.0003385019, 0.99873513]]\n",
            "789        [[0.0005115381, 0.0003879364, 0.99910057]]\n",
            "790         [[0.97576255, 0.0007193418, 0.023518153]]\n",
            "791          [[0.9851902, 0.0006904974, 0.014119279]]\n",
            "792       [[0.99614394, 2.2989312e-05, 0.0038330418]]\n",
            "793         [[0.0011766328, 0.010553311, 0.98827016]]\n",
            "794         [[0.00018386512, 0.8763785, 0.123437665]]\n",
            "795           [[0.0013056413, 0.62843084, 0.3702635]]\n",
            "796            [[5.97048e-05, 0.99380314, 0.0061371]]\n",
            "797       [[5.4183325e-05, 0.99877805, 0.0011678227]]\n",
            "798        [[0.00038441314, 0.9975727, 0.0020429126]]\n",
            "799          [[0.00253625, 0.0032061632, 0.99425757]]\n",
            "800       [[0.00017907923, 0.99882907, 0.0009918299]]\n",
            "801         [[0.0053845257, 0.9901889, 0.0044265785]]\n",
            "802        [[0.000101652164, 0.9927619, 0.007136439]]\n",
            "803         [[8.20207e-05, 4.9644797e-05, 0.9998683]]\n",
            "804       [[0.00034609612, 1.539976e-05, 0.99963856]]\n",
            "805        [[0.000110539455, 0.9919586, 0.007930819]]\n",
            "806              [[0.722384, 0.10268628, 0.17492975]]\n",
            "807         [[0.0020571686, 0.0031587263, 0.9947842]]\n",
            "808            [[0.0005467256, 0.7519388, 0.2475144]]\n",
            "809            [[0.0011859725, 0.6978722, 0.3009418]]\n",
            "810        [[0.90561056, 0.00014798022, 0.094241455]]\n",
            "811          [[0.0037103011, 2.264975e-05, 0.996267]]\n",
            "812          [[0.00027960507, 0.9395254, 0.06019503]]\n",
            "813          [[0.0006837566, 0.18446295, 0.81485325]]\n",
            "814          [[0.0020847677, 0.25842646, 0.73948884]]\n",
            "815        [[0.00092746125, 0.98987436, 0.009198244]]\n",
            "816            [[0.08274329, 0.18188085, 0.73537576]]\n",
            "817         [[0.00071308046, 0.13016684, 0.86912006]]\n",
            "818           [[0.026700826, 0.008920022, 0.9643792]]\n",
            "819         [[0.0010139603, 9.507963e-06, 0.9989766]]\n",
            "820         [[0.00044859434, 9.95415e-06, 0.9995414]]\n",
            "821       [[0.00049729436, 0.0021408221, 0.99736184]]\n",
            "822          [[0.0025342219, 0.010101067, 0.9873647]]\n",
            "823       [[0.00033632683, 2.4742041e-05, 0.9996389]]\n",
            "824            [[0.5853155, 0.027708048, 0.38697642]]\n",
            "825          [[0.94369304, 0.009018958, 0.047288015]]\n",
            "826         [[0.00060631597, 5.01609e-05, 0.9993436]]\n",
            "827        [[0.0027459017, 1.9614381e-05, 0.9972345]]\n",
            "828       [[0.00063358125, 0.00015713532, 0.9992093]]\n",
            "829       [[0.0023593868, 3.5846086e-05, 0.99760485]]\n",
            "830        [[0.0016821452, 1.6420034e-05, 0.9983014]]\n",
            "831        [[0.0019096143, 7.032636e-06, 0.99808335]]\n",
            "832         [[0.00087003165, 9.86357e-05, 0.9990314]]\n",
            "833      [[0.00015166277, 0.00023289234, 0.99961543]]\n",
            "834         [[0.0007844455, 1.7463628e-05, 0.999198]]\n",
            "835        [[0.0005565489, 1.006203e-05, 0.99943346]]\n",
            "836        [[0.0012147593, 0.00012232743, 0.9986628]]\n",
            "837        [[0.00023086996, 0.012036284, 0.98773277]]\n",
            "838      [[0.000107202584, 0.0030608058, 0.99683195]]\n",
            "839        [[0.00048722827, 1.596802e-05, 0.9994968]]\n",
            "840         [[0.007613781, 7.7637196e-05, 0.9923086]]\n",
            "841          [[0.9741217, 6.200172e-05, 0.025816247]]\n",
            "842       [[0.0009415074, 0.00042056112, 0.99863786]]\n",
            "843         [[0.0004075249, 3.731515e-05, 0.9995552]]\n",
            "844       [[0.00015701083, 0.99743456, 0.0024084304]]\n",
            "845       [[0.0021854832, 0.00022949297, 0.99758494]]\n",
            "846         [[0.0018166403, 6.678522e-05, 0.9981166]]\n",
            "847           [[0.000736486, 4.3457294e-05, 0.99922]]\n",
            "848        [[0.00020772645, 0.00020824357, 0.999584]]\n",
            "849        [[0.00025280286, 0.0023091694, 0.9974381]]\n",
            "850       [[0.00049631717, 1.7349923e-05, 0.9994862]]\n",
            "851         [[0.0004372747, 9.814128e-06, 0.9995529]]\n",
            "852            [[0.05792365, 0.02080738, 0.92126906]]\n",
            "853        [[0.0002989768, 6.2205094e-05, 0.9996388]]\n",
            "854           [[0.0007666673, 0.008209298, 0.991024]]\n",
            "855           [[0.002947271, 0.026823372, 0.9702294]]\n",
            "856           [[0.008770053, 0.41944686, 0.57178307]]\n",
            "857       [[0.00037531063, 0.00039791883, 0.9992267]]\n",
            "858            [[0.004192388, 0.21826877, 0.7775389]]\n",
            "859            [[0.11331513, 0.45078444, 0.43590042]]\n",
            "860        [[0.99627715, 0.0021295613, 0.0015931862]]\n",
            "861        [[0.0020851325, 0.00017079587, 0.9977441]]\n",
            "862      [[2.4813684e-05, 0.99943477, 0.00054039573]]\n",
            "863             [[0.8702782, 0.1196493, 0.010072549]]\n",
            "864        [[0.00084198994, 0.98090035, 0.018257694]]\n",
            "865        [[0.00025428244, 3.811358e-05, 0.9997075]]\n",
            "866            [[0.002319963, 0.36871573, 0.6289643]]\n",
            "867         [[0.00090561196, 0.038741853, 0.9603526]]\n",
            "868          [[0.0002562821, 6.87052e-05, 0.9996749]]\n",
            "869            [[0.012706982, 0.7787984, 0.20849462]]\n",
            "870        [[0.00079206843, 0.90355283, 0.095655106]]\n",
            "871            [[0.02865663, 0.8638608, 0.107482605]]\n",
            "872            [[0.02865663, 0.8638608, 0.107482605]]\n",
            "873           [[0.0013586604, 0.14638415, 0.8522572]]\n",
            "874         [[0.0012446602, 0.95825714, 0.040498238]]\n",
            "875         [[0.0049905954, 0.95670646, 0.038302932]]\n",
            "876         [[0.0017241453, 0.95322514, 0.045050725]]\n",
            "877           [[0.000540912, 0.056842115, 0.9426169]]\n",
            "878        [[0.00016872966, 8.281015e-05, 0.9997484]]\n",
            "879         [[0.0005956362, 0.00016135878, 0.999243]]\n",
            "880            [[0.022501662, 0.23944858, 0.7380497]]\n",
            "881         [[0.041003447, 0.95810384, 0.0008927175]]\n",
            "882          [[0.26938453, 0.72837424, 0.0022412417]]\n",
            "883        [[0.0009637009, 0.00031606536, 0.9987203]]\n",
            "884          [[0.0015942905, 0.007565275, 0.9908404]]\n",
            "885       [[0.0010611797, 1.8409306e-05, 0.99892044]]\n",
            "886       [[0.00020326192, 0.00023951867, 0.9995572]]\n",
            "887        [[0.0010938654, 0.0011652613, 0.99774086]]\n",
            "888          [[0.000558625, 0.95751536, 0.041926038]]\n",
            "889        [[0.00059412967, 9.705882e-05, 0.9993088]]\n",
            "890       [[0.00046900232, 4.8944526e-05, 0.9994821]]\n",
            "891       [[0.00047897318, 5.285106e-05, 0.99946815]]\n",
            "892          [[0.0029536448, 0.004411753, 0.9926346]]\n",
            "893       [[0.00075466314, 0.00012769175, 0.9991177]]\n",
            "894         [[8.484407e-05, 0.98814255, 0.011772577]]\n",
            "895            [[0.0087117115, 0.7597541, 0.2315341]]\n",
            "896           [[0.0013330403, 0.79328936, 0.2053776]]\n",
            "897        [[0.0005898965, 0.00049231795, 0.9989178]]\n",
            "898        [[0.00037092326, 8.3008425e-05, 0.999546]]\n",
            "899       [[0.00019395132, 0.00040310537, 0.9994029]]\n",
            "900      [[0.00019827443, 2.2483224e-05, 0.99977916]]\n",
            "901         [[0.0003259271, 0.99424815, 0.005425941]]\n",
            "902         [[0.87372386, 0.0136665255, 0.112609625]]\n",
            "903          [[0.0053102328, 0.82166606, 0.17302373]]\n",
            "904          [[0.028623369, 0.9697185, 0.0016580989]]\n",
            "905        [[0.0008643857, 0.9982002, 0.00093537325]]\n",
            "906             [[0.0795425, 0.59489506, 0.32556245]]\n",
            "907        [[0.0014869093, 0.99755716, 0.0009559188]]\n",
            "908            [[0.63607484, 0.23826799, 0.12565716]]\n",
            "909          [[0.009448617, 0.0006195062, 0.9899318]]\n",
            "910         [[0.98411685, 0.0029609785, 0.012922271]]\n",
            "911           [[0.035296496, 0.58953947, 0.37516406]]\n",
            "912           [[0.95972097, 0.03105497, 0.009224072]]\n",
            "913            [[0.52455604, 0.41102862, 0.06441531]]\n",
            "914           [[0.09452128, 0.0033309602, 0.9021477]]\n",
            "915      [[0.00018010763, 0.00016236492, 0.99965763]]\n",
            "916          [[0.91424763, 0.07968945, 0.0060629505]]\n",
            "917          [[0.9820661, 0.015864864, 0.0020691012]]\n",
            "918            [[0.6901149, 0.30348623, 0.006398853]]\n",
            "919          [[0.0056009656, 0.041871596, 0.9525274]]\n",
            "920           [[0.0036422962, 0.8135445, 0.18281317]]\n",
            "921            [[0.51252323, 0.40378115, 0.08369561]]\n",
            "922      [[0.00010954725, 0.99962175, 0.00026867184]]\n",
            "923         [[0.005259521, 0.0143855335, 0.98035496]]\n",
            "924          [[0.011220401, 0.008002045, 0.98077756]]\n",
            "925            [[0.001103711, 0.3186534, 0.68024284]]\n",
            "926           [[0.0012225077, 0.971905, 0.026872547]]\n",
            "927        [[0.00012497694, 0.9977944, 0.0020806312]]\n",
            "928        [[0.0014997117, 8.174384e-05, 0.99841857]]\n",
            "929       [[0.00039987016, 0.00034692718, 0.9992532]]\n",
            "930           [[0.0009474989, 0.01450833, 0.9845442]]\n",
            "931           [[0.00027189014, 0.0093413, 0.9903868]]\n",
            "932          [[0.00064574997, 0.7924184, 0.20693587]]\n",
            "933         [[0.0006366844, 0.0010743532, 0.9982889]]\n",
            "934          [[0.80192333, 0.00032350654, 0.1977532]]\n",
            "935          [[0.80192333, 0.00032350654, 0.1977532]]\n",
            "936         [[0.0027154498, 0.004279883, 0.99300474]]\n",
            "937      [[0.00060203986, 5.1492985e-05, 0.99934644]]\n",
            "938           [[0.002791682, 0.002939581, 0.9942688]]\n",
            "939         [[0.0005472569, 9.349672e-05, 0.9993592]]\n",
            "940        [[0.00066916615, 0.0013242454, 0.9980065]]\n",
            "941           [[0.001330641, 0.09685371, 0.90181553]]\n",
            "942          [[0.0016991138, 0.91038084, 0.08792004]]\n",
            "943      [[0.00012453759, 2.0377218e-05, 0.99985504]]\n",
            "944         [[0.0005625621, 1.6391532e-05, 0.999421]]\n",
            "945            [[0.0018588665, 0.6547973, 0.3433438]]\n",
            "946         [[0.0006379616, 6.690005e-05, 0.9992951]]\n",
            "947       [[0.00034038845, 0.00016970692, 0.9994899]]\n",
            "948           [[0.00033983513, 0.1538586, 0.8458016]]\n",
            "949        [[0.00028878314, 1.917277e-05, 0.9996921]]\n",
            "950          [[0.00016617886, 0.06708742, 0.9327464]]\n",
            "951           [[0.00097000593, 0.9668792, 0.0321508]]\n",
            "952            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "953         [[3.6067602e-05, 0.9900085, 0.009955429]]\n",
            "954           [[0.038112737, 0.41370255, 0.54818475]]\n",
            "955            [[0.0008476736, 0.0821797, 0.9169726]]\n",
            "956            [[0.03179682, 0.32360587, 0.64459735]]\n",
            "957        [[0.000627454, 0.00025988044, 0.99911267]]\n",
            "958      [[0.00071637373, 0.00016105663, 0.99912256]]\n",
            "959         [[0.00097229966, 0.9696935, 0.029334258]]\n",
            "960          [[0.002543146, 0.0002583053, 0.9971986]]\n",
            "961       [[0.00033899123, 1.624961e-05, 0.99964476]]\n",
            "962       [[0.0015506665, 0.00017547255, 0.99827385]]\n",
            "963        [[0.00061119004, 7.946245e-05, 0.9993093]]\n",
            "964             [[0.07867141, 0.7188952, 0.20243344]]\n",
            "965        [[0.00047951663, 6.511534e-05, 0.9994553]]\n",
            "966         [[0.011793948, 0.0063171308, 0.98188895]]\n",
            "967         [[0.011793948, 0.0063171308, 0.98188895]]\n",
            "968          [[0.0066968766, 0.42984858, 0.56345457]]\n",
            "969       [[0.00054534874, 7.882682e-05, 0.99937576]]\n",
            "970          [[0.0011697231, 0.046262138, 0.9525681]]\n",
            "971         [[0.0065182163, 0.019883202, 0.97359854]]\n",
            "972          [[0.00082260644, 0.45924363, 0.5399338]]\n",
            "973       [[0.00017046626, 2.7762642e-05, 0.9998018]]\n",
            "974      [[0.00055885833, 0.00019859445, 0.99924254]]\n",
            "975      [[0.00055885833, 0.00019859445, 0.99924254]]\n",
            "976        [[0.00043883373, 0.00013523403, 0.999426]]\n",
            "977           [[0.0030459333, 0.28173727, 0.7152168]]\n",
            "978            [[0.005024698, 0.61366993, 0.3813053]]\n",
            "979            [[0.012283108, 0.18649621, 0.8012206]]\n",
            "980        [[0.00068001385, 7.773968e-06, 0.9993123]]\n",
            "981        [[0.0021700799, 9.2391514e-05, 0.9977375]]\n",
            "982         [[0.0011369874, 0.93931806, 0.059544954]]\n",
            "983        [[0.0003005203, 0.0002137878, 0.99948573]]\n",
            "984           [[0.0035068314, 0.25286534, 0.7436278]]\n",
            "985        [[0.0021700799, 9.2391514e-05, 0.9977375]]\n",
            "986          [[0.0015779095, 0.003389817, 0.9950322]]\n",
            "987        [[0.004049318, 0.00035563906, 0.99559504]]\n",
            "988         [[0.0006245494, 1.930345e-05, 0.9993562]]\n",
            "989        [[0.0019126928, 5.8671183e-05, 0.9980286]]\n",
            "990         [[0.0014612399, 3.396995e-05, 0.9985049]]\n",
            "991        [[3.1021846e-05, 0.9985453, 0.0014236843]]\n",
            "992          [[0.0055578714, 0.08280478, 0.91163737]]\n",
            "993         [[0.0010078035, 0.002586811, 0.99640536]]\n",
            "994        [[0.00017129902, 0.0012988541, 0.9985298]]\n",
            "995          [[0.00034359662, 0.5334877, 0.46616873]]\n",
            "996          [[0.0008300636, 0.060441308, 0.9387286]]\n",
            "997          [[0.0028366386, 0.008151261, 0.9890121]]\n",
            "998         [[0.0036470646, 0.015659792, 0.98069316]]\n",
            "999       [[0.0002478387, 0.00042143566, 0.99933076]]\n",
            "1000      [[0.00053955754, 0.0031717487, 0.99628866]]\n",
            "1001        [[0.004163626, 0.00021079724, 0.9956256]]\n",
            "1002       [[0.0002592269, 0.00024330965, 0.9994974]]\n",
            "1003         [[0.0054116547, 0.63432777, 0.36026058]]\n",
            "1004        [[0.0005739237, 1.8114457e-05, 0.999408]]\n",
            "1005       [[0.00019045822, 0.0015251524, 0.9982844]]\n",
            "1006       [[0.0005514066, 0.0005882654, 0.99886036]]\n",
            "1007       [[0.0005514066, 0.0005882654, 0.99886036]]\n",
            "1008        [[0.0020607356, 1.514517e-05, 0.9979241]]\n",
            "1009         [[0.008149706, 0.009623341, 0.98222697]]\n",
            "1010             [[0.09140569, 0.01174535, 0.896849]]\n",
            "1011      [[0.00029148383, 0.0004332002, 0.99927527]]\n",
            "1012        [[0.00037949588, 0.006478827, 0.9931417]]\n",
            "1013      [[0.00024767139, 3.0751136e-05, 0.9997216]]\n",
            "1014       [[0.99552166, 0.0026990462, 0.0017793281]]\n",
            "1015        [[0.001482517, 0.0004650743, 0.99805236]]\n",
            "1016       [[0.002153365, 5.3131367e-05, 0.99779344]]\n",
            "1017         [[0.0008034934, 0.38142958, 0.61776686]]\n",
            "1018       [[0.0015127944, 0.0011700671, 0.99731714]]\n",
            "1019     [[0.00035161822, 2.2882514e-05, 0.99962544]]\n",
            "1020        [[0.0015639308, 0.0012657827, 0.9971704]]\n",
            "1021           [[0.010428152, 0.09797295, 0.8915989]]\n",
            "1022      [[0.00074247096, 6.552867e-05, 0.99919206]]\n",
            "1023         [[0.0015985784, 0.16730934, 0.83109206]]\n",
            "1024         [[0.0006543373, 0.92171687, 0.07762879]]\n",
            "1025           [[0.9567714, 0.00446723, 0.038761362]]\n",
            "1026         [[0.004220101, 0.029518098, 0.96626174]]\n",
            "1027         [[0.000492232, 2.220917e-05, 0.9994856]]\n",
            "1028         [[0.0006183917, 0.006343703, 0.9930379]]\n",
            "1029      [[0.0008469732, 0.00031296842, 0.99884015]]\n",
            "1030    [[0.00039072343, 0.000109159344, 0.99950016]]\n",
            "1031         [[0.00036040033, 0.01481545, 0.9848241]]\n",
            "1032           [[0.001009371, 0.47983512, 0.5191555]]\n",
            "1033           [[0.027860044, 0.5341273, 0.43801266]]\n",
            "1034       [[0.00053669704, 6.522368e-05, 0.9993981]]\n",
            "1035      [[0.00026459323, 2.9917117e-05, 0.9997055]]\n",
            "1036     [[0.00040628336, 1.4572661e-05, 0.99957913]]\n",
            "1037          [[0.000660952, 0.89818645, 0.10115255]]\n",
            "1038        [[0.0020165406, 0.0126016615, 0.9853817]]\n",
            "1039     [[0.00028396206, 1.9357854e-05, 0.99969673]]\n",
            "1040         [[0.00035784164, 3.211882e-05, 0.99961]]\n",
            "1041       [[7.862618e-05, 0.99607074, 0.0038505762]]\n",
            "1042      [[7.3567266e-05, 0.99700207, 0.0029243748]]\n",
            "1043       [[0.00016309349, 0.9976459, 0.0021909543]]\n",
            "1044         [[0.0008849952, 0.13042687, 0.86868817]]\n",
            "1045        [[0.001896274, 0.0033040335, 0.99479973]]\n",
            "1046       [[0.0007370925, 3.323662e-05, 0.99922967]]\n",
            "1047     [[0.00018328817, 5.3009964e-05, 0.99976367]]\n",
            "1048           [[0.9882047, 0.0001974675, 0.0115978]]\n",
            "1049          [[0.7303922, 0.0027345836, 0.26687318]]\n",
            "1050         [[0.9128345, 0.085747145, 0.0014183436]]\n",
            "1051       [[0.00031989123, 6.945515e-05, 0.9996107]]\n",
            "1052            [[0.006604545, 0.1977773, 0.7956182]]\n",
            "1053     [[0.00043019906, 0.00038655344, 0.99918324]]\n",
            "1054        [[0.0016534845, 0.015700651, 0.98264587]]\n",
            "1055            [[0.01519596, 0.37750983, 0.6072942]]\n",
            "1056         [[0.0007476546, 0.004291906, 0.9949604]]\n",
            "1057         [[0.00016720957, 0.8600311, 0.13980168]]\n",
            "1058      [[0.0006049724, 1.4033515e-05, 0.99938095]]\n",
            "1059         [[0.0004828829, 0.52365756, 0.47585952]]\n",
            "1060      [[0.00035862092, 0.00012554202, 0.9995158]]\n",
            "1061        [[5.994665e-05, 0.0002471735, 0.9996929]]\n",
            "1062      [[0.00026242252, 0.00028262456, 0.9994549]]\n",
            "1063            [[0.04346724, 0.21569566, 0.7408371]]\n",
            "1064          [[0.080545165, 0.48838055, 0.43107435]]\n",
            "1065         [[0.0009120999, 0.9639821, 0.035105795]]\n",
            "1066     [[0.00016871071, 0.00010743539, 0.99972385]]\n",
            "1067         [[0.00049386866, 0.93604094, 0.0634652]]\n",
            "1068       [[9.106638e-05, 0.0016748345, 0.99823415]]\n",
            "1069         [[0.0026611777, 0.012692119, 0.9846467]]\n",
            "1070         [[0.00029378408, 0.000235199, 0.999471]]\n",
            "1071       [[0.00027931883, 6.082958e-05, 0.9996599]]\n",
            "1072          [[0.0001687922, 0.18884347, 0.8109877]]\n",
            "1073        [[0.0053944094, 0.0002890753, 0.9943165]]\n",
            "1074       [[0.00026962365, 0.0022339895, 0.9974964]]\n",
            "1075        [[0.0070108967, 6.837905e-05, 0.9929207]]\n",
            "1076         [[0.00038010156, 0.993997, 0.005622889]]\n",
            "1077       [[0.00043346398, 3.641442e-05, 0.9995301]]\n",
            "1078    [[0.000100839665, 0.00014238924, 0.99975675]]\n",
            "1079     [[7.8698766e-05, 0.00030326427, 0.99961805]]\n",
            "1080          [[0.029376982, 0.56064284, 0.40998024]]\n",
            "1081        [[6.8218906e-05, 0.9955913, 0.004340559]]\n",
            "1082           [[0.001062408, 0.77475995, 0.2241776]]\n",
            "1083      [[0.0010532603, 3.9904953e-05, 0.99890685]]\n",
            "1084       [[0.0018727586, 0.00028611877, 0.9978411]]\n",
            "1085       [[0.00018898639, 0.003177676, 0.99663335]]\n",
            "1086        [[0.00038279602, 0.07846252, 0.92115474]]\n",
            "1087       [[0.00040447354, 0.0016556542, 0.9979399]]\n",
            "1088            [[0.01519596, 0.37750983, 0.6072942]]\n",
            "1089         [[0.0004948385, 0.06522014, 0.93428504]]\n",
            "1090        [[0.00018393961, 0.9602284, 0.039587636]]\n",
            "1091           [[0.004501472, 0.6369476, 0.35855094]]\n",
            "1092       [[0.0004338885, 7.1312155e-05, 0.9994947]]\n",
            "1093        [[0.9974921, 0.001673287, 0.00083465077]]\n",
            "1094          [[0.8859804, 0.11020359, 0.0038159052]]\n",
            "1095        [[0.010869821, 0.0056621293, 0.98346806]]\n",
            "1096        [[0.0029721593, 0.0018231677, 0.9952047]]\n",
            "1097      [[0.0011002083, 8.6798405e-05, 0.99881303]]\n",
            "1098       [[0.0015210478, 0.00015677587, 0.9983222]]\n",
            "1099         [[0.0010960463, 0.008031168, 0.9908728]]\n",
            "1100       [[0.0004879045, 0.00015269453, 0.9993594]]\n",
            "1101       [[0.0016713549, 3.1896765e-05, 0.9982968]]\n",
            "1102          [[0.000757673, 2.430648e-05, 0.999218]]\n",
            "1103        [[0.0010649732, 0.003563915, 0.99537116]]\n",
            "1104      [[0.00088323967, 0.0012680568, 0.99784875]]\n",
            "1105      [[0.00070915493, 0.0002566964, 0.99903417]]\n",
            "1106       [[0.0005854051, 0.0014968032, 0.99791783]]\n",
            "1107      [[0.00045504392, 3.0405714e-05, 0.9995146]]\n",
            "1108     [[0.00047025998, 0.00013823112, 0.99939156]]\n",
            "1109       [[0.0002281877, 0.00011925518, 0.9996525]]\n",
            "1110     [[0.00027578737, 2.9764591e-05, 0.99969447]]\n",
            "1111       [[0.00041811957, 0.0016585841, 0.9979233]]\n",
            "1112       [[0.00025155387, 0.0060998057, 0.9936486]]\n",
            "1113         [[0.0005272137, 0.050386343, 0.9490865]]\n",
            "1114     [[0.00038434687, 0.00014871915, 0.99946696]]\n",
            "1115       [[0.00035796527, 0.0040603634, 0.9955817]]\n",
            "1116         [[0.0066232723, 0.020345373, 0.9730313]]\n",
            "1117       [[0.00050274195, 0.0014070062, 0.9980903]]\n",
            "1118      [[0.00010932906, 3.682384e-05, 0.99985385]]\n",
            "1119     [[0.00010199015, 2.9177812e-05, 0.99986875]]\n",
            "1120       [[0.0017235194, 0.0026440984, 0.99563235]]\n",
            "1121       [[0.0010867981, 1.9472622e-05, 0.9988937]]\n",
            "1122           [[0.9011261, 0.08711854, 0.011755355]]\n",
            "1123          [[0.046338264, 0.70382214, 0.24983966]]\n",
            "1124     [[0.00054382975, 0.00044833685, 0.99900776]]\n",
            "1125      [[0.0009194055, 1.34649645e-05, 0.9990671]]\n",
            "1126          [[0.000638452, 0.012903464, 0.9864581]]\n",
            "1127         [[0.0030702967, 0.004359626, 0.9925701]]\n",
            "1128         [[0.0010859474, 0.9443098, 0.054604243]]\n",
            "1129         [[0.0003170367, 0.9893434, 0.010339619]]\n",
            "1130           [[0.00050363, 0.0006273396, 0.998869]]\n",
            "1131       [[0.0023567511, 0.0048314147, 0.99281186]]\n",
            "1132        [[0.0020740053, 0.0016731123, 0.9962529]]\n",
            "1133         [[0.015370823, 0.025163064, 0.95946604]]\n",
            "1134         [[0.024938973, 0.043382213, 0.93167883]]\n",
            "1135       [[0.0005786395, 0.000103368206, 0.999318]]\n",
            "1136      [[0.0005777525, 7.3773466e-05, 0.99934846]]\n",
            "1137          [[0.0012703224, 0.08955159, 0.9091781]]\n",
            "1138       [[0.00083712884, 0.0015637508, 0.9975992]]\n",
            "1139      [[0.00043454944, 0.00080578023, 0.9987596]]\n",
            "1140         [[0.0072908425, 0.02556751, 0.96714157]]\n",
            "1141          [[0.002316564, 0.9384663, 0.059217095]]\n",
            "1142          [[0.004695352, 0.43689236, 0.55841225]]\n",
            "1143     [[0.00034722098, 0.00018162212, 0.99947125]]\n",
            "1144        [[0.001823701, 8.623245e-05, 0.99808997]]\n",
            "1145          [[0.9592448, 0.03728713, 0.0034681044]]\n",
            "1146      [[0.00012863672, 0.00010427766, 0.9997671]]\n",
            "1147         [[0.0012490533, 0.004856701, 0.9938943]]\n",
            "1148      [[0.0005968257, 1.3321777e-05, 0.99938977]]\n",
            "1149        [[0.0059756995, 0.0006766484, 0.9933476]]\n",
            "1150         [[0.0005337087, 0.0037843685, 0.995682]]\n",
            "1151        [[0.0010529394, 0.0014272106, 0.9975198]]\n",
            "1152          [[0.0019287704, 0.32550135, 0.6725698]]\n",
            "1153            [[0.004557866, 0.161453, 0.83398914]]\n",
            "1154        [[0.0033817699, 0.94257444, 0.054043807]]\n",
            "1155          [[0.030423952, 0.066440016, 0.9031361]]\n",
            "1156       [[0.0010915317, 1.5991043e-05, 0.9988925]]\n",
            "1157      [[0.00074904086, 9.104432e-05, 0.99915993]]\n",
            "1158      [[0.0014353975, 0.00015228816, 0.99841225]]\n",
            "1159          [[0.0009182795, 0.8729252, 0.12615652]]\n",
            "1160           [[0.0020405445, 0.186998, 0.81096154]]\n",
            "1161           [[0.088822216, 0.09900405, 0.8121737]]\n",
            "1162         [[0.0010001436, 0.000496869, 0.9985031]]\n",
            "1163        [[0.0011432267, 0.0004509105, 0.9984059]]\n",
            "1164       [[0.0001856253, 0.0010846051, 0.99872977]]\n",
            "1165       [[0.0006698076, 0.0012905778, 0.99803966]]\n",
            "1166       [[0.0019256438, 0.00015137075, 0.9979231]]\n",
            "1167          [[0.00089068606, 0.0054701, 0.9936393]]\n",
            "1168      [[0.00056518614, 8.890011e-05, 0.99934596]]\n",
            "1169         [[0.000302143, 3.9976647e-05, 0.999658]]\n",
            "1170       [[0.00097476423, 0.058558073, 0.94046706]]\n",
            "1171         [[0.0036806476, 0.13428093, 0.86203843]]\n",
            "1172       [[0.0017836521, 0.0014738529, 0.99674255]]\n",
            "1173       [[0.00010456148, 0.98660827, 0.013287182]]\n",
            "1174           [[0.27677435, 0.63014525, 0.09308037]]\n",
            "1175           [[0.9411165, 0.03783655, 0.021046948]]\n",
            "1176         [[0.010971689, 0.9874176, 0.0016107837]]\n",
            "1177           [[0.0037439393, 0.00638208, 0.989874]]\n",
            "1178         [[0.0017129339, 0.00532161, 0.99296546]]\n",
            "1179       [[0.0045732195, 0.00017373766, 0.9952531]]\n",
            "1180       [[0.0025728217, 5.2322306e-05, 0.9973749]]\n",
            "1181       [[0.0017091157, 4.201496e-05, 0.99824893]]\n",
            "1182        [[0.0022209948, 8.632728e-05, 0.9976927]]\n",
            "1183      [[0.00064307253, 0.0006448729, 0.99871206]]\n",
            "1184        [[0.0007112025, 6.384459e-05, 0.9992249]]\n",
            "1185     [[0.00031534742, 1.5846406e-05, 0.99966884]]\n",
            "1186          [[0.1825708, 0.0036287394, 0.81380045]]\n",
            "1187          [[0.016344821, 0.19944714, 0.78420806]]\n",
            "1188      [[0.0129106585, 0.00042381533, 0.98666555]]\n",
            "1189        [[0.0005108748, 0.00033317556, 0.999156]]\n",
            "1190      [[0.00048740054, 0.0004454539, 0.99906725]]\n",
            "1191       [[0.00035040505, 0.0001242722, 0.9995253]]\n",
            "1192           [[0.007653397, 0.42109472, 0.5712519]]\n",
            "1193       [[0.0039985967, 0.00030964083, 0.9956917]]\n",
            "1194        [[0.0011264699, 1.8602723e-05, 0.998855]]\n",
            "1195          [[0.001293261, 1.46499e-05, 0.9986921]]\n",
            "1196          [[0.0014335678, 0.18395069, 0.8146158]]\n",
            "1197     [[0.00019459645, 0.00082853006, 0.99897695]]\n",
            "1198        [[0.0012919332, 0.027686767, 0.97102123]]\n",
            "1199      [[0.00040445477, 0.00072598574, 0.9988695]]\n",
            "1200       [[0.000105091895, 0.9694418, 0.030453144]]\n",
            "1201        [[0.002897416, 2.9891133e-05, 0.9970727]]\n",
            "1202       [[0.00024220398, 2.003713e-05, 0.9997378]]\n",
            "1203       [[0.001481806, 0.00026017296, 0.99825805]]\n",
            "1204       [[0.007274035, 0.00012606554, 0.99259996]]\n",
            "1205       [[0.003604486, 0.00064567337, 0.99574983]]\n",
            "1206       [[0.00012748856, 0.0031596392, 0.9967129]]\n",
            "1207           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1208      [[0.0007633048, 5.8911803e-05, 0.99917775]]\n",
            "1209           [[0.09433365, 0.05512853, 0.85053784]]\n",
            "1210        [[0.0003383565, 0.9952153, 0.0044463845]]\n",
            "1211         [[0.001208676, 0.90387326, 0.094918124]]\n",
            "1212         [[0.0056656306, 0.068151966, 0.9261824]]\n",
            "1213      [[0.00063720706, 0.00037396274, 0.9989888]]\n",
            "1214       [[0.0014376491, 0.00061356864, 0.9979487]]\n",
            "1215       [[0.0005039303, 4.1882467e-05, 0.9994541]]\n",
            "1216         [[0.0003623895, 0.18743181, 0.81220573]]\n",
            "1217         [[0.00079169293, 0.1272078, 0.87200046]]\n",
            "1218      [[0.0009041456, 1.3890119e-05, 0.99908197]]\n",
            "1219      [[0.00026638535, 5.8420188e-05, 0.9996753]]\n",
            "1220           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1221       [[0.00056969037, 0.0002577137, 0.9991725]]\n",
            "1222        [[0.013475255, 0.0019741394, 0.98455065]]\n",
            "1223         [[0.01406719, 0.0013639921, 0.98456883]]\n",
            "1224         [[0.0003003331, 0.031382695, 0.9683169]]\n",
            "1225           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1226       [[0.0028603212, 0.0020004162, 0.99513924]]\n",
            "1227         [[0.0014080812, 0.011812679, 0.9867792]]\n",
            "1228        [[0.0014621024, 0.013019602, 0.98551834]]\n",
            "1229          [[0.13975577, 0.032871835, 0.82737243]]\n",
            "1230         [[0.006871716, 0.0035992223, 0.9895291]]\n",
            "1231      [[0.00077695295, 0.00019560492, 0.9990275]]\n",
            "1232        [[0.9938631, 0.0009265037, 0.0052103736]]\n",
            "1233      [[0.00027174022, 4.1258212e-05, 0.9996871]]\n",
            "1234         [[0.0010036341, 0.026786108, 0.9722102]]\n",
            "1235          [[0.50425875, 0.46408933, 0.031651825]]\n",
            "1236            [[0.07643003, 0.8500004, 0.07356956]]\n",
            "1237            [[0.09152973, 0.8687002, 0.03977003]]\n",
            "1238       [[0.00037644862, 3.408767e-05, 0.9995895]]\n",
            "1239        [[0.0013579845, 0.0010161557, 0.9976259]]\n",
            "1240        [[0.001486346, 1.9798488e-05, 0.9984939]]\n",
            "1241        [[0.0004138238, 0.020255253, 0.97933096]]\n",
            "1242         [[0.0044917003, 0.01215253, 0.98335576]]\n",
            "1243          [[0.0025589138, 0.07687447, 0.9205666]]\n",
            "1244         [[0.001943833, 0.0048555057, 0.9932006]]\n",
            "1245       [[9.837374e-05, 0.0009087167, 0.99899286]]\n",
            "1246         [[0.0005339552, 0.51399237, 0.48547366]]\n",
            "1247       [[0.00020882719, 0.002132206, 0.99765897]]\n",
            "1248     [[0.00023549737, 1.5690013e-05, 0.99974877]]\n",
            "1249        [[0.0007755114, 0.99444205, 0.004782382]]\n",
            "1250          [[0.0010698715, 0.6778538, 0.32107633]]\n",
            "1251           [[0.010242651, 0.25887078, 0.7308866]]\n",
            "1252      [[0.0015905349, 3.2472264e-05, 0.99837697]]\n",
            "1253          [[0.0012649988, 0.9899888, 0.00874619]]\n",
            "1254      [[0.00024414723, 0.0011993018, 0.99855655]]\n",
            "1255       [[0.0001519943, 0.00056635565, 0.9992817]]\n",
            "1256      [[0.00012691652, 0.00013144939, 0.9997416]]\n",
            "1257       [[0.00068748614, 0.0014284162, 0.9978841]]\n",
            "1258      [[0.00015886567, 0.0005272212, 0.99931383]]\n",
            "1259      [[0.00047134014, 0.00040458137, 0.9991241]]\n",
            "1260        [[0.0007990451, 0.98091847, 0.018282488]]\n",
            "1261      [[0.0006265746, 0.00010464429, 0.99926883]]\n",
            "1262     [[0.00043418087, 4.4037984e-05, 0.99952173]]\n",
            "1263          [[0.9787295, 0.005594295, 0.015676294]]\n",
            "1264      [[0.0005646713, 2.9435289e-05, 0.99940586]]\n",
            "1265         [[0.000579541, 0.0014401614, 0.9979804]]\n",
            "1266      [[0.00050444354, 0.00022315828, 0.9992724]]\n",
            "1267           [[0.003235896, 0.23738943, 0.7593747]]\n",
            "1268        [[0.020571107, 0.0033256307, 0.97610325]]\n",
            "1269            [[0.4967098, 0.46154356, 0.04174658]]\n",
            "1270           [[0.8038332, 0.026264701, 0.16990206]]\n",
            "1271         [[0.95777774, 0.0031353477, 0.03908694]]\n",
            "1272       [[1.573557e-05, 0.99877685, 0.0012074612]]\n",
            "1273        [[0.00045212338, 0.9905282, 0.009019674]]\n",
            "1274      [[0.00023058585, 0.00051950937, 0.9992499]]\n",
            "1275         [[0.0014114836, 0.007710813, 0.9908778]]\n",
            "1276          [[0.0030437731, 0.60900754, 0.3879487]]\n",
            "1277            [[0.3691647, 0.59505576, 0.03577954]]\n",
            "1278      [[0.0003971207, 0.00040715252, 0.99919575]]\n",
            "1279         [[0.0013516449, 0.11619156, 0.88245684]]\n",
            "1280         [[0.001521267, 0.0056825457, 0.9927961]]\n",
            "1281           [[0.0010172453, 0.13069564, 0.868287]]\n",
            "1282        [[0.0034461236, 0.027659634, 0.96889424]]\n",
            "1283         [[0.0005460549, 1.3901352e-05, 0.99944]]\n",
            "1284        [[0.0006490906, 0.0028002218, 0.9965507]]\n",
            "1285       [[0.0003655207, 0.0016029757, 0.99803156]]\n",
            "1286          [[0.0003079755, 0.8315471, 0.16814496]]\n",
            "1287      [[0.00018357486, 8.915453e-06, 0.99980754]]\n",
            "1288         [[0.0006849512, 0.23364191, 0.76567316]]\n",
            "1289      [[0.00087601616, 0.99609166, 0.0030323141]]\n",
            "1290          [[0.84739065, 0.03064513, 0.121964216]]\n",
            "1291      [[0.0017509991, 0.000114695154, 0.9981343]]\n",
            "1292             [[0.44784382, 0.11858228, 0.433574]]\n",
            "1293      [[0.00059450854, 0.00012766411, 0.9992778]]\n",
            "1294       [[0.0006751932, 0.00048600533, 0.9988387]]\n",
            "1295           [[0.7036884, 0.024334954, 0.27197668]]\n",
            "1296       [[0.0008619669, 6.668223e-05, 0.99907136]]\n",
            "1297         [[0.0006793173, 0.005586287, 0.9937344]]\n",
            "1298       [[9.754146e-05, 0.99780446, 0.0020979922]]\n",
            "1299      [[0.0006549231, 0.00012308623, 0.99922204]]\n",
            "1300           [[0.47704986, 0.13939662, 0.38355353]]\n",
            "1301         [[0.0006462549, 0.005271904, 0.9940819]]\n",
            "1302       [[0.00044004412, 0.0005959232, 0.9989641]]\n",
            "1303        [[0.0001657027, 0.9944852, 0.0053491453]]\n",
            "1304        [[0.00046055546, 0.85204196, 0.14749749]]\n",
            "1305        [[0.00048083081, 0.024123272, 0.9753959]]\n",
            "1306        [[0.00045414234, 0.035528567, 0.9640172]]\n",
            "1307     [[0.00042636445, 4.0654075e-05, 0.99953306]]\n",
            "1308      [[0.00048847584, 3.5658788e-05, 0.9994759]]\n",
            "1309        [[0.0004183164, 8.109979e-05, 0.9995005]]\n",
            "1310       [[0.00060238235, 2.280398e-05, 0.9993749]]\n",
            "1311         [[0.0008634716, 0.05272335, 0.94641316]]\n",
            "1312     [[0.00014177558, 0.00010894025, 0.99974924]]\n",
            "1313       [[0.00028227223, 0.012429517, 0.98728824]]\n",
            "1314        [[0.00053756236, 0.00831128, 0.99115103]]\n",
            "1315      [[5.0466268e-05, 0.99860257, 0.0013470204]]\n",
            "1316            [[0.001184382, 0.710281, 0.28853458]]\n",
            "1317       [[0.0010756989, 0.0001581828, 0.99876606]]\n",
            "1318       [[0.001696629, 1.2947543e-05, 0.99829036]]\n",
            "1319      [[0.00091952295, 1.5384732e-05, 0.9990651]]\n",
            "1320        [[0.0005615799, 1.618281e-05, 0.9994222]]\n",
            "1321      [[0.00026770268, 0.00062252773, 0.9991097]]\n",
            "1322           [[0.001911946, 0.8157524, 0.18233567]]\n",
            "1323     [[0.00017416825, 0.99950254, 0.00032331204]]\n",
            "1324       [[0.00010435565, 0.9971161, 0.0027796063]]\n",
            "1325        [[0.0004569286, 0.98932225, 0.010220762]]\n",
            "1326     [[0.00016191987, 0.99915814, 0.00067990995]]\n",
            "1327       [[0.0019127016, 0.0022349928, 0.99585223]]\n",
            "1328         [[0.0003772364, 0.007874506, 0.9917482]]\n",
            "1329     [[0.00041900604, 0.00024375998, 0.99933726]]\n",
            "1330      [[0.00017333333, 0.9990501, 0.00077656424]]\n",
            "1331        [[0.00022213228, 0.002812063, 0.9969658]]\n",
            "1332      [[0.00053467706, 0.00076410547, 0.9987012]]\n",
            "1333      [[0.00039629504, 0.0045916988, 0.99501204]]\n",
            "1334       [[0.0005624709, 0.98652494, 0.0129125975]]\n",
            "1335         [[0.00028868302, 0.38040844, 0.6193029]]\n",
            "1336          [[0.052517537, 0.9182295, 0.029252902]]\n",
            "1337        [[0.0010302794, 0.002268233, 0.99670154]]\n",
            "1338       [[0.00043241808, 1.9544674e-05, 0.999548]]\n",
            "1339           [[0.04260746, 0.03444106, 0.92295146]]\n",
            "1340     [[0.0004447262, 1.47500705e-05, 0.99954057]]\n",
            "1341      [[0.0036893853, 0.00024873763, 0.99606186]]\n",
            "1342      [[0.00031244243, 0.00010865464, 0.9995789]]\n",
            "1343          [[0.91007245, 0.007699826, 0.08222776]]\n",
            "1344           [[0.39319438, 0.039956167, 0.5668495]]\n",
            "1345           [[0.081937194, 0.17418684, 0.7438759]]\n",
            "1346         [[0.0022627066, 0.13561429, 0.86212295]]\n",
            "1347         [[0.0008335574, 0.0058904113, 0.993276]]\n",
            "1348       [[0.0006608143, 0.00042583104, 0.9989134]]\n",
            "1349         [[0.00158689, 0.00037675802, 0.9980363]]\n",
            "1350       [[0.0006974326, 0.00070929306, 0.9985933]]\n",
            "1351       [[0.0008666244, 3.8681606e-05, 0.9990947]]\n",
            "1352       [[0.000361009, 0.00087667856, 0.99876237]]\n",
            "1353      [[0.0021984833, 1.1677226e-05, 0.99778986]]\n",
            "1354      [[0.0014674767, 4.1393065e-05, 0.99849105]]\n",
            "1355            [[0.08670398, 0.8013181, 0.11197796]]\n",
            "1356     [[0.00045670161, 0.00022553714, 0.99931777]]\n",
            "1357           [[0.0034531816, 0.960704, 0.03584287]]\n",
            "1358        [[0.0021726342, 3.973738e-05, 0.9977876]]\n",
            "1359        [[0.0017099871, 0.0004486231, 0.9978415]]\n",
            "1360        [[0.0015958557, 1.91712e-05, 0.99838495]]\n",
            "1361      [[0.00036739776, 0.0011212317, 0.99851125]]\n",
            "1362          [[0.5118057, 0.0043107406, 0.48388353]]\n",
            "1363       [[0.00019548446, 0.017793007, 0.98201144]]\n",
            "1364          [[0.00064542587, 0.824328, 0.17502657]]\n",
            "1365       [[0.00086476747, 0.021656228, 0.97747904]]\n",
            "1366         [[0.0029098673, 0.008059457, 0.9890308]]\n",
            "1367       [[0.00074941025, 1.837728e-05, 0.9992323]]\n",
            "1368           [[0.0009924612, 0.0699547, 0.9290529]]\n",
            "1369        [[0.00073363155, 0.040708743, 0.9585576]]\n",
            "1370           [[0.010843886, 0.6225137, 0.36664242]]\n",
            "1371          [[0.0005966747, 0.9034777, 0.09592564]]\n",
            "1372        [[0.001546895, 1.7297061e-05, 0.9984358]]\n",
            "1373     [[0.00097096886, 0.00013078566, 0.99889827]]\n",
            "1374       [[0.00037924998, 0.0001313552, 0.9994894]]\n",
            "1375        [[0.00033953862, 0.9903874, 0.009273033]]\n",
            "1376      [[0.00035045567, 0.00029875388, 0.9993507]]\n",
            "1377       [[0.0002405066, 2.6773334e-05, 0.9997327]]\n",
            "1378      [[0.00024972914, 3.7466994e-05, 0.9997129]]\n",
            "1379      [[0.00028189784, 0.00019235683, 0.9995258]]\n",
            "1380           [[0.15357193, 0.8379253, 0.008502696]]\n",
            "1381       [[0.00073784945, 0.0056710327, 0.9935912]]\n",
            "1382      [[0.99843925, 0.0011017165, 0.00045908694]]\n",
            "1383              [[0.1059459, 0.8822982, 0.0117559]]\n",
            "1384          [[0.048652913, 0.9418475, 0.009499581]]\n",
            "1385       [[0.0010724803, 5.5360317e-05, 0.9988721]]\n",
            "1386        [[0.005571467, 0.00012433816, 0.9943041]]\n",
            "1387       [[0.00018055842, 0.0013525839, 0.9984668]]\n",
            "1388     [[0.00020907355, 0.00010604095, 0.99968493]]\n",
            "1389       [[0.0016802686, 0.00010825917, 0.9982115]]\n",
            "1390          [[0.0033764648, 0.6678627, 0.32876086]]\n",
            "1391     [[0.00063514354, 1.7030527e-05, 0.99934787]]\n",
            "1392         [[0.001085826, 0.0022613062, 0.9966529]]\n",
            "1393        [[0.0010778953, 7.525844e-06, 0.9989146]]\n",
            "1394      [[0.0026053912, 3.0874144e-05, 0.99736375]]\n",
            "1395           [[0.2820876, 0.60063064, 0.117281795]]\n",
            "1396          [[0.011516527, 0.96576935, 0.02271415]]\n",
            "1397           [[0.0034079226, 0.6520982, 0.3444939]]\n",
            "1398         [[0.00053567154, 0.00257734, 0.9968869]]\n",
            "1399          [[0.0029268716, 0.4467631, 0.55030996]]\n",
            "1400         [[0.0016164075, 0.28191617, 0.71646744]]\n",
            "1401        [[0.0008455085, 2.240371e-05, 0.9991321]]\n",
            "1402          [[0.00044224237, 0.8571314, 0.1424263]]\n",
            "1403       [[0.00055127766, 0.0003570283, 0.9990916]]\n",
            "1404        [[0.0003889904, 0.0002912873, 0.9993198]]\n",
            "1405        [[0.0012915605, 0.036445856, 0.96226263]]\n",
            "1406           [[0.13639693, 0.8301203, 0.033482797]]\n",
            "1407       [[0.00086667505, 0.99781895, 0.001314383]]\n",
            "1408          [[0.0007233318, 0.05157437, 0.9477022]]\n",
            "1409         [[0.0021966973, 0.16902818, 0.82877517]]\n",
            "1410        [[0.0011481502, 0.0061174817, 0.9927343]]\n",
            "1411        [[0.00090707175, 0.003589814, 0.9955031]]\n",
            "1412        [[0.0012207131, 0.022590978, 0.97618836]]\n",
            "1413      [[0.00023578183, 2.242658e-05, 0.99974185]]\n",
            "1414           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1415          [[0.001457192, 0.01277309, 0.98576975]]\n",
            "1416           [[0.0038983822, 0.1616542, 0.8344474]]\n",
            "1417        [[0.0056807566, 0.98805064, 0.006268673]]\n",
            "1418     [[0.00049861666, 0.00018103722, 0.99932027]]\n",
            "1419         [[0.005761568, 8.104354e-05, 0.9941573]]\n",
            "1420        [[0.0012151089, 8.011276e-05, 0.9987048]]\n",
            "1421        [[0.0004944133, 5.995126e-05, 0.9994456]]\n",
            "1422       [[0.00013268352, 0.0002612974, 0.9996061]]\n",
            "1423           [[0.004030758, 0.73966515, 0.2563041]]\n",
            "1424         [[0.028254727, 0.0050342544, 0.9667109]]\n",
            "1425          [[0.0011110241, 0.09769264, 0.9011963]]\n",
            "1426          [[0.0020992735, 0.17394713, 0.8239535]]\n",
            "1427          [[0.0014961518, 0.5160479, 0.48245597]]\n",
            "1428         [[0.0018143636, 0.40301424, 0.59517145]]\n",
            "1429          [[0.001041005, 0.056415215, 0.9425438]]\n",
            "1430        [[0.0005562659, 0.0013164383, 0.9981273]]\n",
            "1431      [[0.00046177546, 2.0531852e-05, 0.9995177]]\n",
            "1432        [[0.0029561578, 0.0006322675, 0.9964116]]\n",
            "1433           [[0.69894105, 0.17024398, 0.13081494]]\n",
            "1434            [[0.18726848, 0.29502258, 0.5177089]]\n",
            "1435       [[0.00093287346, 0.0038825881, 0.9951846]]\n",
            "1436         [[0.0025802527, 0.048424426, 0.9489953]]\n",
            "1437        [[0.00047350564, 0.03474009, 0.96478647]]\n",
            "1438          [[0.13975577, 0.032871835, 0.82737243]]\n",
            "1439          [[0.098724216, 0.81392515, 0.08735063]]\n",
            "1440         [[0.0014791475, 0.79929024, 0.19923058]]\n",
            "1441         [[0.0005556022, 0.9659106, 0.033533823]]\n",
            "1442          [[0.40792096, 0.53144944, 0.060629617]]\n",
            "1443         [[0.002423672, 0.94974065, 0.047835644]]\n",
            "1444       [[0.0027117496, 0.00052097527, 0.9967673]]\n",
            "1445          [[0.000733052, 0.74693054, 0.25233644]]\n",
            "1446      [[0.00050853094, 1.600596e-05, 0.99947554]]\n",
            "1447      [[0.0008976951, 8.2386636e-05, 0.99901986]]\n",
            "1448      [[0.0005002359, 4.3385196e-05, 0.99945635]]\n",
            "1449           [[0.8581224, 0.007052111, 0.13482557]]\n",
            "1450         [[0.0002327705, 0.9884467, 0.011320595]]\n",
            "1451        [[6.563342e-05, 0.9944463, 0.0054880604]]\n",
            "1452        [[0.00056489505, 0.19216293, 0.80727214]]\n",
            "1453       [[2.9396608e-05, 0.999143, 0.00082761305]]\n",
            "1454          [[0.0010372907, 0.39998448, 0.5989782]]\n",
            "1455      [[0.00023032252, 7.9493184e-05, 0.9996902]]\n",
            "1456          [[0.004276716, 0.07391505, 0.92180824]]\n",
            "1457           [[0.06037796, 0.021626968, 0.9179951]]\n",
            "1458          [[0.0013126998, 0.0769113, 0.92177606]]\n",
            "1459      [[0.0009146482, 0.00012756165, 0.99895775]]\n",
            "1460     [[0.00048563778, 6.6543864e-05, 0.99944776]]\n",
            "1461          [[0.002552787, 0.008162529, 0.9892847]]\n",
            "1462     [[0.00028293097, 7.6066586e-05, 0.99964106]]\n",
            "1463     [[0.00021854285, 0.00018729149, 0.99959415]]\n",
            "1464        [[0.00015555198, 0.037372734, 0.9624717]]\n",
            "1465         [[0.00085043855, 0.9531335, 0.04601608]]\n",
            "1466          [[0.0003770966, 0.38335928, 0.6162636]]\n",
            "1467        [[0.00046906548, 0.018886827, 0.9806442]]\n",
            "1468       [[0.00024110399, 0.0005911058, 0.9991678]]\n",
            "1469       [[0.0008608193, 2.6938456e-05, 0.9991123]]\n",
            "1470      [[0.0018988132, 2.7199696e-05, 0.99807394]]\n",
            "1471     [[0.00017720956, 0.00017434027, 0.99964845]]\n",
            "1472         [[0.0006352586, 0.01419254, 0.98517215]]\n",
            "1473      [[0.99889946, 0.0008855621, 0.00021489216]]\n",
            "1474           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1475        [[0.0007302596, 2.821066e-05, 0.9992415]]\n",
            "1476         [[0.002879762, 0.037609898, 0.95951027]]\n",
            "1477       [[0.00087923364, 2.78068e-05, 0.99909306]]\n",
            "1478          [[0.008272019, 0.58427995, 0.40744805]]\n",
            "1479       [[0.99744654, 0.00017306567, 0.002380425]]\n",
            "1480         [[9.060687e-05, 0.996784, 0.0031254345]]\n",
            "1481           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1482           [[0.7784832, 0.21277386, 0.008742907]]\n",
            "1483            [[0.83347553, 0.157976, 0.008548514]]\n",
            "1484       [[0.010282634, 6.4415995e-05, 0.98965293]]\n",
            "1485            [[0.773319, 0.18875428, 0.037926797]]\n",
            "1486        [[0.95772743, 0.038869083, 0.0034035156]]\n",
            "1487             [[0.456178, 0.30250993, 0.24131212]]\n",
            "1488        [[0.0038093466, 0.000708875, 0.99548185]]\n",
            "1489         [[0.88763267, 0.10482247, 0.0075448733]]\n",
            "1490             [[0.645315, 0.29148567, 0.06319933]]\n",
            "1491       [[0.0013782907, 3.7865942e-05, 0.9985839]]\n",
            "1492      [[0.0024801153, 0.00022808928, 0.99729174]]\n",
            "1493       [[0.0012222747, 1.669917e-05, 0.99876106]]\n",
            "1494      [[0.00044852396, 2.0672484e-05, 0.9995309]]\n",
            "1495          [[0.0012268181, 0.6801511, 0.31862208]]\n",
            "1496          [[0.0035728326, 0.6417577, 0.35466942]]\n",
            "1497             [[0.07305196, 0.3287838, 0.5981642]]\n",
            "1498         [[0.0008445205, 0.998135, 0.0010205162]]\n",
            "1499       [[0.0017085703, 0.0045700474, 0.99372137]]\n",
            "1500      [[0.0005086454, 2.6878728e-05, 0.99946445]]\n",
            "1501       [[0.0007747159, 2.4463245e-05, 0.9992009]]\n",
            "1502      [[0.00052930316, 9.0543595e-05, 0.9993801]]\n",
            "1503      [[0.00014685217, 0.0001498407, 0.99970335]]\n",
            "1504      [[0.00019512494, 4.749918e-05, 0.99975735]]\n",
            "1505      [[0.00051654334, 2.032559e-05, 0.99946314]]\n",
            "1506      [[0.0013014824, 1.2229946e-05, 0.99868625]]\n",
            "1507       [[0.0005155604, 0.00018115797, 0.9993032]]\n",
            "1508         [[0.0049178307, 0.65386456, 0.34121755]]\n",
            "1509        [[0.00043290015, 0.018996667, 0.9805705]]\n",
            "1510          [[0.0008063047, 0.02541605, 0.9737776]]\n",
            "1511        [[0.0015022926, 0.016675841, 0.98182195]]\n",
            "1512      [[0.00084444636, 3.4372802e-05, 0.9991211]]\n",
            "1513       [[0.0019527748, 0.0033456595, 0.99470156]]\n",
            "1514           [[0.002730303, 0.31259787, 0.6846718]]\n",
            "1515      [[0.00048605964, 0.0067718783, 0.99274206]]\n",
            "1516         [[0.029150182, 0.0029200346, 0.9679298]]\n",
            "1517        [[0.0008411666, 0.0007064261, 0.9984524]]\n",
            "1518      [[0.00051525934, 0.00010040518, 0.9993843]]\n",
            "1519        [[0.0026497783, 0.021706114, 0.97564405]]\n",
            "1520           [[0.8080155, 0.009845967, 0.18213853]]\n",
            "1521           [[0.019445822, 0.16179018, 0.8187641]]\n",
            "1522            [[0.20448187, 0.07925532, 0.7162628]]\n",
            "1523      [[0.0024493267, 0.000114044415, 0.9974367]]\n",
            "1524       [[0.0017733736, 0.0014812655, 0.99674535]]\n",
            "1525         [[0.019602906, 0.93005884, 0.050338235]]\n",
            "1526           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1527      [[0.00029002147, 3.1479805e-05, 0.9996785]]\n",
            "1528           [[0.012436113, 0.025616897, 0.961947]]\n",
            "1529            [[0.26946428, 0.07473897, 0.6557967]]\n",
            "1530            [[0.26946428, 0.07473897, 0.6557967]]\n",
            "1531        [[0.001847559, 0.0008671528, 0.99728525]]\n",
            "1532         [[0.0039486936, 0.005754772, 0.9902964]]\n",
            "1533       [[0.0007832251, 0.00017426685, 0.9990426]]\n",
            "1534         [[0.0008549222, 0.27346867, 0.72567636]]\n",
            "1535      [[0.00024700037, 0.00027339667, 0.9994796]]\n",
            "1536        [[0.97840387, 0.0006808394, 0.020915257]]\n",
            "1537       [[0.9951153, 0.00021777143, 0.0046669412]]\n",
            "1538        [[0.9929316, 0.00022527693, 0.006843179]]\n",
            "1539         [[0.003455564, 5.9387068e-05, 0.996485]]\n",
            "1540      [[0.0005350821, 5.4824708e-05, 0.99941015]]\n",
            "1541     [[0.00019432923, 2.0278905e-05, 0.99978536]]\n",
            "1542       [[0.00015359336, 0.00014743456, 0.999699]]\n",
            "1543      [[0.00035343147, 0.00025597986, 0.9993905]]\n",
            "1544      [[0.00040939575, 7.181023e-05, 0.99951875]]\n",
            "1545         [[0.00031745163, 0.05164909, 0.9480335]]\n",
            "1546      [[0.00028294142, 2.6777408e-05, 0.9996903]]\n",
            "1547        [[0.00026162094, 0.000138444, 0.9995999]]\n",
            "1548     [[0.00019796903, 1.1822099e-05, 0.99979025]]\n",
            "1549           [[0.009881881, 0.7704205, 0.21969756]]\n",
            "1550           [[0.007429325, 0.22306328, 0.7695074]]\n",
            "1551        [[0.0009028848, 4.635639e-05, 0.9990508]]\n",
            "1552       [[0.00037615385, 5.423966e-05, 0.9995696]]\n",
            "1553      [[0.0020240583, 1.9190025e-05, 0.99795675]]\n",
            "1554     [[0.00028289272, 1.9523843e-05, 0.99969757]]\n",
            "1555       [[0.00020454143, 5.334658e-05, 0.9997421]]\n",
            "1556         [[0.00021160643, 0.001356324, 0.998432]]\n",
            "1557      [[0.00021960055, 1.1087473e-05, 0.9997693]]\n",
            "1558        [[0.00081601716, 0.03760923, 0.96157473]]\n",
            "1559          [[0.0009982768, 0.17211391, 0.8268878]]\n",
            "1560        [[0.0014195291, 0.9945562, 0.0040242835]]\n",
            "1561         [[0.005373857, 0.98008907, 0.014537074]]\n",
            "1562        [[0.0013026985, 0.9925046, 0.0061927093]]\n",
            "1563          [[0.008265946, 0.006556479, 0.9851776]]\n",
            "1564           [[0.003995936, 0.16570765, 0.8302964]]\n",
            "1565       [[0.0003100556, 0.0004017583, 0.99928814]]\n",
            "1566          [[0.0015928018, 0.6682313, 0.33017588]]\n",
            "1567         [[0.008289133, 0.0013651418, 0.9903458]]\n",
            "1568        [[0.0001200872, 0.98852855, 0.011351293]]\n",
            "1569      [[5.2211453e-05, 0.99864656, 0.0013012912]]\n",
            "1570        [[0.000107928, 0.99427843, 0.0056135603]]\n",
            "1571          [[8.099535e-05, 0.958389, 0.041530054]]\n",
            "1572         [[0.0067914943, 0.024973722, 0.9682348]]\n",
            "1573          [[0.0015137279, 0.9049156, 0.09357075]]\n",
            "1574      [[0.0038055019, 0.00013750422, 0.99605703]]\n",
            "1575            [[0.6025113, 0.015544098, 0.3819447]]\n",
            "1576         [[0.006548034, 0.0024910532, 0.9909609]]\n",
            "1577          [[0.106585145, 0.048966244, 0.8444487]]\n",
            "1578      [[0.00072435604, 1.1241819e-05, 0.9992644]]\n",
            "1579           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1580        [[0.009399905, 0.0026953362, 0.98790467]]\n",
            "1581       [[6.6095956e-05, 0.010091096, 0.98984283]]\n",
            "1582         [[0.0025480534, 0.014801179, 0.9826508]]\n",
            "1583        [[0.00035596063, 0.97552854, 0.02411545]]\n",
            "1584          [[0.005832245, 0.42704532, 0.56712246]]\n",
            "1585            [[0.23176914, 0.09734428, 0.6708866]]\n",
            "1586         [[0.0073930873, 0.12665853, 0.86594844]]\n",
            "1587            [[0.013223318, 0.8609371, 0.1258396]]\n",
            "1588           [[0.01001672, 0.89989334, 0.09008991]]\n",
            "1589      [[0.00018484466, 0.00083207194, 0.9989831]]\n",
            "1590     [[0.00011756556, 0.00012950947, 0.99975294]]\n",
            "1591         [[0.00027659672, 0.27137813, 0.7283453]]\n",
            "1592            [[0.32075113, 0.30200848, 0.3772404]]\n",
            "1593           [[0.023701724, 0.7727774, 0.20352092]]\n",
            "1594        [[0.000993653, 0.00046481658, 0.9985415]]\n",
            "1595       [[0.00019323254, 0.0013387131, 0.9984681]]\n",
            "1596       [[0.00024037746, 0.030990902, 0.96876884]]\n",
            "1597      [[0.00010337021, 0.99638915, 0.0035074733]]\n",
            "1598        [[0.0003219472, 0.97543913, 0.024238871]]\n",
            "1599       [[0.0004992752, 0.99315333, 0.0063474244]]\n",
            "1600        [[0.0003286578, 0.9932007, 0.0064705857]]\n",
            "1601       [[3.7430527e-05, 0.9993362, 0.0006263137]]\n",
            "1602        [[0.0030230687, 0.00059606944, 0.996381]]\n",
            "1603        [[7.594172e-05, 0.99134946, 0.008574628]]\n",
            "1604      [[0.00023541665, 9.656373e-06, 0.99975497]]\n",
            "1605       [[0.0010575363, 0.00032806784, 0.9986143]]\n",
            "1606        [[0.0005780181, 0.0002517866, 0.9991702]]\n",
            "1607       [[0.0003722874, 0.0008666981, 0.99876106]]\n",
            "1608       [[0.98683965, 0.00033252995, 0.012827773]]\n",
            "1609            [[0.026857615, 0.4387773, 0.5343651]]\n",
            "1610         [[0.9503818, 0.0006713122, 0.048946865]]\n",
            "1611          [[0.0034803117, 0.9368344, 0.05968526]]\n",
            "1612             [[0.002854765, 0.9236482, 0.073497]]\n",
            "1613       [[0.0007547245, 2.865931e-05, 0.99921656]]\n",
            "1614      [[0.00048817386, 6.545191e-05, 0.99944645]]\n",
            "1615     [[0.00024917856, 0.00013464164, 0.99961615]]\n",
            "1616        [[0.00045377147, 0.05545028, 0.94409597]]\n",
            "1617        [[0.0006404199, 0.008605974, 0.99075365]]\n",
            "1618     [[0.00024917437, 3.3189965e-05, 0.99971765]]\n",
            "1619      [[0.0003030131, 5.7840767e-05, 0.99963915]]\n",
            "1620       [[0.021970617, 0.00038623906, 0.97764313]]\n",
            "1621          [[0.017142765, 0.14488363, 0.83797365]]\n",
            "1622      [[0.0022025951, 2.5760586e-05, 0.99777156]]\n",
            "1623      [[0.00072465284, 3.228598e-05, 0.99924314]]\n",
            "1624       [[0.0007391421, 2.9105186e-05, 0.9992318]]\n",
            "1625          [[0.001679327, 0.54515225, 0.45316842]]\n",
            "1626       [[0.0013509872, 7.802798e-05, 0.99857104]]\n",
            "1627         [[0.00037264734, 0.001456301, 0.998171]]\n",
            "1628        [[0.000813585, 0.00019749199, 0.9989889]]\n",
            "1629       [[0.00051028025, 4.728132e-05, 0.9994424]]\n",
            "1630      [[0.00033181597, 1.52078555e-05, 0.999653]]\n",
            "1631       [[0.0003415508, 0.00018801345, 0.9994704]]\n",
            "1632        [[0.0003472671, 0.0003809488, 0.9992718]]\n",
            "1633       [[8.460742e-05, 0.00010371183, 0.9998117]]\n",
            "1634          [[7.20091e-05, 0.020351166, 0.9795768]]\n",
            "1635       [[0.0035436184, 3.3663036e-05, 0.9964227]]\n",
            "1636      [[0.0012047573, 3.7253078e-05, 0.99875796]]\n",
            "1637           [[0.59475803, 0.32395476, 0.08128722]]\n",
            "1638         [[0.011568634, 0.86898124, 0.119450144]]\n",
            "1639        [[0.00022424718, 0.9833309, 0.016444834]]\n",
            "1640       [[0.011047208, 0.00075727486, 0.98819554]]\n",
            "1641      [[0.00019892932, 0.00017465727, 0.9996264]]\n",
            "1642      [[0.00011197828, 0.0010923211, 0.99879575]]\n",
            "1643      [[0.0061545805, 0.00045259538, 0.99339277]]\n",
            "1644          [[0.0066931853, 0.20094734, 0.7923595]]\n",
            "1645            [[0.018134868, 0.3151585, 0.6667066]]\n",
            "1646        [[0.0002460357, 0.00022700893, 0.999527]]\n",
            "1647           [[0.01487436, 0.66463625, 0.32048938]]\n",
            "1648          [[0.0014831321, 0.29866368, 0.6998532]]\n",
            "1649       [[0.00039167167, 0.0062041446, 0.9934042]]\n",
            "1650        [[0.0006970074, 0.0071292114, 0.9921738]]\n",
            "1651       [[4.5557477e-05, 0.99537826, 0.004576162]]\n",
            "1652        [[6.053957e-05, 0.9966545, 0.0032849694]]\n",
            "1653      [[0.0005921014, 2.5011534e-05, 0.99938285]]\n",
            "1654        [[0.0004903718, 0.0025349963, 0.9969746]]\n",
            "1655           [[0.019596586, 0.11590594, 0.8644975]]\n",
            "1656          [[0.00122392, 0.0001196533, 0.9986564]]\n",
            "1657        [[0.0035913417, 0.011604094, 0.98480463]]\n",
            "1658         [[0.0012382929, 0.01691906, 0.98184264]]\n",
            "1659      [[0.0008581732, 0.00017176513, 0.99897015]]\n",
            "1660     [[0.00035437904, 3.1565673e-05, 0.99961406]]\n",
            "1661        [[0.0013630406, 0.0062387385, 0.9923982]]\n",
            "1662          [[0.0015052607, 0.2602389, 0.73825586]]\n",
            "1663         [[0.0007420661, 0.089669585, 0.9095883]]\n",
            "1664        [[0.00030580434, 0.91050726, 0.08918697]]\n",
            "1665       [[0.0009816443, 2.4234105e-05, 0.9989942]]\n",
            "1666       [[0.0006148601, 0.00022961898, 0.9991555]]\n",
            "1667     [[0.00035208778, 0.00029089642, 0.99935704]]\n",
            "1668       [[0.0025259366, 0.00016882517, 0.9973053]]\n",
            "1669          [[0.0052570854, 0.8590949, 0.13564807]]\n",
            "1670      [[0.00093284453, 5.895756e-05, 0.99900824]]\n",
            "1671       [[0.0012350456, 0.00018039795, 0.9985846]]\n",
            "1672          [[0.0022460667, 0.0309479, 0.96680605]]\n",
            "1673          [[0.00052864425, 0.7768357, 0.2226357]]\n",
            "1674           [[0.00088559376, 0.1538504, 0.845264]]\n",
            "1675            [[0.5971808, 0.24144512, 0.16137405]]\n",
            "1676         [[0.0026224256, 0.80008227, 0.19729534]]\n",
            "1677         [[0.0010564118, 0.005351406, 0.9935922]]\n",
            "1678       [[0.00015670163, 0.9988397, 0.0010036172]]\n",
            "1679      [[5.9915776e-05, 0.99934477, 0.0005952488]]\n",
            "1680      [[0.0002221425, 7.9228805e-05, 0.99969864]]\n",
            "1681         [[0.0013680331, 0.085045084, 0.9135869]]\n",
            "1682      [[0.0004854355, 0.00025681363, 0.99925774]]\n",
            "1683       [[0.00023064454, 6.400726e-05, 0.9997054]]\n",
            "1684        [[0.00083941006, 1.454924e-05, 0.999146]]\n",
            "1685           [[0.7013771, 0.26486427, 0.033758674]]\n",
            "1686           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1687      [[0.0006664958, 0.00017770153, 0.99915576]]\n",
            "1688      [[0.0021881668, 0.00081626634, 0.99699557]]\n",
            "1689         [[0.008188866, 0.001349384, 0.99046177]]\n",
            "1690        [[0.000931585, 2.8094457e-05, 0.9990403]]\n",
            "1691           [[0.016388165, 0.3644214, 0.61919045]]\n",
            "1692           [[0.12761836, 0.09747391, 0.77490777]]\n",
            "1693         [[0.0005978577, 0.0028362663, 0.996566]]\n",
            "1694             [[0.0646935, 0.880829, 0.054477546]]\n",
            "1695       [[0.0005024236, 0.0013122087, 0.99818534]]\n",
            "1696      [[0.00033060726, 7.525964e-05, 0.99959415]]\n",
            "1697        [[0.0010857009, 0.0008149268, 0.9980994]]\n",
            "1698         [[0.0012015987, 0.15306424, 0.84573424]]\n",
            "1699      [[0.0003676116, 1.2549782e-05, 0.99961984]]\n",
            "1700           [[0.00110582, 0.037539378, 0.9613548]]\n",
            "1701        [[0.0013756845, 0.0065474664, 0.9920769]]\n",
            "1702        [[0.0001455649, 0.9986218, 0.0012325783]]\n",
            "1703       [[6.8569534e-05, 0.99742126, 0.002510176]]\n",
            "1704         [[0.0013739398, 0.96525407, 0.03337204]]\n",
            "1705      [[0.00031403542, 3.0321018e-05, 0.9996557]]\n",
            "1706          [[0.002273757, 0.07484826, 0.92287797]]\n",
            "1707      [[0.00074288243, 0.0011040446, 0.99815303]]\n",
            "1708        [[0.00032026743, 0.9817409, 0.017938854]]\n",
            "1709           [[0.15884596, 0.48384687, 0.35730714]]\n",
            "1710            [[0.03847904, 0.8599356, 0.10158532]]\n",
            "1711           [[0.6418756, 0.085520186, 0.27260423]]\n",
            "1712            [[0.008697411, 0.71107554, 0.280227]]\n",
            "1713        [[0.0006092887, 0.016123435, 0.98326725]]\n",
            "1714           [[0.002727309, 0.49901655, 0.4982561]]\n",
            "1715          [[0.90152323, 0.013881158, 0.08459557]]\n",
            "1716     [[0.00029933982, 5.7720365e-05, 0.99964297]]\n",
            "1717          [[0.51647955, 0.010307779, 0.47321263]]\n",
            "1718           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1719       [[0.0022797373, 0.0052550524, 0.99246526]]\n",
            "1720      [[0.99812406, 0.00046452592, 0.0014114565]]\n",
            "1721          [[0.0015265159, 0.15865016, 0.8398233]]\n",
            "1722        [[0.00088902144, 0.90088016, 0.09823084]]\n",
            "1723         [[0.0070379227, 0.017852543, 0.9751095]]\n",
            "1724         [[0.0007633932, 0.85587597, 0.14336066]]\n",
            "1725       [[0.00066660607, 3.937872e-05, 0.9992939]]\n",
            "1726         [[0.008971562, 0.025878754, 0.96514976]]\n",
            "1727       [[0.0011933527, 2.0027555e-05, 0.9987866]]\n",
            "1728            [[0.9315323, 0.0146904, 0.053777263]]\n",
            "1729          [[0.9715674, 0.012934214, 0.015498413]]\n",
            "1730     [[0.00029675665, 8.2224695e-05, 0.99962103]]\n",
            "1731       [[0.0002931041, 3.2711643e-05, 0.9996742]]\n",
            "1732         [[0.004106465, 4.035284e-05, 0.9958532]]\n",
            "1733        [[0.001874815, 0.0037226842, 0.99440247]]\n",
            "1734         [[0.0016108791, 0.0015220837, 0.996867]]\n",
            "1735          [[0.022179253, 0.42086053, 0.55696017]]\n",
            "1736         [[0.0004940102, 0.009937044, 0.9895689]]\n",
            "1737     [[0.00031139408, 1.1685172e-05, 0.99967694]]\n",
            "1738      [[0.0006151174, 1.0473098e-05, 0.99937445]]\n",
            "1739         [[0.0052330093, 0.010308713, 0.9844582]]\n",
            "1740        [[0.00022042822, 0.70652866, 0.29325092]]\n",
            "1741           [[0.060425695, 0.21447909, 0.7250952]]\n",
            "1742            [[0.0112126265, 0.778023, 0.2107644]]\n",
            "1743          [[0.018921744, 0.60724044, 0.37383774]]\n",
            "1744       [[6.737856e-05, 7.870766e-05, 0.99985397]]\n",
            "1745      [[0.00089562725, 3.2772023e-05, 0.9990716]]\n",
            "1746       [[0.0004816355, 1.0535388e-05, 0.9995079]]\n",
            "1747      [[0.00047105498, 2.7156488e-05, 0.9995018]]\n",
            "1748          [[0.012203701, 0.107133634, 0.8806627]]\n",
            "1749            [[0.03462098, 0.1302895, 0.83508956]]\n",
            "1750          [[0.016355729, 0.07456529, 0.90907896]]\n",
            "1751        [[0.0008401851, 0.0029321415, 0.9962276]]\n",
            "1752           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1753        [[0.0038187136, 0.018457646, 0.97772354]]\n",
            "1754       [[0.0033676464, 0.99543226, 0.0012001726]]\n",
            "1755           [[0.2712945, 0.7251003, 0.0036052226]]\n",
            "1756         [[0.007243842, 0.0024920655, 0.9902642]]\n",
            "1757            [[0.0194913, 0.036611885, 0.9438969]]\n",
            "1758           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1759         [[0.0004884534, 0.84272087, 0.15679064]]\n",
            "1760        [[0.00044100743, 0.8854569, 0.114102036]]\n",
            "1761       [[0.00023886688, 0.003077029, 0.99668413]]\n",
            "1762          [[0.0055615203, 0.01671769, 0.9777207]]\n",
            "1763          [[0.020914037, 0.03354687, 0.94553906]]\n",
            "1764      [[0.00052596914, 0.00036043886, 0.9991136]]\n",
            "1765         [[0.0058520464, 0.75973487, 0.23441309]]\n",
            "1766       [[0.00023816217, 0.037814256, 0.96194756]]\n",
            "1767         [[0.0019816747, 0.73543274, 0.26258555]]\n",
            "1768      [[0.0008957568, 0.00011439871, 0.99898976]]\n",
            "1769      [[0.00016273679, 0.0002902301, 0.99954695]]\n",
            "1770        [[0.00010198669, 0.004586743, 0.9953112]]\n",
            "1771       [[5.041879e-05, 0.99853885, 0.0014107066]]\n",
            "1772          [[0.0006360519, 0.11458431, 0.8847797]]\n",
            "1773      [[0.99894184, 9.539243e-05, 0.00096273463]]\n",
            "1774          [[0.0051068286, 0.21144389, 0.7834493]]\n",
            "1775      [[0.0008060921, 0.00072501914, 0.99846894]]\n",
            "1776      [[0.00030924473, 0.0072141364, 0.99247664]]\n",
            "1777        [[0.00043694963, 0.000465505, 0.9990976]]\n",
            "1778     [[0.00015821177, 0.00078994996, 0.99905187]]\n",
            "1779        [[0.0013934504, 0.026830532, 0.97177595]]\n",
            "1780          [[0.0019008967, 0.8964697, 0.10162935]]\n",
            "1781          [[0.006625169, 0.75105226, 0.24232255]]\n",
            "1782       [[0.0013159335, 3.6674995e-05, 0.9986474]]\n",
            "1783      [[0.0005287801, 4.5064593e-05, 0.99942625]]\n",
            "1784          [[0.0015871864, 0.60783166, 0.3905812]]\n",
            "1785          [[0.0016016788, 0.7374812, 0.26091716]]\n",
            "1786      [[0.00010963567, 0.00079259946, 0.9990977]]\n",
            "1787       [[0.00033338278, 0.062086005, 0.93758065]]\n",
            "1788      [[0.00031444032, 0.0003242584, 0.99936134]]\n",
            "1789       [[0.00013997336, 0.0005014453, 0.9993586]]\n",
            "1790      [[7.237148e-05, 0.00050089305, 0.99942684]]\n",
            "1791       [[0.0003519879, 0.0050116745, 0.99463624]]\n",
            "1792         [[0.0012400706, 0.20101932, 0.79774064]]\n",
            "1793        [[0.00027607792, 0.9811808, 0.018543145]]\n",
            "1794        [[0.00057137967, 0.21439894, 0.78502965]]\n",
            "1795          [[0.0061769956, 0.20623948, 0.7875835]]\n",
            "1796        [[0.0013633322, 0.96528107, 0.033355664]]\n",
            "1797      [[0.00034164474, 0.00030388046, 0.9993544]]\n",
            "1798         [[0.0004893557, 0.18189049, 0.81762016]]\n",
            "1799          [[0.0013417512, 0.13132259, 0.8673356]]\n",
            "1800       [[0.0001279932, 6.4696185e-05, 0.9998073]]\n",
            "1801       [[0.0012089236, 2.3146331e-05, 0.9987679]]\n",
            "1802            [[0.00805939, 0.17402345, 0.8179171]]\n",
            "1803        [[0.00030889738, 0.008667599, 0.9910234]]\n",
            "1804           [[0.0013432358, 0.5954622, 0.4031946]]\n",
            "1805         [[9.91792e-05, 0.022117129, 0.97778374]]\n",
            "1806         [[0.00033109143, 0.09896621, 0.9007027]]\n",
            "1807         [[0.00031816965, 0.19426873, 0.8054131]]\n",
            "1808          [[0.0007591267, 0.00991414, 0.9893267]]\n",
            "1809       [[0.001464066, 0.00034427742, 0.99819165]]\n",
            "1810       [[0.0006425315, 0.00027730875, 0.9990802]]\n",
            "1811          [[0.037069965, 0.9502171, 0.012712952]]\n",
            "1812       [[0.0020262587, 0.0015410673, 0.99643266]]\n",
            "1813        [[0.002553556, 4.999255e-05, 0.99739647]]\n",
            "1814        [[0.0020033082, 0.029259644, 0.96873707]]\n",
            "1815           [[0.11234724, 0.020953052, 0.8666997]]\n",
            "1816         [[0.0007199909, 0.00022010876, 0.99906]]\n",
            "1817       [[0.0021140592, 0.00020460591, 0.9976814]]\n",
            "1818          [[0.924797, 0.0027964253, 0.072406486]]\n",
            "1819            [[0.8539199, 0.08975452, 0.05632551]]\n",
            "1820       [[0.0037750874, 0.0015609602, 0.99466383]]\n",
            "1821           [[0.08178908, 0.107539795, 0.8106711]]\n",
            "1822         [[0.026257824, 0.0035125352, 0.9702297]]\n",
            "1823          [[0.0057776663, 0.26959106, 0.7246313]]\n",
            "1824       [[0.97293323, 0.00035602704, 0.026710654]]\n",
            "1825     [[0.00022762932, 0.00062585116, 0.99914646]]\n",
            "1826           [[0.008286242, 0.18158944, 0.8101242]]\n",
            "1827          [[0.004631002, 0.047670785, 0.9476982]]\n",
            "1828          [[0.0010454067, 0.9591688, 0.03978584]]\n",
            "1829        [[0.37424096, 0.00011527272, 0.62564373]]\n",
            "1830         [[0.0011030344, 0.9368213, 0.062075667]]\n",
            "1831       [[0.0002944276, 2.348863e-05, 0.99968207]]\n",
            "1832       [[0.0022304861, 0.0013894277, 0.99638003]]\n",
            "1833        [[0.0051339124, 0.014489347, 0.98037684]]\n",
            "1834          [[0.004785338, 0.68483484, 0.31037977]]\n",
            "1835       [[0.005524756, 4.2017895e-05, 0.99443334]]\n",
            "1836        [[0.057955295, 0.0044331094, 0.93761164]]\n",
            "1837       [[0.0056672404, 0.00012696043, 0.9942059]]\n",
            "1838       [[0.0027475648, 0.00057563506, 0.9966768]]\n",
            "1839          [[0.9482102, 0.04874854, 0.0030412239]]\n",
            "1840         [[0.00096905726, 0.0046910583, 0.99434]]\n",
            "1841          [[0.0021271687, 0.01416369, 0.9837092]]\n",
            "1842       [[0.00079197297, 0.0005781731, 0.9986298]]\n",
            "1843       [[0.0004488703, 5.0870338e-05, 0.9995003]]\n",
            "1844     [[0.0009161359, 0.000112956106, 0.99897087]]\n",
            "1845      [[0.0012740227, 8.0098165e-05, 0.99864584]]\n",
            "1846         [[0.0012454502, 0.001763724, 0.9969908]]\n",
            "1847        [[0.0028753178, 0.0036892532, 0.9934355]]\n",
            "1848        [[0.003409469, 0.0087446375, 0.98784584]]\n",
            "1849           [[0.002364008, 0.18197116, 0.8156648]]\n",
            "1850          [[0.020872554, 0.007833346, 0.9712941]]\n",
            "1851        [[0.0034138986, 0.0005732505, 0.9960129]]\n",
            "1852       [[0.0006772219, 9.016197e-05, 0.99923265]]\n",
            "1853       [[0.0015592434, 9.000409e-05, 0.99835086]]\n",
            "1854          [[0.0028382004, 0.9027597, 0.09440214]]\n",
            "1855            [[0.3198491, 0.67686546, 0.00328541]]\n",
            "1856        [[0.9875711, 0.00015408578, 0.012274761]]\n",
            "1857        [[0.0005838315, 5.916658e-05, 0.9993569]]\n",
            "1858     [[0.00014869394, 2.0852256e-05, 0.99983037]]\n",
            "1859        [[0.0002656202, 0.0004959465, 0.9992385]]\n",
            "1860       [[0.00028915907, 3.76485e-05, 0.99967325]]\n",
            "1861      [[0.0013570772, 0.00059434917, 0.99804854]]\n",
            "1862          [[0.00078254, 0.0014103658, 0.9978071]]\n",
            "1863        [[0.0003450348, 9.414626e-05, 0.9995608]]\n",
            "1864     [[0.00021322208, 3.2624095e-05, 0.99975413]]\n",
            "1865      [[0.0007453235, 0.00058290374, 0.99867177]]\n",
            "1866         [[0.0011870862, 0.000269228, 0.9985436]]\n",
            "1867         [[0.000410728, 0.0033535196, 0.9962358]]\n",
            "1868           [[0.003468238, 0.31689996, 0.6796318]]\n",
            "1869           [[0.002542758, 0.4871026, 0.51035464]]\n",
            "1870           [[0.001471405, 0.7938177, 0.20471092]]\n",
            "1871       [[0.0076238196, 0.00049272884, 0.9918834]]\n",
            "1872         [[0.0006809373, 0.07642624, 0.92289287]]\n",
            "1873       [[0.0005806644, 0.0026497012, 0.99676967]]\n",
            "1874      [[0.00029639245, 6.8990594e-05, 0.9996346]]\n",
            "1875         [[0.001937433, 0.021440415, 0.97662216]]\n",
            "1876           [[0.00078269, 0.34040618, 0.65881115]]\n",
            "1877      [[0.00028243058, 3.2786633e-05, 0.9996848]]\n",
            "1878        [[0.0003828779, 0.00031217068, 0.999305]]\n",
            "1879       [[0.00028967898, 0.0028498196, 0.9968605]]\n",
            "1880         [[0.0052010333, 0.58657426, 0.40822467]]\n",
            "1881        [[0.0010570547, 0.0041277045, 0.9948153]]\n",
            "1882      [[0.00029045506, 0.0016774939, 0.99803203]]\n",
            "1883       [[0.0009487805, 0.0009564458, 0.99809474]]\n",
            "1884        [[0.0005077374, 0.0005184948, 0.9989737]]\n",
            "1885      [[0.0037007125, 0.00016952946, 0.99612975]]\n",
            "1886          [[0.21408209, 0.67284167, 0.113076255]]\n",
            "1887         [[0.008260064, 0.92534626, 0.066393636]]\n",
            "1888           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1889        [[0.9966078, 0.0012981367, 0.0020940765]]\n",
            "1890          [[0.80344355, 0.07990658, 0.116649814]]\n",
            "1891            [[0.10179952, 0.20155318, 0.6966473]]\n",
            "1892          [[0.0072780866, 0.4887539, 0.50396794]]\n",
            "1893       [[0.0036953865, 0.00043042543, 0.9958741]]\n",
            "1894       [[0.00021881108, 0.0017176311, 0.9980636]]\n",
            "1895           [[0.003001203, 0.09966636, 0.8973325]]\n",
            "1896        [[0.0010958166, 0.035353124, 0.96355104]]\n",
            "1897        [[0.00083632965, 0.67439395, 0.32476968]]\n",
            "1898            [[0.5347491, 0.43351677, 0.03173417]]\n",
            "1899          [[0.008210505, 0.9868776, 0.004911891]]\n",
            "1900           [[0.0039550294, 0.9471446, 0.0489004]]\n",
            "1901           [[0.020861493, 0.7059433, 0.27319524]]\n",
            "1902      [[0.00038661787, 0.0001015123, 0.99951184]]\n",
            "1903       [[0.004379599, 0.00029549256, 0.99532497]]\n",
            "1904        [[0.99195623, 0.0003253346, 0.007718455]]\n",
            "1905       [[0.9926623, 8.7775414e-05, 0.0072498396]]\n",
            "1906          [[0.09174476, 0.89216805, 0.016087268]]\n",
            "1907       [[0.0001571876, 0.00018666418, 0.9996562]]\n",
            "1908      [[0.00041087967, 2.1442087e-05, 0.9995677]]\n",
            "1909         [[0.004560641, 0.0010520121, 0.9943873]]\n",
            "1910      [[0.00065893563, 1.0238915e-05, 0.9993309]]\n",
            "1911       [[0.00038729075, 0.0049762493, 0.9946365]]\n",
            "1912           [[0.001274324, 0.5198352, 0.47889048]]\n",
            "1913        [[0.0007207251, 5.90005e-05, 0.99922025]]\n",
            "1914     [[0.00041760496, 2.3568055e-05, 0.99955875]]\n",
            "1915    [[0.00035454967, 1.50677415e-05, 0.99963045]]\n",
            "1916     [[0.00094660185, 0.00010647971, 0.99894696]]\n",
            "1917       [[0.0013800423, 0.00073409063, 0.9978859]]\n",
            "1918         [[0.0012196096, 0.07560209, 0.92317826]]\n",
            "1919     [[0.00064205844, 1.0201154e-05, 0.99934775]]\n",
            "1920          [[0.0015383472, 0.04199933, 0.9564623]]\n",
            "1921             [[0.20445497, 0.5539681, 0.2415769]]\n",
            "1922          [[0.004134763, 0.057998303, 0.9378669]]\n",
            "1923       [[0.00018632387, 0.0025650645, 0.9972486]]\n",
            "1924      [[4.8741593e-05, 0.00014940224, 0.9998018]]\n",
            "1925      [[0.0012492178, 5.5782544e-05, 0.99869496]]\n",
            "1926       [[0.0004526826, 4.1180505e-05, 0.9995061]]\n",
            "1927     [[0.00028879012, 0.00024742293, 0.99946374]]\n",
            "1928       [[0.000107219734, 0.008224901, 0.9916679]]\n",
            "1929       [[0.00011310529, 0.0003433857, 0.9995435]]\n",
            "1930      [[0.0013989215, 0.00011362354, 0.99848735]]\n",
            "1931      [[0.00020955759, 0.00015701905, 0.9996333]]\n",
            "1932      [[8.9573994e-05, 0.00039425565, 0.9995161]]\n",
            "1933          [[0.85955757, 0.062343463, 0.07809895]]\n",
            "1934        [[0.99435294, 0.002252594, 0.0033945334]]\n",
            "1935          [[0.07160368, 0.91059524, 0.017801069]]\n",
            "1936         [[0.0003641715, 0.9855135, 0.014122344]]\n",
            "1937     [[0.00059765216, 2.9723302e-05, 0.99937266]]\n",
            "1938         [[0.00015842494, 0.10553322, 0.8943084]]\n",
            "1939           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "1940      [[0.0001813498, 0.00035746724, 0.99946123]]\n",
            "1941             [[0.5522992, 0.2051276, 0.24257317]]\n",
            "1942     [[0.00016735784, 0.00028245777, 0.99955016]]\n",
            "1943        [[0.00016500981, 0.00790144, 0.99193364]]\n",
            "1944      [[0.00067012955, 8.0363956e-05, 0.9992494]]\n",
            "1945       [[0.009573511, 0.00026694458, 0.99015945]]\n",
            "1946        [[0.002080508, 2.4368426e-05, 0.9978951]]\n",
            "1947       [[0.0005288367, 0.0010394466, 0.99843174]]\n",
            "1948          [[0.016633254, 0.011002222, 0.9723646]]\n",
            "1949          [[0.0011731043, 0.8317699, 0.16705701]]\n",
            "1950       [[0.0027300653, 0.0029327532, 0.99433714]]\n",
            "1951        [[0.0009197398, 0.0017898346, 0.9972905]]\n",
            "1952        [[0.003544289, 0.0015699401, 0.99488586]]\n",
            "1953      [[0.0011342409, 2.5625093e-05, 0.99884015]]\n",
            "1954       [[0.0008869524, 0.00013652774, 0.9989766]]\n",
            "1955      [[5.5978428e-05, 6.5730135e-05, 0.9998783]]\n",
            "1956      [[5.4478693e-05, 0.0006544314, 0.99929106]]\n",
            "1957          [[0.0011617253, 0.7512105, 0.24762776]]\n",
            "1958         [[0.00039475894, 0.9021627, 0.09744255]]\n",
            "1959           [[0.005021642, 0.9823454, 0.01263294]]\n",
            "1960        [[0.0003305604, 0.9995821, 8.733997e-05]]\n",
            "1961       [[3.2098684e-05, 0.9988594, 0.0011085161]]\n",
            "1962        [[9.5961484e-05, 0.9766733, 0.023230774]]\n",
            "1963        [[0.00022465407, 0.002245454, 0.9975299]]\n",
            "1964       [[0.0008056672, 7.373357e-05, 0.99912065]]\n",
            "1965       [[0.0008056672, 7.373357e-05, 0.99912065]]\n",
            "1966      [[0.00043956377, 0.0013840739, 0.99817634]]\n",
            "1967         [[0.00018585444, 0.04384866, 0.9559654]]\n",
            "1968         [[0.00031520214, 0.5878262, 0.41185856]]\n",
            "1969           [[0.15819597, 0.70430547, 0.13749856]]\n",
            "1970           [[0.0010456865, 0.927085, 0.07186931]]\n",
            "1971       [[0.0006421702, 0.0001177772, 0.99924004]]\n",
            "1972       [[0.0004860945, 0.00015029372, 0.9993636]]\n",
            "1973       [[0.0011530009, 0.0064026015, 0.99244434]]\n",
            "1974       [[0.0007170704, 0.0015026169, 0.99778026]]\n",
            "1975         [[0.0014002981, 0.013892843, 0.9847068]]\n",
            "1976       [[0.00061894296, 0.00012900142, 0.999252]]\n",
            "1977         [[0.0043084123, 0.11503536, 0.88065624]]\n",
            "1978          [[0.00964537, 0.017664688, 0.97268987]]\n",
            "1979          [[0.005011123, 0.056339037, 0.9386498]]\n",
            "1980        [[0.005036151, 0.00028201108, 0.9946819]]\n",
            "1981           [[0.0018242621, 0.023155784, 0.97502]]\n",
            "1982      [[0.00021912955, 0.00021598134, 0.9995648]]\n",
            "1983      [[0.00043001177, 5.9508213e-05, 0.9995105]]\n",
            "1984       [[0.0005010714, 1.6707276e-05, 0.9994823]]\n",
            "1985      [[0.0012570688, 1.9418681e-05, 0.99872345]]\n",
            "1986       [[0.0043805777, 0.0025540183, 0.99306536]]\n",
            "1987           [[0.002545409, 0.05034033, 0.9471142]]\n",
            "1988          [[0.0059228595, 0.15668799, 0.8373891]]\n",
            "1989           [[0.0365942, 0.060062006, 0.90334386]]\n",
            "1990         [[0.0010256892, 0.009452873, 0.9895215]]\n",
            "1991          [[0.0018166896, 0.35909995, 0.6390833]]\n",
            "1992          [[0.0007283471, 0.08198181, 0.9172898]]\n",
            "1993         [[0.0010943835, 0.00029237, 0.99861324]]\n",
            "1994       [[0.00086222764, 0.0070320573, 0.9921057]]\n",
            "1995        [[0.00016850304, 0.34275907, 0.65707237]]\n",
            "1996          [[6.96679e-05, 0.9539198, 0.046010524]]\n",
            "1997         [[0.0011528911, 0.71630704, 0.28254008]]\n",
            "1998      [[0.00055277185, 0.99363106, 0.0058161276]]\n",
            "1999         [[0.00051578274, 0.7786167, 0.22086743]]\n",
            "2000         [[0.0009409886, 0.44470102, 0.55435795]]\n",
            "2001           [[0.004135369, 0.12758419, 0.8682804]]\n",
            "2002       [[0.00016440816, 0.99127144, 0.008564176]]\n",
            "2003        [[0.0001275406, 0.9981225, 0.0017499069]]\n",
            "2004        [[0.00055868324, 0.9822291, 0.017212218]]\n",
            "2005       [[0.00014874418, 0.9940234, 0.0058279173]]\n",
            "2006       [[7.2434144e-05, 0.9966329, 0.0032947038]]\n",
            "2007         [[0.0015884452, 0.010497125, 0.9879144]]\n",
            "2008        [[0.0010657951, 0.87726325, 0.121670984]]\n",
            "2009         [[0.0055429093, 0.013735411, 0.9807217]]\n",
            "2010          [[0.97614384, 0.00512055, 0.018735623]]\n",
            "2011       [[0.000117611344, 0.06690475, 0.93297774]]\n",
            "2012      [[0.00038785502, 0.0001871161, 0.99942505]]\n",
            "2013      [[0.00044101622, 0.0004081784, 0.99915075]]\n",
            "2014       [[0.0028410265, 6.302203e-05, 0.99709594]]\n",
            "2015           [[0.3603948, 0.008460949, 0.63114434]]\n",
            "2016       [[0.0017744853, 2.7906095e-05, 0.9981976]]\n",
            "2017        [[0.00043755773, 0.9803801, 0.019182289]]\n",
            "2018             [[0.3096319, 0.03884416, 0.6515239]]\n",
            "2019          [[0.0088132825, 0.7912934, 0.19989334]]\n",
            "2020     [[0.00063000765, 0.00041719322, 0.99895287]]\n",
            "2021        [[0.00065855915, 0.021427516, 0.9779139]]\n",
            "2022          [[0.029516798, 0.02003262, 0.95045066]]\n",
            "2023       [[0.0007057563, 5.040004e-05, 0.99924386]]\n",
            "2024         [[0.00060288055, 0.008655042, 0.990742]]\n",
            "2025        [[0.0004055352, 3.615823e-05, 0.9995584]]\n",
            "2026       [[0.00068661105, 7.668883e-05, 0.9992367]]\n",
            "2027       [[0.00051065633, 0.003146589, 0.99634284]]\n",
            "2028       [[0.00060301746, 0.0006413287, 0.9987556]]\n",
            "2029         [[0.0003161312, 0.45287356, 0.54681027]]\n",
            "2030         [[0.002780205, 6.437725e-05, 0.9971553]]\n",
            "2031          [[0.0045145927, 0.007299477, 0.988186]]\n",
            "2032           [[0.0031906874, 0.25684026, 0.739969]]\n",
            "2033         [[0.0010908624, 0.040283523, 0.9586256]]\n",
            "2034        [[0.0008516722, 5.875047e-05, 0.9990896]]\n",
            "2035        [[8.459447e-05, 0.99661165, 0.003303719]]\n",
            "2036       [[0.00013539463, 0.9990852, 0.0007794032]]\n",
            "2037        [[0.0006125333, 0.9965161, 0.0028713061]]\n",
            "2038      [[6.0877548e-05, 0.99924576, 0.0006933768]]\n",
            "2039       [[5.7040532e-05, 0.9993518, 0.0005911718]]\n",
            "2040       [[0.0044228267, 0.98799324, 0.0075839134]]\n",
            "2041        [[0.0033051046, 4.460549e-05, 0.9966504]]\n",
            "2042      [[0.00024374503, 3.5120396e-05, 0.9997211]]\n",
            "2043       [[0.0002890427, 3.8710834e-05, 0.9996723]]\n",
            "2044          [[0.0023087126, 0.38514882, 0.6125425]]\n",
            "2045             [[0.001346607, 0.76201344, 0.23664]]\n",
            "2046         [[0.00068873627, 0.8775146, 0.12179666]]\n",
            "2047         [[0.0012015433, 0.9041615, 0.094636895]]\n",
            "2048         [[0.9803255, 0.0030180041, 0.016656538]]\n",
            "2049         [[0.9760768, 0.0053484594, 0.018574685]]\n",
            "2050         [[0.0117973685, 0.006707373, 0.9814953]]\n",
            "2051        [[0.0010175196, 0.0063507166, 0.9926318]]\n",
            "2052          [[0.0002518704, 0.00026064, 0.9994874]]\n",
            "2053           [[0.0003893416, 0.0096415, 0.9899692]]\n",
            "2054       [[0.00039811776, 0.97576594, 0.023835994]]\n",
            "2055     [[0.00035917977, 1.0937949e-05, 0.99962986]]\n",
            "2056     [[0.00010504536, 5.2243995e-05, 0.99984276]]\n",
            "2057        [[0.0004063218, 0.0001049709, 0.9994887]]\n",
            "2058      [[0.00050163275, 0.00021478895, 0.9992836]]\n",
            "2059     [[0.00012453277, 0.00049205404, 0.99938345]]\n",
            "2060        [[0.0001028542, 3.677831e-05, 0.9998603]]\n",
            "2061     [[0.00031721237, 2.2571463e-05, 0.99966025]]\n",
            "2062       [[0.0016592582, 0.0035868268, 0.99475396]]\n",
            "2063       [[0.0017377154, 0.0025735733, 0.99568874]]\n",
            "2064      [[0.00039641862, 7.5090815e-05, 0.9995285]]\n",
            "2065        [[0.0023586652, 3.061121e-05, 0.9976108]]\n",
            "2066           [[0.26954186, 0.69739634, 0.03306185]]\n",
            "2067         [[0.98374104, 0.008631255, 0.007627621]]\n",
            "2068       [[0.0020034863, 1.611622e-05, 0.99798054]]\n",
            "2069        [[0.000352143, 4.5505392e-05, 0.9996024]]\n",
            "2070        [[0.0008675843, 0.006697714, 0.99243474]]\n",
            "2071      [[0.99918693, 0.0005323249, 0.00028072103]]\n",
            "2072        [[0.0003172916, 6.551798e-05, 0.9996171]]\n",
            "2073      [[0.00022506248, 0.00026383027, 0.9995111]]\n",
            "2074        [[0.0023006217, 0.0017129213, 0.9959864]]\n",
            "2075        [[0.0066688578, 0.0017837608, 0.9915474]]\n",
            "2076       [[0.9972583, 0.00074072316, 0.0020009445]]\n",
            "2077       [[0.99838626, 0.0007956402, 0.0008180815]]\n",
            "2078         [[0.006013296, 0.0011098953, 0.9928768]]\n",
            "2079        [[0.00025589365, 8.4107895e-05, 0.99966]]\n",
            "2080      [[0.00011732745, 0.00017818937, 0.9997044]]\n",
            "2081      [[0.00013643428, 0.00020191525, 0.9996617]]\n",
            "2082     [[0.00047907684, 0.000108663575, 0.9994123]]\n",
            "2083          [[0.0002498428, 0.3088062, 0.69094396]]\n",
            "2084      [[0.00044832687, 0.0001689516, 0.99938273]]\n",
            "2085       [[0.00059496594, 8.584792e-05, 0.9993192]]\n",
            "2086      [[0.00066982245, 0.00071722135, 0.9986129]]\n",
            "2087         [[0.001462962, 1.685869e-05, 0.9985202]]\n",
            "2088         [[0.99348843, 0.0042912723, 0.00222024]]\n",
            "2089          [[0.0014752701, 0.025371756, 0.973153]]\n",
            "2090      [[0.0014427572, 1.7855933e-05, 0.99853945]]\n",
            "2091         [[0.00025187587, 0.02318768, 0.9765604]]\n",
            "2092           [[0.001146055, 0.45272702, 0.5461269]]\n",
            "2093       [[0.0003709274, 6.910239e-05, 0.99955994]]\n",
            "2094        [[0.0008649311, 0.00013207064, 0.999003]]\n",
            "2095         [[0.0006657306, 0.028950706, 0.9703836]]\n",
            "2096      [[4.7299014e-05, 0.9994598, 0.00049293804]]\n",
            "2097       [[4.321261e-05, 0.99895835, 0.0009983759]]\n",
            "2098      [[0.00023626948, 0.99351305, 0.0062506655]]\n",
            "2099       [[0.00024046288, 0.006329674, 0.99342996]]\n",
            "2100      [[0.00024074344, 7.5133525e-05, 0.9996842]]\n",
            "2101        [[0.0002803269, 2.120963e-05, 0.9996985]]\n",
            "2102       [[0.0015696035, 4.7745296e-05, 0.9983827]]\n",
            "2103      [[0.00020651026, 0.00097121956, 0.9988223]]\n",
            "2104        [[0.0010212527, 0.002553301, 0.99642545]]\n",
            "2105       [[0.00014640974, 2.232368e-05, 0.9998313]]\n",
            "2106      [[0.0001413057, 0.000113189875, 0.9997454]]\n",
            "2107      [[0.99661595, 0.00023378176, 0.0031503013]]\n",
            "2108         [[0.9108707, 2.6155132e-05, 0.08910318]]\n",
            "2109         [[9.338525e-05, 0.9968245, 0.003082141]]\n",
            "2110       [[0.00081495306, 0.026453402, 0.97273165]]\n",
            "2111          [[0.0004913918, 0.56589013, 0.4336185]]\n",
            "2112         [[0.00033393782, 0.12175085, 0.8779152]]\n",
            "2113       [[0.00014520752, 0.99027854, 0.009576242]]\n",
            "2114           [[0.014813992, 0.27946034, 0.7057256]]\n",
            "2115      [[0.00022195306, 0.0044872244, 0.99529076]]\n",
            "2116       [[0.00020468867, 0.049382135, 0.95041317]]\n",
            "2117           [[0.54891855, 0.07936037, 0.37172112]]\n",
            "2118        [[0.00010124617, 0.01941777, 0.98048097]]\n",
            "2119         [[0.00026052108, 0.15389311, 0.8458463]]\n",
            "2120          [[0.014979941, 0.039843652, 0.9451764]]\n",
            "2121      [[0.00030671505, 0.00012752906, 0.9995658]]\n",
            "2122         [[0.0014771156, 0.009778248, 0.9887446]]\n",
            "2123         [[0.0011543914, 0.024384871, 0.9744607]]\n",
            "2124           [[0.0015957376, 0.2267011, 0.7717032]]\n",
            "2125        [[0.0012396009, 0.001422674, 0.99733776]]\n",
            "2126        [[0.00046064492, 0.018451497, 0.9810878]]\n",
            "2127     [[0.00028351718, 3.7106955e-05, 0.99967945]]\n",
            "2128      [[0.0003868192, 0.00010250867, 0.99951077]]\n",
            "2129       [[0.0021913587, 0.00021825584, 0.9975904]]\n",
            "2130          [[0.66796756, 0.32611153, 0.005920893]]\n",
            "2131           [[0.4832955, 0.50880015, 0.007904344]]\n",
            "2132        [[0.00017134266, 0.003344142, 0.9964845]]\n",
            "2133      [[0.00013128131, 0.0006700684, 0.99919873]]\n",
            "2134     [[0.00021091821, 1.2573625e-05, 0.99977654]]\n",
            "2135       [[0.00019731477, 0.0005900632, 0.9992125]]\n",
            "2136         [[0.0029454608, 0.04418582, 0.95286876]]\n",
            "2137         [[0.00010018352, 0.15968874, 0.8402111]]\n",
            "2138        [[0.0042667207, 0.011487957, 0.98424524]]\n",
            "2139          [[0.011259999, 0.005919452, 0.9828205]]\n",
            "2140         [[0.016374612, 0.0016689415, 0.9819565]]\n",
            "2141          [[0.0012562482, 0.9326733, 0.06607043]]\n",
            "2142         [[0.0013728938, 0.8866327, 0.111994445]]\n",
            "2143       [[0.00018652882, 0.005125878, 0.99468756]]\n",
            "2144     [[0.00037319146, 8.8628785e-06, 0.99961793]]\n",
            "2145       [[0.0011027158, 2.0776313e-05, 0.9988765]]\n",
            "2146       [[0.00042060963, 8.96913e-05, 0.99948967]]\n",
            "2147           [[0.9448628, 0.00573425, 0.049402952]]\n",
            "2148         [[0.000303202, 0.00083390926, 0.998863]]\n",
            "2149        [[0.9964721, 9.480795e-05, 0.0034331235]]\n",
            "2150         [[0.3045223, 0.00011887616, 0.69535875]]\n",
            "2151       [[0.0010641309, 1.1639273e-05, 0.9989242]]\n",
            "2152         [[0.0024192103, 0.83392745, 0.16365339]]\n",
            "2153       [[0.0035242492, 0.0006948005, 0.99578094]]\n",
            "2154        [[0.0007512506, 0.0029146124, 0.9963342]]\n",
            "2155        [[0.016810006, 0.00027468233, 0.9829153]]\n",
            "2156       [[0.00049417716, 4.237498e-05, 0.9994634]]\n",
            "2157          [[0.005132954, 0.020782579, 0.9740845]]\n",
            "2158      [[0.00016976256, 5.4710494e-05, 0.9997756]]\n",
            "2159       [[0.00031663603, 0.0010121898, 0.9986712]]\n",
            "2160     [[0.00040840465, 0.00012151542, 0.99947006]]\n",
            "2161     [[0.00057274546, 5.0953746e-05, 0.99937624]]\n",
            "2162         [[0.9990866, 9.6360534e-05, 0.00081707]]\n",
            "2163        [[0.00097023114, 0.82490224, 0.17412752]]\n",
            "2164         [[0.0026995344, 0.994572, 0.0027284739]]\n",
            "2165            [[0.003001301, 0.565147, 0.43185166]]\n",
            "2166       [[0.008513481, 0.000121819976, 0.9913647]]\n",
            "2167        [[0.00066600484, 0.0013460726, 0.997988]]\n",
            "2168        [[0.0022450017, 4.488783e-05, 0.9977101]]\n",
            "2169       [[0.0035243498, 4.0232837e-05, 0.9964354]]\n",
            "2170         [[0.00044691813, 0.8675099, 0.13204315]]\n",
            "2171       [[0.99817455, 0.001606784, 0.00021872357]]\n",
            "2172           [[0.003626314, 0.33702427, 0.6593494]]\n",
            "2173          [[0.0065741953, 0.49936965, 0.4940562]]\n",
            "2174        [[0.00062206323, 0.88567877, 0.11369919]]\n",
            "2175           [[0.013054892, 0.12414463, 0.8628004]]\n",
            "2176         [[0.0014585669, 0.038763814, 0.9597776]]\n",
            "2177        [[0.0041881455, 0.013578361, 0.98223346]]\n",
            "2178            [[0.008964582, 0.39721635, 0.593819]]\n",
            "2179            [[0.43556362, 0.084182344, 0.480254]]\n",
            "2180           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "2181       [[0.0003012036, 0.00010010257, 0.9995987]]\n",
            "2182        [[0.0016709857, 0.0004612149, 0.9978678]]\n",
            "2183       [[0.0029463645, 0.99383116, 0.0032225028]]\n",
            "2184            [[0.015743198, 0.4998726, 0.4843842]]\n",
            "2185            [[0.00461043, 0.23425733, 0.7611322]]\n",
            "2186        [[0.0004163148, 0.0005823881, 0.9990013]]\n",
            "2187         [[0.06410951, 0.0011715143, 0.93471897]]\n",
            "2188         [[0.06410951, 0.0011715143, 0.93471897]]\n",
            "2189       [[0.0005726051, 9.342999e-06, 0.99941814]]\n",
            "2190     [[0.00021236368, 1.7103923e-05, 0.99977046]]\n",
            "2191     [[0.00026070772, 1.2999868e-05, 0.99972624]]\n",
            "2192       [[0.00025359675, 4.205471e-05, 0.9997043]]\n",
            "2193       [[0.0010400028, 0.00036016712, 0.9985998]]\n",
            "2194          [[0.0004508374, 0.04668738, 0.9528617]]\n",
            "2195         [[0.0019306145, 0.16778365, 0.83028567]]\n",
            "2196        [[0.000242039, 0.0005191391, 0.99923885]]\n",
            "2197            [[0.12334432, 0.15194237, 0.7247133]]\n",
            "2198           [[0.001669686, 0.12732165, 0.8710086]]\n",
            "2199         [[0.001155004, 0.0010575544, 0.9977875]]\n",
            "2200       [[0.00088100677, 0.0034322278, 0.9956868]]\n",
            "2201          [[0.024212964, 0.51336634, 0.46242073]]\n",
            "2202         [[0.0003823557, 0.0006866023, 0.998931]]\n",
            "2203         [[0.027319796, 0.0011412572, 0.9715389]]\n",
            "2204     [[0.00068860326, 2.2169974e-05, 0.99928916]]\n",
            "2205     [[0.00022431751, 0.00032614887, 0.99944955]]\n",
            "2206          [[0.0006127647, 0.30446178, 0.6949254]]\n",
            "2207     [[0.00032513274, 1.8448432e-05, 0.99965644]]\n",
            "2208      [[0.00042255622, 0.99059063, 0.0089868335]]\n",
            "2209        [[0.0001442873, 0.98099893, 0.018856777]]\n",
            "2210        [[0.0026442434, 0.042422462, 0.95493335]]\n",
            "2211      [[0.00033647034, 2.7196145e-05, 0.9996363]]\n",
            "2212        [[0.0005508644, 0.007345012, 0.99210405]]\n",
            "2213           [[0.0115884505, 0.6117556, 0.3766559]]\n",
            "2214        [[5.144528e-05, 0.9987558, 0.0011927573]]\n",
            "2215         [[0.0034164474, 0.9513535, 0.045230042]]\n",
            "2216          [[0.0031318136, 0.1402381, 0.85663015]]\n",
            "2217          [[0.030140677, 0.027942006, 0.9419174]]\n",
            "2218         [[0.97860694, 0.004835344, 0.016557604]]\n",
            "2219           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "2220      [[0.99213845, 0.00013290822, 0.0077286316]]\n",
            "2221      [[0.00046284276, 0.00020990039, 0.9993273]]\n",
            "2222      [[0.00018000521, 0.00058588275, 0.9992341]]\n",
            "2223      [[0.00076185446, 0.00073876255, 0.9984993]]\n",
            "2224       [[0.00025422446, 3.632685e-05, 0.9997094]]\n",
            "2225       [[0.00019757585, 6.0461116e-05, 0.999742]]\n",
            "2226       [[0.00043299235, 3.983841e-05, 0.9995272]]\n",
            "2227       [[0.00024625767, 0.001618847, 0.99813485]]\n",
            "2228        [[0.0022222595, 6.856651e-05, 0.9977093]]\n",
            "2229      [[0.0006542828, 0.00020250265, 0.99914324]]\n",
            "2230      [[0.00027123268, 1.4365349e-05, 0.9997143]]\n",
            "2231       [[0.004617645, 1.5448826e-05, 0.99536693]]\n",
            "2232      [[0.0028191647, 2.8959248e-05, 0.99715185]]\n",
            "2233          [[0.001775215, 0.014093494, 0.9841313]]\n",
            "2234       [[0.000554161, 4.9304617e-05, 0.99939656]]\n",
            "2235            [[0.000979794, 0.16732916, 0.831691]]\n",
            "2236      [[0.0013775699, 1.7662262e-05, 0.99860483]]\n",
            "2237      [[0.00026781633, 2.2921346e-05, 0.9997093]]\n",
            "2238             [[0.142123, 0.24196261, 0.61591434]]\n",
            "2239           [[0.025356265, 0.1380848, 0.83655894]]\n",
            "2240        [[0.0016470299, 0.0070025506, 0.9913504]]\n",
            "2241        [[0.98383254, 0.0033876991, 0.012779729]]\n",
            "2242         [[0.0025565631, 0.025226984, 0.9722164]]\n",
            "2243          [[0.0014049677, 0.890464, 0.108131036]]\n",
            "2244       [[0.0008189766, 0.00038080738, 0.9988003]]\n",
            "2245          [[0.041904144, 0.0016527436, 0.956443]]\n",
            "2246        [[0.0026581553, 2.291675e-05, 0.9973189]]\n",
            "2247     [[0.00056673243, 4.1149353e-05, 0.99939215]]\n",
            "2248        [[0.0002251079, 8.50082e-05, 0.99968994]]\n",
            "2249       [[0.000274785, 3.2701104e-05, 0.99969256]]\n",
            "2250       [[0.00046502598, 1.0919156e-05, 0.999524]]\n",
            "2251       [[0.9884701, 0.000105070365, 0.011424833]]\n",
            "2252         [[0.0040927017, 0.9741589, 0.021748438]]\n",
            "2253        [[0.0052447915, 0.035130467, 0.95962465]]\n",
            "2254      [[0.00043625326, 0.0006598765, 0.99890375]]\n",
            "2255           [[0.047154848, 0.32169876, 0.6311464]]\n",
            "2256     [[0.00026217598, 0.00013014583, 0.99960774]]\n",
            "2257      [[0.00045407782, 0.00013676504, 0.9994092]]\n",
            "2258         [[0.0020589659, 0.022636134, 0.9753049]]\n",
            "2259        [[0.0013114363, 0.004272271, 0.99441624]]\n",
            "2260      [[0.00048173373, 3.5756144e-05, 0.9994825]]\n",
            "2261        [[0.0010509789, 0.011430851, 0.98751813]]\n",
            "2262       [[0.00058061327, 0.0021175116, 0.9973018]]\n",
            "2263      [[0.00015261068, 8.580781e-05, 0.99976164]]\n",
            "2264          [[0.0019852377, 0.5623424, 0.43567234]]\n",
            "2265           [[0.18876854, 0.805421, 0.0058104065]]\n",
            "2266          [[0.011914914, 0.012597541, 0.9754876]]\n",
            "2267          [[0.0036446312, 0.34524673, 0.6511087]]\n",
            "2268     [[0.00012255792, 2.8505883e-05, 0.99984896]]\n",
            "2269      [[0.00013829015, 0.00018437274, 0.9996774]]\n",
            "2270          [[0.006043495, 0.89549446, 0.09846208]]\n",
            "2271          [[0.0001844894, 0.9386751, 0.06114046]]\n",
            "2272       [[0.00014427438, 6.905185e-05, 0.9997867]]\n",
            "2273        [[0.00087542186, 0.003954952, 0.9951696]]\n",
            "2274      [[0.0003876748, 0.00012888949, 0.99948335]]\n",
            "2275             [[0.3934115, 0.32539874, 0.2811898]]\n",
            "2276          [[0.00029651917, 0.8170267, 0.1826768]]\n",
            "2277           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "2278       [[0.0015807741, 1.4515475e-05, 0.9984047]]\n",
            "2279          [[0.0019996285, 0.34760913, 0.6503912]]\n",
            "2280        [[0.0011028267, 0.0027542377, 0.9961429]]\n",
            "2281      [[0.0004322962, 1.6884413e-05, 0.99955076]]\n",
            "2282      [[0.00045359618, 1.2676271e-05, 0.9995338]]\n",
            "2283       [[0.00080905017, 0.00012402938, 0.999067]]\n",
            "2284           [[0.003029799, 0.02198567, 0.9749845]]\n",
            "2285          [[0.004235545, 0.56098837, 0.43477613]]\n",
            "2286     [[0.00056026643, 3.6885656e-05, 0.99940276]]\n",
            "2287       [[0.00059066294, 0.031902898, 0.96750647]]\n",
            "2288       [[0.0009945782, 0.00087870413, 0.9981267]]\n",
            "2289      [[0.00077885215, 4.602396e-05, 0.99917513]]\n",
            "2290      [[0.00070164097, 0.0076810974, 0.99161726]]\n",
            "2291       [[0.00015349538, 0.0062098266, 0.9936367]]\n",
            "2292           [[0.000256027, 0.8594196, 0.14032441]]\n",
            "2293        [[0.0005728702, 0.9966629, 0.0027642406]]\n",
            "2294         [[0.0008713759, 0.018751064, 0.9803775]]\n",
            "2295     [[0.00038882133, 0.00050655456, 0.99910456]]\n",
            "2296        [[0.00026903805, 0.12271976, 0.87701124]]\n",
            "2297          [[0.006743467, 0.97129506, 0.02196149]]\n",
            "2298      [[0.00073177146, 6.6261244e-05, 0.9992021]]\n",
            "2299      [[0.0021157016, 5.0949326e-05, 0.99783343]]\n",
            "2300        [[0.0011259353, 0.010681309, 0.98819274]]\n",
            "2301          [[0.0008862965, 0.8661467, 0.13296701]]\n",
            "2302           [[0.7622589, 0.0004656381, 0.2372755]]\n",
            "2303       [[0.0004901502, 2.7656113e-05, 0.9994822]]\n",
            "2304      [[0.00083499495, 0.0012045848, 0.99796045]]\n",
            "2305      [[0.00027628828, 2.1947637e-05, 0.9997018]]\n",
            "2306          [[0.75448245, 0.018669745, 0.22684778]]\n",
            "2307           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "2308       [[0.00038106574, 8.135471e-05, 0.9995376]]\n",
            "2309      [[0.00038058366, 5.508612e-05, 0.99956435]]\n",
            "2310      [[0.00090437755, 0.00061275356, 0.9984829]]\n",
            "2311          [[0.007168469, 0.080330074, 0.9125014]]\n",
            "2312         [[0.0012902521, 6.481775e-05, 0.998645]]\n",
            "2313           [[0.0012552914, 0.9262164, 0.0725283]]\n",
            "2314          [[0.92972034, 0.024492774, 0.04578687]]\n",
            "2315          [[0.0015005273, 0.7433688, 0.25513062]]\n",
            "2316       [[0.00018207746, 0.97196656, 0.027851319]]\n",
            "2317      [[4.4068856e-05, 0.9995999, 0.00035606854]]\n",
            "2318         [[0.0058711683, 0.03255621, 0.96157265]]\n",
            "2319          [[0.009411555, 0.031967983, 0.9586205]]\n",
            "2320         [[0.0001801231, 0.055343974, 0.9444759]]\n",
            "2321           [[0.002250345, 0.08961769, 0.9081319]]\n",
            "2322           [[0.002250345, 0.08961769, 0.9081319]]\n",
            "2323       [[0.0038318317, 7.1266826e-05, 0.9960969]]\n",
            "2324        [[0.0004714295, 5.831732e-05, 0.9994703]]\n",
            "2325      [[0.00023463315, 0.0069971234, 0.99276817]]\n",
            "2326         [[0.002581132, 7.337431e-05, 0.9973455]]\n",
            "2327      [[0.0005191092, 1.9594896e-05, 0.99946135]]\n",
            "2328           [[0.03179682, 0.32360587, 0.64459735]]\n",
            "2329        [[0.0015855216, 0.010730197, 0.98768425]]\n",
            "2330         [[0.0009082379, 0.67421275, 0.32487908]]\n",
            "2331      [[0.00040343226, 0.00018077935, 0.9994159]]\n",
            "2332      [[0.0004966387, 1.5697617e-05, 0.99948764]]\n",
            "2333      [[0.00058661285, 2.0256688e-05, 0.9993931]]\n",
            "2334        [[0.01939847, 0.00028105147, 0.98032045]]\n",
            "2335         [[0.0028572897, 0.11369743, 0.88344526]]\n",
            "2336       [[0.0035277312, 0.00013149164, 0.9963408]]\n",
            "2337       [[0.0012167675, 1.9989915e-05, 0.9987632]]\n",
            "2338         [[0.0019492814, 0.0033647271, 0.994686]]\n",
            "2339         [[0.0014778541, 0.01649227, 0.98202986]]\n",
            "2340           [[0.015065799, 0.22427902, 0.7606551]]\n",
            "2341        [[0.00078651705, 0.57366824, 0.42554525]]\n",
            "2342       [[8.3497194e-05, 5.287787e-05, 0.9998635]]\n",
            "2343     [[0.00014783429, 0.00029515373, 0.99955696]]\n",
            "2344       [[9.134734e-05, 8.1275306e-05, 0.9998274]]\n",
            "2345      [[0.00015746072, 2.7738974e-05, 0.9998148]]\n",
            "2346      [[0.0002870913, 1.4251008e-05, 0.99969864]]\n",
            "2347       [[0.00023721377, 2.014322e-05, 0.9997427]]\n",
            "2348       [[0.002636498, 1.4382502e-05, 0.99734914]]\n",
            "2349         [[0.0028420754, 0.050234795, 0.9469232]]\n",
            "2350            [[0.03859106, 0.3399169, 0.62149197]]\n",
            "2351            [[0.06926203, 0.844416, 0.086321905]]\n",
            "2352          [[0.013849699, 0.24376276, 0.74238753]]\n",
            "2353      [[0.0016961402, 1.5913003e-05, 0.99828786]]\n",
            "2354      [[0.00040911222, 3.9770464e-05, 0.9995511]]\n",
            "2355       [[0.002275888, 0.99689627, 0.00082782144]]\n",
            "2356         [[0.106846154, 0.88726574, 0.005888061]]\n",
            "2357        [[7.127533e-05, 0.025832884, 0.97409576]]\n",
            "2358      [[0.00026185627, 0.00012809553, 0.9996101]]\n",
            "2359        [[0.0006152022, 0.0035667142, 0.9958182]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_padanan_know_val_f1_0.7972'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_padanan_know_val_f1_0.7972\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "eGsS2it6IR-q"
    },
    {
      "cell_type": "markdown",
      "id": "jy54z5NwOp1_",
      "metadata": {
        "id": "jy54z5NwOp1_"
      },
      "source": [
        "## s5 state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "4xvUPe_jXUmc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4xvUPe_jXUmc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QGV12Yw9XUmc",
        "outputId": "6529be79-5704-4c61-849e-4e0ce4ed83e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0              [[0.06079268, 0.014395219, 0.9248121]]\n",
            "1          [[0.004208365, 0.00018688072, 0.99560475]]\n",
            "2              [[0.9855494, 0.012820882, 0.00162978]]\n",
            "3         [[0.9993036, 0.00017636004, 0.00052009104]]\n",
            "4          [[0.99824584, 0.0002676478, 0.0014865855]]\n",
            "5           [[0.002837611, 1.0678298e-05, 0.9971517]]\n",
            "6         [[0.0026093775, 0.00014939696, 0.99724114]]\n",
            "7           [[0.0028371592, 0.0002773601, 0.9968855]]\n",
            "8          [[0.003355329, 0.00036364532, 0.99628097]]\n",
            "9         [[0.0013442636, 0.00029333396, 0.99836236]]\n",
            "10             [[0.024692269, 0.7640487, 0.21125907]]\n",
            "11            [[0.0040604207, 0.21020073, 0.7857389]]\n",
            "12          [[0.00017998349, 0.98892576, 0.01089429]]\n",
            "13         [[5.4764816e-05, 0.9929489, 0.0069963187]]\n",
            "14           [[0.0013560344, 0.9350501, 0.063593894]]\n",
            "15            [[0.0964664, 0.0024872222, 0.90104634]]\n",
            "16            [[0.91655093, 0.06797585, 0.015473186]]\n",
            "17          [[0.003288857, 3.1752566e-05, 0.9966794]]\n",
            "18        [[0.0055079963, 1.7078075e-05, 0.99447495]]\n",
            "19           [[0.001513257, 0.00053576066, 0.997951]]\n",
            "20         [[0.0027074534, 0.00015967723, 0.9971329]]\n",
            "21          [[0.004636482, 0.00013158114, 0.9952319]]\n",
            "22        [[0.0015351957, 2.8690038e-05, 0.99843615]]\n",
            "23            [[0.86095726, 0.111809924, 0.02723285]]\n",
            "24            [[0.0050036674, 0.13794945, 0.8570469]]\n",
            "25            [[0.0034031488, 0.7953959, 0.20120098]]\n",
            "26           [[0.011839035, 9.689883e-06, 0.9881513]]\n",
            "27             [[0.01611401, 1.10004e-05, 0.9838749]]\n",
            "28          [[0.0012805704, 9.025189e-06, 0.9987104]]\n",
            "29          [[0.000532977, 1.5976839e-05, 0.9994511]]\n",
            "30          [[0.0017158722, 0.017910244, 0.98037386]]\n",
            "31          [[0.005693822, 2.1336187e-05, 0.9942848]]\n",
            "32         [[0.0066310978, 1.4209611e-05, 0.9933547]]\n",
            "33         [[0.0030040315, 1.6145174e-05, 0.9969798]]\n",
            "34             [[0.0075151687, 0.0129144, 0.9795704]]\n",
            "35           [[0.003573499, 0.0015658542, 0.9948606]]\n",
            "36           [[0.0015424911, 0.9872437, 0.011213747]]\n",
            "37           [[0.9850395, 0.012818245, 0.0021423276]]\n",
            "38          [[0.10287042, 0.00015739558, 0.89697224]]\n",
            "39         [[0.0025963173, 7.444978e-06, 0.99739623]]\n",
            "40         [[0.0013994174, 0.0056028124, 0.99299777]]\n",
            "41         [[0.0035887323, 1.5454445e-05, 0.9963959]]\n",
            "42          [[0.0023118402, 1.65029e-05, 0.99767166]]\n",
            "43          [[0.0012706625, 1.0321559e-05, 0.998719]]\n",
            "44             [[0.032007173, 0.64364654, 0.3243463]]\n",
            "45            [[0.017897466, 0.9739838, 0.008118691]]\n",
            "46               [[0.3650037, 0.01885423, 0.6161421]]\n",
            "47            [[0.05747002, 0.012583679, 0.92994636]]\n",
            "48         [[0.0050895265, 2.3389772e-05, 0.9948872]]\n",
            "49              [[0.080356985, 0.5489114, 0.3707316]]\n",
            "50          [[0.0026665735, 0.0035719567, 0.9937615]]\n",
            "51         [[0.030092109, 0.00052598043, 0.96938187]]\n",
            "52           [[0.0117656365, 0.17830777, 0.80992657]]\n",
            "53          [[0.0017453968, 0.98379576, 0.014458889]]\n",
            "54            [[0.001978935, 0.16142656, 0.83659446]]\n",
            "55              [[0.36484408, 0.2002836, 0.43487236]]\n",
            "56          [[0.016826037, 1.2016502e-05, 0.9831619]]\n",
            "57             [[0.036118977, 0.04731989, 0.9165612]]\n",
            "58            [[0.0042620394, 0.43700537, 0.5587326]]\n",
            "59           [[0.92509705, 0.051524576, 0.023378365]]\n",
            "60         [[0.003403925, 1.7340515e-05, 0.99657875]]\n",
            "61             [[0.001046414, 0.5921254, 0.40682814]]\n",
            "62          [[0.000656429, 0.0008153007, 0.99852824]]\n",
            "63         [[0.0014852113, 2.694006e-05, 0.99848783]]\n",
            "64          [[0.0012018202, 2.951611e-05, 0.9987686]]\n",
            "65         [[0.019500561, 7.0755006e-05, 0.98042876]]\n",
            "66           [[0.015686741, 8.564032e-06, 0.9843047]]\n",
            "67             [[0.97325957, 0.01579955, 0.01094081]]\n",
            "68          [[0.96443164, 0.0011536841, 0.034414653]]\n",
            "69           [[0.015682582, 0.89663035, 0.087687075]]\n",
            "70            [[0.9714599, 0.005883179, 0.022656797]]\n",
            "71            [[0.81236064, 0.008026452, 0.17961292]]\n",
            "72         [[0.00044492897, 0.007926261, 0.99162877]]\n",
            "73            [[6.151716e-05, 0.9805238, 0.01941465]]\n",
            "74           [[0.0020099478, 0.13756597, 0.86042404]]\n",
            "75           [[0.9915929, 0.0002290261, 0.008178164]]\n",
            "76            [[0.0018609238, 0.030080026, 0.968059]]\n",
            "77         [[0.010624269, 1.3855224e-05, 0.98936194]]\n",
            "78           [[0.009100666, 4.079604e-05, 0.9908586]]\n",
            "79          [[0.002822111, 1.525999e-05, 0.99716264]]\n",
            "80           [[0.007278083, 0.015407895, 0.97731405]]\n",
            "81          [[0.0062840157, 8.066112e-06, 0.9937079]]\n",
            "82         [[0.021607691, 2.2764905e-05, 0.97836953]]\n",
            "83           [[0.9953335, 0.002435808, 0.0022306556]]\n",
            "84              [[0.05411639, 0.15183996, 0.7940437]]\n",
            "85            [[0.103939876, 0.8581094, 0.037950743]]\n",
            "86             [[0.9322362, 0.05730467, 0.010459086]]\n",
            "87         [[0.0012665902, 1.0036763e-05, 0.9987233]]\n",
            "88             [[0.012405133, 0.7937699, 0.19382498]]\n",
            "89        [[0.00081489113, 0.0005100669, 0.99867505]]\n",
            "90         [[0.002294279, 1.2796884e-05, 0.99769294]]\n",
            "91             [[0.027151868, 0.9653406, 0.00750754]]\n",
            "92           [[0.0006588582, 0.016022155, 0.9833189]]\n",
            "93            [[0.042668153, 0.014379052, 0.9429528]]\n",
            "94         [[0.054931134, 0.00018294064, 0.94488597]]\n",
            "95            [[0.8672067, 0.0045237904, 0.12826955]]\n",
            "96         [[0.0006800001, 9.426787e-05, 0.99922574]]\n",
            "97           [[0.003710568, 6.3959515e-06, 0.996283]]\n",
            "98        [[0.0057748747, 4.3579103e-06, 0.99422073]]\n",
            "99          [[0.0132786445, 2.753285e-05, 0.9866939]]\n",
            "100         [[0.005898808, 5.3909184e-06, 0.9940958]]\n",
            "101            [[0.002495288, 0.7712704, 0.22623436]]\n",
            "102         [[0.0019147838, 1.9329966e-05, 0.998066]]\n",
            "103            [[0.009569062, 0.00146657, 0.9889643]]\n",
            "104         [[0.0041376282, 1.7367784e-05, 0.995845]]\n",
            "105        [[0.0012614172, 0.0015926089, 0.99714595]]\n",
            "106       [[0.00073727133, 0.0001709237, 0.99909186]]\n",
            "107          [[0.0032260173, 0.017563345, 0.9792107]]\n",
            "108          [[0.002798644, 7.0312584e-05, 0.997131]]\n",
            "109         [[0.005270196, 2.2129489e-05, 0.9947076]]\n",
            "110           [[0.00047134823, 0.04990666, 0.949622]]\n",
            "111        [[0.0016091372, 1.2469705e-05, 0.9983784]]\n",
            "112           [[0.0016560932, 0.09326853, 0.9050754]]\n",
            "113        [[0.007398345, 0.00017739383, 0.99242425]]\n",
            "114            [[0.9016908, 0.06696389, 0.031345308]]\n",
            "115         [[0.0012611606, 0.99558926, 0.003149638]]\n",
            "116            [[0.013057215, 0.7930304, 0.19391243]]\n",
            "117         [[0.00730189, 1.6600861e-05, 0.99268156]]\n",
            "118       [[0.0011833338, 0.00010295223, 0.99871373]]\n",
            "119           [[0.008539211, 0.9748599, 0.016600939]]\n",
            "120           [[0.0022217054, 0.18467255, 0.8131057]]\n",
            "121          [[0.005867459, 8.189855e-05, 0.9940507]]\n",
            "122        [[0.000385741, 2.1936863e-05, 0.99959236]]\n",
            "123         [[0.0058949376, 1.6141834e-05, 0.994089]]\n",
            "124           [[0.005220221, 0.010014527, 0.9847652]]\n",
            "125            [[0.010095875, 0.20042184, 0.7894823]]\n",
            "126           [[0.005658613, 0.048439104, 0.9459022]]\n",
            "127           [[0.0047942786, 0.13768208, 0.8575237]]\n",
            "128           [[0.0014143765, 0.3587177, 0.63986796]]\n",
            "129         [[0.007683871, 1.7789638e-05, 0.9922984]]\n",
            "130         [[0.007955274, 0.00011090648, 0.9919338]]\n",
            "131         [[0.99514186, 0.00071952667, 0.00413862]]\n",
            "132       [[0.99857557, 0.00015272616, 0.0012717493]]\n",
            "133        [[0.00055905635, 3.4973444e-05, 0.999406]]\n",
            "134            [[0.32544354, 0.6586728, 0.015883649]]\n",
            "135          [[0.87228566, 0.123072386, 0.004642001]]\n",
            "136            [[0.05778046, 0.63305426, 0.30916533]]\n",
            "137         [[0.002619198, 1.1470025e-05, 0.9973694]]\n",
            "138       [[0.0022190302, 4.4482127e-05, 0.99773645]]\n",
            "139         [[0.0019229902, 9.917367e-05, 0.9979778]]\n",
            "140        [[0.005376677, 6.2188647e-06, 0.99461716]]\n",
            "141        [[0.9971614, 0.00018539352, 0.0026532235]]\n",
            "142         [[0.98226625, 0.015762115, 0.0019716807]]\n",
            "143          [[0.0008984765, 0.012142025, 0.9869595]]\n",
            "144           [[0.0525205, 0.00044602118, 0.9470334]]\n",
            "145          [[0.00729937, 1.0010141e-05, 0.9926906]]\n",
            "146        [[0.003942707, 0.00029118606, 0.99576616]]\n",
            "147             [[0.0024024309, 0.5959586, 0.401639]]\n",
            "148                [[0.7974723, 0.153452, 0.0490757]]\n",
            "149         [[0.0016636786, 0.0010526018, 0.9972837]]\n",
            "150        [[0.0017260594, 1.9160365e-05, 0.9982547]]\n",
            "151          [[0.14326397, 0.85094094, 0.0057950537]]\n",
            "152         [[0.0019195223, 2.2532877e-05, 0.998058]]\n",
            "153        [[0.0006291639, 0.99628013, 0.0030906822]]\n",
            "154        [[0.0016999055, 0.00022770147, 0.9980724]]\n",
            "155      [[0.000114000526, 0.99680567, 0.0030803462]]\n",
            "156         [[0.00018409775, 0.9841666, 0.015649356]]\n",
            "157            [[0.015129172, 0.10428678, 0.8805841]]\n",
            "158         [[0.017089237, 0.98131025, 0.0016005094]]\n",
            "159             [[0.9262581, 0.0651545, 0.008587475]]\n",
            "160           [[0.040283706, 0.52978677, 0.42992947]]\n",
            "161        [[0.009936303, 1.4385655e-05, 0.99004924]]\n",
            "162         [[0.00437684, 7.9311185e-06, 0.99561524]]\n",
            "163        [[0.0018718184, 0.0002528871, 0.99787533]]\n",
            "164          [[0.00735702, 1.7500855e-05, 0.9926254]]\n",
            "165          [[0.1293435, 0.00019346981, 0.87046313]]\n",
            "166             [[0.20964836, 0.7797429, 0.01060878]]\n",
            "167        [[0.011735427, 7.7237586e-05, 0.98818725]]\n",
            "168          [[0.0014703703, 0.9157948, 0.082734786]]\n",
            "169            [[0.039255217, 0.7599546, 0.20079021]]\n",
            "170           [[0.0034539679, 0.8821051, 0.11444094]]\n",
            "171        [[0.0049473676, 0.00062433473, 0.9944283]]\n",
            "172           [[0.0010029925, 0.12741046, 0.8715866]]\n",
            "173         [[0.0013296086, 0.013337241, 0.98533314]]\n",
            "174         [[0.000505779, 0.99784327, 0.0016509389]]\n",
            "175        [[0.0058896835, 1.32730165e-05, 0.994097]]\n",
            "176         [[0.008036272, 0.00036636254, 0.9915975]]\n",
            "177         [[0.0067984983, 0.0045746285, 0.9886269]]\n",
            "178           [[0.0010478158, 0.018789152, 0.980163]]\n",
            "179             [[0.02060014, 0.28730622, 0.6920936]]\n",
            "180          [[0.9980519, 0.0012861171, 0.000662005]]\n",
            "181        [[0.0045617656, 0.00033748295, 0.9951008]]\n",
            "182          [[0.0014961843, 0.009465099, 0.9890387]]\n",
            "183          [[0.007242151, 0.060393978, 0.93236387]]\n",
            "184        [[0.0053728945, 3.6014793e-05, 0.9945911]]\n",
            "185         [[0.0007340869, 2.802866e-05, 0.9992379]]\n",
            "186        [[0.0036903184, 3.2456115e-05, 0.9962773]]\n",
            "187          [[0.0010629824, 8.45731e-05, 0.9988525]]\n",
            "188        [[0.017874356, 2.0418245e-05, 0.98210526]]\n",
            "189           [[0.0033411577, 0.6768004, 0.31985846]]\n",
            "190           [[0.014229883, 0.09767994, 0.88809013]]\n",
            "191             [[0.006934254, 0.12249476, 0.870571]]\n",
            "192          [[0.0005250172, 0.9748199, 0.024655018]]\n",
            "193         [[0.0021067795, 2.288431e-05, 0.9978703]]\n",
            "194         [[0.0032472685, 5.153434e-05, 0.9967012]]\n",
            "195            [[0.10464899, 0.7723903, 0.122960776]]\n",
            "196         [[0.00037169957, 0.9979746, 0.001653769]]\n",
            "197          [[0.0003788844, 0.17469484, 0.82492626]]\n",
            "198         [[0.002079085, 0.0033524982, 0.99456847]]\n",
            "199       [[0.0025011115, 0.00074456603, 0.99675435]]\n",
            "200            [[0.967611, 0.0011597387, 0.03122924]]\n",
            "201         [[0.82557136, 0.00061230164, 0.17381635]]\n",
            "202         [[0.006573563, 1.0728988e-05, 0.9934156]]\n",
            "203           [[0.8947373, 0.031865902, 0.073396705]]\n",
            "204          [[0.0012129549, 0.021554982, 0.9772321]]\n",
            "205      [[0.0010013246, 0.000118166994, 0.99888057]]\n",
            "206           [[9.252588e-05, 0.9908098, 0.00909765]]\n",
            "207            [[0.05924977, 0.011220605, 0.9295296]]\n",
            "208         [[0.57972157, 0.00086765725, 0.41941077]]\n",
            "209       [[0.0013498586, 2.7634067e-05, 0.99862254]]\n",
            "210        [[0.00025425098, 0.0016983246, 0.9980475]]\n",
            "211          [[0.00404518, 1.1149693e-05, 0.9959436]]\n",
            "212         [[0.0065302574, 2.213166e-05, 0.9934476]]\n",
            "213        [[0.007837132, 2.5943535e-05, 0.99213696]]\n",
            "214       [[0.0018893046, 0.00050023716, 0.99761045]]\n",
            "215        [[0.0025932032, 0.0014447782, 0.99596196]]\n",
            "216           [[0.0015352238, 0.41497737, 0.5834874]]\n",
            "217       [[0.0015355467, 0.00021797633, 0.99824643]]\n",
            "218        [[0.002990338, 1.1179219e-05, 0.99699855]]\n",
            "219         [[0.021671688, 2.1747204e-05, 0.9783066]]\n",
            "220         [[0.002423749, 2.0520138e-05, 0.9975556]]\n",
            "221         [[0.006761683, 2.6844607e-05, 0.9932114]]\n",
            "222       [[0.0014199273, 5.3544605e-05, 0.99852645]]\n",
            "223             [[0.003450288, 0.5486901, 0.4478596]]\n",
            "224       [[0.0016783831, 5.9920574e-05, 0.99826163]]\n",
            "225         [[0.008894935, 0.00037211826, 0.9907329]]\n",
            "226           [[0.9370378, 0.05822928, 0.0047328523]]\n",
            "227          [[0.008750631, 0.0061117304, 0.9851377]]\n",
            "228        [[3.4128894e-05, 0.9994106, 0.0005552868]]\n",
            "229          [[0.010610043, 0.016550777, 0.97283924]]\n",
            "230          [[0.009900097, 0.0006378199, 0.9894622]]\n",
            "231            [[0.28207842, 0.39260644, 0.32531515]]\n",
            "232             [[0.09921341, 0.6180608, 0.28272572]]\n",
            "233        [[0.0015343667, 4.165981e-05, 0.99842393]]\n",
            "234         [[0.98138535, 0.015883619, 0.0027310704]]\n",
            "235          [[0.10768991, 0.0002868722, 0.89202327]]\n",
            "236        [[0.0014861582, 0.00013810894, 0.9983758]]\n",
            "237        [[0.0007826048, 0.0013992278, 0.99781823]]\n",
            "238          [[0.9922913, 0.0029121465, 0.004796517]]\n",
            "239        [[0.008602412, 0.00050880027, 0.99088883]]\n",
            "240          [[0.9544164, 0.0022716639, 0.043311965]]\n",
            "241         [[0.0018873273, 0.0022659076, 0.9958468]]\n",
            "242           [[0.00080796, 0.021768266, 0.97742385]]\n",
            "243           [[0.83668536, 0.11625357, 0.047061138]]\n",
            "244       [[0.0006358764, 0.00013760057, 0.99922657]]\n",
            "245         [[0.00010506482, 0.9955519, 0.004343039]]\n",
            "246          [[0.09295671, 3.0196525e-05, 0.9070131]]\n",
            "247            [[0.39664206, 0.042709574, 0.5606483]]\n",
            "248             [[0.04933381, 0.07818965, 0.8724765]]\n",
            "249         [[0.0021554562, 3.081893e-05, 0.9978137]]\n",
            "250         [[0.0030643241, 7.286252e-05, 0.9968629]]\n",
            "251           [[0.107271254, 4.80707e-05, 0.8926806]]\n",
            "252         [[0.001756176, 8.1478815e-05, 0.9981623]]\n",
            "253       [[0.0018664513, 0.00014806414, 0.99798536]]\n",
            "254         [[0.004079662, 0.0004929807, 0.99542737]]\n",
            "255         [[0.00066948513, 0.022223098, 0.9771074]]\n",
            "256         [[0.00075456523, 0.80985856, 0.18938684]]\n",
            "257        [[0.0052758045, 6.384722e-05, 0.99466044]]\n",
            "258          [[0.0077887424, 9.47907e-06, 0.9922018]]\n",
            "259           [[0.0036913012, 0.27523062, 0.7210781]]\n",
            "260         [[0.0044367383, 0.98184663, 0.013716668]]\n",
            "261       [[0.00014722502, 0.99618584, 0.0036669793]]\n",
            "262          [[0.0021767996, 0.75189275, 0.24593046]]\n",
            "263           [[0.9726213, 0.021124309, 0.006254308]]\n",
            "264          [[0.9936701, 0.0009790552, 0.005350864]]\n",
            "265             [[0.3238313, 0.030189808, 0.6459789]]\n",
            "266          [[0.0006591039, 0.9867443, 0.012596601]]\n",
            "267          [[0.06293901, 0.00030059606, 0.9367604]]\n",
            "268          [[0.06293901, 0.00030059606, 0.9367604]]\n",
            "269         [[0.004074629, 4.0077313e-05, 0.9958852]]\n",
            "270          [[0.74255234, 0.0046085394, 0.25283906]]\n",
            "271          [[0.9828851, 0.0037305432, 0.013384279]]\n",
            "272            [[0.006635086, 0.003990983, 0.989374]]\n",
            "273       [[0.0027173315, 0.00015341696, 0.99712926]]\n",
            "274        [[0.0079806335, 7.7616416e-05, 0.9919418]]\n",
            "275         [[0.0019043238, 0.004703974, 0.99339175]]\n",
            "276          [[0.00054372515, 0.18633656, 0.8131197]]\n",
            "277        [[0.0004028641, 2.6722033e-05, 0.9995704]]\n",
            "278         [[0.006425787, 4.6589197e-05, 0.9935276]]\n",
            "279       [[0.0026547187, 1.7857372e-05, 0.99732745]]\n",
            "280        [[0.0041716304, 0.00077907264, 0.9950493]]\n",
            "281          [[0.0014033341, 0.27815813, 0.72043854]]\n",
            "282       [[0.0007812915, 4.4056796e-05, 0.99917465]]\n",
            "283         [[0.00095581746, 0.33112094, 0.66792333]]\n",
            "284          [[0.0010904642, 0.004169144, 0.9947404]]\n",
            "285        [[0.0004959014, 0.9985726, 0.00093155337]]\n",
            "286          [[0.0019482792, 0.9826905, 0.015361175]]\n",
            "287         [[0.001361507, 0.00011174342, 0.9985267]]\n",
            "288            [[0.36098787, 0.018510008, 0.6205021]]\n",
            "289          [[0.00314009, 7.1849613e-06, 0.9968528]]\n",
            "290            [[0.36098787, 0.018510008, 0.6205021]]\n",
            "291          [[0.003947597, 6.4119376e-06, 0.996046]]\n",
            "292       [[0.0014516168, 7.5722186e-05, 0.99847263]]\n",
            "293        [[0.004663621, 1.6816211e-05, 0.99531955]]\n",
            "294            [[0.0017312213, 0.6307009, 0.3675679]]\n",
            "295           [[0.0010286088, 0.10307199, 0.8958994]]\n",
            "296           [[0.007048504, 0.16995731, 0.82299423]]\n",
            "297          [[0.000865828, 0.9973592, 0.0017749625]]\n",
            "298           [[0.00411363, 0.96252495, 0.033361375]]\n",
            "299       [[0.0052148663, 7.9287165e-05, 0.99470586]]\n",
            "300          [[0.010072515, 0.00018856999, 0.989739]]\n",
            "301            [[0.022189211, 0.16934961, 0.8084611]]\n",
            "302        [[0.0007149507, 0.99735045, 0.0019345429]]\n",
            "303          [[0.0136109395, 0.9543252, 0.032063894]]\n",
            "304         [[0.033833556, 0.0006533029, 0.96551317]]\n",
            "305             [[0.08012934, 0.08488184, 0.8349888]]\n",
            "306        [[0.0030794218, 0.0008847695, 0.99603575]]\n",
            "307        [[0.0008685298, 9.299317e-05, 0.99903846]]\n",
            "308           [[0.0018630885, 0.67388785, 0.3242491]]\n",
            "309          [[0.016913349, 0.025878873, 0.95720774]]\n",
            "310        [[0.0025216816, 0.00017473566, 0.9973035]]\n",
            "311          [[0.005083386, 2.934152e-05, 0.9948873]]\n",
            "312           [[0.011774775, 0.09416905, 0.89405626]]\n",
            "313           [[0.004062868, 0.07022709, 0.92570996]]\n",
            "314          [[0.0007714361, 0.014851765, 0.9843768]]\n",
            "315       [[0.0024781155, 0.00080428313, 0.99671763]]\n",
            "316       [[0.0046533286, 1.1668465e-05, 0.99533504]]\n",
            "317        [[0.0029019217, 1.0325595e-05, 0.9970878]]\n",
            "318        [[0.0033955344, 1.380244e-05, 0.99659073]]\n",
            "319             [[0.021102346, 0.17726877, 0.801629]]\n",
            "320          [[0.0033705859, 0.25950953, 0.73711985]]\n",
            "321           [[0.018443469, 0.031063294, 0.9504933]]\n",
            "322           [[0.009042932, 8.115251e-06, 0.990949]]\n",
            "323         [[0.0070833676, 7.089114e-06, 0.9929095]]\n",
            "324         [[0.025791954, 7.013481e-05, 0.97413784]]\n",
            "325         [[0.015383636, 5.523574e-06, 0.98461086]]\n",
            "326          [[0.66576254, 0.0019689323, 0.33226848]]\n",
            "327        [[0.0038782598, 2.0928925e-05, 0.9961008]]\n",
            "328         [[0.99964166, 0.00026032, 9.7964505e-05]]\n",
            "329        [[0.99803597, 0.0014258773, 0.0005380689]]\n",
            "330            [[0.16646495, 0.830384, 0.0031510578]]\n",
            "331           [[0.09593439, 0.89666176, 0.007403893]]\n",
            "332            [[0.02319031, 0.009168032, 0.9676416]]\n",
            "333         [[0.014680862, 1.173816e-05, 0.98530746]]\n",
            "334            [[0.38265786, 0.59327763, 0.02406452]]\n",
            "335          [[0.0012027372, 0.9773781, 0.021419223]]\n",
            "336            [[0.019901285, 0.971943, 0.008155642]]\n",
            "337          [[0.012142646, 2.5327752e-05, 0.987832]]\n",
            "338         [[0.030678775, 3.063908e-05, 0.96929055]]\n",
            "339           [[0.982205, 0.0017022898, 0.016092682]]\n",
            "340           [[0.38876182, 0.6071511, 0.0040871454]]\n",
            "341       [[0.0014378408, 2.1599895e-05, 0.99854064]]\n",
            "342       [[0.0007096294, 0.00019124494, 0.99909914]]\n",
            "343        [[0.0009115544, 5.4772234e-05, 0.9990337]]\n",
            "344           [[0.022977853, 0.017554963, 0.9594672]]\n",
            "345       [[0.012738945, 1.49713005e-05, 0.98724604]]\n",
            "346          [[0.03879932, 2.1845197e-05, 0.9611788]]\n",
            "347       [[0.99804074, 0.00033269514, 0.0016266466]]\n",
            "348         [[0.002610818, 1.8388582e-05, 0.9973707]]\n",
            "349        [[0.0023251104, 2.4037286e-05, 0.9976509]]\n",
            "350            [[0.962152, 0.017942652, 0.019905241]]\n",
            "351       [[0.9996679, 0.00019066343, 0.00014149123]]\n",
            "352          [[0.05207173, 0.00078072253, 0.9471475]]\n",
            "353          [[0.0010376737, 0.022827363, 0.9761351]]\n",
            "354        [[0.0027742672, 4.2243497e-05, 0.9971835]]\n",
            "355         [[0.003667265, 3.4087476e-05, 0.9962986]]\n",
            "356           [[0.061820224, 0.072558485, 0.8656212]]\n",
            "357          [[0.010941132, 0.030779552, 0.95827925]]\n",
            "358            [[0.03561092, 0.34551698, 0.61887217]]\n",
            "359             [[0.010405352, 0.051742, 0.93785274]]\n",
            "360             [[0.3592975, 0.04144333, 0.59925914]]\n",
            "361         [[0.0008399889, 0.9969048, 0.0022552223]]\n",
            "362         [[0.0006521934, 0.9988128, 0.0005350625]]\n",
            "363        [[0.0101290075, 0.0010565777, 0.98881453]]\n",
            "364       [[0.00076700904, 0.9986846, 0.00054838014]]\n",
            "365        [[0.0004864977, 0.99946266, 5.078834e-05]]\n",
            "366      [[0.00032595024, 0.99962795, 4.6128458e-05]]\n",
            "367           [[0.33452386, 0.65837795, 0.007098215]]\n",
            "368         [[0.0007468958, 0.9968112, 0.0024418803]]\n",
            "369         [[0.0016721705, 8.388053e-05, 0.9982439]]\n",
            "370        [[0.0018543726, 0.00025347646, 0.9978922]]\n",
            "371        [[0.0015663998, 0.00016733092, 0.9982663]]\n",
            "372         [[0.00031921317, 0.99185807, 0.00782273]]\n",
            "373           [[0.002561099, 9.85904e-06, 0.9974291]]\n",
            "374        [[0.0011288088, 2.4275958e-05, 0.9988469]]\n",
            "375         [[0.0025466122, 5.947524e-06, 0.9974475]]\n",
            "376        [[0.04279694, 1.20522955e-05, 0.95719093]]\n",
            "377          [[0.039553236, 1.1809309e-05, 0.960435]]\n",
            "378          [[0.012633844, 0.0021733574, 0.9851929]]\n",
            "379          [[0.0126085635, 0.009273975, 0.9781174]]\n",
            "380        [[0.00040917058, 0.99240655, 0.007184329]]\n",
            "381         [[0.005230634, 2.0610303e-05, 0.9947488]]\n",
            "382         [[0.9981578, 0.0004738785, 0.0013683182]]\n",
            "383        [[0.008303836, 0.00015945469, 0.99153674]]\n",
            "384           [[0.0006137471, 0.9888265, 0.01055971]]\n",
            "385             [[0.063277446, 0.2131488, 0.7235738]]\n",
            "386        [[0.0050362395, 4.2838088e-05, 0.9949209]]\n",
            "387         [[0.008642959, 0.0017174577, 0.98963964]]\n",
            "388          [[0.018486306, 3.553234e-05, 0.9814781]]\n",
            "389               [[0.1054308, 0.3274037, 0.5671655]]\n",
            "390         [[0.9956867, 0.0006003488, 0.0037128464]]\n",
            "391       [[0.0034865325, 2.0435624e-05, 0.99649304]]\n",
            "392             [[0.050887663, 0.10696739, 0.842145]]\n",
            "393           [[0.03813187, 0.00013516922, 0.961733]]\n",
            "394          [[0.08583721, 0.0016169739, 0.91254586]]\n",
            "395         [[0.0007552568, 0.9954242, 0.0038204968]]\n",
            "396          [[0.0025630207, 0.9850691, 0.012367937]]\n",
            "397        [[0.0003997628, 0.9990841, 0.00051609933]]\n",
            "398          [[0.0017474678, 0.0023345312, 0.995918]]\n",
            "399          [[0.0017057067, 0.004279897, 0.9940143]]\n",
            "400      [[0.00035336966, 0.99918145, 0.00046517103]]\n",
            "401           [[0.002431275, 0.9889759, 0.008592825]]\n",
            "402            [[0.005267577, 0.45534414, 0.5393883]]\n",
            "403          [[3.8839862e-05, 0.9977876, 0.00217351]]\n",
            "404         [[0.00050254166, 0.9763059, 0.023191478]]\n",
            "405       [[0.00012747274, 0.99817574, 0.0016967326]]\n",
            "406       [[1.6028875e-05, 0.9998016, 0.00018238228]]\n",
            "407          [[0.008491293, 0.9896484, 0.0018602959]]\n",
            "408       [[0.00012378757, 0.99542797, 0.0044481754]]\n",
            "409           [[0.007952125, 0.064431384, 0.9276164]]\n",
            "410          [[0.0074444544, 0.032786027, 0.9597696]]\n",
            "411            [[0.009894941, 0.16857761, 0.8215275]]\n",
            "412      [[0.00031924163, 0.00034788187, 0.99933285]]\n",
            "413         [[0.00032518606, 0.9849685, 0.014706313]]\n",
            "414             [[0.0024923272, 0.5792006, 0.418307]]\n",
            "415        [[0.99891925, 8.669371e-05, 0.0009941366]]\n",
            "416           [[0.007159619, 9.322456e-06, 0.992831]]\n",
            "417           [[0.9191676, 0.0003413524, 0.08049113]]\n",
            "418           [[0.7571334, 0.0009812869, 0.24188536]]\n",
            "419          [[0.007060374, 8.381088e-05, 0.9928558]]\n",
            "420         [[0.004837992, 1.1184955e-05, 0.9951508]]\n",
            "421         [[0.00291864, 1.5029293e-05, 0.99706644]]\n",
            "422            [[0.0033267408, 0.1956131, 0.8010602]]\n",
            "423           [[0.6810484, 0.0019056442, 0.31704593]]\n",
            "424           [[0.012588409, 0.107071035, 0.8803405]]\n",
            "425         [[0.999634, 4.639712e-05, 0.00031962912]]\n",
            "426          [[0.34616527, 0.0012478165, 0.65258694]]\n",
            "427        [[0.0018087913, 0.00024575752, 0.9979455]]\n",
            "428          [[0.008732583, 0.015242894, 0.97602445]]\n",
            "429         [[0.010415875, 5.8981226e-05, 0.9895251]]\n",
            "430         [[0.006285521, 1.8267136e-05, 0.9936963]]\n",
            "431        [[0.0049637267, 0.00033959933, 0.9946966]]\n",
            "432       [[0.0054873894, 1.15181365e-05, 0.9945011]]\n",
            "433         [[0.007322894, 1.5944344e-05, 0.9926611]]\n",
            "434         [[0.98583883, 7.643631e-05, 0.014084783]]\n",
            "435      [[8.8775094e-05, 0.99922824, 0.00068300415]]\n",
            "436        [[0.0039605666, 1.6904702e-05, 0.9960226]]\n",
            "437         [[0.001852851, 4.1079707e-05, 0.9981061]]\n",
            "438        [[0.0060028285, 4.9086448e-05, 0.9939481]]\n",
            "439        [[0.00039302034, 0.95061976, 0.048987255]]\n",
            "440          [[0.000616351, 0.95966417, 0.039719466]]\n",
            "441        [[0.0018825986, 0.00032996407, 0.9977875]]\n",
            "442          [[0.001456659, 0.005877927, 0.99266535]]\n",
            "443          [[0.0003156561, 0.004047729, 0.9956365]]\n",
            "444         [[0.00090438395, 0.66119695, 0.33789864]]\n",
            "445         [[0.0015850683, 7.684951e-06, 0.9984072]]\n",
            "446      [[0.0024333564, 1.18127655e-05, 0.99755484]]\n",
            "447       [[0.0008148643, 2.5767307e-05, 0.99915946]]\n",
            "448        [[0.0012611806, 0.00080309255, 0.9979358]]\n",
            "449        [[0.0012307819, 0.99409384, 0.0046754256]]\n",
            "450           [[0.0048644063, 0.7886478, 0.20648782]]\n",
            "451           [[0.004091202, 0.13343863, 0.86247015]]\n",
            "452             [[0.005873648, 0.308076, 0.68605036]]\n",
            "453            [[0.011327825, 0.07623971, 0.9124325]]\n",
            "454           [[0.0008478023, 0.975863, 0.023289211]]\n",
            "455              [[0.464512, 0.05413363, 0.48135445]]\n",
            "456       [[0.00072611764, 0.0006891502, 0.99858475]]\n",
            "457          [[0.0034542847, 0.003929232, 0.9926165]]\n",
            "458            [[0.0106491, 0.0003046128, 0.9890463]]\n",
            "459        [[0.0041947975, 1.6692093e-05, 0.9957885]]\n",
            "460        [[0.0022676578, 4.601845e-05, 0.99768627]]\n",
            "461         [[0.0045248647, 2.3158407e-05, 0.995452]]\n",
            "462            [[0.0032237074, 0.0478589, 0.9489174]]\n",
            "463          [[0.009253998, 4.409363e-05, 0.9907019]]\n",
            "464        [[0.0028130002, 0.00072457956, 0.9964624]]\n",
            "465       [[0.0036895194, 1.4692389e-05, 0.99629575]]\n",
            "466         [[5.2474246e-05, 0.997735, 0.0022124576]]\n",
            "467          [[0.082983255, 0.0057138735, 0.9113028]]\n",
            "468             [[0.8529459, 0.07392829, 0.07312573]]\n",
            "469          [[0.001032422, 0.020592283, 0.97837526]]\n",
            "470            [[0.03162968, 0.31933692, 0.64903337]]\n",
            "471           [[0.04588416, 9.201974e-05, 0.9540239]]\n",
            "472       [[0.0022921714, 2.5372874e-05, 0.99768245]]\n",
            "473           [[0.04588416, 9.201974e-05, 0.9540239]]\n",
            "474        [[0.0011790484, 0.00058105745, 0.9982399]]\n",
            "475            [[0.01010696, 0.044584308, 0.9453087]]\n",
            "476       [[0.0007665217, 0.00030639512, 0.99892706]]\n",
            "477          [[0.0011598609, 0.004632668, 0.9942075]]\n",
            "478          [[0.0039598783, 0.019124202, 0.9769159]]\n",
            "479         [[0.00742512, 2.2783497e-05, 0.99255204]]\n",
            "480            [[0.0023164477, 0.68049854, 0.317185]]\n",
            "481        [[0.0011482579, 6.131811e-05, 0.99879044]]\n",
            "482          [[0.0051458143, 0.82276326, 0.17209092]]\n",
            "483         [[0.0017918124, 8.406809e-06, 0.9981997]]\n",
            "484       [[0.0008302768, 0.00018624829, 0.99898344]]\n",
            "485           [[0.00196154, 3.868814e-05, 0.9979997]]\n",
            "486          [[0.002170093, 0.098183066, 0.89964676]]\n",
            "487           [[0.0023572638, 0.22677454, 0.7708681]]\n",
            "488         [[0.0016220887, 0.020898858, 0.97747904]]\n",
            "489       [[0.00070640707, 0.0121904155, 0.98710316]]\n",
            "490          [[0.0035485132, 0.015049357, 0.9814022]]\n",
            "491           [[0.06534305, 0.0010517311, 0.9336052]]\n",
            "492         [[0.0009220834, 9.778788e-06, 0.9990682]]\n",
            "493      [[0.00073254225, 4.6011086e-05, 0.99922144]]\n",
            "494      [[0.00095244055, 2.4161362e-05, 0.99902344]]\n",
            "495         [[0.00057055964, 0.16698195, 0.83244747]]\n",
            "496             [[0.019670136, 0.530488, 0.44984183]]\n",
            "497          [[0.95553225, 0.016153049, 0.028314725]]\n",
            "498        [[0.0018943142, 7.3562614e-06, 0.9980983]]\n",
            "499           [[0.032617126, 0.34223875, 0.62514406]]\n",
            "500       [[0.0033893196, 2.4713854e-05, 0.99658597]]\n",
            "501         [[0.012094988, 2.4649098e-05, 0.9878804]]\n",
            "502              [[0.00346942, 0.039050546, 0.95748]]\n",
            "503         [[0.026533207, 0.0026119468, 0.97085494]]\n",
            "504          [[0.111009344, 0.0035870967, 0.8854035]]\n",
            "505          [[0.0037174826, 0.035344318, 0.9609382]]\n",
            "506       [[0.0035379806, 0.00041084972, 0.99605125]]\n",
            "507       [[4.0286348e-05, 0.99819857, 0.0017611732]]\n",
            "508         [[0.0005790232, 0.99501085, 0.004410172]]\n",
            "509         [[0.00070155214, 0.06114533, 0.93815315]]\n",
            "510       [[0.00054780405, 4.8466092e-05, 0.9994037]]\n",
            "511        [[0.002653439, 3.9524668e-05, 0.99730706]]\n",
            "512        [[0.004432451, 8.8099505e-06, 0.99555874]]\n",
            "513          [[0.0017688493, 7.03348e-06, 0.9982241]]\n",
            "514          [[0.00405784, 3.4982797e-06, 0.9959388]]\n",
            "515          [[0.0047371774, 0.003478097, 0.9917848]]\n",
            "516        [[0.006334393, 0.000121488585, 0.9935441]]\n",
            "517            [[0.002513969, 0.5275497, 0.46993634]]\n",
            "518          [[0.0052396767, 0.91949993, 0.07526041]]\n",
            "519        [[0.0051584844, 0.0016376723, 0.99320376]]\n",
            "520         [[0.0036880246, 0.0027392872, 0.9935727]]\n",
            "521        [[0.0037756956, 0.00013756551, 0.9960867]]\n",
            "522         [[0.0015988599, 3.475015e-05, 0.9983664]]\n",
            "523       [[0.0013181384, 1.2105927e-05, 0.99866974]]\n",
            "524         [[0.008307842, 3.9846196e-05, 0.9916523]]\n",
            "525        [[0.009169926, 0.00094110717, 0.98988897]]\n",
            "526            [[0.015857974, 0.9028138, 0.08132829]]\n",
            "527         [[0.018050302, 0.0065539884, 0.97539574]]\n",
            "528         [[0.009957717, 4.8360063e-05, 0.9899939]]\n",
            "529            [[0.003920448, 0.37246597, 0.6236136]]\n",
            "530           [[0.10504191, 0.0011561807, 0.8938019]]\n",
            "531         [[0.023933453, 8.8240085e-05, 0.9759783]]\n",
            "532       [[0.0019098328, 1.2985109e-05, 0.99807715]]\n",
            "533         [[0.0015738518, 7.474355e-06, 0.9984187]]\n",
            "534      [[0.00069901824, 0.00017732222, 0.99912363]]\n",
            "535           [[0.006229843, 0.16993906, 0.82383114]]\n",
            "536        [[0.0005384106, 0.0022778474, 0.99718374]]\n",
            "537         [[0.002605265, 4.0362906e-05, 0.9973544]]\n",
            "538          [[0.83844805, 0.16072905, 0.0008229272]]\n",
            "539           [[0.039733265, 0.79571795, 0.16454877]]\n",
            "540           [[0.013880929, 0.013011231, 0.9731078]]\n",
            "541           [[0.9616323, 0.03704315, 0.0013244902]]\n",
            "542           [[0.025970617, 0.26216903, 0.71186036]]\n",
            "543       [[0.0038121962, 0.00019214783, 0.99599564]]\n",
            "544        [[0.0008974004, 0.00041549501, 0.9986871]]\n",
            "545       [[0.0011549052, 8.7764245e-05, 0.99875736]]\n",
            "546      [[2.2476555e-05, 0.99966955, 0.00030801588]]\n",
            "547         [[0.014589867, 6.7907404e-06, 0.9854033]]\n",
            "548         [[0.002710676, 2.1132237e-05, 0.9972682]]\n",
            "549         [[0.008634057, 0.00011539549, 0.9912505]]\n",
            "550        [[0.9997373, 5.029929e-05, 0.00021234024]]\n",
            "551           [[0.24387585, 0.70087236, 0.055251773]]\n",
            "552           [[0.018950814, 0.12008025, 0.86096895]]\n",
            "553           [[0.003578823, 0.09036722, 0.90605396]]\n",
            "554            [[0.002583993, 0.28365624, 0.7137598]]\n",
            "555             [[0.00128389, 0.6440913, 0.35462475]]\n",
            "556       [[0.0018995177, 2.3995626e-05, 0.99807644]]\n",
            "557       [[0.0036606907, 9.8559234e-05, 0.99624074]]\n",
            "558        [[0.0027720376, 3.3467128e-05, 0.9971944]]\n",
            "559             [[0.14429016, 0.11516135, 0.7405485]]\n",
            "560        [[0.009127715, 0.00020811374, 0.99066424]]\n",
            "561        [[0.00042244323, 0.0004879742, 0.9990896]]\n",
            "562       [[0.00028209077, 0.0044549634, 0.99526286]]\n",
            "563           [[0.0013201445, 0.04478147, 0.9538985]]\n",
            "564        [[0.0014201584, 1.8019551e-05, 0.9985619]]\n",
            "565          [[0.0021883969, 0.032956097, 0.9648555]]\n",
            "566            [[0.0017835514, 0.32722834, 0.670988]]\n",
            "567         [[0.002086656, 1.434643e-05, 0.99789894]]\n",
            "568             [[0.0013312896, 0.48304868, 0.51562]]\n",
            "569         [[0.0007024919, 7.401319e-05, 0.9992235]]\n",
            "570          [[0.0004560293, 0.000757692, 0.9987863]]\n",
            "571        [[0.0009528427, 5.306548e-05, 0.99899405]]\n",
            "572       [[0.0023618736, 1.1159201e-05, 0.99762696]]\n",
            "573        [[0.0015081675, 3.548513e-05, 0.99845636]]\n",
            "574          [[0.008737615, 0.00010834346, 0.991154]]\n",
            "575             [[0.01699929, 0.01782817, 0.9651725]]\n",
            "576          [[0.0070119933, 0.019725727, 0.9732623]]\n",
            "577        [[0.0034763056, 0.0015991402, 0.99492455]]\n",
            "578         [[0.9977876, 0.00047234786, 0.001740052]]\n",
            "579           [[0.3878929, 0.00041097522, 0.6116962]]\n",
            "580           [[0.94442993, 0.00261958, 0.052950393]]\n",
            "581      [[0.0044471994, 0.000107665495, 0.99544513]]\n",
            "582      [[0.00093830726, 0.00034412227, 0.99871767]]\n",
            "583         [[0.0030387447, 9.653652e-06, 0.9969516]]\n",
            "584          [[0.9573789, 0.0039131525, 0.038707882]]\n",
            "585       [[0.0029535184, 0.000107933825, 0.9969386]]\n",
            "586            [[0.9474833, 0.042606995, 0.00990972]]\n",
            "587         [[0.012498525, 3.4412365e-05, 0.9874671]]\n",
            "588             [[0.5368405, 0.456929, 0.0062304875]]\n",
            "589         [[0.018983915, 0.97869027, 0.0023257793]]\n",
            "590        [[0.0032148813, 1.2275892e-05, 0.9967728]]\n",
            "591        [[0.0018066909, 0.0001187339, 0.99807453]]\n",
            "592         [[0.016138727, 1.2846071e-05, 0.9838484]]\n",
            "593         [[0.042463277, 3.549379e-05, 0.95750123]]\n",
            "594        [[0.0035329598, 2.1657808e-05, 0.9964455]]\n",
            "595          [[0.0002732586, 0.9805502, 0.019176519]]\n",
            "596           [[0.7313097, 0.0010302282, 0.26766008]]\n",
            "597       [[0.0027091021, 1.2297815e-05, 0.99727863]]\n",
            "598        [[0.0022817517, 4.6821853e-05, 0.9976714]]\n",
            "599         [[0.0055691875, 0.0005163872, 0.9939144]]\n",
            "600       [[0.0072990744, 1.2030971e-05, 0.99268883]]\n",
            "601          [[0.007469448, 0.98738664, 0.005143941]]\n",
            "602         [[0.021016534, 0.0016077084, 0.97737575]]\n",
            "603        [[0.0023863057, 1.5116943e-05, 0.9975986]]\n",
            "604          [[0.06632153, 0.0016554757, 0.93202305]]\n",
            "605          [[0.010404126, 0.0008477103, 0.9887482]]\n",
            "606         [[0.013734834, 3.0436377e-05, 0.9862347]]\n",
            "607        [[0.9991999, 2.1457596e-05, 0.0007786791]]\n",
            "608         [[0.001433429, 1.3908361e-05, 0.9985526]]\n",
            "609         [[0.0024269405, 0.0006515205, 0.9969215]]\n",
            "610        [[0.0047321455, 7.121987e-05, 0.99519664]]\n",
            "611          [[0.00502983, 6.722406e-05, 0.99490297]]\n",
            "612          [[0.12915248, 0.00061584555, 0.8702317]]\n",
            "613       [[0.023168372, 1.13124115e-05, 0.97682035]]\n",
            "614           [[0.008043832, 0.81777084, 0.17418538]]\n",
            "615          [[0.9912515, 0.0006953309, 0.008053185]]\n",
            "616            [[0.7002711, 0.0023257984, 0.2974031]]\n",
            "617           [[0.8664938, 0.0012056312, 0.13230054]]\n",
            "618           [[0.08416491, 0.004247582, 0.91158754]]\n",
            "619        [[0.00031708772, 0.9982681, 0.0014147048]]\n",
            "620             [[0.0018665278, 0.915743, 0.0823905]]\n",
            "621         [[0.00019360347, 0.9653177, 0.034488704]]\n",
            "622           [[0.002417839, 0.001014503, 0.9965676]]\n",
            "623        [[0.0008547454, 0.99732935, 0.0018158888]]\n",
            "624        [[0.00013763177, 0.9974802, 0.0023821758]]\n",
            "625        [[0.00043512127, 0.9936824, 0.0058825235]]\n",
            "626         [[0.018606843, 5.906341e-05, 0.98133415]]\n",
            "627       [[0.00053724286, 0.99766433, 0.0017984497]]\n",
            "628        [[0.00026697016, 0.9973322, 0.0024008087]]\n",
            "629         [[6.678475e-05, 0.999688, 0.00024523638]]\n",
            "630         [[0.00021610105, 0.003675403, 0.9961085]]\n",
            "631         [[0.0011792494, 8.494899e-06, 0.9988123]]\n",
            "632       [[0.00090666284, 1.9206089e-05, 0.9990741]]\n",
            "633        [[0.0023644909, 5.9294434e-06, 0.9976295]]\n",
            "634        [[0.000568618, 2.3120609e-05, 0.99940825]]\n",
            "635        [[0.006196363, 2.7162972e-05, 0.99377656]]\n",
            "636         [[0.018448954, 2.8873788e-05, 0.9815221]]\n",
            "637             [[0.381642, 0.033901725, 0.58445626]]\n",
            "638        [[0.9992391, 3.1447544e-05, 0.0007294592]]\n",
            "639       [[0.9991722, 2.8281565e-05, 0.00079960644]]\n",
            "640         [[0.0045088604, 1.068485e-05, 0.9954804]]\n",
            "641          [[0.109571874, 0.88249433, 0.007933845]]\n",
            "642         [[0.94589686, 0.0011133867, 0.052989762]]\n",
            "643        [[0.0065767327, 1.1014201e-05, 0.9934123]]\n",
            "644        [[0.004818046, 1.6039914e-05, 0.99516594]]\n",
            "645         [[0.008676859, 0.0002643897, 0.99105877]]\n",
            "646           [[0.0015092787, 0.5739439, 0.42454687]]\n",
            "647          [[0.0027009412, 0.052439433, 0.9448597]]\n",
            "648           [[0.011189471, 0.74835926, 0.24045126]]\n",
            "649            [[0.002371341, 0.7821185, 0.21551019]]\n",
            "650             [[0.00693883, 0.41335496, 0.5797062]]\n",
            "651          [[0.003962433, 5.722871e-05, 0.9959804]]\n",
            "652           [[0.9191841, 0.07754643, 0.0032695502]]\n",
            "653           [[0.96798295, 0.00352746, 0.028489618]]\n",
            "654          [[0.011637908, 8.798709e-06, 0.9883533]]\n",
            "655         [[0.007697574, 2.0361615e-05, 0.9922821]]\n",
            "656             [[0.5089922, 0.37104812, 0.11995972]]\n",
            "657         [[0.011864533, 1.3059078e-05, 0.9881224]]\n",
            "658         [[0.014540562, 3.3280074e-05, 0.9854262]]\n",
            "659             [[0.002592415, 0.22243054, 0.774977]]\n",
            "660        [[0.001650591, 0.00014016763, 0.99820924]]\n",
            "661        [[0.0021286588, 6.379746e-05, 0.99780756]]\n",
            "662           [[0.008767903, 0.01112413, 0.98010796]]\n",
            "663        [[0.0017145249, 8.612914e-05, 0.99819934]]\n",
            "664         [[0.0009893363, 0.0010305401, 0.9979802]]\n",
            "665         [[0.0011420127, 0.006661457, 0.99219656]]\n",
            "666          [[0.032260276, 0.023314912, 0.94442475]]\n",
            "667            [[0.017753301, 0.7423304, 0.23991637]]\n",
            "668            [[0.587784, 0.0031352574, 0.40908074]]\n",
            "669            [[0.05223664, 0.03063555, 0.91712785]]\n",
            "670         [[0.0067932275, 0.0041156905, 0.9890911]]\n",
            "671        [[0.0016586902, 0.0002282421, 0.99811316]]\n",
            "672           [[0.0025371085, 0.8383188, 0.15914407]]\n",
            "673          [[0.025758851, 0.9726432, 0.0015979955]]\n",
            "674       [[0.00010950289, 0.99862826, 0.0012622958]]\n",
            "675             [[0.10620569, 0.7215098, 0.17228445]]\n",
            "676          [[0.85931814, 0.13586661, 0.0048152697]]\n",
            "677           [[0.6686147, 0.31684765, 0.0145376865]]\n",
            "678           [[0.008229193, 0.9846209, 0.007149844]]\n",
            "679         [[0.008655672, 0.98700017, 0.0043441732]]\n",
            "680           [[0.53590924, 0.45149118, 0.012599628]]\n",
            "681         [[0.9978192, 0.0004301242, 0.0017507119]]\n",
            "682          [[0.9904033, 0.008565628, 0.0010310509]]\n",
            "683         [[0.93984646, 0.058554877, 0.0015987227]]\n",
            "684         [[0.0045781564, 0.038155932, 0.95726585]]\n",
            "685        [[0.0059555634, 3.2805634e-05, 0.9940116]]\n",
            "686          [[0.00020704817, 0.9878391, 0.01195389]]\n",
            "687           [[0.0019064614, 0.9599918, 0.03810176]]\n",
            "688       [[0.00010953008, 0.99851435, 0.0013761066]]\n",
            "689        [[0.9917401, 0.000106671876, 0.008153296]]\n",
            "690        [[0.0109042125, 7.742807e-06, 0.98908806]]\n",
            "691        [[0.0036035315, 0.00047694254, 0.9959196]]\n",
            "692          [[7.126978e-05, 0.9961145, 0.003814255]]\n",
            "693          [[0.0006591561, 0.86525744, 0.13408339]]\n",
            "694            [[0.0011819784, 0.8579208, 0.1408972]]\n",
            "695       [[0.00024572923, 0.99646145, 0.0032928463]]\n",
            "696         [[0.0004896474, 0.98429155, 0.015218836]]\n",
            "697       [[0.0022360955, 6.0154965e-05, 0.99770373]]\n",
            "698         [[0.0034550317, 4.46999e-05, 0.99650025]]\n",
            "699         [[0.0025939622, 2.036797e-05, 0.9973857]]\n",
            "700        [[0.00062048616, 4.008896e-05, 0.9993394]]\n",
            "701        [[0.0007720947, 0.00043310833, 0.9987947]]\n",
            "702              [[0.0729587, 0.07561304, 0.8514282]]\n",
            "703        [[0.0047793277, 4.5206456e-05, 0.9951755]]\n",
            "704         [[0.000886326, 0.0012833237, 0.99783033]]\n",
            "705         [[0.008201878, 0.00018858365, 0.9916095]]\n",
            "706             [[0.47490484, 0.2672773, 0.25781786]]\n",
            "707         [[0.0005890517, 0.9980872, 0.0013237364]]\n",
            "708       [[7.6185745e-05, 0.99227273, 0.0076511255]]\n",
            "709         [[5.390569e-05, 0.9966888, 0.0032572958]]\n",
            "710          [[0.010228515, 0.008794768, 0.98097664]]\n",
            "711            [[0.058290027, 0.9009756, 0.04073435]]\n",
            "712            [[0.40020052, 0.39918864, 0.20061079]]\n",
            "713           [[0.015590165, 0.9593636, 0.025046239]]\n",
            "714         [[0.008356871, 0.00022059174, 0.9914226]]\n",
            "715        [[0.00011108447, 0.9947127, 0.0051762145]]\n",
            "716         [[0.009602874, 0.00031176666, 0.9900855]]\n",
            "717             [[0.29238787, 0.6562604, 0.05135179]]\n",
            "718           [[0.01406618, 0.96670836, 0.019225473]]\n",
            "719        [[0.0015528572, 0.00073586754, 0.9977113]]\n",
            "720      [[0.000107065745, 0.9992016, 0.00069139176]]\n",
            "721       [[0.00029039456, 0.9992649, 0.00044471974]]\n",
            "722          [[0.018893423, 6.928166e-05, 0.9810373]]\n",
            "723        [[0.006656861, 1.2594093e-05, 0.99333054]]\n",
            "724         [[0.9982253, 0.0002892725, 0.0014854644]]\n",
            "725       [[0.9996258, 2.2097747e-05, 0.00035218112]]\n",
            "726          [[0.951624, 0.00057073747, 0.047805298]]\n",
            "727              [[0.08443068, 0.16824737, 0.747322]]\n",
            "728           [[0.009239608, 0.9464328, 0.044327606]]\n",
            "729        [[0.020425098, 1.6916068e-05, 0.97955793]]\n",
            "730          [[0.0020705, 0.00011825965, 0.99781126]]\n",
            "731             [[0.011765892, 0.1564814, 0.8317527]]\n",
            "732        [[0.0020670227, 2.7481605e-05, 0.9979055]]\n",
            "733             [[0.13109782, 0.6457532, 0.22314891]]\n",
            "734         [[0.018196141, 0.00015658457, 0.9816473]]\n",
            "735           [[0.72233546, 0.0004846934, 0.2771799]]\n",
            "736            [[0.52592427, 0.31409883, 0.15997683]]\n",
            "737             [[0.6637884, 0.23393402, 0.10227754]]\n",
            "738            [[0.15762807, 0.65820044, 0.18417153]]\n",
            "739           [[0.72233546, 0.0004846934, 0.2771799]]\n",
            "740            [[0.6972222, 0.090453304, 0.21232449]]\n",
            "741       [[0.0022584873, 0.00034881948, 0.99739265]]\n",
            "742        [[0.00097044243, 0.021359917, 0.97766954]]\n",
            "743         [[0.0004672152, 0.0028003003, 0.9967325]]\n",
            "744          [[0.007382797, 0.033132482, 0.95948464]]\n",
            "745         [[6.5390996e-05, 0.997556, 0.0023786435]]\n",
            "746        [[0.000106802676, 0.9957963, 0.004096848]]\n",
            "747        [[0.053179804, 0.000103645114, 0.9467166]]\n",
            "748          [[0.0005347558, 0.011887583, 0.9875777]]\n",
            "749         [[0.009174882, 0.00018766984, 0.9906375]]\n",
            "750        [[0.00029960895, 0.95898783, 0.040712606]]\n",
            "751          [[0.058193337, 0.000942957, 0.94086367]]\n",
            "752              [[0.12640902, 0.5184906, 0.3551003]]\n",
            "753        [[0.0009846872, 0.00081249874, 0.9982028]]\n",
            "754         [[0.00089462736, 0.94654155, 0.05256388]]\n",
            "755            [[0.0010493338, 0.00723671, 0.991714]]\n",
            "756         [[5.336688e-05, 0.9983948, 0.0015518203]]\n",
            "757          [[0.0019566333, 1.3380733e-05, 0.99803]]\n",
            "758           [[0.0008226549, 0.9168085, 0.08236881]]\n",
            "759        [[0.005605774, 1.1435909e-05, 0.99438286]]\n",
            "760        [[0.0086773215, 1.6143063e-05, 0.9913065]]\n",
            "761            [[0.1304841, 0.8632732, 0.0062427092]]\n",
            "762         [[0.0006054619, 0.99696213, 0.002432369]]\n",
            "763       [[0.0068909368, 2.4577468e-05, 0.99308443]]\n",
            "764          [[0.19548438, 0.0125875445, 0.79192805]]\n",
            "765           [[0.22351478, 0.0055151656, 0.7709701]]\n",
            "766           [[0.9169179, 0.047977585, 0.035104387]]\n",
            "767           [[0.50124127, 0.102973446, 0.39578527]]\n",
            "768         [[0.005469141, 9.739835e-06, 0.99452114]]\n",
            "769           [[0.02922473, 0.00013235166, 0.970643]]\n",
            "770         [[0.0005864844, 0.9962475, 0.0031660618]]\n",
            "771          [[0.07215467, 0.00025394326, 0.9275913]]\n",
            "772          [[0.020010987, 3.99406e-05, 0.97994906]]\n",
            "773           [[0.0009450942, 0.8760926, 0.12296222]]\n",
            "774         [[0.0024726512, 0.9939879, 0.0035394304]]\n",
            "775            [[0.00968918, 0.00863579, 0.98167497]]\n",
            "776         [[0.0016859351, 0.00012906415, 0.998185]]\n",
            "777         [[0.024672447, 0.0010244859, 0.97430307]]\n",
            "778        [[0.00013627717, 0.9993242, 0.0005395735]]\n",
            "779            [[0.01448954, 0.18343346, 0.80207705]]\n",
            "780          [[0.05456973, 0.0001389679, 0.94529134]]\n",
            "781           [[0.012006574, 0.045411255, 0.9425822]]\n",
            "782        [[0.00034708515, 0.0010037665, 0.9986492]]\n",
            "783        [[0.0015919631, 9.057516e-06, 0.99839896]]\n",
            "784         [[0.0012509811, 2.2014865e-05, 0.998727]]\n",
            "785         [[0.0050879577, 0.0010682906, 0.9938438]]\n",
            "786            [[0.18212804, 0.28279346, 0.53507847]]\n",
            "787         [[0.0029995767, 0.00015344801, 0.996847]]\n",
            "788         [[0.009456275, 3.0004157e-05, 0.9905137]]\n",
            "789          [[0.0057298876, 0.0018860535, 0.992384]]\n",
            "790        [[0.9987557, 2.7883805e-05, 0.0012164955]]\n",
            "791        [[0.99925095, 0.00022095452, 0.000528014]]\n",
            "792        [[0.9984958, 5.8167803e-05, 0.0014459365]]\n",
            "793           [[0.007138282, 0.003593539, 0.9892681]]\n",
            "794         [[7.2340896e-05, 0.9939421, 0.005985563]]\n",
            "795           [[0.012379273, 0.80918694, 0.17843376]]\n",
            "796        [[0.00025996432, 0.9957581, 0.0039819097]]\n",
            "797           [[9.4314e-05, 0.9907815, 0.0091241505]]\n",
            "798              [[0.014124615, 0.826484, 0.1593913]]\n",
            "799          [[0.0056297397, 0.18400933, 0.81036097]]\n",
            "800        [[0.00037131796, 0.9953607, 0.0042680413]]\n",
            "801            [[0.17335245, 0.8068177, 0.019829841]]\n",
            "802          [[0.0105779655, 0.9639163, 0.025505703]]\n",
            "803       [[0.0046311845, 7.6093543e-06, 0.99536127]]\n",
            "804         [[0.0036224423, 9.190111e-06, 0.9963684]]\n",
            "805        [[0.00022054513, 0.97382563, 0.025953777]]\n",
            "806            [[0.9885389, 0.00066197, 0.010799147]]\n",
            "807           [[0.66038674, 0.050804906, 0.28880835]]\n",
            "808           [[0.0017327412, 0.5071308, 0.49113646]]\n",
            "809         [[0.00082085765, 0.85615236, 0.14302677]]\n",
            "810          [[0.6446586, 2.4797404e-05, 0.35531652]]\n",
            "811         [[0.016873354, 2.888051e-05, 0.98309785]]\n",
            "812         [[0.0006007746, 0.95277715, 0.046622165]]\n",
            "813           [[0.0017941255, 0.7349029, 0.26330292]]\n",
            "814         [[0.00030902168, 0.98899627, 0.01069466]]\n",
            "815          [[0.029610634, 0.9692788, 0.0011106012]]\n",
            "816          [[0.81423676, 0.18298937, 0.0027739094]]\n",
            "817          [[0.0022529464, 0.52343124, 0.47431582]]\n",
            "818           [[0.9618728, 0.025619155, 0.012508068]]\n",
            "819         [[0.010601244, 1.3568057e-05, 0.9893852]]\n",
            "820         [[0.004020235, 2.1172102e-05, 0.9959586]]\n",
            "821            [[0.14430568, 0.31519932, 0.54049504]]\n",
            "822          [[0.011503337, 0.003757225, 0.98473954]]\n",
            "823         [[0.006841497, 1.5974987e-05, 0.9931425]]\n",
            "824         [[0.9885994, 0.00078856316, 0.010612052]]\n",
            "825         [[0.9901923, 0.00039973418, 0.009408064]]\n",
            "826         [[0.004955427, 2.0846945e-05, 0.9950237]]\n",
            "827        [[0.0034067594, 1.9912766e-05, 0.9965733]]\n",
            "828         [[0.0018825752, 0.0021975716, 0.9959198]]\n",
            "829           [[0.02412565, 8.9339024e-05, 0.975785]]\n",
            "830        [[0.024005126, 2.4094845e-05, 0.97597075]]\n",
            "831        [[0.0143219335, 6.7775486e-06, 0.9856712]]\n",
            "832         [[0.0045471424, 9.649662e-05, 0.9953564]]\n",
            "833        [[0.0005450162, 0.00034942597, 0.9991055]]\n",
            "834           [[0.0011434575, 0.0002465587, 0.99861]]\n",
            "835        [[0.008880983, 1.17143645e-05, 0.9911073]]\n",
            "836           [[0.006836974, 0.007445053, 0.9857179]]\n",
            "837           [[0.0075592636, 0.4139618, 0.57847893]]\n",
            "838           [[0.0009136348, 0.05157086, 0.9475154]]\n",
            "839        [[0.0032183505, 1.2257683e-05, 0.9967694]]\n",
            "840          [[0.027730023, 0.0004041472, 0.9718659]]\n",
            "841          [[0.9641501, 0.00028334834, 0.03556665]]\n",
            "842           [[0.00683275, 0.0003130144, 0.9928542]]\n",
            "843       [[0.0033977227, 2.7248012e-05, 0.99657506]]\n",
            "844          [[0.008243843, 0.98548996, 0.006266148]]\n",
            "845           [[0.03283264, 0.0023913628, 0.9647759]]\n",
            "846         [[0.015017747, 4.6364992e-05, 0.9849358]]\n",
            "847        [[0.0055200774, 2.4633842e-05, 0.9944553]]\n",
            "848        [[0.0024608015, 0.00020886952, 0.9973303]]\n",
            "849          [[0.0021310535, 0.25438762, 0.74348134]]\n",
            "850        [[0.002353803, 6.1128067e-06, 0.99764013]]\n",
            "851         [[0.0016613669, 9.959715e-06, 0.9983286]]\n",
            "852         [[0.0026893779, 9.48078e-06, 0.99730116]]\n",
            "853          [[0.0019213472, 0.0005906689, 0.997488]]\n",
            "854             [[0.2989749, 0.65208554, 0.04893952]]\n",
            "855            [[0.43948662, 0.18342507, 0.37708837]]\n",
            "856              [[0.3442056, 0.58491004, 0.0708844]]\n",
            "857         [[0.004281663, 0.00014385355, 0.9955745]]\n",
            "858              [[0.07718383, 0.36735114, 0.555465]]\n",
            "859          [[0.024176309, 0.092911154, 0.88291246]]\n",
            "860       [[0.9995466, 0.00018362114, 0.00026972214]]\n",
            "861         [[0.018863639, 6.5791624e-05, 0.9810705]]\n",
            "862        [[7.9675905e-05, 0.9981844, 0.0017359372]]\n",
            "863            [[0.7950566, 0.19504559, 0.009897819]]\n",
            "864          [[0.027736733, 0.9662704, 0.0059928414]]\n",
            "865       [[0.0021298141, 3.9859893e-05, 0.99783033]]\n",
            "866          [[0.0010219774, 0.94145066, 0.05752739]]\n",
            "867           [[0.0009384217, 0.1293068, 0.86975473]]\n",
            "868         [[0.00523879, 0.00036934682, 0.99439186]]\n",
            "869             [[0.719593, 0.2769565, 0.0034505413]]\n",
            "870           [[0.075073965, 0.8966064, 0.028319614]]\n",
            "871           [[0.9580107, 0.03853989, 0.0034494402]]\n",
            "872           [[0.9580107, 0.03853989, 0.0034494402]]\n",
            "873            [[0.025245294, 0.13390401, 0.8408508]]\n",
            "874            [[0.10763101, 0.66035783, 0.23201114]]\n",
            "875            [[0.79447716, 0.09396892, 0.11155389]]\n",
            "876          [[0.004423947, 0.9933067, 0.0022693202]]\n",
            "877         [[0.00045935423, 0.002243483, 0.9972971]]\n",
            "878          [[0.002217955, 1.850506e-05, 0.9977635]]\n",
            "879        [[0.0052100704, 1.4150773e-05, 0.9947758]]\n",
            "880             [[0.8800408, 0.06081638, 0.05914276]]\n",
            "881            [[0.5127534, 0.48357275, 0.003673784]]\n",
            "882             [[0.3362482, 0.6536332, 0.010118572]]\n",
            "883         [[0.0028835603, 7.314705e-05, 0.9970433]]\n",
            "884          [[0.004436802, 0.055962842, 0.93960035]]\n",
            "885        [[0.005937031, 1.21258845e-05, 0.9940509]]\n",
            "886           [[0.010195991, 8.943599e-06, 0.989795]]\n",
            "887         [[0.010124201, 0.00091312616, 0.9889627]]\n",
            "888           [[0.004727738, 0.9503114, 0.044960793]]\n",
            "889         [[0.004679523, 0.0013044288, 0.99401605]]\n",
            "890          [[0.004983053, 7.2048795e-05, 0.994945]]\n",
            "891          [[0.01064319, 0.0005021956, 0.98885465]]\n",
            "892          [[0.0046420125, 0.028133048, 0.9672249]]\n",
            "893        [[0.0051219477, 9.340912e-05, 0.99478465]]\n",
            "894         [[0.0002830344, 0.99640614, 0.003310742]]\n",
            "895      [[0.000107860666, 0.99917823, 0.0007139388]]\n",
            "896             [[0.002154449, 0.008485622, 0.98936]]\n",
            "897        [[0.0021634945, 2.315104e-05, 0.99781334]]\n",
            "898        [[0.0017292752, 4.747192e-06, 0.99826604]]\n",
            "899        [[0.002106399, 8.3080005e-05, 0.99781054]]\n",
            "900           [[0.001266424, 6.553138e-06, 0.998727]]\n",
            "901         [[0.00041900817, 0.96451235, 0.03506863]]\n",
            "902           [[0.9655389, 0.021435041, 0.013025958]]\n",
            "903            [[0.8235071, 0.15341833, 0.023074603]]\n",
            "904          [[0.21156143, 0.78695506, 0.0014835205]]\n",
            "905        [[0.0009762682, 0.9988771, 0.00014667271]]\n",
            "906           [[0.009422161, 0.86491233, 0.12566553]]\n",
            "907           [[0.039647635, 0.959364, 0.0009883444]]\n",
            "908              [[0.768516, 0.15432274, 0.07716128]]\n",
            "909          [[0.047488432, 0.008566243, 0.94394535]]\n",
            "910           [[0.9835227, 0.01237104, 0.0041062557]]\n",
            "911              [[0.032591056, 0.0727129, 0.894696]]\n",
            "912           [[0.95512426, 0.03690944, 0.007966264]]\n",
            "913             [[0.6967245, 0.25720072, 0.04607486]]\n",
            "914         [[0.98842794, 0.0005294683, 0.011042548]]\n",
            "915        [[0.0041283076, 3.5292043e-05, 0.9958364]]\n",
            "916           [[0.9513536, 0.045269314, 0.003377172]]\n",
            "917        [[0.99709725, 0.0017328457, 0.0011699317]]\n",
            "918          [[0.084028564, 0.9140051, 0.0019663356]]\n",
            "919         [[0.016370067, 0.0050963173, 0.97853357]]\n",
            "920            [[0.082956254, 0.03520089, 0.8818428]]\n",
            "921            [[0.993339, 0.004254339, 0.002406656]]\n",
            "922        [[0.0009262593, 0.9985177, 0.00055602565]]\n",
            "923        [[0.0056429277, 0.00012659843, 0.9942305]]\n",
            "924           [[0.14352782, 0.012308296, 0.84416384]]\n",
            "925         [[0.003219895, 0.0024562536, 0.99432385]]\n",
            "926          [[0.0120679205, 0.08363602, 0.90429604]]\n",
            "927          [[0.00014323827, 0.998099, 0.001757792]]\n",
            "928       [[0.0070037656, 5.1104627e-05, 0.99294513]]\n",
            "929         [[0.008665206, 0.0013019254, 0.99003285]]\n",
            "930             [[0.00443843, 0.3057625, 0.68979913]]\n",
            "931           [[0.0066262507, 0.08122009, 0.9121537]]\n",
            "932           [[0.0039119893, 0.81994164, 0.1761464]]\n",
            "933          [[0.007046603, 0.0023464148, 0.9906069]]\n",
            "934           [[0.06963064, 0.00011436266, 0.930255]]\n",
            "935           [[0.06963064, 0.00011436266, 0.930255]]\n",
            "936        [[0.017312469, 1.8309604e-05, 0.98266923]]\n",
            "937         [[0.014681514, 0.00021773488, 0.9851008]]\n",
            "938         [[0.009940804, 1.4731225e-05, 0.9900445]]\n",
            "939         [[0.012302923, 0.00022581268, 0.9874713]]\n",
            "940          [[0.0011891099, 0.0017979131, 0.997013]]\n",
            "941            [[0.003502387, 0.02593275, 0.9705649]]\n",
            "942         [[0.0031830987, 0.99037045, 0.006446467]]\n",
            "943      [[0.00073373644, 1.2870574e-05, 0.99925333]]\n",
            "944        [[0.0025840828, 9.991913e-06, 0.99740595]]\n",
            "945           [[0.0006590407, 0.09660971, 0.9027313]]\n",
            "946       [[0.0039280932, 2.3111641e-05, 0.99604875]]\n",
            "947           [[0.0026218442, 0.00123843, 0.9961397]]\n",
            "948       [[0.00062668015, 0.00031737666, 0.9990559]]\n",
            "949        [[0.0017254966, 5.3987683e-06, 0.9982691]]\n",
            "950          [[0.0003919108, 0.014737521, 0.9848706]]\n",
            "951             [[0.1088742, 0.021322351, 0.8698034]]\n",
            "952        [[0.0004309422, 0.0026390331, 0.99693006]]\n",
            "953         [[0.00019611225, 0.76003903, 0.23976484]]\n",
            "954             [[0.3799762, 0.41577706, 0.20424667]]\n",
            "955         [[0.004638996, 0.0003966591, 0.99496436]]\n",
            "956        [[0.0027597826, 0.0043151304, 0.99292505]]\n",
            "957        [[0.0054184287, 0.0008015184, 0.99377996]]\n",
            "958       [[0.0081691155, 4.0246065e-05, 0.99179065]]\n",
            "959             [[0.07253141, 0.7002807, 0.22718789]]\n",
            "960        [[0.0092395125, 6.0658178e-05, 0.9906998]]\n",
            "961       [[0.0076832534, 1.0161867e-05, 0.99230665]]\n",
            "962        [[0.005451768, 4.7554022e-05, 0.99450064]]\n",
            "963        [[0.0062628086, 8.2405146e-05, 0.9936547]]\n",
            "964            [[0.8472041, 0.08277198, 0.070024036]]\n",
            "965        [[0.0027326108, 7.0558184e-05, 0.9971968]]\n",
            "966            [[0.12825759, 0.36647913, 0.50526327]]\n",
            "967            [[0.12825759, 0.36647913, 0.50526327]]\n",
            "968             [[0.17580898, 0.7792213, 0.04496973]]\n",
            "969        [[0.006732021, 4.0505205e-05, 0.99322754]]\n",
            "970           [[0.0038851849, 0.028747737, 0.967367]]\n",
            "971            [[0.8978051, 0.07553694, 0.026657945]]\n",
            "972           [[0.001588805, 0.48240292, 0.51600826]]\n",
            "973      [[0.00038162404, 3.7736274e-05, 0.99958056]]\n",
            "974            [[0.21388213, 0.020021126, 0.7660968]]\n",
            "975            [[0.21388213, 0.020021126, 0.7660968]]\n",
            "976        [[0.0010713817, 0.00015525584, 0.9987734]]\n",
            "977           [[0.017572243, 0.008322663, 0.9741052]]\n",
            "978           [[0.008602172, 0.11309685, 0.87830096]]\n",
            "979       [[0.00063262903, 0.0012610184, 0.99810636]]\n",
            "980           [[0.03783177, 8.437007e-05, 0.9620838]]\n",
            "981          [[0.98842514, 0.000185194, 0.011389644]]\n",
            "982           [[0.39629197, 0.122624345, 0.48108372]]\n",
            "983          [[0.009628998, 3.456974e-05, 0.9903364]]\n",
            "984            [[0.020730356, 0.1036202, 0.87564945]]\n",
            "985          [[0.98842514, 0.000185194, 0.011389644]]\n",
            "986            [[0.0047522387, 0.36674976, 0.628498]]\n",
            "987          [[0.10206337, 0.00030477755, 0.8976319]]\n",
            "988         [[0.020108653, 0.00016241537, 0.9797289]]\n",
            "989         [[0.008547292, 1.4180012e-05, 0.9914385]]\n",
            "990          [[0.02452287, 1.6235585e-05, 0.9754608]]\n",
            "991         [[4.360967e-05, 0.99698144, 0.002974937]]\n",
            "992        [[0.0022454704, 2.5058513e-05, 0.9977295]]\n",
            "993        [[0.0027648848, 0.00012922719, 0.9971059]]\n",
            "994         [[0.0005240795, 0.009563562, 0.98991233]]\n",
            "995         [[5.4637647e-05, 0.9902209, 0.009724449]]\n",
            "996             [[0.00550611, 0.35202202, 0.6424719]]\n",
            "997            [[0.03079617, 0.0006258185, 0.968578]]\n",
            "998            [[0.027299853, 0.30693805, 0.6657621]]\n",
            "999            [[0.104242936, 0.009893051, 0.885864]]\n",
            "1000        [[0.002308055, 3.0800464e-05, 0.9976611]]\n",
            "1001        [[0.022606863, 0.00010233815, 0.9772908]]\n",
            "1002      [[0.0003821999, 0.00070596836, 0.99891174]]\n",
            "1003           [[0.012306432, 0.7921797, 0.19551386]]\n",
            "1004       [[0.0011808762, 1.6267635e-05, 0.9988028]]\n",
            "1005         [[0.0006573384, 0.21204112, 0.78730154]]\n",
            "1006      [[0.00091419206, 2.3735598e-05, 0.9990621]]\n",
            "1007      [[0.00091419206, 2.3735598e-05, 0.9990621]]\n",
            "1008       [[0.0068487152, 9.470349e-06, 0.99314183]]\n",
            "1009           [[0.54178035, 0.009905981, 0.4483137]]\n",
            "1010        [[0.0060457597, 4.267595e-05, 0.9939116]]\n",
            "1011      [[0.0038940152, 0.00042049968, 0.99568546]]\n",
            "1012          [[0.12262754, 0.013371937, 0.86400044]]\n",
            "1013       [[0.0058735376, 3.6924772e-05, 0.9940895]]\n",
            "1014        [[0.9880167, 0.0057850573, 0.0061982386]]\n",
            "1015           [[0.8081116, 0.0040125544, 0.1878759]]\n",
            "1016       [[0.0072214245, 1.7260325e-05, 0.9927614]]\n",
            "1017          [[0.0042508757, 0.5874864, 0.40826276]]\n",
            "1018      [[0.0028465677, 2.5408348e-05, 0.99712795]]\n",
            "1019        [[0.0040435637, 0.0001705776, 0.9957859]]\n",
            "1020        [[0.027471375, 2.0233285e-05, 0.9725084]]\n",
            "1021         [[0.019532746, 0.94791234, 0.032554932]]\n",
            "1022          [[0.047425203, 0.001613597, 0.9509612]]\n",
            "1023           [[0.0015005172, 0.34498745, 0.653512]]\n",
            "1024        [[0.00054747675, 0.9185634, 0.080889106]]\n",
            "1025             [[0.4626496, 0.06971223, 0.4676382]]\n",
            "1026         [[0.05526162, 0.00043562648, 0.9443028]]\n",
            "1027      [[0.0059060142, 6.0862453e-06, 0.99408793]]\n",
            "1028         [[0.86295813, 0.0007496319, 0.13629222]]\n",
            "1029         [[0.011281589, 3.046719e-05, 0.9886878]]\n",
            "1030         [[0.01675038, 4.6777743e-05, 0.9832028]]\n",
            "1031       [[0.00032004985, 0.0004126278, 0.9992673]]\n",
            "1032        [[0.00046703353, 0.002653425, 0.9968796]]\n",
            "1033        [[0.9984151, 0.00041979435, 0.001165139]]\n",
            "1034       [[0.0055450103, 1.8555009e-05, 0.9944364]]\n",
            "1035        [[0.007082692, 3.1355306e-05, 0.9928859]]\n",
            "1036        [[0.008564668, 1.1985387e-05, 0.9914234]]\n",
            "1037          [[0.010654508, 0.003779446, 0.9855661]]\n",
            "1038       [[0.0032229128, 0.00023586472, 0.9965412]]\n",
            "1039      [[0.0022837748, 3.7318274e-05, 0.99767894]]\n",
            "1040      [[0.0030440274, 0.00024403672, 0.99671197]]\n",
            "1041         [[0.038084023, 0.94924647, 0.012669486]]\n",
            "1042       [[0.0012157991, 0.99755585, 0.0012283042]]\n",
            "1043          [[0.011386079, 0.98526937, 0.00334453]]\n",
            "1044           [[0.006594474, 0.76475537, 0.2286501]]\n",
            "1045        [[0.001496526, 1.6987133e-05, 0.9984864]]\n",
            "1046        [[0.0047899745, 9.580268e-06, 0.9952004]]\n",
            "1047       [[0.0026021583, 8.2717825e-06, 0.9973895]]\n",
            "1048          [[0.9987765, 8.095244e-05, 0.00114259]]\n",
            "1049          [[0.9736713, 0.0022713933, 0.02405728]]\n",
            "1050        [[0.63493794, 0.36433527, 0.00072688697]]\n",
            "1051       [[0.00089764094, 0.0047824783, 0.9943198]]\n",
            "1052        [[0.0025105614, 0.0005008915, 0.9969886]]\n",
            "1053       [[0.0032099206, 0.00010011368, 0.9966899]]\n",
            "1054       [[0.0017032828, 3.509525e-05, 0.99826163]]\n",
            "1055      [[0.0047327867, 4.3795528e-05, 0.99522346]]\n",
            "1056          [[0.8319325, 0.0009411152, 0.16712639]]\n",
            "1057          [[0.0012224014, 0.29740036, 0.7013773]]\n",
            "1058       [[0.0011499368, 2.5692814e-05, 0.9988243]]\n",
            "1059          [[0.009570502, 0.010327309, 0.9801021]]\n",
            "1060      [[0.0036735197, 3.0919004e-05, 0.99629563]]\n",
            "1061         [[0.0008627111, 6.26076e-05, 0.9990746]]\n",
            "1062        [[0.0014772363, 0.0001373626, 0.9983854]]\n",
            "1063            [[0.10077856, 0.5020571, 0.39716434]]\n",
            "1064          [[0.70729345, 0.020755785, 0.27195072]]\n",
            "1065           [[0.0062516676, 0.4878987, 0.5058496]]\n",
            "1066      [[0.0041738767, 2.9066585e-05, 0.99579704]]\n",
            "1067         [[0.0055829687, 0.010029498, 0.9843875]]\n",
            "1068        [[0.0049422327, 0.0006042541, 0.9944535]]\n",
            "1069         [[0.0027740481, 0.000211531, 0.9970144]]\n",
            "1070       [[0.00084716926, 0.0006086988, 0.9985441]]\n",
            "1071         [[0.002252856, 4.845503e-05, 0.9976987]]\n",
            "1072          [[0.0007936127, 0.25853735, 0.7406691]]\n",
            "1073       [[0.025949476, 2.7458442e-05, 0.97402316]]\n",
            "1074          [[0.08384544, 0.0014832604, 0.9146713]]\n",
            "1075       [[0.022463428, 1.8955516e-05, 0.97751755]]\n",
            "1076         [[0.0005220725, 0.9584666, 0.041011367]]\n",
            "1077        [[0.001757489, 1.5281092e-05, 0.9982273]]\n",
            "1078       [[0.00026457515, 0.0038433885, 0.9958919]]\n",
            "1079       [[0.0011035297, 7.612709e-05, 0.99882036]]\n",
            "1080         [[0.028495263, 0.050645977, 0.92085874]]\n",
            "1081        [[0.00023819269, 0.9898509, 0.009910887]]\n",
            "1082        [[0.00025000295, 0.9911445, 0.008605441]]\n",
            "1083        [[0.003402862, 1.8865461e-05, 0.9965783]]\n",
            "1084       [[0.0061273803, 2.4094157e-05, 0.9938486]]\n",
            "1085        [[0.0018089088, 9.466564e-05, 0.9980964]]\n",
            "1086          [[0.0027189397, 0.07116131, 0.9261197]]\n",
            "1087      [[0.0056599863, 0.00028298312, 0.99405706]]\n",
            "1088         [[0.0012893446, 0.14698024, 0.85173035]]\n",
            "1089       [[0.00053921115, 0.024163667, 0.97529703]]\n",
            "1090           [[0.0007289066, 0.7293326, 0.2699385]]\n",
            "1091        [[0.97810304, 0.017998235, 0.0038986998]]\n",
            "1092      [[0.0033978256, 2.4026212e-05, 0.99657816]]\n",
            "1093         [[0.9906657, 0.008438488, 0.0008959209]]\n",
            "1094         [[0.91840565, 0.07883853, 0.0027557397]]\n",
            "1095         [[0.008053639, 0.002385095, 0.98956126]]\n",
            "1096        [[0.002657563, 0.00010876277, 0.9972337]]\n",
            "1097        [[0.010937685, 3.3715398e-05, 0.9890286]]\n",
            "1098        [[0.014715085, 3.1969186e-05, 0.9852529]]\n",
            "1099        [[0.008579568, 3.4291916e-05, 0.9913862]]\n",
            "1100       [[0.0031432852, 0.00032843134, 0.9965282]]\n",
            "1101        [[0.008400151, 6.657752e-06, 0.99159324]]\n",
            "1102         [[0.002621147, 8.415412e-05, 0.9972947]]\n",
            "1103          [[0.014427086, 0.005428323, 0.9801445]]\n",
            "1104      [[0.0115809515, 3.4056506e-05, 0.98838496]]\n",
            "1105        [[0.0011149792, 0.001528341, 0.99735665]]\n",
            "1106        [[0.004239305, 2.1147813e-05, 0.9957396]]\n",
            "1107        [[0.008543239, 1.1590873e-05, 0.9914452]]\n",
            "1108       [[0.0035333184, 0.00022418403, 0.9962425]]\n",
            "1109        [[0.0012576286, 0.0006655161, 0.9980768]]\n",
            "1110        [[0.0070211748, 4.4878085e-05, 0.992934]]\n",
            "1111       [[0.0031719704, 6.4855034e-05, 0.9967631]]\n",
            "1112          [[0.0014662131, 0.45706388, 0.5414699]]\n",
            "1113        [[0.003048624, 0.0008812022, 0.99607015]]\n",
            "1114        [[0.0016978274, 7.802236e-05, 0.9982241]]\n",
            "1115       [[0.004533637, 5.0345978e-05, 0.99541605]]\n",
            "1116           [[0.8852044, 0.032550443, 0.08224521]]\n",
            "1117       [[0.001499781, 0.00010928764, 0.99839103]]\n",
            "1118       [[0.001117633, 6.6280394e-05, 0.99881613]]\n",
            "1119      [[0.0016176085, 1.7634658e-05, 0.99836475]]\n",
            "1120           [[0.054874364, 0.08794109, 0.8571846]]\n",
            "1121        [[0.008725832, 1.1415473e-05, 0.9912627]]\n",
            "1122        [[0.9984712, 0.0009891804, 0.0005396078]]\n",
            "1123            [[0.24155444, 0.7329836, 0.02546196]]\n",
            "1124       [[0.00044443028, 8.078354e-05, 0.9994748]]\n",
            "1125        [[0.0043246746, 9.721998e-06, 0.9956656]]\n",
            "1126        [[0.0015084059, 0.008768654, 0.98972285]]\n",
            "1127          [[0.023600766, 0.026858049, 0.9495412]]\n",
            "1128          [[0.0017934071, 0.9278249, 0.07038163]]\n",
            "1129         [[0.0010076121, 0.88097346, 0.11801889]]\n",
            "1130        [[0.007989511, 0.00013802497, 0.9918725]]\n",
            "1131        [[0.036426548, 0.0060038147, 0.95756966]]\n",
            "1132          [[0.27931055, 0.027175937, 0.69351345]]\n",
            "1133      [[0.0072168782, 1.6315333e-05, 0.99276674]]\n",
            "1134           [[0.08656462, 0.011325919, 0.9021095]]\n",
            "1135       [[0.0012475946, 2.4842706e-05, 0.9987275]]\n",
            "1136       [[0.0011586805, 3.1119667e-05, 0.9988103]]\n",
            "1137       [[0.00067455135, 0.0011601208, 0.9981653]]\n",
            "1138       [[0.0011263727, 0.00019395132, 0.9986797]]\n",
            "1139        [[0.0025490061, 0.0017566484, 0.9956943]]\n",
            "1140       [[0.0032005818, 0.0002560674, 0.99654335]]\n",
            "1141         [[0.0024513458, 0.9413913, 0.056157343]]\n",
            "1142            [[0.00433809, 0.30598444, 0.6896775]]\n",
            "1143       [[0.0019238081, 0.0009875301, 0.99708873]]\n",
            "1144         [[0.04434053, 8.909375e-05, 0.95557034]]\n",
            "1145             [[0.22460084, 0.5985899, 0.1768093]]\n",
            "1146       [[0.0014032278, 3.340649e-05, 0.99856335]]\n",
            "1147      [[0.0019132622, 1.3264248e-05, 0.99807346]]\n",
            "1148        [[0.003529949, 7.432216e-06, 0.99646264]]\n",
            "1149          [[0.0909703, 0.00025766582, 0.9087721]]\n",
            "1150         [[0.007327681, 0.012917576, 0.97975475]]\n",
            "1151           [[0.028499283, 0.15335386, 0.8181469]]\n",
            "1152          [[0.017552903, 0.51182014, 0.47062692]]\n",
            "1153      [[0.00042146636, 0.0007395519, 0.99883896]]\n",
            "1154          [[0.5907858, 0.0023125138, 0.40690166]]\n",
            "1155           [[0.8101661, 0.1892382, 0.0005956771]]\n",
            "1156         [[0.004732778, 4.477621e-05, 0.9952225]]\n",
            "1157        [[0.002723347, 0.00016434523, 0.9971123]]\n",
            "1158          [[0.007374594, 0.000134473, 0.9924908]]\n",
            "1159          [[0.0028101867, 0.7738708, 0.22331901]]\n",
            "1160        [[0.0022124494, 0.011984172, 0.98580337]]\n",
            "1161         [[0.012415647, 0.017238019, 0.97034633]]\n",
            "1162        [[0.009109428, 0.00023318722, 0.9906573]]\n",
            "1163        [[0.004790581, 0.00010122344, 0.9951082]]\n",
            "1164     [[0.00054237025, 0.00046174423, 0.99899596]]\n",
            "1165       [[0.0015098545, 0.0050955736, 0.99339455]]\n",
            "1166         [[0.010184763, 5.446869e-05, 0.9897607]]\n",
            "1167        [[0.0004893125, 0.0003660387, 0.9991447]]\n",
            "1168        [[0.0029922777, 2.8735041e-05, 0.996979]]\n",
            "1169       [[0.014218309, 2.2593305e-05, 0.98575914]]\n",
            "1170            [[0.04206861, 0.43219057, 0.5257408]]\n",
            "1171        [[0.0043461276, 0.00011482604, 0.995539]]\n",
            "1172       [[0.0021491775, 0.00030824292, 0.9975426]]\n",
            "1173        [[0.0009633038, 0.98214597, 0.016890764]]\n",
            "1174         [[0.97066295, 0.020779567, 0.008557488]]\n",
            "1175             [[0.5350224, 0.4218199, 0.04315771]]\n",
            "1176         [[0.015665952, 0.9831118, 0.0012222609]]\n",
            "1177         [[0.08324839, 0.0005707694, 0.91618085]]\n",
            "1178       [[0.0050212382, 9.929113e-06, 0.99496883]]\n",
            "1179        [[0.009944597, 1.7557222e-05, 0.9900378]]\n",
            "1180       [[0.012566554, 2.7991347e-05, 0.98740536]]\n",
            "1181        [[0.018770821, 3.5077588e-05, 0.9811941]]\n",
            "1182       [[0.017809184, 9.7467164e-05, 0.98209333]]\n",
            "1183      [[0.0060674204, 0.00034630668, 0.99358624]]\n",
            "1184       [[0.0013310007, 9.0772206e-05, 0.9985782]]\n",
            "1185       [[0.0015140952, 4.9359536e-05, 0.9984365]]\n",
            "1186           [[0.54266703, 0.04945311, 0.40787983]]\n",
            "1187          [[0.5703572, 0.0062906328, 0.42335224]]\n",
            "1188          [[0.09248402, 0.0007628068, 0.9067531]]\n",
            "1189        [[0.0006439276, 0.0002278741, 0.9991283]]\n",
            "1190        [[0.0014393121, 7.016098e-05, 0.9984906]]\n",
            "1191       [[0.0015029841, 0.00022968433, 0.9982673]]\n",
            "1192        [[0.0014477818, 0.0006053802, 0.9979468]]\n",
            "1193      [[0.0062383353, 0.00080371206, 0.99295795]]\n",
            "1194         [[0.009908203, 0.0002693065, 0.9898225]]\n",
            "1195        [[0.007351438, 1.7815275e-05, 0.9926307]]\n",
            "1196      [[0.00076493854, 7.8341276e-05, 0.9991567]]\n",
            "1197      [[0.00048353797, 0.00028907563, 0.9992274]]\n",
            "1198         [[0.0014692777, 0.77708596, 0.22144479]]\n",
            "1199            [[0.001359677, 0.0638604, 0.9347799]]\n",
            "1200         [[0.0007332223, 0.95186424, 0.04740261]]\n",
            "1201         [[0.008223171, 7.746976e-06, 0.9917691]]\n",
            "1202       [[0.0029393532, 8.118392e-06, 0.99705255]]\n",
            "1203        [[0.019695966, 0.00018483677, 0.9801192]]\n",
            "1204       [[0.98211426, 0.00029911756, 0.017586606]]\n",
            "1205        [[0.007320208, 2.7281363e-05, 0.9926524]]\n",
            "1206         [[0.012252894, 0.0011212442, 0.9866259]]\n",
            "1207       [[0.0024786803, 1.5684127e-05, 0.9975056]]\n",
            "1208        [[0.0009954715, 2.083462e-05, 0.9989837]]\n",
            "1209            [[0.6311603, 0.09877784, 0.27006182]]\n",
            "1210         [[0.013123716, 0.93987966, 0.046996668]]\n",
            "1211          [[0.59537333, 0.30311802, 0.101508595]]\n",
            "1212              [[0.78461105, 0.03293, 0.18245892]]\n",
            "1213         [[0.0022829592, 4.77004e-05, 0.9976693]]\n",
            "1214        [[0.007955253, 3.438876e-05, 0.99201035]]\n",
            "1215        [[0.002284656, 4.059138e-05, 0.99767476]]\n",
            "1216         [[0.0010536499, 0.01144604, 0.98750025]]\n",
            "1217          [[0.001067507, 0.89156514, 0.10736741]]\n",
            "1218       [[0.004207215, 1.2410348e-05, 0.99578035]]\n",
            "1219        [[0.0010514772, 6.332501e-05, 0.9988852]]\n",
            "1220       [[0.0061504617, 1.5664595e-05, 0.9938339]]\n",
            "1221         [[0.004671672, 6.226356e-05, 0.9952661]]\n",
            "1222        [[0.0028015857, 0.0015088499, 0.9956896]]\n",
            "1223         [[0.89744866, 0.053734858, 0.048816454]]\n",
            "1224           [[0.005623858, 0.13675791, 0.8576182]]\n",
            "1225         [[0.004948863, 3.992436e-06, 0.9950471]]\n",
            "1226       [[0.0064059165, 0.00088116183, 0.9927129]]\n",
            "1227        [[0.005082032, 2.5433626e-05, 0.9948926]]\n",
            "1228          [[0.011145518, 0.012669772, 0.9761847]]\n",
            "1229         [[0.0081015155, 5.49398e-05, 0.9918435]]\n",
            "1230        [[0.015318584, 2.8257688e-05, 0.9846532]]\n",
            "1231        [[0.010291814, 2.5789646e-05, 0.9896824]]\n",
            "1232         [[0.99840206, 0.000399548, 0.001198376]]\n",
            "1233      [[0.0021649324, 0.00025608722, 0.99757904]]\n",
            "1234          [[0.02425051, 2.598615e-05, 0.9757236]]\n",
            "1235           [[0.68400407, 0.308201, 0.0077949576]]\n",
            "1236           [[0.33050388, 0.54208654, 0.12740962]]\n",
            "1237         [[0.044782277, 8.066542e-05, 0.9551371]]\n",
            "1238          [[0.008546759, 0.003975274, 0.9874779]]\n",
            "1239          [[0.61834794, 0.058443785, 0.32320824]]\n",
            "1240        [[0.006420701, 3.1114534e-05, 0.9935481]]\n",
            "1241          [[0.01810077, 2.6222846e-05, 0.981873]]\n",
            "1242        [[0.010335564, 2.3588687e-05, 0.9896408]]\n",
            "1243           [[0.01965026, 0.13762876, 0.84272105]]\n",
            "1244         [[0.016001344, 0.021898307, 0.96210027]]\n",
            "1245       [[0.0047917967, 4.3095763e-05, 0.9951651]]\n",
            "1246         [[0.002620883, 0.0047404394, 0.9926386]]\n",
            "1247       [[0.006969604, 0.00016947342, 0.99286085]]\n",
            "1248         [[0.01166321, 7.4941318e-06, 0.9883293]]\n",
            "1249         [[0.026551312, 0.9682745, 0.0051741963]]\n",
            "1250            [[0.00673762, 0.9296498, 0.06361266]]\n",
            "1251         [[0.011087393, 0.93629146, 0.052621152]]\n",
            "1252       [[0.009670387, 1.4548006e-05, 0.99031514]]\n",
            "1253        [[0.0005788003, 0.98791194, 0.011509309]]\n",
            "1254        [[0.01724573, 0.00022611757, 0.98252815]]\n",
            "1255        [[0.0011813369, 6.39481e-05, 0.99875474]]\n",
            "1256       [[0.0018790761, 0.00011159588, 0.9980094]]\n",
            "1257      [[0.0028790664, 0.00034609673, 0.99677473]]\n",
            "1258         [[0.0011865279, 0.19881351, 0.79999995]]\n",
            "1259        [[0.002947038, 0.00010850209, 0.9969445]]\n",
            "1260         [[0.0017454197, 0.78089976, 0.21735486]]\n",
            "1261         [[0.00831239, 2.6831724e-05, 0.9916608]]\n",
            "1262       [[0.0068709557, 2.2159757e-05, 0.9931069]]\n",
            "1263        [[0.9971499, 0.00035925422, 0.002490965]]\n",
            "1264        [[0.008791056, 1.2944339e-05, 0.9911959]]\n",
            "1265       [[0.0037159617, 7.173519e-05, 0.99621236]]\n",
            "1266        [[0.0035699646, 0.0001463056, 0.9962837]]\n",
            "1267            [[0.12563772, 0.63528347, 0.2390788]]\n",
            "1268        [[0.011416373, 0.0024958334, 0.98608774]]\n",
            "1269             [[0.34605485, 0.63128, 0.022665178]]\n",
            "1270          [[0.86719054, 0.010682241, 0.12212723]]\n",
            "1271         [[0.9917571, 0.0009273763, 0.007315562]]\n",
            "1272      [[0.00019902318, 0.99840647, 0.0013944906]]\n",
            "1273      [[0.0013440435, 0.99789584, 0.00076006644]]\n",
            "1274       [[0.013378768, 5.9329264e-05, 0.98656195]]\n",
            "1275        [[0.001735173, 4.6245204e-05, 0.9982185]]\n",
            "1276         [[0.039978545, 0.93726367, 0.022757849]]\n",
            "1277         [[0.96258026, 0.034606438, 0.002813238]]\n",
            "1278       [[0.0028977373, 0.00020574602, 0.9968965]]\n",
            "1279           [[0.025516193, 0.93769914, 0.0367846]]\n",
            "1280           [[0.02316246, 0.78509516, 0.19174245]]\n",
            "1281          [[0.0043383576, 0.19316031, 0.8025014]]\n",
            "1282       [[0.0022948158, 1.9878642e-05, 0.9976853]]\n",
            "1283       [[0.0048681325, 7.787569e-06, 0.99512404]]\n",
            "1284         [[0.003909158, 0.002292979, 0.99379784]]\n",
            "1285        [[0.006108942, 0.00023025219, 0.9936608]]\n",
            "1286          [[0.002075425, 0.014113333, 0.9838113]]\n",
            "1287      [[0.0016363175, 4.5812576e-06, 0.99835914]]\n",
            "1288           [[0.0064627943, 0.915863, 0.07767418]]\n",
            "1289       [[0.027295437, 0.97202975, 0.00067483174]]\n",
            "1290            [[0.6606691, 0.02325704, 0.31607386]]\n",
            "1291         [[0.014679915, 1.55071e-05, 0.98530453]]\n",
            "1292          [[0.96988994, 0.02028841, 0.009821699]]\n",
            "1293       [[0.017336998, 2.4942123e-05, 0.98263806]]\n",
            "1294       [[0.0023574277, 0.00014375465, 0.9974988]]\n",
            "1295          [[0.94319516, 0.03336984, 0.023435079]]\n",
            "1296        [[0.005632974, 2.110766e-05, 0.99434584]]\n",
            "1297       [[0.0074953954, 0.00027848905, 0.9922261]]\n",
            "1298        [[0.0029161172, 0.015416244, 0.98166764]]\n",
            "1299       [[0.005296651, 2.3504852e-05, 0.99467987]]\n",
            "1300           [[0.76038426, 0.00192011, 0.23769559]]\n",
            "1301         [[0.002151395, 0.0015871935, 0.9962614]]\n",
            "1302        [[0.0041310606, 0.00020598824, 0.995663]]\n",
            "1303      [[3.129181e-05, 0.99940896, 0.00055974786]]\n",
            "1304          [[0.0016162333, 0.3777126, 0.62067115]]\n",
            "1305      [[0.0016821958, 0.00064930174, 0.99766856]]\n",
            "1306      [[0.0022803356, 0.00023985456, 0.99747986]]\n",
            "1307         [[0.00137149, 4.9214294e-05, 0.9985794]]\n",
            "1308       [[0.0021314414, 2.7393904e-05, 0.9978411]]\n",
            "1309        [[0.0018825085, 4.235032e-05, 0.9980751]]\n",
            "1310          [[0.00891017, 9.125104e-06, 0.9910807]]\n",
            "1311         [[0.0018855154, 4.558315e-05, 0.998069]]\n",
            "1312       [[0.0012431042, 1.4065301e-05, 0.9987429]]\n",
            "1313        [[0.0016005074, 0.010177447, 0.98822206]]\n",
            "1314         [[0.0008894297, 0.0016966009, 0.997414]]\n",
            "1315        [[0.00026104334, 0.9962171, 0.003521844]]\n",
            "1316           [[0.004803439, 0.7068609, 0.28833565]]\n",
            "1317         [[0.003645238, 7.7621735e-06, 0.996347]]\n",
            "1318        [[0.006063963, 1.6497721e-05, 0.9939196]]\n",
            "1319         [[0.008546042, 8.796169e-06, 0.9914452]]\n",
            "1320          [[0.0231976, 1.866309e-05, 0.97678375]]\n",
            "1321       [[0.001148019, 0.00018041367, 0.99867165]]\n",
            "1322         [[0.0021655797, 0.85930276, 0.13853168]]\n",
            "1323         [[0.00035748552, 0.996203, 0.003439492]]\n",
            "1324       [[0.00014007797, 0.98896503, 0.010894946]]\n",
            "1325        [[0.00060516543, 0.9671997, 0.032195136]]\n",
            "1326       [[0.00039873933, 0.9971836, 0.0024175842]]\n",
            "1327       [[0.00096224906, 0.017234147, 0.98180354]]\n",
            "1328           [[0.02156558, 0.048605885, 0.9298285]]\n",
            "1329       [[0.0019317488, 0.00030546536, 0.9977628]]\n",
            "1330      [[0.00014679837, 0.99437666, 0.0054765376]]\n",
            "1331         [[0.000913991, 0.0025025818, 0.9965835]]\n",
            "1332       [[0.0022599753, 7.573531e-05, 0.99766433]]\n",
            "1333        [[0.0023741706, 0.003855821, 0.99376994]]\n",
            "1334            [[0.02948455, 0.09317381, 0.8773417]]\n",
            "1335        [[0.0008301147, 0.0002572207, 0.9989127]]\n",
            "1336          [[0.0262344, 0.96931463, 0.0044509256]]\n",
            "1337       [[0.0044233245, 0.00094818854, 0.9946285]]\n",
            "1338        [[0.004020675, 1.5588214e-05, 0.9959637]]\n",
            "1339       [[0.049779214, 0.00012571599, 0.95009506]]\n",
            "1340        [[0.007071693, 2.5031582e-05, 0.9929033]]\n",
            "1341         [[0.014030658, 9.041723e-05, 0.9858789]]\n",
            "1342         [[0.014210856, 0.0005335758, 0.9852556]]\n",
            "1343        [[0.98863935, 0.0034219122, 0.007938706]]\n",
            "1344         [[0.19756626, 0.0004399199, 0.80199385]]\n",
            "1345         [[0.0015649562, 0.9615417, 0.036893316]]\n",
            "1346          [[0.18399243, 0.0068186526, 0.8091889]]\n",
            "1347          [[0.0011776122, 0.01890071, 0.9799217]]\n",
            "1348        [[0.046455555, 0.00025784675, 0.9532865]]\n",
            "1349       [[0.0061215577, 3.8682418e-05, 0.9938397]]\n",
            "1350       [[0.009323148, 0.00013859355, 0.99053824]]\n",
            "1351        [[0.029305613, 1.1597332e-05, 0.9706828]]\n",
            "1352         [[0.0025564162, 3.072645e-05, 0.997413]]\n",
            "1353        [[0.008627198, 6.7320514e-05, 0.9913054]]\n",
            "1354        [[0.015255354, 1.5069664e-05, 0.9847296]]\n",
            "1355            [[0.26611072, 0.60159546, 0.1322938]]\n",
            "1356       [[0.0042740093, 0.00051242195, 0.9952136]]\n",
            "1357           [[0.2571613, 0.72758436, 0.015254417]]\n",
            "1358        [[0.012932858, 4.3507072e-05, 0.9870236]]\n",
            "1359       [[0.0038219593, 0.00014625226, 0.9960317]]\n",
            "1360      [[0.0027577968, 1.7167346e-05, 0.99722517]]\n",
            "1361       [[0.0017232562, 0.00063563016, 0.9976411]]\n",
            "1362           [[0.9769142, 0.00445827, 0.018627608]]\n",
            "1363      [[0.00032832896, 0.0064451457, 0.99322647]]\n",
            "1364            [[0.0025780883, 0.46115, 0.53627187]]\n",
            "1365       [[0.00048342915, 0.009590103, 0.98992646]]\n",
            "1366          [[0.0033650708, 0.970445, 0.026189987]]\n",
            "1367       [[0.007690664, 1.3562781e-05, 0.99229574]]\n",
            "1368        [[0.0015262315, 0.0024951021, 0.9959786]]\n",
            "1369          [[0.00741413, 0.037126288, 0.95545954]]\n",
            "1370          [[0.44055185, 0.55101347, 0.008434691]]\n",
            "1371          [[0.013988617, 0.82653826, 0.15947306]]\n",
            "1372       [[0.0016351561, 1.8065253e-05, 0.9983468]]\n",
            "1373        [[0.02842332, 0.00015779687, 0.97141886]]\n",
            "1374       [[0.007120645, 0.00039921908, 0.99248016]]\n",
            "1375       [[0.00024890382, 0.9991561, 0.0005950101]]\n",
            "1376           [[0.0013525777, 0.1613531, 0.8372943]]\n",
            "1377       [[0.00038599817, 0.0003172513, 0.9992968]]\n",
            "1378      [[0.0007599097, 7.3292416e-05, 0.99916685]]\n",
            "1379        [[0.001242738, 0.00034488036, 0.9984124]]\n",
            "1380          [[0.930565, 0.067832366, 0.0016026088]]\n",
            "1381        [[0.0034329768, 1.2072749e-05, 0.996555]]\n",
            "1382     [[0.99981636, 4.1188257e-05, 0.00014244717]]\n",
            "1383           [[0.49686232, 0.44683734, 0.05630042]]\n",
            "1384           [[0.55468404, 0.22612903, 0.21918696]]\n",
            "1385      [[0.0020461178, 9.3076866e-05, 0.99786085]]\n",
            "1386         [[0.009493344, 0.0004502604, 0.9900564]]\n",
            "1387         [[0.0016687369, 0.091405936, 0.9069254]]\n",
            "1388          [[0.009975154, 0.028515385, 0.9615095]]\n",
            "1389        [[0.002683905, 0.0014466485, 0.99586934]]\n",
            "1390           [[0.06139592, 0.59791297, 0.34069112]]\n",
            "1391       [[0.0056972816, 1.0820498e-05, 0.9942919]]\n",
            "1392           [[0.08647958, 0.000792949, 0.9127275]]\n",
            "1393      [[0.0075559337, 1.01511205e-05, 0.9924339]]\n",
            "1394      [[0.023319328, 1.36279905e-05, 0.97666705]]\n",
            "1395          [[0.06416391, 0.91499823, 0.020837858]]\n",
            "1396         [[0.012002106, 0.9847077, 0.0032901922]]\n",
            "1397        [[0.0070898114, 0.0012790025, 0.9916311]]\n",
            "1398       [[0.0021261165, 0.0010322742, 0.99684155]]\n",
            "1399         [[0.0044162767, 0.13642839, 0.85915536]]\n",
            "1400           [[0.012024401, 0.37776452, 0.6102111]]\n",
            "1401       [[0.0096355695, 1.6732656e-05, 0.9903476]]\n",
            "1402          [[0.0010314641, 0.9277205, 0.07124808]]\n",
            "1403        [[0.0021881498, 5.742323e-05, 0.9977544]]\n",
            "1404         [[0.00812649, 0.00027077916, 0.9916027]]\n",
            "1405          [[0.004720758, 0.007024403, 0.9882549]]\n",
            "1406            [[0.46662095, 0.5130464, 0.02033269]]\n",
            "1407            [[0.5120348, 0.4742575, 0.013707688]]\n",
            "1408          [[0.006592818, 0.70475906, 0.28864816]]\n",
            "1409            [[0.20925035, 0.29880586, 0.4919438]]\n",
            "1410         [[0.007518549, 0.0042828983, 0.9881986]]\n",
            "1411        [[0.0074837063, 0.005685707, 0.98683053]]\n",
            "1412         [[0.0055949893, 0.016440535, 0.9779644]]\n",
            "1413       [[0.004940832, 1.2433131e-05, 0.99504673]]\n",
            "1414      [[0.0031318506, 1.7684175e-05, 0.99685043]]\n",
            "1415           [[0.15818527, 0.36747077, 0.47434393]]\n",
            "1416        [[0.008001753, 0.0016484661, 0.99034977]]\n",
            "1417          [[0.23990567, 0.75332415, 0.006770151]]\n",
            "1418        [[0.008225051, 4.4559394e-05, 0.9917304]]\n",
            "1419       [[0.022205371, 1.5886018e-05, 0.97777885]]\n",
            "1420        [[0.015949689, 0.00010613019, 0.9839442]]\n",
            "1421       [[0.003865001, 1.5232057e-05, 0.99611986]]\n",
            "1422         [[0.013676778, 2.406895e-05, 0.9862991]]\n",
            "1423           [[0.02204768, 0.092709094, 0.8852432]]\n",
            "1424         [[0.9883604, 0.0047701113, 0.006869471]]\n",
            "1425          [[0.011945845, 0.030360619, 0.9576935]]\n",
            "1426            [[0.04001887, 0.7868196, 0.17316154]]\n",
            "1427         [[0.0013597623, 0.9853102, 0.013330013]]\n",
            "1428        [[0.0010837353, 0.99034274, 0.008573575]]\n",
            "1429            [[0.018795641, 0.5570938, 0.4241106]]\n",
            "1430        [[0.020487182, 0.0010756862, 0.97843724]]\n",
            "1431       [[0.0044756387, 7.253802e-05, 0.99545187]]\n",
            "1432         [[0.043485265, 0.002348545, 0.95416623]]\n",
            "1433          [[0.019556995, 0.9639419, 0.016501114]]\n",
            "1434           [[0.02944453, 0.60472864, 0.36582682]]\n",
            "1435           [[0.0157735, 0.109199435, 0.87502706]]\n",
            "1436           [[0.16282718, 0.04550694, 0.79166585]]\n",
            "1437          [[0.00174726, 0.0017687676, 0.9964839]]\n",
            "1438      [[0.0061671566, 2.6571284e-05, 0.99380636]]\n",
            "1439         [[0.008235596, 0.98896116, 0.002803251]]\n",
            "1440        [[0.0021859696, 0.005910787, 0.99190325]]\n",
            "1441          [[0.0017037285, 0.8579542, 0.14034201]]\n",
            "1442           [[0.09798642, 0.44796956, 0.45404404]]\n",
            "1443           [[0.027105574, 0.2594179, 0.71347654]]\n",
            "1444           [[0.12035284, 0.086580545, 0.7930666]]\n",
            "1445       [[0.00051958126, 0.9958955, 0.0035849295]]\n",
            "1446        [[0.0030084732, 9.640688e-06, 0.9969819]]\n",
            "1447       [[0.0030345002, 4.0674095e-05, 0.9969248]]\n",
            "1448       [[0.0027008525, 0.00016083583, 0.9971384]]\n",
            "1449           [[0.12663059, 0.059420053, 0.8139494]]\n",
            "1450           [[0.008527021, 0.8781006, 0.11337242]]\n",
            "1451        [[0.0002683806, 0.98901343, 0.010718232]]\n",
            "1452       [[0.0005894539, 0.99762875, 0.0017818487]]\n",
            "1453      [[7.6656026e-05, 0.9997125, 0.00021076237]]\n",
            "1454          [[0.0054284725, 0.970697, 0.023874499]]\n",
            "1455         [[0.001733065, 0.0003646493, 0.9979023]]\n",
            "1456             [[0.7535245, 0.029066503, 0.217409]]\n",
            "1457           [[0.8848496, 0.04795037, 0.067200035]]\n",
            "1458            [[0.7101122, 0.16767277, 0.12221498]]\n",
            "1459      [[0.0032495195, 1.1671602e-05, 0.99673885]]\n",
            "1460        [[0.002830417, 3.0980482e-05, 0.9971386]]\n",
            "1461       [[0.0066303527, 1.1965627e-05, 0.9933577]]\n",
            "1462       [[0.0027730206, 9.429186e-06, 0.99721754]]\n",
            "1463         [[0.0018269734, 0.000341187, 0.9978319]]\n",
            "1464        [[0.00038580236, 0.0015062223, 0.998108]]\n",
            "1465          [[0.020576082, 0.67847097, 0.30095294]]\n",
            "1466         [[0.001492974, 0.0034476693, 0.9950594]]\n",
            "1467         [[0.002362694, 0.0032194306, 0.9944179]]\n",
            "1468       [[0.0013020112, 0.0025871822, 0.99611074]]\n",
            "1469         [[0.004491054, 8.258898e-06, 0.9955006]]\n",
            "1470        [[0.00830605, 2.9993742e-05, 0.99166393]]\n",
            "1471        [[0.0012129718, 0.0001011208, 0.9986859]]\n",
            "1472        [[0.029915452, 0.00050506776, 0.9695794]]\n",
            "1473       [[0.9998072, 7.319567e-05, 0.00011963271]]\n",
            "1474        [[0.007256172, 9.888092e-06, 0.99273384]]\n",
            "1475       [[0.023244381, 1.2228767e-05, 0.97674334]]\n",
            "1476          [[0.13759175, 0.081500806, 0.78090745]]\n",
            "1477       [[0.0029267287, 8.734024e-06, 0.99706465]]\n",
            "1478         [[0.002709138, 0.001236058, 0.99605477]]\n",
            "1479        [[0.9987759, 5.481354e-05, 0.0011693238]]\n",
            "1480      [[0.00054898905, 0.99703264, 0.0024183053]]\n",
            "1481          [[0.09067523, 0.0004183031, 0.9089064]]\n",
            "1482          [[0.98771185, 0.0119736, 0.0003145909]]\n",
            "1483        [[0.8839367, 0.115582086, 0.00048127573]]\n",
            "1484          [[0.036155764, 0.00039577, 0.96344846]]\n",
            "1485         [[0.9663078, 0.028218545, 0.0054736035]]\n",
            "1486         [[0.9810301, 0.014937624, 0.0040323045]]\n",
            "1487         [[0.9915523, 0.0006557996, 0.007791836]]\n",
            "1488         [[0.03675195, 0.0007857804, 0.96246225]]\n",
            "1489         [[0.9913468, 0.004931181, 0.0037219687]]\n",
            "1490          [[0.9887304, 0.0029642482, 0.00830544]]\n",
            "1491        [[0.03137144, 0.00054644945, 0.96808213]]\n",
            "1492        [[0.019902898, 8.0689475e-05, 0.9800164]]\n",
            "1493       [[0.008298353, 0.00010688127, 0.99159473]]\n",
            "1494        [[0.010395804, 6.399494e-05, 0.98954016]]\n",
            "1495         [[0.0057892757, 0.19190143, 0.80230933]]\n",
            "1496       [[0.00012148632, 0.9968274, 0.0030511075]]\n",
            "1497       [[0.00077613187, 0.9972145, 0.0020093985]]\n",
            "1498        [[0.001222992, 0.9986345, 0.00014246373]]\n",
            "1499         [[0.0037518146, 0.29912448, 0.69712377]]\n",
            "1500       [[0.0036935275, 1.8713192e-05, 0.9962877]]\n",
            "1501      [[0.0028105627, 3.2075783e-05, 0.99715734]]\n",
            "1502      [[0.0028481563, 5.3353473e-05, 0.99709845]]\n",
            "1503       [[0.009898286, 0.00013653662, 0.98996514]]\n",
            "1504      [[0.0012285111, 5.1279065e-05, 0.99872017]]\n",
            "1505       [[0.0023444854, 2.7852526e-05, 0.9976277]]\n",
            "1506      [[0.0033845382, 1.4964146e-05, 0.99660057]]\n",
            "1507      [[0.0024310122, 1.1883117e-05, 0.99755704]]\n",
            "1508           [[0.008172861, 0.032861046, 0.958966]]\n",
            "1509         [[0.001395365, 0.0024182799, 0.9961863]]\n",
            "1510          [[0.0038762928, 0.01001725, 0.9861064]]\n",
            "1511         [[0.0014631469, 0.0003809321, 0.998156]]\n",
            "1512        [[0.0036234895, 6.127364e-05, 0.9963153]]\n",
            "1513      [[0.002324691, 0.000111947455, 0.99756336]]\n",
            "1514         [[0.020262457, 0.009006258, 0.97073126]]\n",
            "1515          [[0.001110311, 0.026809145, 0.9720805]]\n",
            "1516        [[0.018058045, 3.370912e-05, 0.98190826]]\n",
            "1517        [[0.006060591, 0.00016557235, 0.9937738]]\n",
            "1518         [[0.006501025, 6.124642e-05, 0.9934377]]\n",
            "1519       [[0.99959177, 5.286763e-05, 0.0003553214]]\n",
            "1520         [[0.995455, 0.0019827764, 0.0025621536]]\n",
            "1521          [[0.016402649, 0.054787707, 0.9288096]]\n",
            "1522            [[0.5034143, 0.40086773, 0.09571799]]\n",
            "1523         [[0.004771649, 2.5348707e-05, 0.995203]]\n",
            "1524      [[0.0051814253, 0.00038469574, 0.99443394]]\n",
            "1525       [[0.00014004491, 0.99765587, 0.002204028]]\n",
            "1526       [[0.9978806, 0.00012110808, 0.0019983407]]\n",
            "1527        [[0.0061219507, 5.776121e-06, 0.9938723]]\n",
            "1528         [[0.019040052, 0.0005633752, 0.9803966]]\n",
            "1529           [[0.63368857, 0.0007683915, 0.365543]]\n",
            "1530           [[0.63368857, 0.0007683915, 0.365543]]\n",
            "1531       [[0.0029614067, 0.0003567937, 0.99668175]]\n",
            "1532      [[0.0066179433, 0.00085937127, 0.99252266]]\n",
            "1533        [[0.029062543, 3.1318297e-05, 0.9709061]]\n",
            "1534        [[0.0013388108, 0.019178439, 0.97948277]]\n",
            "1535       [[0.012556564, 4.3252276e-05, 0.98740023]]\n",
            "1536           [[0.9432776, 0.006319032, 0.05040346]]\n",
            "1537         [[0.9941293, 0.0014941697, 0.004376574]]\n",
            "1538      [[0.99773645, 0.00020597377, 0.0020575526]]\n",
            "1539       [[0.024059985, 1.9971203e-05, 0.97591996]]\n",
            "1540      [[0.0056209527, 4.5213088e-05, 0.99433386]]\n",
            "1541       [[0.0022232516, 7.466131e-06, 0.99776924]]\n",
            "1542       [[0.00089480384, 0.0010434494, 0.9980617]]\n",
            "1543       [[0.002401992, 1.4993806e-05, 0.99758303]]\n",
            "1544       [[0.0026979689, 0.00018121279, 0.9971207]]\n",
            "1545            [[0.012283537, 0.5259426, 0.4617738]]\n",
            "1546      [[0.0034713757, 6.7866386e-05, 0.99646086]]\n",
            "1547          [[0.008858884, 0.003441615, 0.9876995]]\n",
            "1548       [[0.0016957272, 7.293099e-06, 0.99829704]]\n",
            "1549           [[0.077847235, 0.6297519, 0.29240087]]\n",
            "1550            [[0.14692742, 0.7137931, 0.13927953]]\n",
            "1551        [[0.0034556242, 0.0005886292, 0.9959557]]\n",
            "1552        [[0.0026988832, 7.45472e-05, 0.99722654]]\n",
            "1553        [[0.005320291, 1.5455656e-05, 0.9946643]]\n",
            "1554       [[0.0064108386, 1.2859602e-05, 0.9935762]]\n",
            "1555      [[0.0015508999, 0.00023542503, 0.99821377]]\n",
            "1556         [[0.0038484724, 0.017207267, 0.9789442]]\n",
            "1557       [[0.0033639956, 1.0154913e-05, 0.9966259]]\n",
            "1558        [[0.0071172584, 0.0015211159, 0.9913617]]\n",
            "1559          [[0.0007871816, 0.943818, 0.055394795]]\n",
            "1560          [[0.00923801, 0.97299147, 0.017770572]]\n",
            "1561            [[0.07300905, 0.6417216, 0.28526938]]\n",
            "1562          [[0.010235762, 0.9858269, 0.003937398]]\n",
            "1563         [[0.006799897, 9.577424e-05, 0.9931043]]\n",
            "1564          [[0.034954358, 0.26563326, 0.69941247]]\n",
            "1565        [[0.0011303778, 3.249058e-05, 0.9988372]]\n",
            "1566         [[0.0018672071, 0.9876009, 0.010531932]]\n",
            "1567        [[0.98862374, 0.007942323, 0.0034339263]]\n",
            "1568       [[9.8578035e-05, 0.9986093, 0.0012920684]]\n",
            "1569      [[0.00016175701, 0.99785525, 0.0019830351]]\n",
            "1570       [[6.248059e-05, 0.9996854, 0.00025214042]]\n",
            "1571        [[0.00010983877, 0.9718184, 0.028071776]]\n",
            "1572          [[0.043391746, 0.77199095, 0.18461737]]\n",
            "1573           [[0.048479166, 0.7365499, 0.21497093]]\n",
            "1574           [[0.9843544, 9.61748e-05, 0.01554945]]\n",
            "1575      [[0.084005386, 0.000114258924, 0.91588026]]\n",
            "1576          [[0.9669784, 0.010562644, 0.022458987]]\n",
            "1577        [[0.9970289, 6.569677e-05, 0.0029054154]]\n",
            "1578        [[0.00577131, 4.9706478e-06, 0.99422365]]\n",
            "1579       [[0.009918239, 1.5146313e-05, 0.99006665]]\n",
            "1580       [[0.007748818, 6.5592835e-06, 0.99224466]]\n",
            "1581       [[0.00069274334, 0.0068140817, 0.9924932]]\n",
            "1582         [[0.045373663, 0.0006557253, 0.9539706]]\n",
            "1583         [[0.0011636631, 0.9799171, 0.018919243]]\n",
            "1584         [[0.034521177, 0.93828535, 0.027193474]]\n",
            "1585          [[0.97326577, 0.019335665, 0.00739854]]\n",
            "1586        [[0.003903501, 8.650183e-05, 0.99600995]]\n",
            "1587          [[0.014006817, 0.9596789, 0.026314253]]\n",
            "1588        [[0.0007234984, 0.9987816, 0.0004949186]]\n",
            "1589         [[0.0013825776, 4.00183e-05, 0.9985775]]\n",
            "1590      [[0.00066744565, 4.3553275e-05, 0.9992889]]\n",
            "1591      [[0.0011515178, 0.00017163302, 0.99867684]]\n",
            "1592           [[0.7264946, 0.23526956, 0.038235802]]\n",
            "1593           [[0.20614555, 0.006080637, 0.7877737]]\n",
            "1594      [[0.0033914244, 0.00012760545, 0.99648094]]\n",
            "1595     [[0.00063030934, 0.00013710951, 0.99923265]]\n",
            "1596        [[0.0011041973, 0.0015196332, 0.9973762]]\n",
            "1597         [[0.0021513635, 0.8816016, 0.116247065]]\n",
            "1598         [[0.0025807025, 0.87370974, 0.12370953]]\n",
            "1599      [[8.7230546e-05, 0.99683714, 0.0030755782]]\n",
            "1600        [[4.5991503e-05, 0.9982591, 0.001694911]]\n",
            "1601       [[2.1351556e-05, 0.9994185, 0.0005601729]]\n",
            "1602          [[0.02101701, 0.000613523, 0.97836953]]\n",
            "1603       [[5.0608473e-05, 0.9984945, 0.0014548993]]\n",
            "1604      [[0.0032593878, 5.5057094e-06, 0.99673516]]\n",
            "1605       [[0.0033382801, 2.3356826e-05, 0.9966383]]\n",
            "1606        [[0.004650516, 2.2013535e-05, 0.9953275]]\n",
            "1607      [[0.0011298726, 3.5471836e-05, 0.99883467]]\n",
            "1608       [[0.99455714, 0.00023339673, 0.005209479]]\n",
            "1609         [[0.9782779, 0.0019558226, 0.019766299]]\n",
            "1610         [[0.17445044, 0.0011058773, 0.82444376]]\n",
            "1611            [[0.01998466, 0.14578898, 0.8342263]]\n",
            "1612        [[0.0041480777, 0.92344207, 0.072409846]]\n",
            "1613      [[0.0026752166, 1.1216063e-05, 0.99731356]]\n",
            "1614       [[0.0017427275, 2.2891656e-05, 0.9982344]]\n",
            "1615       [[0.004247696, 6.9267335e-05, 0.99568295]]\n",
            "1616         [[0.002059851, 0.0024082751, 0.9955318]]\n",
            "1617        [[0.0062792515, 0.0002579236, 0.9934628]]\n",
            "1618         [[0.002321261, 1.7683977e-05, 0.997661]]\n",
            "1619       [[0.011188375, 0.00014339342, 0.98866814]]\n",
            "1620          [[0.020172058, 0.000109788, 0.9797181]]\n",
            "1621            [[0.008468366, 0.339169, 0.65236264]]\n",
            "1622      [[0.0043551894, 1.50678125e-05, 0.9956298]]\n",
            "1623        [[0.004149855, 1.11140425e-05, 0.995839]]\n",
            "1624        [[0.0046184603, 1.3517206e-05, 0.995368]]\n",
            "1625      [[0.0038504624, 0.00011874914, 0.99603075]]\n",
            "1626        [[0.030557651, 0.00036886064, 0.9690735]]\n",
            "1627         [[0.01636555, 0.00017671238, 0.9834578]]\n",
            "1628       [[0.047220934, 0.00012413744, 0.95265496]]\n",
            "1629        [[0.004577858, 6.610246e-06, 0.99541545]]\n",
            "1630      [[0.00079941575, 7.796267e-05, 0.99912256]]\n",
            "1631       [[0.0034058357, 0.0031497513, 0.99344444]]\n",
            "1632          [[0.004731325, 0.01777346, 0.97749525]]\n",
            "1633       [[0.0008299679, 6.764682e-05, 0.99910235]]\n",
            "1634          [[0.00040322542, 0.01356985, 0.986027]]\n",
            "1635      [[0.0025655762, 1.6422395e-05, 0.99741805]]\n",
            "1636       [[0.007952033, 2.5875479e-05, 0.99202204]]\n",
            "1637         [[0.9802474, 0.019080201, 0.0006723697]]\n",
            "1638           [[0.0025232288, 0.9338455, 0.0636313]]\n",
            "1639       [[6.279779e-05, 0.9995136, 0.00042358288]]\n",
            "1640         [[0.5327865, 0.00031996632, 0.46689355]]\n",
            "1641         [[0.001623425, 9.1572314e-05, 0.998285]]\n",
            "1642      [[0.0025856022, 0.00085444207, 0.99656004]]\n",
            "1643        [[0.020845048, 0.00014435357, 0.9790106]]\n",
            "1644           [[0.002631045, 0.31737152, 0.6799975]]\n",
            "1645          [[0.037747867, 0.27176854, 0.69048357]]\n",
            "1646         [[0.006155227, 0.0002353777, 0.9936094]]\n",
            "1647          [[0.9826037, 0.005074229, 0.012322044]]\n",
            "1648          [[0.19927579, 0.008165248, 0.79255897]]\n",
            "1649         [[0.0019715508, 0.018566733, 0.9794617]]\n",
            "1650          [[0.0029052238, 0.06614649, 0.9309484]]\n",
            "1651         [[0.0015332558, 0.9828591, 0.015607643]]\n",
            "1652       [[6.772468e-05, 0.9996964, 0.00023594048]]\n",
            "1653      [[0.0039177295, 6.0702012e-05, 0.99602157]]\n",
            "1654      [[0.0053055016, 1.1542688e-05, 0.99468297]]\n",
            "1655             [[0.4001943, 0.0539976, 0.54580814]]\n",
            "1656        [[0.007043768, 1.7591243e-05, 0.9929386]]\n",
            "1657         [[0.9662632, 0.0037294242, 0.030007398]]\n",
            "1658        [[0.008692778, 5.4628026e-06, 0.9913018]]\n",
            "1659       [[0.013946157, 1.2463487e-05, 0.98604137]]\n",
            "1660         [[0.00168579, 2.510786e-05, 0.99828905]]\n",
            "1661         [[0.05468647, 0.0016821878, 0.94363135]]\n",
            "1662           [[0.33991674, 0.5724948, 0.087588504]]\n",
            "1663        [[0.004797478, 4.295548e-05, 0.99515957]]\n",
            "1664           [[0.008529724, 0.35483852, 0.6366318]]\n",
            "1665      [[0.0020687447, 5.2714193e-05, 0.99787855]]\n",
            "1666        [[0.001074377, 0.00013436015, 0.9987914]]\n",
            "1667        [[0.0007499229, 0.00018305774, 0.999067]]\n",
            "1668           [[0.20554563, 0.003218505, 0.7912359]]\n",
            "1669           [[0.21901207, 0.77586335, 0.00512465]]\n",
            "1670        [[0.0058506513, 1.470073e-05, 0.9941347]]\n",
            "1671          [[0.01581662, 9.1348054e-05, 0.984092]]\n",
            "1672        [[0.0025237978, 0.0058027557, 0.9916734]]\n",
            "1673          [[0.0024973773, 0.27551275, 0.7219899]]\n",
            "1674           [[0.004632085, 0.13812143, 0.8572465]]\n",
            "1675            [[0.5853606, 0.35303158, 0.06160787]]\n",
            "1676         [[0.0009728903, 0.9875673, 0.011459832]]\n",
            "1677         [[0.007085002, 0.0028812487, 0.9900337]]\n",
            "1678       [[0.0008150578, 0.99756515, 0.0016198009]]\n",
            "1679           [[0.03477177, 0.74772984, 0.21749839]]\n",
            "1680       [[0.0038775906, 0.00019112244, 0.9959313]]\n",
            "1681           [[0.09867042, 0.28943658, 0.61189294]]\n",
            "1682       [[0.0063055614, 0.0005610109, 0.99313337]]\n",
            "1683          [[0.0051735477, 1.644298e-05, 0.99481]]\n",
            "1684      [[0.0033282444, 9.6243646e-05, 0.99657553]]\n",
            "1685        [[0.99718213, 0.002065824, 0.0007521295]]\n",
            "1686         [[0.004179281, 0.002956982, 0.99286383]]\n",
            "1687         [[0.0025147223, 0.01819909, 0.97928625]]\n",
            "1688         [[0.9920334, 0.004134456, 0.0038320443]]\n",
            "1689         [[0.9965062, 0.001331275, 0.0021625268]]\n",
            "1690        [[0.011016861, 0.00016161588, 0.9888215]]\n",
            "1691           [[0.1442668, 0.84975946, 0.005973686]]\n",
            "1692         [[0.95886475, 0.03971312, 0.0014222095]]\n",
            "1693       [[0.0012082412, 0.0004842958, 0.99830747]]\n",
            "1694          [[0.9832153, 0.007986731, 0.008798008]]\n",
            "1695       [[0.016322408, 0.00015077757, 0.98352677]]\n",
            "1696       [[0.0014892139, 1.045866e-05, 0.99850035]]\n",
            "1697          [[0.08375723, 0.023961946, 0.89228076]]\n",
            "1698        [[0.00096504396, 0.9874806, 0.011554356]]\n",
            "1699       [[0.0064800065, 7.558946e-06, 0.99351245]]\n",
            "1700         [[0.008904766, 6.6112654e-05, 0.991029]]\n",
            "1701         [[0.011355697, 0.00037022473, 0.988274]]\n",
            "1702     [[0.00070595683, 0.99865735, 0.00063667976]]\n",
            "1703       [[8.510579e-05, 0.99780613, 0.0021087495]]\n",
            "1704             [[0.319854, 0.64687824, 0.03326779]]\n",
            "1705        [[0.0022959358, 5.032882e-06, 0.9976991]]\n",
            "1706        [[0.0034690092, 0.033008162, 0.96352285]]\n",
            "1707         [[0.0014567374, 0.003458745, 0.9950846]]\n",
            "1708       [[0.00022026843, 0.9984079, 0.0013718547]]\n",
            "1709           [[0.05214872, 0.64334875, 0.30450255]]\n",
            "1710          [[0.17980874, 0.76443446, 0.055756774]]\n",
            "1711       [[0.9982917, 0.00024522925, 0.0014630388]]\n",
            "1712          [[0.9854645, 0.004615556, 0.009919941]]\n",
            "1713         [[0.010088315, 0.014710307, 0.97520137]]\n",
            "1714          [[0.011355972, 0.60262865, 0.38601533]]\n",
            "1715         [[0.9909576, 0.0042696977, 0.004772663]]\n",
            "1716        [[0.0011628702, 5.6112993e-05, 0.998781]]\n",
            "1717           [[0.7608847, 0.030612724, 0.20850259]]\n",
            "1718         [[0.00295163, 0.00011667577, 0.9969317]]\n",
            "1719         [[0.028485287, 0.025246317, 0.94626844]]\n",
            "1720       [[0.999814, 5.0534716e-05, 0.00013547065]]\n",
            "1721            [[0.08177475, 0.01740391, 0.9008214]]\n",
            "1722           [[0.032278243, 0.9326518, 0.03506989]]\n",
            "1723       [[0.0033259424, 2.8645845e-05, 0.9966454]]\n",
            "1724         [[0.0017830069, 0.81995416, 0.17826289]]\n",
            "1725         [[0.0016574517, 4.53914e-05, 0.9982973]]\n",
            "1726          [[0.024438495, 0.030298347, 0.9452632]]\n",
            "1727        [[0.0064091748, 7.201999e-06, 0.9935836]]\n",
            "1728         [[0.995758, 0.0032577876, 0.0009841152]]\n",
            "1729          [[0.89373136, 0.01968955, 0.086579144]]\n",
            "1730      [[0.0042339214, 1.5595435e-05, 0.99575055]]\n",
            "1731        [[0.0019187039, 2.7196065e-05, 0.998054]]\n",
            "1732         [[0.008652643, 2.2313097e-05, 0.991325]]\n",
            "1733           [[0.020871595, 0.32641655, 0.6527118]]\n",
            "1734       [[0.013554493, 0.00048786448, 0.98595756]]\n",
            "1735          [[0.73609734, 0.20912212, 0.054780543]]\n",
            "1736      [[0.00076286617, 0.00024158921, 0.9989955]]\n",
            "1737      [[0.0057736314, 4.5319084e-06, 0.99422187]]\n",
            "1738        [[0.004676061, 4.0067534e-06, 0.9953199]]\n",
            "1739     [[0.00044711074, 5.6321434e-05, 0.99949646]]\n",
            "1740          [[0.0008840802, 0.05265697, 0.9464589]]\n",
            "1741              [[0.166945, 0.7435614, 0.08949368]]\n",
            "1742             [[0.24352087, 0.7350226, 0.0214565]]\n",
            "1743          [[0.02312913, 0.97119844, 0.005672448]]\n",
            "1744      [[0.00047749738, 0.00025872083, 0.9992638]]\n",
            "1745        [[0.005796184, 1.7540699e-05, 0.9941863]]\n",
            "1746         [[0.005310945, 1.292187e-05, 0.9946761]]\n",
            "1747        [[0.007034687, 0.00012308417, 0.9928422]]\n",
            "1748            [[0.37651646, 0.5609163, 0.06256725]]\n",
            "1749            [[0.26503384, 0.20065363, 0.5343125]]\n",
            "1750          [[0.014672931, 0.038858566, 0.9464685]]\n",
            "1751         [[0.0035816508, 0.05933047, 0.93708783]]\n",
            "1752      [[0.0049345745, 1.2025784e-05, 0.99505347]]\n",
            "1753         [[0.012957556, 0.032338105, 0.95470434]]\n",
            "1754           [[0.47837368, 0.5116428, 0.009983513]]\n",
            "1755        [[0.9990085, 0.0006598469, 0.0003317112]]\n",
            "1756         [[0.021780083, 0.0085519785, 0.9696679]]\n",
            "1757           [[0.04216437, 0.002252533, 0.9555831]]\n",
            "1758           [[0.04517217, 1.19724e-05, 0.9548158]]\n",
            "1759        [[0.0009595566, 0.9913584, 0.0076821065]]\n",
            "1760          [[0.0019623456, 0.1314815, 0.86655617]]\n",
            "1761          [[0.001108079, 0.013071082, 0.9858209]]\n",
            "1762         [[0.049166046, 0.010185712, 0.94064826]]\n",
            "1763           [[0.11108008, 0.005069921, 0.8838499]]\n",
            "1764       [[0.0036365252, 3.855226e-05, 0.99632484]]\n",
            "1765          [[0.004549053, 0.035586137, 0.9598648]]\n",
            "1766      [[0.00059093355, 0.0062042186, 0.99320483]]\n",
            "1767         [[0.0010343762, 0.9604707, 0.038494963]]\n",
            "1768         [[0.025108004, 0.0001392699, 0.9747526]]\n",
            "1769       [[0.00029863103, 6.493985e-05, 0.9996364]]\n",
            "1770       [[0.0002583751, 3.9287435e-05, 0.9997023]]\n",
            "1771        [[6.941107e-05, 0.9987249, 0.0012057289]]\n",
            "1772        [[0.01032301, 5.8650894e-05, 0.98961836]]\n",
            "1773     [[0.99928635, 0.00013401188, 0.00057961995]]\n",
            "1774       [[0.0032115397, 4.1721327e-05, 0.9967468]]\n",
            "1775            [[0.12603754, 0.04418425, 0.8297782]]\n",
            "1776            [[0.012854868, 0.1811999, 0.8059452]]\n",
            "1777        [[0.0011156646, 0.0033694555, 0.9955149]]\n",
            "1778        [[0.0010741532, 0.0043649827, 0.9945609]]\n",
            "1779         [[0.004821123, 0.010225706, 0.98495317]]\n",
            "1780           [[0.09768591, 0.47115186, 0.43116218]]\n",
            "1781          [[0.22241332, 0.76967674, 0.007910009]]\n",
            "1782      [[0.0022948387, 0.00010606117, 0.99759907]]\n",
            "1783       [[0.0013246383, 6.861772e-05, 0.99860686]]\n",
            "1784           [[0.009368808, 0.6223486, 0.36828262]]\n",
            "1785           [[0.029425623, 0.4837776, 0.48679674]]\n",
            "1786        [[0.0009712777, 0.0014717487, 0.9975569]]\n",
            "1787           [[0.0006506404, 0.0693348, 0.9300145]]\n",
            "1788        [[0.003034781, 0.00011356197, 0.9968516]]\n",
            "1789      [[0.0013727761, 4.8023194e-05, 0.99857926]]\n",
            "1790        [[0.0003501208, 0.0003762371, 0.9992737]]\n",
            "1791           [[0.014041661, 0.07621403, 0.9097443]]\n",
            "1792           [[0.007450019, 0.06647677, 0.9260732]]\n",
            "1793          [[0.008682659, 0.79581136, 0.19550599]]\n",
            "1794           [[0.002187254, 0.8937261, 0.10408668]]\n",
            "1795          [[0.055626694, 0.16315095, 0.78122234]]\n",
            "1796       [[0.0024511113, 0.0013790744, 0.99616987]]\n",
            "1797      [[0.0013967381, 3.5325935e-05, 0.99856794]]\n",
            "1798          [[0.029188946, 0.12428892, 0.84652215]]\n",
            "1799         [[0.0041706413, 0.124452546, 0.8713768]]\n",
            "1800       [[0.0020797637, 0.0001080416, 0.99781215]]\n",
            "1801       [[0.0049166577, 1.7793507e-05, 0.9950656]]\n",
            "1802         [[0.009632716, 0.009880216, 0.98048705]]\n",
            "1803        [[0.0011217674, 0.0036440955, 0.9952342]]\n",
            "1804       [[0.00050355087, 0.9979018, 0.0015946735]]\n",
            "1805         [[0.0014994885, 0.43513107, 0.56336945]]\n",
            "1806         [[0.0021197808, 0.68218863, 0.31569162]]\n",
            "1807        [[0.00020595742, 0.9864847, 0.013309416]]\n",
            "1808         [[0.063995235, 0.009619392, 0.92638534]]\n",
            "1809       [[0.007187255, 3.0440922e-05, 0.99278235]]\n",
            "1810        [[0.004825856, 2.4759034e-05, 0.9951493]]\n",
            "1811       [[0.014511065, 0.98498154, 0.00050736574]]\n",
            "1812          [[0.34736392, 0.002383295, 0.65025276]]\n",
            "1813           [[0.01826947, 5.78808e-05, 0.9816726]]\n",
            "1814          [[0.019270528, 0.046589263, 0.9341402]]\n",
            "1815          [[0.7375107, 0.0013059354, 0.26118335]]\n",
            "1816        [[0.016274303, 1.947572e-05, 0.98370624]]\n",
            "1817        [[0.02119921, 1.6556503e-05, 0.97878426]]\n",
            "1818        [[0.97727394, 0.00031965747, 0.02240631]]\n",
            "1819          [[0.96526974, 0.00554735, 0.029182957]]\n",
            "1820       [[0.007375796, 0.00011175837, 0.99251246]]\n",
            "1821            [[0.124413535, 0.7270842, 0.1485022]]\n",
            "1822        [[0.20862688, 0.00018936099, 0.79118377]]\n",
            "1823            [[0.18862636, 0.2442179, 0.56715566]]\n",
            "1824        [[0.99529946, 0.0003001983, 0.004400388]]\n",
            "1825         [[0.0055472953, 0.011322847, 0.9831298]]\n",
            "1826           [[0.019123692, 0.17861466, 0.8022617]]\n",
            "1827           [[0.14917354, 0.094685994, 0.7561404]]\n",
            "1828          [[0.014048152, 0.87360495, 0.11234696]]\n",
            "1829         [[0.80060625, 8.284073e-05, 0.19931091]]\n",
            "1830         [[0.0021190194, 0.83375895, 0.16412206]]\n",
            "1831        [[0.003013892, 1.759163e-05, 0.99696857]]\n",
            "1832        [[0.0054596937, 6.493181e-05, 0.9944753]]\n",
            "1833          [[0.0016583652, 0.33194372, 0.6663979]]\n",
            "1834        [[0.0022062068, 0.002233004, 0.99556077]]\n",
            "1835        [[0.043062255, 4.2452935e-05, 0.9568953]]\n",
            "1836       [[0.99171937, 0.00017678835, 0.008103948]]\n",
            "1837        [[0.012847806, 2.7110158e-05, 0.9871251]]\n",
            "1838        [[0.0021197214, 0.009188668, 0.98869157]]\n",
            "1839           [[0.6028746, 0.39270663, 0.004418844]]\n",
            "1840       [[0.007364008, 1.3801216e-05, 0.99262214]]\n",
            "1841         [[0.032275535, 0.0029862176, 0.9647382]]\n",
            "1842      [[0.0025577387, 1.8665904e-05, 0.99742365]]\n",
            "1843      [[0.0017698297, 1.4791681e-05, 0.99821544]]\n",
            "1844       [[0.0062896097, 0.0032254157, 0.99048495]]\n",
            "1845         [[0.014121093, 0.0002332221, 0.9856457]]\n",
            "1846       [[0.005281221, 0.00017209872, 0.99454665]]\n",
            "1847          [[0.03794162, 0.001310662, 0.96074766]]\n",
            "1848          [[0.15725051, 0.027537275, 0.81521225]]\n",
            "1849            [[0.004840544, 0.10732552, 0.887834]]\n",
            "1850           [[0.4186698, 0.0007160406, 0.5806142]]\n",
            "1851       [[0.039131783, 0.00036059128, 0.96050763]]\n",
            "1852       [[0.004462972, 2.1849386e-05, 0.99551517]]\n",
            "1853      [[0.0050041135, 9.2860955e-06, 0.99498665]]\n",
            "1854        [[0.0039815623, 0.0045544123, 0.9914641]]\n",
            "1855        [[0.96604407, 0.032656144, 0.0012998291]]\n",
            "1856        [[0.93718827, 0.0009957467, 0.061815962]]\n",
            "1857      [[0.0027035552, 1.3667079e-05, 0.99728274]]\n",
            "1858      [[0.0011944139, 2.1161719e-05, 0.99878436]]\n",
            "1859      [[0.00096965174, 7.816846e-05, 0.99895215]]\n",
            "1860       [[0.0019054518, 1.131772e-05, 0.99808323]]\n",
            "1861           [[0.034337, 0.0009839111, 0.96467906]]\n",
            "1862        [[0.0017672325, 0.004542526, 0.99369025]]\n",
            "1863         [[0.00286278, 1.7838634e-05, 0.9971194]]\n",
            "1864        [[0.0021425108, 9.200252e-06, 0.9978484]]\n",
            "1865         [[0.01413484, 0.0038575677, 0.98200756]]\n",
            "1866          [[0.002376331, 0.060788464, 0.9368352]]\n",
            "1867        [[0.0008491714, 0.0016482996, 0.9975025]]\n",
            "1868           [[0.00980846, 0.39744055, 0.59275097]]\n",
            "1869      [[0.00027808768, 0.98632926, 0.0133926915]]\n",
            "1870       [[0.00011853343, 0.9982907, 0.0015907685]]\n",
            "1871          [[0.004216405, 0.011599269, 0.9841844]]\n",
            "1872          [[0.030343048, 0.006641248, 0.9630158]]\n",
            "1873       [[0.016025791, 0.00053730834, 0.98343694]]\n",
            "1874       [[0.0033316223, 1.9854762e-05, 0.9966485]]\n",
            "1875       [[0.005222637, 2.7986465e-05, 0.99474937]]\n",
            "1876          [[0.020910574, 0.90352637, 0.07556311]]\n",
            "1877       [[0.004094827, 1.0598222e-05, 0.99589455]]\n",
            "1878          [[0.001386746, 6.525595e-05, 0.998548]]\n",
            "1879        [[0.0022130047, 7.057926e-05, 0.9977164]]\n",
            "1880          [[0.013834739, 0.0020402973, 0.984125]]\n",
            "1881      [[0.0022354305, 0.00017065476, 0.99759394]]\n",
            "1882       [[0.0050594644, 0.0011680152, 0.99377257]]\n",
            "1883      [[0.0048492206, 3.3231925e-05, 0.99511755]]\n",
            "1884         [[0.007460216, 0.003326829, 0.98921293]]\n",
            "1885       [[0.058659226, 5.9212307e-05, 0.94128156]]\n",
            "1886         [[0.95577276, 0.040158663, 0.004068549]]\n",
            "1887             [[0.70779777, 0.269882, 0.02232029]]\n",
            "1888        [[0.019413695, 3.1180924e-05, 0.9805551]]\n",
            "1889           [[0.989622, 0.00886677, 0.0015112362]]\n",
            "1890          [[0.16017315, 0.83507514, 0.004751655]]\n",
            "1891         [[0.008305049, 1.536004e-05, 0.9916796]]\n",
            "1892         [[0.012074739, 0.0061296164, 0.9817957]]\n",
            "1893         [[0.046640195, 5.853748e-05, 0.9533013]]\n",
            "1894          [[0.002618741, 0.001106401, 0.9962748]]\n",
            "1895           [[0.026583532, 0.10779109, 0.8656253]]\n",
            "1896       [[0.0014842484, 2.589674e-05, 0.99848974]]\n",
            "1897         [[0.0027615367, 0.73066926, 0.26656914]]\n",
            "1898          [[0.30608192, 0.6888531, 0.0050649275]]\n",
            "1899         [[0.030331133, 0.96578836, 0.003880515]]\n",
            "1900        [[0.007421345, 0.98892874, 0.0036499263]]\n",
            "1901      [[0.0055029294, 9.1891336e-05, 0.99440515]]\n",
            "1902              [[0.04555375, 0.298005, 0.6564412]]\n",
            "1903            [[0.07071911, 0.1640136, 0.76526725]]\n",
            "1904          [[0.9555167, 0.036584157, 0.007899151]]\n",
            "1905           [[0.59141195, 0.36823186, 0.04035622]]\n",
            "1906        [[0.0029870612, 0.9955428, 0.0014701084]]\n",
            "1907       [[0.0011550564, 6.076227e-05, 0.99878424]]\n",
            "1908       [[0.011335022, 2.5631749e-05, 0.98863935]]\n",
            "1909             [[0.522462, 0.41075727, 0.06678071]]\n",
            "1910       [[0.0077505554, 1.5610362e-05, 0.9922339]]\n",
            "1911         [[0.012320529, 4.428619e-05, 0.9876352]]\n",
            "1912          [[0.0037673241, 0.67084724, 0.3253854]]\n",
            "1913         [[0.003972981, 3.085899e-05, 0.9959961]]\n",
            "1914       [[0.0029888512, 2.6845368e-05, 0.9969843]]\n",
            "1915         [[0.001936324, 0.0002275336, 0.9978362]]\n",
            "1916        [[0.009199072, 0.00010403723, 0.9906969]]\n",
            "1917         [[0.0025053846, 0.010944933, 0.9865497]]\n",
            "1918      [[0.00046956047, 0.0001968175, 0.99933356]]\n",
            "1919        [[0.0033366175, 6.4357046e-05, 0.996599]]\n",
            "1920          [[0.0022956517, 0.01103069, 0.9866737]]\n",
            "1921        [[0.9862136, 0.0025543172, 0.0112320315]]\n",
            "1922           [[0.20140298, 0.13655655, 0.66204053]]\n",
            "1923         [[0.00070837804, 0.04837398, 0.9509176]]\n",
            "1924      [[0.0009659814, 0.00013572932, 0.99889827]]\n",
            "1925         [[0.006838134, 9.519919e-06, 0.9931524]]\n",
            "1926        [[0.012803947, 1.0801089e-05, 0.9871852]]\n",
            "1927        [[0.0015032605, 1.124798e-05, 0.9984856]]\n",
            "1928          [[0.0014726081, 0.7403027, 0.25822476]]\n",
            "1929       [[0.0005429292, 0.0021653094, 0.99729174]]\n",
            "1930       [[0.014714709, 1.5409098e-05, 0.98526996]]\n",
            "1931       [[0.0019450956, 0.0004377534, 0.99761707]]\n",
            "1932           [[0.00044554, 0.0006403736, 0.998914]]\n",
            "1933         [[0.993824, 0.0016244274, 0.0045516375]]\n",
            "1934        [[0.9954823, 0.0018336693, 0.0026839857]]\n",
            "1935          [[0.60225135, 0.38868603, 0.009062652]]\n",
            "1936       [[0.99656856, 0.0019782684, 0.0014531937]]\n",
            "1937       [[0.010465639, 1.3228626e-05, 0.98952115]]\n",
            "1938          [[0.0014488338, 0.93612605, 0.0624251]]\n",
            "1939       [[0.0071611423, 3.1083853e-06, 0.9928358]]\n",
            "1940          [[0.009879306, 0.041116577, 0.9490041]]\n",
            "1941           [[0.04779716, 0.007363011, 0.9448399]]\n",
            "1942       [[0.00094645965, 0.0001946911, 0.9988588]]\n",
            "1943         [[0.00044266006, 0.8276363, 0.17192106]]\n",
            "1944        [[0.0120447315, 7.395672e-05, 0.9878813]]\n",
            "1945         [[0.9288627, 0.00093150116, 0.07020583]]\n",
            "1946        [[0.011807223, 1.0234985e-05, 0.9881825]]\n",
            "1947       [[0.0017801812, 0.0008030623, 0.99741673]]\n",
            "1948          [[0.24382342, 0.021608772, 0.73456776]]\n",
            "1949       [[0.00070821814, 0.91775405, 0.081537746]]\n",
            "1950       [[0.0046240585, 3.614389e-05, 0.99533975]]\n",
            "1951         [[0.016641485, 0.0005693875, 0.9827891]]\n",
            "1952        [[0.03969743, 0.00012333516, 0.96017915]]\n",
            "1953       [[0.0056299637, 1.0881823e-05, 0.9943592]]\n",
            "1954         [[0.002337104, 1.580667e-05, 0.9976471]]\n",
            "1955      [[0.0012101135, 2.0956764e-05, 0.99876887]]\n",
            "1956        [[0.0002445143, 0.00017053496, 0.999585]]\n",
            "1957          [[0.013495354, 0.91541845, 0.07108619]]\n",
            "1958               [[0.094907, 0.815098, 0.08999496]]\n",
            "1959        [[0.99320436, 0.006033779, 0.0007618812]]\n",
            "1960      [[0.0142744435, 0.98533547, 0.00039008027]]\n",
            "1961      [[8.9304456e-05, 0.99300885, 0.0069018523]]\n",
            "1962          [[0.001055045, 0.9605201, 0.038424898]]\n",
            "1963       [[0.0069577736, 0.0065747346, 0.98646754]]\n",
            "1964        [[0.012830938, 3.7425216e-05, 0.9871316]]\n",
            "1965        [[0.012830938, 3.7425216e-05, 0.9871316]]\n",
            "1966       [[0.0039502336, 0.0005098697, 0.99553996]]\n",
            "1967          [[0.0013745712, 0.21637672, 0.7822487]]\n",
            "1968             [[0.02768267, 0.7756378, 0.1966795]]\n",
            "1969            [[0.026704168, 0.9636834, 0.0096124]]\n",
            "1970         [[0.13978992, 0.0013798242, 0.85883033]]\n",
            "1971       [[0.0071660616, 1.3775366e-05, 0.9928202]]\n",
            "1972      [[0.0050477413, 3.8942788e-05, 0.99491334]]\n",
            "1973             [[0.0589116, 0.00395371, 0.9371346]]\n",
            "1974        [[0.004157703, 8.871563e-05, 0.99575365]]\n",
            "1975            [[0.02567254, 0.21341279, 0.7609147]]\n",
            "1976        [[0.011041308, 7.1360505e-06, 0.9889515]]\n",
            "1977            [[0.10736178, 0.4835772, 0.40906104]]\n",
            "1978           [[0.019391773, 0.10091872, 0.8796896]]\n",
            "1979           [[0.005056514, 0.6523397, 0.34260383]]\n",
            "1980        [[0.081749745, 7.507911e-05, 0.91817516]]\n",
            "1981        [[0.0021216634, 0.013393286, 0.98448503]]\n",
            "1982       [[0.00083358947, 0.0031226727, 0.9960438]]\n",
            "1983       [[0.0038789443, 1.3500044e-05, 0.9961075]]\n",
            "1984        [[0.005359729, 9.4755615e-06, 0.9946308]]\n",
            "1985          [[0.27245352, 0.0005718886, 0.7269746]]\n",
            "1986       [[0.0056728944, 5.316779e-05, 0.99427384]]\n",
            "1987         [[0.0030589027, 0.001426448, 0.9955146]]\n",
            "1988          [[0.012060093, 0.9531061, 0.034833767]]\n",
            "1989          [[0.9295079, 0.025950616, 0.044541467]]\n",
            "1990         [[0.0010321856, 0.82577246, 0.17319533]]\n",
            "1991          [[0.0017216203, 0.9652494, 0.03302893]]\n",
            "1992          [[0.0050791563, 0.66220254, 0.3327183]]\n",
            "1993      [[0.0058591748, 2.5620211e-05, 0.99411523]]\n",
            "1994           [[0.0021739253, 0.51463014, 0.483196]]\n",
            "1995        [[0.0013820545, 0.007597165, 0.99102074]]\n",
            "1996             [[0.00431537, 0.5400169, 0.4556677]]\n",
            "1997         [[0.00062082126, 0.67771935, 0.3216599]]\n",
            "1998           [[0.0905911, 0.88766235, 0.021746526]]\n",
            "1999          [[0.0004588012, 0.8972499, 0.10229135]]\n",
            "2000          [[0.0024627615, 0.52423245, 0.4733048]]\n",
            "2001       [[0.0033727428, 0.00056391984, 0.9960634]]\n",
            "2002        [[0.0040784273, 0.93873507, 0.057186507]]\n",
            "2003         [[0.0035094752, 0.99201137, 0.00447916]]\n",
            "2004        [[0.0009843284, 0.92474973, 0.074265964]]\n",
            "2005         [[0.0032817845, 0.97331583, 0.02340235]]\n",
            "2006       [[0.00019027195, 0.98965925, 0.010150485]]\n",
            "2007            [[0.03132002, 0.0016900669, 0.96699]]\n",
            "2008           [[0.2490056, 0.71959895, 0.031395435]]\n",
            "2009            [[0.14494902, 0.13045093, 0.7246001]]\n",
            "2010          [[0.91318285, 0.07309997, 0.013717259]]\n",
            "2011         [[0.0072195865, 0.00166496, 0.99111545]]\n",
            "2012       [[0.009931447, 2.2651515e-05, 0.99004585]]\n",
            "2013          [[0.012976502, 0.045373026, 0.9416504]]\n",
            "2014        [[0.017715124, 1.1981755e-05, 0.9822729]]\n",
            "2015          [[0.928616, 0.00023207506, 0.07115195]]\n",
            "2016       [[0.009995814, 2.6232326e-05, 0.98997796]]\n",
            "2017           [[0.007997721, 0.9212637, 0.07073855]]\n",
            "2018           [[0.44152558, 0.012396027, 0.5460784]]\n",
            "2019          [[0.0026831252, 0.79626757, 0.2010493]]\n",
            "2020        [[0.0022807443, 3.405347e-05, 0.9976852]]\n",
            "2021          [[0.0014280025, 0.3480049, 0.65056705]]\n",
            "2022         [[0.010992943, 7.556268e-05, 0.9889314]]\n",
            "2023          [[0.03645839, 2.971993e-05, 0.9635119]]\n",
            "2024          [[0.12588187, 0.029372048, 0.84474605]]\n",
            "2025        [[0.0017862042, 0.0001678394, 0.9980459]]\n",
            "2026        [[0.003603554, 0.00014560604, 0.9962508]]\n",
            "2027        [[0.0044763037, 0.000719868, 0.99480385]]\n",
            "2028        [[0.005072534, 0.0034745564, 0.99145293]]\n",
            "2029           [[0.002588225, 0.18429779, 0.8131139]]\n",
            "2030       [[0.0069290674, 1.9365307e-05, 0.9930515]]\n",
            "2031          [[0.19788677, 0.0043148664, 0.7977983]]\n",
            "2032            [[0.02466762, 0.6140017, 0.36133075]]\n",
            "2033          [[0.69512033, 0.042660642, 0.26221904]]\n",
            "2034       [[0.004111417, 0.00011067634, 0.99577796]]\n",
            "2035        [[4.6299327e-05, 0.9963348, 0.003618848]]\n",
            "2036       [[0.0005044208, 0.9989791, 0.00051650126]]\n",
            "2037        [[0.004951721, 0.99396294, 0.0010853147]]\n",
            "2038     [[0.00015524731, 0.99961424, 0.00023052107]]\n",
            "2039        [[0.0008429069, 0.97019243, 0.028964678]]\n",
            "2040          [[0.85572296, 0.13504903, 0.009227915]]\n",
            "2041       [[0.031903714, 2.1656559e-05, 0.96807456]]\n",
            "2042        [[0.036242913, 0.0068540727, 0.95690304]]\n",
            "2043        [[0.0017062847, 7.079404e-05, 0.9982229]]\n",
            "2044        [[0.0015732925, 0.97729856, 0.021128148]]\n",
            "2045      [[0.00017137751, 0.99704856, 0.0027801336]]\n",
            "2046         [[0.0006510993, 0.9942714, 0.005077464]]\n",
            "2047          [[0.00502237, 0.97950053, 0.015477144]]\n",
            "2048       [[0.99639434, 0.00057961355, 0.003026037]]\n",
            "2049       [[0.99659806, 0.0005874752, 0.0028144885]]\n",
            "2050         [[0.017560089, 1.337652e-05, 0.9824265]]\n",
            "2051         [[0.0022151524, 0.016215414, 0.9815694]]\n",
            "2052         [[0.011952881, 0.024863046, 0.96318406]]\n",
            "2053         [[0.0010539613, 0.0002500606, 0.998696]]\n",
            "2054          [[0.0027525136, 0.01888119, 0.9783664]]\n",
            "2055        [[0.0024435823, 1.0369922e-05, 0.997546]]\n",
            "2056       [[0.0025107602, 0.0026716914, 0.99481744]]\n",
            "2057        [[0.0043545044, 1.9494699e-05, 0.995626]]\n",
            "2058       [[0.004502244, 5.0433537e-05, 0.99544734]]\n",
            "2059        [[0.0024458563, 4.579128e-05, 0.9975083]]\n",
            "2060      [[0.00050762383, 0.00013187055, 0.9993605]]\n",
            "2061      [[0.0014524095, 2.0646858e-05, 0.99852693]]\n",
            "2062           [[0.39579102, 0.09830749, 0.50590146]]\n",
            "2063       [[0.011897397, 2.3405903e-05, 0.98807913]]\n",
            "2064        [[0.0024608222, 7.690799e-05, 0.9974623]]\n",
            "2065        [[0.007036446, 1.5180451e-05, 0.9929484]]\n",
            "2066           [[0.7667516, 0.20723453, 0.026013922]]\n",
            "2067      [[0.99806327, 0.00041528261, 0.0015214881]]\n",
            "2068        [[0.019039592, 1.7425975e-05, 0.9809429]]\n",
            "2069         [[0.004011237, 0.001261803, 0.99472696]]\n",
            "2070         [[0.02446714, 0.0027552685, 0.97277755]]\n",
            "2071     [[0.99954563, 0.00023735865, 0.00021694848]]\n",
            "2072      [[0.0022432166, 1.5962923e-05, 0.99774086]]\n",
            "2073       [[0.0020406644, 2.789775e-05, 0.99793136]]\n",
            "2074         [[0.91850674, 0.0022848616, 0.07920844]]\n",
            "2075        [[0.044884432, 0.0013266696, 0.95378894]]\n",
            "2076       [[0.9992436, 0.00020132826, 0.0005551506]]\n",
            "2077      [[0.9996599, 0.00017580252, 0.00016427842]]\n",
            "2078            [[0.3272621, 0.20909254, 0.46364534]]\n",
            "2079      [[0.0010589336, 0.00012717622, 0.99881387]]\n",
            "2080         [[0.001179403, 7.541871e-05, 0.9987452]]\n",
            "2081        [[0.0010977461, 0.0023116232, 0.9965906]]\n",
            "2082       [[0.0007966565, 4.8438833e-05, 0.9991549]]\n",
            "2083           [[0.0003550215, 0.921089, 0.07855601]]\n",
            "2084     [[0.00023193509, 0.00026105004, 0.99950695]]\n",
            "2085       [[0.0026217273, 2.8781931e-05, 0.9973495]]\n",
            "2086          [[0.0028695115, 0.3018654, 0.69526505]]\n",
            "2087       [[0.0050979513, 2.0701702e-05, 0.9948813]]\n",
            "2088      [[0.9996741, 6.9260175e-05, 0.00025671412]]\n",
            "2089       [[0.0017653167, 0.0008757903, 0.99735886]]\n",
            "2090       [[0.013620266, 6.1141536e-06, 0.98637366]]\n",
            "2091        [[0.021544488, 0.00017011506, 0.9782853]]\n",
            "2092        [[0.0033687586, 0.0016050953, 0.9950262]]\n",
            "2093        [[0.010795033, 9.5585114e-05, 0.9891094]]\n",
            "2094        [[0.011564832, 0.00016668865, 0.9882685]]\n",
            "2095          [[0.005312257, 0.019347113, 0.9753406]]\n",
            "2096       [[0.0002414434, 0.99846965, 0.0012889071]]\n",
            "2097         [[0.0006813432, 0.9875661, 0.011752526]]\n",
            "2098        [[0.0008020104, 0.97480154, 0.024396472]]\n",
            "2099        [[0.0021483372, 0.013560253, 0.98429143]]\n",
            "2100      [[0.00066515437, 7.9114594e-05, 0.9992557]]\n",
            "2101        [[0.0046427804, 6.657148e-06, 0.9953506]]\n",
            "2102       [[0.0036897284, 2.7931874e-05, 0.9962824]]\n",
            "2103        [[0.0027636162, 0.070718475, 0.92651784]]\n",
            "2104      [[0.0059923925, 1.6012084e-05, 0.99399155]]\n",
            "2105       [[0.0013398036, 8.051603e-06, 0.99865216]]\n",
            "2106     [[0.00032714097, 2.4423838e-05, 0.99964845]]\n",
            "2107      [[0.99650383, 3.5350204e-05, 0.0034608135]]\n",
            "2108        [[0.9751558, 1.27303365e-05, 0.02483148]]\n",
            "2109         [[0.016676396, 0.96029025, 0.023033382]]\n",
            "2110         [[0.9703203, 0.0039489362, 0.025730804]]\n",
            "2111        [[0.0005959502, 0.96510434, 0.034299653]]\n",
            "2112        [[0.0016370598, 0.018515512, 0.97984743]]\n",
            "2113       [[0.0008784355, 0.99652016, 0.0026013907]]\n",
            "2114          [[0.31928468, 0.025618993, 0.65509635]]\n",
            "2115      [[0.00067238783, 0.00046577878, 0.9988618]]\n",
            "2116           [[0.0005221538, 0.0213834, 0.9780945]]\n",
            "2117        [[0.0072877575, 6.950791e-05, 0.9926428]]\n",
            "2118          [[0.0011729472, 0.07329264, 0.9255344]]\n",
            "2119       [[0.0010103565, 0.0004544855, 0.99853516]]\n",
            "2120      [[0.0027727506, 0.00011210908, 0.99711514]]\n",
            "2121        [[0.0022760713, 0.00016583534, 0.997558]]\n",
            "2122        [[0.0014816725, 0.0015955068, 0.9969228]]\n",
            "2123         [[0.0010942025, 0.016708275, 0.9821975]]\n",
            "2124         [[0.0036723195, 0.000779201, 0.9955485]]\n",
            "2125            [[0.26096907, 0.11746942, 0.6215615]]\n",
            "2126         [[0.0022759817, 0.0046270057, 0.993097]]\n",
            "2127       [[0.0008553643, 1.3155314e-05, 0.9991315]]\n",
            "2128      [[0.00059651566, 0.00011518532, 0.9992884]]\n",
            "2129        [[0.0058951373, 7.93543e-05, 0.99402547]]\n",
            "2130           [[0.9103957, 0.08546033, 0.004144036]]\n",
            "2131           [[0.4542923, 0.52787423, 0.017833482]]\n",
            "2132       [[0.0012180852, 0.0072376933, 0.99154425]]\n",
            "2133        [[0.0012562021, 0.0003000473, 0.9984438]]\n",
            "2134      [[0.00033158401, 1.2946739e-05, 0.9996555]]\n",
            "2135         [[0.00070751, 0.0007214155, 0.99857104]]\n",
            "2136           [[0.07470538, 0.20272525, 0.72256935]]\n",
            "2137          [[0.0001494543, 0.8977377, 0.10211283]]\n",
            "2138        [[0.044921663, 1.2108908e-05, 0.9550663]]\n",
            "2139           [[0.21550062, 0.000179788, 0.7843196]]\n",
            "2140         [[0.9850071, 0.011251751, 0.0037411884]]\n",
            "2141           [[0.011233553, 0.7344948, 0.25427166]]\n",
            "2142          [[0.049048748, 0.40608922, 0.54486203]]\n",
            "2143        [[0.0107988985, 0.0018786405, 0.9873224]]\n",
            "2144        [[0.0031289903, 1.5884723e-05, 0.996855]]\n",
            "2145      [[0.0107835485, 4.1096922e-05, 0.98917526]]\n",
            "2146          [[0.003569008, 0.069422804, 0.9270083]]\n",
            "2147           [[0.23469867, 0.01024316, 0.75505817]]\n",
            "2148        [[0.021022238, 0.00033511381, 0.9786427]]\n",
            "2149     [[0.99924076, 0.00010588129, 0.00065332244]]\n",
            "2150        [[0.95626324, 0.00032237676, 0.04341432]]\n",
            "2151          [[0.011838211, 6.783647e-06, 0.988155]]\n",
            "2152           [[0.41496998, 0.35021082, 0.23481917]]\n",
            "2153       [[0.0074103205, 1.5511743e-05, 0.9925742]]\n",
            "2154       [[0.0011190297, 0.00039476546, 0.9984862]]\n",
            "2155       [[0.0024067026, 0.00015048945, 0.9974427]]\n",
            "2156        [[0.014814319, 9.242804e-05, 0.98509324]]\n",
            "2157      [[0.0034195674, 0.00013173056, 0.99644864]]\n",
            "2158       [[0.007981181, 6.0493017e-05, 0.99195826]]\n",
            "2159            [[0.0018897466, 0.670268, 0.3278422]]\n",
            "2160          [[0.0033970787, 0.05487535, 0.9417276]]\n",
            "2161       [[0.052223623, 0.00042569902, 0.94735074]]\n",
            "2162    [[0.99952066, 0.000113053524, 0.00036624857]]\n",
            "2163          [[0.05504027, 0.9436667, 0.0012930853]]\n",
            "2164         [[0.019514615, 0.97847134, 0.002014051]]\n",
            "2165           [[0.028783442, 0.05023422, 0.9209823]]\n",
            "2166        [[0.009704389, 2.4497886e-05, 0.9902711]]\n",
            "2167         [[0.001443753, 0.005329153, 0.99322706]]\n",
            "2168         [[0.016469784, 0.0014755285, 0.9820547]]\n",
            "2169        [[0.013785581, 2.5772384e-05, 0.9861887]]\n",
            "2170         [[0.0006484002, 0.93484706, 0.06450451]]\n",
            "2171        [[0.99983025, 9.368613e-05, 7.60126e-05]]\n",
            "2172          [[0.0028795411, 0.9216764, 0.07544409]]\n",
            "2173          [[0.004288193, 0.89746094, 0.09825086]]\n",
            "2174           [[0.001334849, 0.9753572, 0.02330795]]\n",
            "2175         [[0.006834496, 8.356519e-06, 0.9931571]]\n",
            "2176        [[0.0058926386, 0.0013745915, 0.9927328]]\n",
            "2177          [[0.46171826, 0.016736865, 0.52154493]]\n",
            "2178       [[0.98268515, 0.0039862315, 0.0133287115]]\n",
            "2179        [[0.019142948, 5.5556407e-05, 0.9808015]]\n",
            "2180         [[0.010023158, 0.0017679906, 0.9882088]]\n",
            "2181        [[0.002513058, 1.4162006e-05, 0.9974728]]\n",
            "2182       [[0.0028771486, 0.00022375745, 0.9968991]]\n",
            "2183       [[0.00021975613, 0.9962102, 0.0035700586]]\n",
            "2184          [[0.025411017, 0.09342868, 0.88116026]]\n",
            "2185            [[0.0469113, 0.62299633, 0.33009237]]\n",
            "2186       [[0.00042562853, 0.0005049311, 0.9990694]]\n",
            "2187           [[0.19484732, 0.01484519, 0.79030746]]\n",
            "2188           [[0.19484732, 0.01484519, 0.79030746]]\n",
            "2189      [[0.0031885281, 1.23106975e-05, 0.9967991]]\n",
            "2190           [[0.004307597, 3.241096e-05, 0.99566]]\n",
            "2191        [[0.0053485916, 6.4190654e-06, 0.994645]]\n",
            "2192         [[0.008977612, 4.906099e-05, 0.9909733]]\n",
            "2193        [[0.04209289, 0.00073386345, 0.95717317]]\n",
            "2194       [[5.9135466e-05, 0.9947514, 0.0051894397]]\n",
            "2195          [[0.01285095, 0.89670473, 0.090444386]]\n",
            "2196        [[0.0035837232, 4.470986e-05, 0.9963716]]\n",
            "2197        [[0.0032213319, 9.108045e-05, 0.9966876]]\n",
            "2198           [[0.0072864094, 0.653701, 0.33901262]]\n",
            "2199       [[0.0016795365, 0.00024779662, 0.9980726]]\n",
            "2200         [[0.017787104, 0.0010073098, 0.9812056]]\n",
            "2201       [[0.005472995, 0.00013470008, 0.99439234]]\n",
            "2202         [[0.00246039, 0.00047210758, 0.9970675]]\n",
            "2203        [[0.005554551, 1.2759604e-05, 0.9944326]]\n",
            "2204       [[0.0029630703, 1.7356213e-05, 0.9970196]]\n",
            "2205       [[0.0044581313, 0.00013972908, 0.9954021]]\n",
            "2206            [[0.05016506, 0.18383712, 0.7659979]]\n",
            "2207       [[0.0017059701, 0.00073939445, 0.9975546]]\n",
            "2208        [[0.0026733556, 0.9961343, 0.0011923809]]\n",
            "2209          [[0.0015939943, 0.6650365, 0.33336946]]\n",
            "2210             [[0.4530116, 0.1058143, 0.44117412]]\n",
            "2211       [[0.0016291339, 1.8373677e-05, 0.9983525]]\n",
            "2212         [[0.005280374, 0.003569888, 0.99114966]]\n",
            "2213          [[0.007478192, 0.17073536, 0.82178646]]\n",
            "2214      [[4.2553012e-05, 0.99889475, 0.0010627415]]\n",
            "2215          [[0.008682237, 0.9654647, 0.025853015]]\n",
            "2216           [[0.015325843, 0.07148695, 0.9131872]]\n",
            "2217            [[0.9029819, 0.02992008, 0.06709811]]\n",
            "2218       [[0.99688953, 0.0004291313, 0.0026814057]]\n",
            "2219       [[0.0046285423, 1.6381662e-05, 0.9953551]]\n",
            "2220        [[0.9928665, 0.0010182958, 0.0061152424]]\n",
            "2221        [[0.000980455, 4.688104e-05, 0.99897265]]\n",
            "2222       [[0.0010158324, 1.6050804e-05, 0.9989681]]\n",
            "2223           [[0.4611262, 0.0012270998, 0.5376467]]\n",
            "2224       [[0.0013231845, 8.988712e-06, 0.99866784]]\n",
            "2225      [[0.00062264275, 0.00011490739, 0.9992624]]\n",
            "2226      [[0.0017222234, 4.0523773e-05, 0.99823713]]\n",
            "2227        [[0.0010845842, 0.0004888077, 0.9984267]]\n",
            "2228          [[0.020766728, 0.002169282, 0.9770641]]\n",
            "2229        [[0.007058875, 0.0004125852, 0.99252856]]\n",
            "2230        [[0.002037646, 5.5177698e-06, 0.9979569]]\n",
            "2231       [[0.023942925, 2.2658996e-05, 0.97603446]]\n",
            "2232       [[0.018326884, 4.1669144e-05, 0.98163146]]\n",
            "2233          [[0.005338781, 0.005326939, 0.9893343]]\n",
            "2234        [[0.018183181, 1.2036637e-05, 0.9818048]]\n",
            "2235            [[0.055345204, 0.1028677, 0.8417871]]\n",
            "2236        [[0.016601201, 1.1306694e-05, 0.9833875]]\n",
            "2237        [[0.0072223856, 1.383095e-05, 0.9927638]]\n",
            "2238          [[0.19302304, 0.0023488272, 0.8046281]]\n",
            "2239          [[0.12852642, 0.0010624317, 0.8704112]]\n",
            "2240           [[0.09383094, 0.044200577, 0.8619685]]\n",
            "2241        [[0.9977598, 0.0005906552, 0.0016494578]]\n",
            "2242            [[0.7052015, 0.06648914, 0.22830938]]\n",
            "2243          [[0.0072703343, 0.9165068, 0.07622288]]\n",
            "2244       [[0.0011688083, 0.0014257113, 0.99740547]]\n",
            "2245           [[0.46011218, 0.012848284, 0.5270395]]\n",
            "2246      [[0.0072016995, 2.0823638e-05, 0.99277747]]\n",
            "2247        [[0.0050092572, 2.2802697e-05, 0.994968]]\n",
            "2248       [[0.0013495059, 6.324373e-05, 0.99858737]]\n",
            "2249       [[0.0034119538, 5.308804e-05, 0.99653494]]\n",
            "2250        [[0.003194128, 2.1539134e-05, 0.9967843]]\n",
            "2251        [[0.9653869, 0.00041683813, 0.034196246]]\n",
            "2252         [[0.0026523443, 0.98120236, 0.01614534]]\n",
            "2253        [[0.0016032394, 0.0010434826, 0.9973532]]\n",
            "2254         [[0.0010451976, 0.007605258, 0.9913496]]\n",
            "2255       [[0.0016061164, 5.8048317e-05, 0.9983358]]\n",
            "2256        [[0.007216927, 0.00029127364, 0.9924918]]\n",
            "2257       [[0.001734117, 3.2863896e-05, 0.99823296]]\n",
            "2258            [[0.8039778, 0.03376202, 0.16226017]]\n",
            "2259         [[0.049102414, 0.0056459648, 0.9452516]]\n",
            "2260       [[0.009062594, 2.0331434e-05, 0.99091715]]\n",
            "2261           [[0.13731562, 0.016066985, 0.8466174]]\n",
            "2262       [[0.0011509694, 0.00020175535, 0.9986473]]\n",
            "2263       [[0.002685691, 2.9774732e-05, 0.99728453]]\n",
            "2264         [[0.0064692665, 0.20797274, 0.78555804]]\n",
            "2265         [[0.98923177, 0.01004827, 0.0007199721]]\n",
            "2266          [[0.94018924, 0.007907656, 0.05190318]]\n",
            "2267             [[0.33459955, 0.3720386, 0.2933618]]\n",
            "2268       [[0.002124194, 3.5528054e-05, 0.99784017]]\n",
            "2269      [[0.0012712437, 0.00042985257, 0.99829894]]\n",
            "2270          [[0.014638092, 0.23284198, 0.75251997]]\n",
            "2271          [[0.012373062, 0.23860379, 0.74902314]]\n",
            "2272      [[0.0086919125, 1.9368634e-05, 0.99128866]]\n",
            "2273        [[0.0022749559, 7.355826e-05, 0.9976514]]\n",
            "2274       [[0.0010887289, 2.7867274e-05, 0.9988834]]\n",
            "2275             [[0.43902257, 0.0372251, 0.5237523]]\n",
            "2276           [[0.004824406, 0.47744077, 0.5177348]]\n",
            "2277         [[0.004113966, 9.43391e-06, 0.99587667]]\n",
            "2278          [[0.01000334, 9.563924e-06, 0.9899871]]\n",
            "2279          [[0.074864686, 0.67553824, 0.24959715]]\n",
            "2280         [[0.00239284, 0.00023888315, 0.9973683]]\n",
            "2281       [[0.0071093957, 8.907252e-06, 0.99288166]]\n",
            "2282        [[0.015227996, 2.0920897e-05, 0.9847511]]\n",
            "2283         [[0.007989803, 0.0003589671, 0.9916511]]\n",
            "2284      [[0.0020432267, 1.2904964e-05, 0.99794394]]\n",
            "2285      [[0.0047839317, 3.9051527e-05, 0.99517703]]\n",
            "2286       [[0.0038145357, 2.1433221e-05, 0.9961641]]\n",
            "2287       [[0.0015233561, 0.00064213685, 0.9978345]]\n",
            "2288        [[0.0028523726, 0.003275447, 0.99387217]]\n",
            "2289        [[0.010910971, 2.1921625e-05, 0.9890671]]\n",
            "2290       [[0.0070347358, 0.00011430891, 0.9928509]]\n",
            "2291        [[0.0065914695, 0.0035804186, 0.9898282]]\n",
            "2292            [[0.08016441, 0.7763476, 0.14348803]]\n",
            "2293            [[0.037119176, 0.12397479, 0.838906]]\n",
            "2294     [[0.00087494456, 0.00021142018, 0.99891365]]\n",
            "2295         [[0.003642406, 0.0003920875, 0.9959656]]\n",
            "2296           [[0.03524104, 0.024325728, 0.9404332]]\n",
            "2297            [[0.109148964, 0.14707702, 0.743774]]\n",
            "2298        [[0.0016117733, 4.996661e-05, 0.9983382]]\n",
            "2299        [[0.007602428, 3.9921648e-05, 0.9923577]]\n",
            "2300         [[0.007021658, 0.0012096495, 0.9917687]]\n",
            "2301           [[0.004150891, 0.21107747, 0.7847717]]\n",
            "2302           [[0.971312, 0.020288652, 0.008399362]]\n",
            "2303       [[0.0027110928, 5.4654032e-05, 0.9972343]]\n",
            "2304         [[0.0019822146, 0.012211874, 0.9858059]]\n",
            "2305       [[0.0036234965, 4.0218394e-05, 0.9963362]]\n",
            "2306           [[0.34618238, 0.6105218, 0.043295853]]\n",
            "2307      [[0.0022564062, 2.0407902e-05, 0.99772316]]\n",
            "2308       [[0.0012084754, 8.815753e-05, 0.99870336]]\n",
            "2309       [[0.0009118902, 4.0346815e-05, 0.9990477]]\n",
            "2310       [[0.0015951071, 3.8413877e-05, 0.9983664]]\n",
            "2311        [[0.0013907888, 8.298403e-05, 0.9985262]]\n",
            "2312       [[0.0048597744, 3.6110123e-05, 0.9951042]]\n",
            "2313            [[0.034625992, 0.41326803, 0.552106]]\n",
            "2314         [[0.9991986, 8.09475e-05, 0.0007204256]]\n",
            "2315         [[0.0036106578, 0.044009745, 0.9523796]]\n",
            "2316         [[8.925808e-05, 0.9819457, 0.017965017]]\n",
            "2317       [[9.3443305e-05, 0.9973738, 0.0025326966]]\n",
            "2318        [[0.006265956, 0.00020641944, 0.9935276]]\n",
            "2319        [[0.0011702318, 0.038607612, 0.96022224]]\n",
            "2320           [[0.00621691, 0.03229669, 0.96148634]]\n",
            "2321         [[0.0041154744, 0.017719792, 0.9781647]]\n",
            "2322         [[0.0041154744, 0.017719792, 0.9781647]]\n",
            "2323        [[0.015724156, 1.1502107e-05, 0.9842643]]\n",
            "2324       [[0.0101943165, 9.776893e-06, 0.98979586]]\n",
            "2325        [[0.0013939926, 9.922491e-05, 0.9985067]]\n",
            "2326        [[0.013019396, 4.731741e-05, 0.98693323]]\n",
            "2327     [[0.00083571713, 1.7238104e-05, 0.99914706]]\n",
            "2328       [[0.0007480913, 0.0009660412, 0.99828583]]\n",
            "2329        [[0.0010465046, 0.012404603, 0.98654896]]\n",
            "2330          [[0.00017872085, 0.962587, 0.03723428]]\n",
            "2331        [[0.004251742, 3.794334e-05, 0.99571025]]\n",
            "2332       [[0.0032120226, 7.374228e-06, 0.99678063]]\n",
            "2333       [[0.0033992615, 1.0063489e-05, 0.9965906]]\n",
            "2334        [[0.014716881, 1.4733015e-05, 0.9852684]]\n",
            "2335      [[0.0036645099, 0.00013007758, 0.99620545]]\n",
            "2336          [[0.017698279, 0.0019336891, 0.980368]]\n",
            "2337        [[0.012919272, 2.1033497e-05, 0.9870597]]\n",
            "2338        [[0.018355586, 0.00074382935, 0.9809006]]\n",
            "2339           [[0.27339935, 0.007729124, 0.7188716]]\n",
            "2340            [[0.7081455, 0.2717739, 0.020080674]]\n",
            "2341          [[0.0029694226, 0.7187474, 0.27828315]]\n",
            "2342     [[0.00043451748, 1.8322024e-05, 0.99954706]]\n",
            "2343     [[0.00063577853, 2.4992103e-05, 0.99933916]]\n",
            "2344     [[0.00034440315, 0.00011900244, 0.99953663]]\n",
            "2345      [[0.0009949716, 6.6957823e-06, 0.99899834]]\n",
            "2346      [[0.00062079256, 8.611748e-06, 0.99937063]]\n",
            "2347    [[0.00086010236, 1.00804355e-05, 0.99912983]]\n",
            "2348        [[0.003336865, 1.4491286e-05, 0.9966486]]\n",
            "2349         [[0.0069123195, 0.16262862, 0.83045906]]\n",
            "2350          [[0.015576154, 0.11142575, 0.87299806]]\n",
            "2351              [[0.324357, 0.5987997, 0.07684324]]\n",
            "2352          [[0.0151186185, 0.14720875, 0.8376726]]\n",
            "2353       [[0.016090063, 1.5157365e-05, 0.98389477]]\n",
            "2354        [[0.013795665, 1.7247705e-05, 0.9861871]]\n",
            "2355            [[0.56844896, 0.428974, 0.002576982]]\n",
            "2356        [[0.9874802, 0.011807674, 0.00071211584]]\n",
            "2357      [[0.00012198042, 0.0010761382, 0.99880195]]\n",
            "2358       [[0.00044052352, 0.0003088367, 0.9992506]]\n",
            "2359      [[0.0005464248, 0.00013976767, 0.99931383]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "QGV12Yw9XUmc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contoh inference teks ulasan"
      ],
      "metadata": {
        "id": "mE1u-A9djzqK"
      },
      "id": "mE1u-A9djzqK"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[258] = f\"    t_probs = inf.evaluate('tempat yang sangat cocok untuk dikunjungi keluarga dan teman-teman', 'tempat')\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "xZl9AIAwpkPG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xZl9AIAwpkPG"
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_padanan_trim_val_f1_0.7996\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eZHfx-_y7q5",
        "outputId": "d97301ac-f54f-4b37-afaa-1dbd9ae9d850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "[1]\n"
          ]
        }
      ],
      "id": "9eZHfx-_y7q5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsP7y_hxKu0R"
      },
      "source": [
        "## s6 state_dict/bert_spc_combined_padanan_select_val_f1_0.7783"
      ],
      "id": "OsP7y_hxKu0R"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/l_insert_padanan_selected_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "U37iif5mKu0W"
      },
      "execution_count": null,
      "outputs": [],
      "id": "U37iif5mKu0W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c4fb8528-d293-4027-f81e-1ffe2e3712ba",
        "id": "gmelnRNvKu0W"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0           [[0.054895464, 0.20186055, 0.74324393]]\n",
            "1           [[0.007854967, 0.37218097, 0.61996406]]\n",
            "2            [[0.08774151, 0.54795945, 0.36429906]]\n",
            "3             [[0.20903431, 0.1943631, 0.59660256]]\n",
            "4           [[0.123902224, 0.20703335, 0.66906434]]\n",
            "5        [[0.0017432148, 0.0027957493, 0.99546105]]\n",
            "6          [[0.0052887616, 0.06570225, 0.92900896]]\n",
            "7             [[0.036620267, 0.3125182, 0.6508615]]\n",
            "8           [[0.0045730206, 0.3152876, 0.68013936]]\n",
            "9         [[0.0063564447, 0.003699106, 0.98994446]]\n",
            "10           [[0.010697369, 0.40895334, 0.5803493]]\n",
            "11           [[0.0030145128, 0.3621962, 0.6347893]]\n",
            "12          [[0.0025649136, 0.5978603, 0.39957482]]\n",
            "13         [[0.0011101512, 0.89823735, 0.10065246]]\n",
            "14          [[0.0025649136, 0.5978603, 0.39957482]]\n",
            "15             [[0.03833355, 0.0578992, 0.9037673]]\n",
            "16           [[0.7369226, 0.23596624, 0.027111096]]\n",
            "17        [[0.0009910536, 0.0009888137, 0.9980202]]\n",
            "18        [[0.0012476107, 0.0016537774, 0.9970987]]\n",
            "19         [[0.0009979177, 0.020326875, 0.9786751]]\n",
            "20          [[0.00947603, 0.031002598, 0.95952135]]\n",
            "21         [[0.0069527337, 0.005206034, 0.9878412]]\n",
            "22        [[0.0025876584, 0.008246374, 0.98916596]]\n",
            "23           [[0.07725866, 0.077161185, 0.8455802]]\n",
            "24            [[0.0130058, 0.049640313, 0.9373539]]\n",
            "25          [[0.026968174, 0.44062835, 0.53240347]]\n",
            "26      [[0.0013692072, 0.00030389937, 0.99832684]]\n",
            "27          [[0.002352361, 0.0012725225, 0.996375]]\n",
            "28        [[0.0012953323, 0.0019230634, 0.9967816]]\n",
            "29        [[0.0008169825, 0.005393231, 0.99378985]]\n",
            "30         [[0.0031051529, 0.12711966, 0.86977524]]\n",
            "31       [[0.0014937666, 0.0010065774, 0.99749964]]\n",
            "32         [[0.0045229667, 0.049817678, 0.9456593]]\n",
            "33       [[0.0006131813, 0.00069656677, 0.9986903]]\n",
            "34         [[0.005899358, 0.042904947, 0.95119566]]\n",
            "35         [[0.0044473954, 0.20765822, 0.78789437]]\n",
            "36          [[0.004795869, 0.48907363, 0.50613046]]\n",
            "37            [[0.1758742, 0.73795104, 0.08617477]]\n",
            "38          [[0.08110958, 0.025020786, 0.89386964]]\n",
            "39          [[0.0030410767, 0.00121228, 0.9957467]]\n",
            "40          [[0.0070658866, 0.21699443, 0.7759397]]\n",
            "41         [[0.004202161, 0.0016190255, 0.9941788]]\n",
            "42         [[0.0105999345, 0.025035536, 0.9643645]]\n",
            "43           [[0.006857837, 0.03649574, 0.9566463]]\n",
            "44          [[0.017800061, 0.66313666, 0.31906328]]\n",
            "45           [[0.029481633, 0.5323283, 0.43819007]]\n",
            "46             [[0.050859, 0.09046569, 0.85867536]]\n",
            "47          [[0.063130684, 0.64553595, 0.29133332]]\n",
            "48        [[0.009733314, 0.0077780266, 0.98248863]]\n",
            "49           [[0.029946866, 0.5021318, 0.46792132]]\n",
            "50        [[0.0057215677, 0.023894357, 0.97038406]]\n",
            "51           [[0.012876432, 0.09855179, 0.8885718]]\n",
            "52        [[0.009733314, 0.0077780266, 0.98248863]]\n",
            "53             [[0.0171536, 0.7071054, 0.27574098]]\n",
            "54          [[0.006090695, 0.46100587, 0.53290343]]\n",
            "55            [[0.16781983, 0.21415861, 0.6180215]]\n",
            "56            [[0.16781983, 0.21415861, 0.6180215]]\n",
            "57             [[0.12712023, 0.760967, 0.11191278]]\n",
            "58             [[0.03542972, 0.729269, 0.23530127]]\n",
            "59           [[0.30873108, 0.37448654, 0.31678236]]\n",
            "60        [[0.0022224914, 0.0025229983, 0.9952545]]\n",
            "61         [[0.0026333209, 0.14691976, 0.85044694]]\n",
            "62        [[0.0040271906, 0.060583107, 0.93538964]]\n",
            "63          [[0.0025681646, 0.01139627, 0.9860356]]\n",
            "64          [[0.004586284, 0.013323677, 0.9820901]]\n",
            "65           [[0.019375727, 0.01845945, 0.9621648]]\n",
            "66        [[0.016593661, 0.0022220598, 0.98118436]]\n",
            "67            [[0.03546179, 0.3547636, 0.60977465]]\n",
            "68            [[0.7652838, 0.009116698, 0.2255995]]\n",
            "69            [[0.6176484, 0.21562575, 0.16672583]]\n",
            "70            [[0.6102728, 0.32921767, 0.06050953]]\n",
            "71            [[0.40284055, 0.5280745, 0.06908495]]\n",
            "72           [[0.002131237, 0.07934103, 0.9185277]]\n",
            "73           [[0.0035739762, 0.44554305, 0.550883]]\n",
            "74         [[0.0040888772, 0.20748198, 0.78842914]]\n",
            "75          [[0.20295252, 0.027112152, 0.76993537]]\n",
            "76         [[0.005436634, 0.026077854, 0.96848553]]\n",
            "77        [[0.0074010226, 0.037458777, 0.95514023]]\n",
            "78        [[0.0029574998, 0.0036182608, 0.9934242]]\n",
            "79        [[0.0074010226, 0.037458777, 0.95514023]]\n",
            "80         [[0.0056921956, 0.04174685, 0.95256096]]\n",
            "81        [[0.0010929119, 0.0019760642, 0.9969311]]\n",
            "82        [[0.008282188, 0.0075059687, 0.98421174]]\n",
            "83          [[0.85403365, 0.065609954, 0.08035645]]\n",
            "84          [[0.012678889, 0.047504056, 0.9398171]]\n",
            "85           [[0.29634005, 0.61645925, 0.08720071]]\n",
            "86           [[0.24993546, 0.7173038, 0.032760702]]\n",
            "87         [[0.0029125588, 0.000783714, 0.9963037]]\n",
            "88           [[0.11420993, 0.09791017, 0.78787994]]\n",
            "89       [[0.0034087554, 0.0061667864, 0.99042445]]\n",
            "90       [[0.0010985248, 0.0010769641, 0.99782455]]\n",
            "91           [[0.14774518, 0.8192563, 0.032998547]]\n",
            "92         [[0.0024077566, 0.24060284, 0.75698936]]\n",
            "93           [[0.52950567, 0.07488892, 0.39560533]]\n",
            "94          [[0.11397239, 0.015863143, 0.87016445]]\n",
            "95            [[0.33047578, 0.19088489, 0.4786394]]\n",
            "96        [[0.027921403, 0.0138515495, 0.95822704]]\n",
            "97        [[0.0010578035, 0.0013236075, 0.9976185]]\n",
            "98       [[0.0007161548, 0.0017122094, 0.99757165]]\n",
            "99         [[0.0056467834, 0.004860945, 0.9894922]]\n",
            "100       [[0.0011418414, 0.0007653554, 0.9980927]]\n",
            "101        [[0.0049105566, 0.36515218, 0.62993723]]\n",
            "102      [[0.00058741146, 0.0019347345, 0.9974778]]\n",
            "103       [[0.0011950058, 0.008026556, 0.99077845]]\n",
            "104        [[0.0058776373, 0.003252856, 0.9908695]]\n",
            "105        [[0.046299305, 0.024906076, 0.92879456]]\n",
            "106        [[0.0031602425, 0.010050454, 0.9867893]]\n",
            "107         [[0.0047920723, 0.092149906, 0.903058]]\n",
            "108        [[0.0012730096, 0.00197671, 0.99675024]]\n",
            "109      [[0.0018816406, 0.0071989503, 0.99091935]]\n",
            "110        [[0.001926392, 0.029222837, 0.96885085]]\n",
            "111     [[0.00032404045, 0.0023663237, 0.99730957]]\n",
            "112      [[0.0027089245, 0.0052465214, 0.99204457]]\n",
            "113        [[0.038028523, 0.010173336, 0.95179814]]\n",
            "114          [[0.04815018, 0.78947467, 0.16237514]]\n",
            "115          [[0.04815018, 0.78947467, 0.16237514]]\n",
            "116          [[0.04815018, 0.78947467, 0.16237514]]\n",
            "117       [[0.0009228977, 0.0009411644, 0.9981359]]\n",
            "118        [[0.003991885, 0.006189995, 0.98981804]]\n",
            "119          [[0.022006229, 0.38743117, 0.5905626]]\n",
            "120         [[0.0027430723, 0.60255444, 0.3947025]]\n",
            "121        [[0.003886337, 0.013823919, 0.98228973]]\n",
            "122        [[0.0010796107, 0.001147507, 0.9977729]]\n",
            "123        [[0.0061622285, 0.004958604, 0.9888791]]\n",
            "124        [[0.007788941, 0.007068249, 0.98514277]]\n",
            "125         [[0.005283729, 0.12060894, 0.87410736]]\n",
            "126         [[0.005763652, 0.20554695, 0.78868943]]\n",
            "127         [[0.0032396377, 0.16949257, 0.8272678]]\n",
            "128         [[0.0070503326, 0.29741728, 0.6955324]]\n",
            "129         [[0.00068301, 0.0008251034, 0.9984919]]\n",
            "130       [[0.0019108846, 0.008719976, 0.98936915]]\n",
            "131          [[0.6805676, 0.087840006, 0.23159234]]\n",
            "132             [[0.355682, 0.04825585, 0.5960621]]\n",
            "133         [[0.0022316163, 0.02303563, 0.9747328]]\n",
            "134           [[0.18340337, 0.6903487, 0.12624796]]\n",
            "135          [[0.10294476, 0.81869674, 0.07835853]]\n",
            "136          [[0.008673243, 0.2770499, 0.71427685]]\n",
            "137        [[0.00557146, 0.0022489144, 0.99217963]]\n",
            "138       [[0.0007108382, 0.0015110736, 0.9977781]]\n",
            "139        [[0.0030992478, 0.014295048, 0.9826057]]\n",
            "140       [[0.0065872543, 0.0056918524, 0.9877209]]\n",
            "141          [[0.16232286, 0.018511316, 0.8191658]]\n",
            "142           [[0.06210331, 0.44575173, 0.4921449]]\n",
            "143          [[0.006738718, 0.07301034, 0.9202509]]\n",
            "144            [[0.030567443, 0.15898256, 0.81045]]\n",
            "145       [[0.0015902467, 0.0021125418, 0.9962972]]\n",
            "146       [[0.0016896289, 0.017984387, 0.98032594]]\n",
            "147           [[0.034236886, 0.38359803, 0.582165]]\n",
            "148         [[0.23469165, 0.73959434, 0.025713978]]\n",
            "149           [[0.034236886, 0.38359803, 0.582165]]\n",
            "150         [[0.001060942, 0.0055760834, 0.993363]]\n",
            "151            [[0.09048247, 0.725674, 0.18384354]]\n",
            "152         [[0.001060942, 0.0055760834, 0.993363]]\n",
            "153          [[0.020090252, 0.9089381, 0.07097161]]\n",
            "154         [[0.0019499535, 0.08029136, 0.9177587]]\n",
            "155         [[0.0062736277, 0.5806115, 0.41311488]]\n",
            "156          [[0.00628933, 0.23100731, 0.76270336]]\n",
            "157         [[0.020413578, 0.18458314, 0.79500335]]\n",
            "158          [[0.22253574, 0.7559506, 0.021513637]]\n",
            "159            [[0.1416872, 0.7679381, 0.09037468]]\n",
            "160           [[0.032385115, 0.530735, 0.43687984]]\n",
            "161       [[0.007317462, 0.0040602894, 0.98862225]]\n",
            "162         [[0.007361874, 0.01088084, 0.98175734]]\n",
            "163          [[0.010748311, 0.00865382, 0.9805979]]\n",
            "164        [[0.007746489, 0.0017426042, 0.9905109]]\n",
            "165         [[0.47983757, 0.034286644, 0.48587576]]\n",
            "166          [[0.5165089, 0.038062174, 0.44542897]]\n",
            "167        [[0.0030255085, 0.00692358, 0.99005085]]\n",
            "168            [[0.03760798, 0.6012392, 0.3611528]]\n",
            "169       [[0.0056088497, 0.037367407, 0.95702374]]\n",
            "170            [[0.013754155, 0.513882, 0.4723639]]\n",
            "171       [[0.0037681214, 0.0041704867, 0.9920614]]\n",
            "172         [[0.035244364, 0.15703386, 0.80772173]]\n",
            "173           [[0.0104389, 0.023310483, 0.9662507]]\n",
            "174         [[0.010668189, 0.83524394, 0.15408783]]\n",
            "175       [[0.0011912315, 0.001278084, 0.99753064]]\n",
            "176          [[0.0014047571, 0.2097516, 0.7888437]]\n",
            "177         [[0.0011137843, 0.009211131, 0.989675]]\n",
            "178         [[0.0010983805, 0.014648622, 0.984253]]\n",
            "179        [[0.0046377573, 0.09945918, 0.89590305]]\n",
            "180         [[0.9655647, 0.022389783, 0.012045526]]\n",
            "181      [[0.0030686953, 0.0062479232, 0.99068344]]\n",
            "182          [[0.009762694, 0.3207749, 0.66946244]]\n",
            "183        [[0.0027256603, 0.030715168, 0.9665591]]\n",
            "184           [[0.5170123, 0.06791131, 0.41507643]]\n",
            "185        [[0.0035557617, 0.011791045, 0.9846532]]\n",
            "186          [[0.04562684, 0.015823836, 0.9385493]]\n",
            "187       [[0.0035643117, 0.018778434, 0.97765726]]\n",
            "188        [[0.010994669, 0.024951866, 0.96405345]]\n",
            "189         [[0.0035720447, 0.5126379, 0.48379007]]\n",
            "190         [[0.0097194025, 0.5285183, 0.46176228]]\n",
            "191           [[0.010185787, 0.72061616, 0.269198]]\n",
            "192        [[0.0027968972, 0.28156197, 0.71564114]]\n",
            "193       [[0.0007714896, 0.0048106466, 0.9944179]]\n",
            "194         [[0.0009797164, 0.0074503263, 0.99157]]\n",
            "195          [[0.10578826, 0.21547495, 0.67873675]]\n",
            "196         [[0.027418496, 0.8973733, 0.075208195]]\n",
            "197          [[0.0010236949, 0.1413307, 0.8576456]]\n",
            "198       [[0.0018466695, 0.022764837, 0.97538847]]\n",
            "199        [[0.0022988257, 0.07015697, 0.92754424]]\n",
            "200          [[0.06823086, 0.072094575, 0.8596746]]\n",
            "201           [[0.3839968, 0.06552362, 0.55047953]]\n",
            "202           [[0.006514, 0.0038785785, 0.9896074]]\n",
            "203         [[0.9274379, 0.051173393, 0.021388669]]\n",
            "204           [[0.0031521067, 0.603386, 0.3934619]]\n",
            "205         [[0.0019777908, 0.03928162, 0.9587406]]\n",
            "206          [[0.015772829, 0.31802633, 0.6662008]]\n",
            "207         [[0.008264773, 0.008333512, 0.9834018]]\n",
            "208         [[0.005855102, 0.006939201, 0.9872056]]\n",
            "209         [[0.005855102, 0.006939201, 0.9872056]]\n",
            "210         [[0.001555347, 0.060102608, 0.9383419]]\n",
            "211      [[0.0065855067, 0.0034560275, 0.98995847]]\n",
            "212      [[0.0011831528, 0.00090995297, 0.9979069]]\n",
            "213         [[0.007776191, 0.014900188, 0.9773236]]\n",
            "214         [[0.0033362294, 0.20147021, 0.7951936]]\n",
            "215         [[0.0024724002, 0.16716206, 0.8303655]]\n",
            "216          [[0.0022361616, 0.1349043, 0.8628595]]\n",
            "217        [[0.0019867967, 0.051028363, 0.9469849]]\n",
            "218         [[0.0029370554, 0.14815767, 0.8489053]]\n",
            "219       [[0.0013178797, 0.0035128023, 0.9951692]]\n",
            "220      [[0.0013564425, 0.0064826803, 0.99216086]]\n",
            "221           [[0.033062078, 0.0572263, 0.9097116]]\n",
            "222          [[0.009376086, 0.01541966, 0.9752043]]\n",
            "223         [[0.09442849, 0.79245794, 0.113113545]]\n",
            "224          [[0.009376086, 0.01541966, 0.9752043]]\n",
            "225         [[0.013433762, 0.041639045, 0.9449273]]\n",
            "226           [[0.5044819, 0.42600393, 0.06951408]]\n",
            "227         [[0.0045392653, 0.25067508, 0.7447857]]\n",
            "228         [[0.001046278, 0.9584218, 0.040531896]]\n",
            "229          [[0.005154708, 0.38785085, 0.6069944]]\n",
            "230         [[0.010166732, 0.59930545, 0.39052776]]\n",
            "231          [[0.13034335, 0.14410128, 0.72555536]]\n",
            "232           [[0.14016284, 0.19932272, 0.6605144]]\n",
            "233           [[0.15481973, 0.14186385, 0.7033164]]\n",
            "234          [[0.48551816, 0.4213187, 0.093163095]]\n",
            "235          [[0.03198731, 0.007866064, 0.9601466]]\n",
            "236       [[0.003713957, 0.0036933825, 0.99259263]]\n",
            "237         [[0.005503856, 0.008892198, 0.9856039]]\n",
            "238         [[0.9426671, 0.036790527, 0.020542307]]\n",
            "239           [[0.12435219, 0.3947856, 0.48086223]]\n",
            "240           [[0.07274103, 0.09096155, 0.8362974]]\n",
            "241          [[0.011140031, 0.09424056, 0.8946194]]\n",
            "242          [[0.013103889, 0.33068082, 0.6562153]]\n",
            "243           [[0.26010892, 0.4537737, 0.28611737]]\n",
            "244           [[0.18644299, 0.5162857, 0.29727125]]\n",
            "245        [[0.002303925, 0.94021714, 0.057478882]]\n",
            "246         [[0.039274182, 0.021055713, 0.9396701]]\n",
            "247          [[0.030481739, 0.057572275, 0.911946]]\n",
            "248          [[0.0232018, 0.066969976, 0.90982825]]\n",
            "249       [[0.0010462988, 0.0036840711, 0.9952696]]\n",
            "250       [[0.0016873112, 0.024727492, 0.97358525]]\n",
            "251         [[0.0078902505, 0.00506869, 0.9870411]]\n",
            "252       [[0.0015710645, 0.006607521, 0.99182135]]\n",
            "253        [[0.0016279507, 0.029286882, 0.9690851]]\n",
            "254          [[0.0062932204, 0.6210585, 0.3726483]]\n",
            "255           [[0.003567382, 0.1659189, 0.8305137]]\n",
            "256          [[0.0046181874, 0.713696, 0.28168583]]\n",
            "257       [[0.0012837725, 0.0036749209, 0.9950413]]\n",
            "258        [[0.0008743159, 0.006264438, 0.9928612]]\n",
            "259        [[0.0026388464, 0.89598507, 0.10137614]]\n",
            "260         [[0.030415764, 0.9538102, 0.015774006]]\n",
            "261         [[0.0019679253, 0.92366195, 0.0743701]]\n",
            "262          [[0.0046181874, 0.713696, 0.28168583]]\n",
            "263          [[0.043543972, 0.14937949, 0.8070765]]\n",
            "264          [[0.83397645, 0.01764413, 0.14837942]]\n",
            "265           [[0.04605252, 0.14018564, 0.8137619]]\n",
            "266         [[0.014028612, 0.31882432, 0.66714704]]\n",
            "267          [[0.04099299, 0.010160797, 0.9488462]]\n",
            "268          [[0.04099299, 0.010160797, 0.9488462]]\n",
            "269          [[0.004759423, 0.01259979, 0.9826408]]\n",
            "270         [[0.90230346, 0.022215039, 0.07548146]]\n",
            "271            [[0.4532884, 0.3416831, 0.20502846]]\n",
            "272         [[0.009434297, 0.04357398, 0.94699174]]\n",
            "273        [[0.0010408274, 0.016382387, 0.9825768]]\n",
            "274       [[0.0007370356, 0.0022178679, 0.9970451]]\n",
            "275        [[0.00092018885, 0.028163875, 0.970916]]\n",
            "276        [[0.0032493253, 0.31740725, 0.67934346]]\n",
            "277        [[0.000830054, 0.054127283, 0.94504267]]\n",
            "278       [[0.0025833875, 0.0044709616, 0.9929456]]\n",
            "279        [[0.0099878395, 0.17629759, 0.81371456]]\n",
            "280         [[0.0031294925, 0.006617583, 0.990253]]\n",
            "281         [[0.0014458569, 0.22757448, 0.7709796]]\n",
            "282       [[0.0021858239, 0.0025764657, 0.9952377]]\n",
            "283         [[0.0025733283, 0.08146188, 0.9159648]]\n",
            "284         [[0.0018014256, 0.19030951, 0.8078891]]\n",
            "285         [[0.007488547, 0.84268373, 0.14982775]]\n",
            "286          [[0.005044562, 0.34298202, 0.6519734]]\n",
            "287         [[0.0035309778, 0.049262036, 0.947207]]\n",
            "288          [[0.83276594, 0.09094901, 0.07628506]]\n",
            "289       [[0.0007649534, 0.0009676088, 0.9982674]]\n",
            "290          [[0.83276594, 0.09094901, 0.07628506]]\n",
            "291      [[0.0013172857, 0.0022542907, 0.99642843]]\n",
            "292          [[0.0038090881, 0.1433564, 0.8528345]]\n",
            "293       [[0.0037882002, 0.027214682, 0.96899724]]\n",
            "294         [[0.0026682047, 0.41357663, 0.5837552]]\n",
            "295         [[0.0015306904, 0.11587853, 0.8825908]]\n",
            "296         [[0.025703495, 0.37526768, 0.59902877]]\n",
            "297           [[0.0033171708, 0.52387, 0.47281286]]\n",
            "298             [[0.004391015, 0.615731, 0.379878]]\n",
            "299          [[0.12757333, 0.081088245, 0.7913384]]\n",
            "300          [[0.00452761, 0.043191183, 0.9522812]]\n",
            "301         [[0.013936687, 0.49398696, 0.49207628]]\n",
            "302          [[0.023672592, 0.9138159, 0.06251147]]\n",
            "303         [[0.011664969, 0.60442954, 0.38390547]]\n",
            "304          [[0.12757333, 0.081088245, 0.7913384]]\n",
            "305          [[0.039167654, 0.7760497, 0.18478268]]\n",
            "306     [[0.00086056686, 0.0023783685, 0.99676114]]\n",
            "307       [[0.0046405094, 0.034602754, 0.96075684]]\n",
            "308         [[0.010342322, 0.78876626, 0.20089146]]\n",
            "309           [[0.006223005, 0.8301349, 0.1636421]]\n",
            "310       [[0.0022687868, 0.010791206, 0.98693997]]\n",
            "311        [[0.0026739065, 0.029120628, 0.9682055]]\n",
            "312         [[0.0061859787, 0.6936847, 0.30012932]]\n",
            "313          [[0.0042019715, 0.0630652, 0.9327328]]\n",
            "314        [[0.0028160522, 0.022247467, 0.9749365]]\n",
            "315          [[0.024179839, 0.10118186, 0.8746382]]\n",
            "316        [[0.0035385918, 0.006099799, 0.9903616]]\n",
            "317       [[0.0013652953, 0.0053976285, 0.9932371]]\n",
            "318        [[0.0021153504, 0.007866908, 0.9900177]]\n",
            "319          [[0.004836144, 0.35796946, 0.6371944]]\n",
            "320          [[0.00160177, 0.22779997, 0.77059823]]\n",
            "321          [[0.004836144, 0.35796946, 0.6371944]]\n",
            "322         [[0.00090706, 0.0007490607, 0.9983438]]\n",
            "323     [[0.0006244774, 0.00058034365, 0.99879515]]\n",
            "324         [[0.004246649, 0.014346737, 0.9814067]]\n",
            "325         [[0.002529641, 0.003108547, 0.9943619]]\n",
            "326          [[0.020652255, 0.15653482, 0.8228128]]\n",
            "327        [[0.006779309, 0.0023948639, 0.9908257]]\n",
            "328          [[0.8818623, 0.06019556, 0.057942145]]\n",
            "329          [[0.52606815, 0.26122114, 0.21271072]]\n",
            "330          [[0.8811319, 0.061359998, 0.05750815]]\n",
            "331           [[0.14201064, 0.7227228, 0.13526656]]\n",
            "332          [[0.8818623, 0.06019556, 0.057942145]]\n",
            "333        [[0.012898528, 0.045223113, 0.94187826]]\n",
            "334          [[0.45911646, 0.50814575, 0.03273776]]\n",
            "335       [[0.0046061845, 0.025898617, 0.96949524]]\n",
            "336            [[0.4885375, 0.32628632, 0.1851762]]\n",
            "337          [[0.43339795, 0.30493495, 0.26166704]]\n",
            "338          [[0.0070811785, 0.029678795, 0.96324]]\n",
            "339         [[0.11964276, 0.021845112, 0.85851216]]\n",
            "340           [[0.46786729, 0.3818204, 0.15031222]]\n",
            "341      [[0.0013366232, 0.0015456994, 0.99711764]]\n",
            "342        [[0.0016716771, 0.04196237, 0.95636594]]\n",
            "343       [[0.0006927536, 0.007630114, 0.99167717]]\n",
            "344        [[0.124007836, 0.099648565, 0.77634364]]\n",
            "345      [[0.0018852433, 0.0020832515, 0.99603146]]\n",
            "346      [[0.0015096696, 0.0019672948, 0.99652314]]\n",
            "347          [[0.36350134, 0.17575647, 0.46074212]]\n",
            "348       [[0.0060050176, 0.0027577032, 0.9912373]]\n",
            "349       [[0.0060050176, 0.0027577032, 0.9912373]]\n",
            "350            [[0.6236312, 0.24206147, 0.1343073]]\n",
            "351        [[0.97296584, 0.019976616, 0.007057598]]\n",
            "352        [[0.0019055954, 0.031660993, 0.9664335]]\n",
            "353           [[0.006627572, 0.556863, 0.43650943]]\n",
            "354         [[0.003826577, 0.023259131, 0.9729143]]\n",
            "355       [[0.0031145427, 0.0023732174, 0.9945122]]\n",
            "356           [[0.04774152, 0.37237924, 0.5798792]]\n",
            "357           [[0.032711655, 0.5968728, 0.3704156]]\n",
            "358          [[0.02871251, 0.84952575, 0.12176176]]\n",
            "359         [[0.018750515, 0.47597894, 0.50527054]]\n",
            "360           [[0.6443527, 0.12783416, 0.22781314]]\n",
            "361         [[0.083973825, 0.83763653, 0.07838964]]\n",
            "362         [[0.024528028, 0.75502414, 0.22044781]]\n",
            "363          [[0.01521691, 0.013197692, 0.9715854]]\n",
            "364           [[0.01442413, 0.8791878, 0.10638808]]\n",
            "365          [[0.008222074, 0.98696935, 0.0048086]]\n",
            "366        [[0.002092958, 0.9925488, 0.0053581847]]\n",
            "367            [[0.50201136, 0.35388565, 0.144103]]\n",
            "368          [[0.011554536, 0.8874121, 0.10103333]]\n",
            "369        [[0.0020036323, 0.004706967, 0.9932894]]\n",
            "370        [[0.0044029728, 0.054693144, 0.9409038]]\n",
            "371         [[0.0012344071, 0.08027478, 0.9184908]]\n",
            "372         [[0.007403994, 0.8716204, 0.120975636]]\n",
            "373       [[0.0018200477, 0.0015554195, 0.9966246]]\n",
            "374         [[0.0038129091, 0.16391098, 0.8322761]]\n",
            "375      [[0.0008922499, 0.0006734936, 0.99843425]]\n",
            "376       [[0.0035446482, 0.0019121103, 0.9945432]]\n",
            "377         [[0.010045897, 0.014534832, 0.9754192]]\n",
            "378        [[0.0016763164, 0.03310508, 0.96521854]]\n",
            "379        [[0.0024239132, 0.014087617, 0.9834884]]\n",
            "380          [[0.012076844, 0.7121918, 0.27573138]]\n",
            "381       [[0.0014770407, 0.014112151, 0.98441076]]\n",
            "382           [[0.007635208, 0.865194, 0.12717077]]\n",
            "383         [[0.009300727, 0.020033361, 0.9706659]]\n",
            "384         [[0.027154626, 0.65404254, 0.31880286]]\n",
            "385         [[0.016970139, 0.14470087, 0.83832896]]\n",
            "386      [[0.0018007809, 0.0010292033, 0.99717003]]\n",
            "387         [[0.005497926, 0.03703564, 0.95746636]]\n",
            "388        [[0.0037480914, 0.023472704, 0.9727792]]\n",
            "389          [[0.040103387, 0.13759613, 0.8223005]]\n",
            "390          [[0.14022496, 0.014833548, 0.8449415]]\n",
            "391       [[0.0018499509, 0.0013472799, 0.9968028]]\n",
            "392       [[0.0063490304, 0.024693718, 0.96895725]]\n",
            "393         [[0.005034431, 0.018092839, 0.9768727]]\n",
            "394         [[0.018994542, 0.037309457, 0.9436961]]\n",
            "395           [[0.001730355, 0.6522282, 0.3460415]]\n",
            "396        [[0.0037629784, 0.53784025, 0.45839676]]\n",
            "397        [[0.0029575247, 0.90045965, 0.09658285]]\n",
            "398        [[0.0029735854, 0.16411327, 0.83291316]]\n",
            "399          [[0.03879589, 0.042258475, 0.9189456]]\n",
            "400         [[0.004800851, 0.9562431, 0.038956128]]\n",
            "401        [[0.0036454669, 0.67838603, 0.31796855]]\n",
            "402         [[0.008529772, 0.11427965, 0.87719053]]\n",
            "403         [[0.0013828493, 0.9353148, 0.06330243]]\n",
            "404         [[0.0045731706, 0.8813812, 0.11404566]]\n",
            "405         [[0.0032712827, 0.9085606, 0.08816818]]\n",
            "406       [[0.00067583116, 0.9810605, 0.018263653]]\n",
            "407          [[0.0023862533, 0.939013, 0.05860069]]\n",
            "408        [[0.0009718142, 0.9389201, 0.060108107]]\n",
            "409        [[0.0008875363, 0.93886083, 0.06025166]]\n",
            "410        [[0.0012920272, 0.86243033, 0.13627766]]\n",
            "411        [[0.0016736396, 0.73731583, 0.26101053]]\n",
            "412          [[0.0014934405, 0.2439043, 0.7546022]]\n",
            "413        [[0.0034532733, 0.85768354, 0.13886324]]\n",
            "414          [[0.010914072, 0.8240967, 0.16498925]]\n",
            "415         [[0.94648504, 0.029229695, 0.02428527]]\n",
            "416        [[0.0031396314, 0.006182141, 0.9906782]]\n",
            "417          [[0.54029655, 0.006835863, 0.4528676]]\n",
            "418          [[0.25127798, 0.05969354, 0.68902844]]\n",
            "419          [[0.020438224, 0.35483584, 0.6247259]]\n",
            "420           [[0.017809074, 0.4758556, 0.5063353]]\n",
            "421      [[0.0024325065, 0.0064933985, 0.99107414]]\n",
            "422           [[0.14692774, 0.16279098, 0.6902813]]\n",
            "423         [[0.0074544633, 0.007824487, 0.984721]]\n",
            "424          [[0.012486695, 0.05031414, 0.9371991]]\n",
            "425         [[0.8678374, 0.045099065, 0.087063536]]\n",
            "426          [[0.8320205, 0.059646826, 0.10833268]]\n",
            "427         [[0.0024687916, 0.01395347, 0.9835776]]\n",
            "428         [[0.012848781, 0.40584457, 0.58130664]]\n",
            "429          [[0.07846105, 0.05241055, 0.86912847]]\n",
            "430       [[0.003238336, 0.0016099903, 0.99515176]]\n",
            "431          [[0.016195482, 0.20129865, 0.7825058]]\n",
            "432       [[0.001327945, 0.0032957809, 0.99537635]]\n",
            "433      [[0.0011783263, 0.0036727674, 0.99514884]]\n",
            "434          [[0.037793964, 0.03521609, 0.9269899]]\n",
            "435        [[0.010592572, 0.87625784, 0.113149635]]\n",
            "436        [[0.0020261724, 0.016426725, 0.9815471]]\n",
            "437       [[0.0019257682, 0.0020297081, 0.9960445]]\n",
            "438        [[0.002460315, 0.025466992, 0.97207266]]\n",
            "439         [[0.0029742941, 0.6692501, 0.32777563]]\n",
            "440         [[0.0027533541, 0.9470136, 0.05023296]]\n",
            "441         [[0.0037775286, 0.11255191, 0.8836705]]\n",
            "442       [[0.0022944254, 0.044575322, 0.95313036]]\n",
            "443        [[0.0016089954, 0.08135292, 0.91703814]]\n",
            "444         [[0.0037775286, 0.11255191, 0.8836705]]\n",
            "445      [[0.00059289986, 0.0028151034, 0.9965919]]\n",
            "446        [[0.0011292276, 0.015477267, 0.9833935]]\n",
            "447        [[0.0010638296, 0.028442672, 0.9704935]]\n",
            "448         [[0.0037775286, 0.11255191, 0.8836705]]\n",
            "449         [[0.026154466, 0.66747814, 0.30636743]]\n",
            "450           [[0.02602554, 0.7913809, 0.18259357]]\n",
            "451           [[0.02033067, 0.6038982, 0.37577105]]\n",
            "452           [[0.009527488, 0.7322946, 0.2581779]]\n",
            "453           [[0.042107336, 0.3980145, 0.5598782]]\n",
            "454           [[0.008509758, 0.736434, 0.25505632]]\n",
            "455         [[0.012886648, 0.65410715, 0.33300623]]\n",
            "456       [[0.0041814423, 0.0075332164, 0.9882854]]\n",
            "457         [[0.008369054, 0.010731689, 0.9808992]]\n",
            "458         [[0.008369054, 0.010731689, 0.9808992]]\n",
            "459       [[0.0032674612, 0.0009858793, 0.9957467]]\n",
            "460      [[0.0010098672, 0.0033025057, 0.99568766]]\n",
            "461       [[0.002979282, 0.0047956756, 0.99222505]]\n",
            "462       [[0.0013299681, 0.028354581, 0.97031546]]\n",
            "463       [[0.0032674612, 0.0009858793, 0.9957467]]\n",
            "464          [[0.0019478257, 0.10559815, 0.892454]]\n",
            "465       [[0.0010214107, 0.0018093108, 0.9971692]]\n",
            "466         [[0.0011370531, 0.9112397, 0.08762333]]\n",
            "467       [[0.0043049837, 0.029105151, 0.96658987]]\n",
            "468           [[0.15720429, 0.19313812, 0.6496576]]\n",
            "469         [[0.0025582535, 0.10564426, 0.8917974]]\n",
            "470         [[0.0013935732, 0.2591336, 0.73947287]]\n",
            "471          [[0.34173486, 0.15080893, 0.50745624]]\n",
            "472        [[0.0019692888, 0.019111212, 0.9789195]]\n",
            "473          [[0.34173486, 0.15080893, 0.50745624]]\n",
            "474        [[0.001960842, 0.021703215, 0.97633606]]\n",
            "475        [[0.0019692888, 0.019111212, 0.9789195]]\n",
            "476        [[0.0019692888, 0.019111212, 0.9789195]]\n",
            "477        [[0.0019692888, 0.019111212, 0.9789195]]\n",
            "478         [[0.0024489993, 0.02611014, 0.9714408]]\n",
            "479        [[0.0066854334, 0.032603752, 0.9607108]]\n",
            "480         [[0.006582461, 0.03041752, 0.96300006]]\n",
            "481        [[0.004077458, 0.0009821521, 0.9949404]]\n",
            "482         [[0.004597246, 0.54763067, 0.44777212]]\n",
            "483       [[0.0030032538, 0.028087154, 0.96890956]]\n",
            "484       [[0.0038544026, 0.0040514143, 0.9920941]]\n",
            "485       [[0.0010471559, 0.0012231272, 0.9977297]]\n",
            "486         [[0.003012077, 0.19290979, 0.80407816]]\n",
            "487         [[0.0027866107, 0.4094589, 0.58775455]]\n",
            "488         [[0.0021382992, 0.13437645, 0.8634852]]\n",
            "489        [[0.0036774587, 0.100648426, 0.8956741]]\n",
            "490        [[0.0017132985, 0.019766463, 0.9785202]]\n",
            "491       [[0.0018985881, 0.0016330439, 0.9964683]]\n",
            "492        [[0.0024997338, 0.0016572746, 0.995843]]\n",
            "493       [[0.001741835, 0.0062072487, 0.99205095]]\n",
            "494       [[0.0054148394, 0.0048478744, 0.9897372]]\n",
            "495       [[0.0065941787, 0.099218026, 0.89418775]]\n",
            "496         [[0.004985598, 0.019173045, 0.9758413]]\n",
            "497           [[0.20250942, 0.29206675, 0.5054239]]\n",
            "498       [[0.0029683511, 0.009151631, 0.98788005]]\n",
            "499           [[0.07840957, 0.22158977, 0.7000007]]\n",
            "500       [[0.0049131527, 0.0010407028, 0.9940462]]\n",
            "501       [[0.0078254705, 0.0044970396, 0.9876774]]\n",
            "502         [[0.004797463, 0.25548214, 0.73972046]]\n",
            "503          [[0.0028624034, 0.0190267, 0.9781109]]\n",
            "504           [[0.06640289, 0.03333054, 0.9002665]]\n",
            "505          [[0.007782603, 0.07907913, 0.9131383]]\n",
            "506          [[0.0048031416, 0.1254046, 0.8697923]]\n",
            "507        [[0.0068062614, 0.58266973, 0.41052404]]\n",
            "508           [[0.020871343, 0.16644764, 0.812681]]\n",
            "509        [[0.0032743826, 0.16921677, 0.82750887]]\n",
            "510        [[0.0012700581, 0.013810116, 0.9849199]]\n",
            "511       [[0.0061362763, 0.0011865395, 0.9926771]]\n",
            "512       [[0.0023614746, 0.0018838407, 0.9957547]]\n",
            "513       [[0.0013038883, 0.0015234537, 0.9971726]]\n",
            "514        [[0.005544876, 0.0007429798, 0.9937122]]\n",
            "515          [[0.028220478, 0.011523478, 0.960256]]\n",
            "516        [[0.0014821853, 0.014304165, 0.9842136]]\n",
            "517        [[0.0034181033, 0.37094444, 0.62563753]]\n",
            "518          [[0.0057697897, 0.9166551, 0.0775751]]\n",
            "519        [[0.002503454, 0.012706395, 0.98479015]]\n",
            "520        [[0.0025465693, 0.19435912, 0.80309427]]\n",
            "521        [[0.0025712068, 0.034714166, 0.9627146]]\n",
            "522      [[0.00061643566, 0.0011561378, 0.9982274]]\n",
            "523       [[0.0017817428, 0.0014315387, 0.9967867]]\n",
            "524        [[0.00415601, 0.0067195254, 0.98912454]]\n",
            "525        [[0.0023226785, 0.005143621, 0.9925337]]\n",
            "526           [[0.013716751, 0.24449421, 0.741789]]\n",
            "527       [[0.0020361065, 0.0015984366, 0.9963654]]\n",
            "528         [[0.018018506, 0.003647274, 0.9783342]]\n",
            "529         [[0.033037737, 0.06275644, 0.90420574]]\n",
            "530         [[0.14623772, 0.038054988, 0.81570727]]\n",
            "531          [[0.07192746, 0.028888168, 0.8991844]]\n",
            "532        [[0.0036421272, 0.012471741, 0.9838861]]\n",
            "533        [[0.0009806694, 0.00186623, 0.99715304]]\n",
            "534           [[0.009885647, 0.1680257, 0.8220887]]\n",
            "535          [[0.024632711, 0.20059974, 0.7747675]]\n",
            "536        [[0.0022457223, 0.62049425, 0.37726003]]\n",
            "537      [[0.0028624244, 0.0055918247, 0.99154574]]\n",
            "538         [[0.24808753, 0.73105264, 0.020859841]]\n",
            "539          [[0.034464296, 0.8531256, 0.11241015]]\n",
            "540            [[0.12653093, 0.5016403, 0.3718287]]\n",
            "541             [[0.574241, 0.3470642, 0.07869478]]\n",
            "542           [[0.05659844, 0.42420927, 0.5191923]]\n",
            "543        [[0.0016275449, 0.055685993, 0.9426864]]\n",
            "544       [[0.00046469102, 0.010498112, 0.9890372]]\n",
            "545      [[0.00067033595, 0.0034031302, 0.9959266]]\n",
            "546         [[0.0012254958, 0.8526096, 0.14616495]]\n",
            "547          [[0.011317402, 0.02048673, 0.9681959]]\n",
            "548       [[0.0055210544, 0.007918594, 0.98656034]]\n",
            "549      [[0.0037468334, 0.0061385687, 0.99011457]]\n",
            "550         [[0.9675743, 0.023776496, 0.008649194]]\n",
            "551         [[0.0052541234, 0.21374498, 0.7810009]]\n",
            "552          [[0.0021098768, 0.035800114, 0.96209]]\n",
            "553          [[0.0076581836, 0.4769794, 0.5153624]]\n",
            "554         [[0.004074501, 0.24649793, 0.74942756]]\n",
            "555        [[0.0015883049, 0.18397225, 0.81443954]]\n",
            "556       [[0.0016196142, 0.013813177, 0.98456717]]\n",
            "557         [[0.001810894, 0.020685242, 0.9775039]]\n",
            "558        [[0.002413526, 0.0028809432, 0.9947055]]\n",
            "559          [[0.020818727, 0.18236138, 0.7968199]]\n",
            "560          [[0.004151279, 0.4604418, 0.53540695]]\n",
            "561           [[0.00351595, 0.5058142, 0.49066982]]\n",
            "562           [[0.005573788, 0.3473278, 0.6470985]]\n",
            "563        [[0.0021079034, 0.031581577, 0.9663105]]\n",
            "564       [[0.0053748135, 0.0077280696, 0.9868972]]\n",
            "565          [[0.008107787, 0.23789547, 0.7539968]]\n",
            "566         [[0.006092817, 0.49745014, 0.49645707]]\n",
            "567         [[0.012035855, 0.09565114, 0.89231294]]\n",
            "568         [[0.003676976, 0.14494535, 0.85137767]]\n",
            "569       [[0.0061366996, 0.039582435, 0.95428085]]\n",
            "570       [[0.0064423513, 0.009709555, 0.98384804]]\n",
            "571       [[0.0008445034, 0.0073746475, 0.9917808]]\n",
            "572       [[0.0039249617, 0.004358437, 0.99171656]]\n",
            "573       [[0.0033161638, 0.014989211, 0.98169464]]\n",
            "574          [[0.009401872, 0.01525358, 0.9753446]]\n",
            "575          [[0.016063029, 0.47420585, 0.5097311]]\n",
            "576          [[0.012682879, 0.5746547, 0.41266242]]\n",
            "577         [[0.029225184, 0.71607244, 0.25470236]]\n",
            "578         [[0.94606733, 0.005381684, 0.04855105]]\n",
            "579         [[0.94606733, 0.005381684, 0.04855105]]\n",
            "580         [[0.92085236, 0.01968116, 0.059466403]]\n",
            "581            [[0.26976407, 0.1981262, 0.5321098]]\n",
            "582        [[0.0017853103, 0.002266097, 0.9959486]]\n",
            "583       [[0.0015523809, 0.0041356576, 0.9943119]]\n",
            "584          [[0.071054384, 0.4131073, 0.51583827]]\n",
            "585         [[0.004893938, 0.017640596, 0.9774654]]\n",
            "586           [[0.12665103, 0.6740101, 0.19933882]]\n",
            "587         [[0.016249008, 0.016935144, 0.9668159]]\n",
            "588         [[0.019450288, 0.017662954, 0.9628867]]\n",
            "589         [[0.029747864, 0.9142301, 0.056022078]]\n",
            "590      [[0.0037555103, 0.0028191442, 0.99342537]]\n",
            "591        [[0.003938962, 0.038311075, 0.95774996]]\n",
            "592       [[0.0084786685, 0.002236799, 0.98928446]]\n",
            "593       [[0.011518476, 0.00074025156, 0.9877413]]\n",
            "594      [[0.0015577298, 0.0012299303, 0.99721235]]\n",
            "595         [[0.0072410805, 0.8813281, 0.11143076]]\n",
            "596        [[0.010602596, 0.0033137884, 0.9860837]]\n",
            "597       [[0.0028255805, 0.0020832538, 0.9950911]]\n",
            "598       [[0.0019189382, 0.0013696323, 0.9967115]]\n",
            "599           [[0.0022881688, 0.8474348, 0.150277]]\n",
            "600        [[0.0012135955, 0.002772615, 0.9960139]]\n",
            "601             [[0.517792, 0.3238186, 0.15838942]]\n",
            "602          [[0.016578164, 0.13975331, 0.8436685]]\n",
            "603       [[0.0016957673, 0.009669855, 0.98863435]]\n",
            "604          [[0.027132818, 0.14260685, 0.8302603]]\n",
            "605       [[0.0012456225, 0.0068515544, 0.9919029]]\n",
            "606         [[0.009036659, 0.17758992, 0.81337345]]\n",
            "607           [[0.7277104, 0.11657042, 0.15571915]]\n",
            "608      [[0.0016033194, 0.0061410894, 0.99225557]]\n",
            "609          [[0.0012787158, 0.021441236, 0.97728]]\n",
            "610        [[0.002909054, 0.039867222, 0.95722383]]\n",
            "611      [[0.0050434694, 0.0076823276, 0.98727417]]\n",
            "612           [[0.13089241, 0.1060127, 0.76309484]]\n",
            "613       [[0.0065707965, 0.0027647654, 0.9906645]]\n",
            "614         [[0.0081444355, 0.8227044, 0.16915123]]\n",
            "615          [[0.45036474, 0.41127723, 0.13835803]]\n",
            "616           [[0.6968163, 0.15931827, 0.14386545]]\n",
            "617          [[0.022918407, 0.03055339, 0.9465283]]\n",
            "618        [[0.0023126754, 0.018762786, 0.9789245]]\n",
            "619           [[0.0055013415, 0.829042, 0.1654566]]\n",
            "620          [[0.011857047, 0.6979984, 0.29014456]]\n",
            "621        [[0.0022970056, 0.88514197, 0.11256107]]\n",
            "622          [[0.003562998, 0.44120574, 0.5552313]]\n",
            "623          [[0.003562998, 0.44120574, 0.5552313]]\n",
            "624         [[0.0028050577, 0.9423321, 0.05486287]]\n",
            "625         [[0.0050607393, 0.8835038, 0.11143543]]\n",
            "626       [[0.0057699988, 0.022712564, 0.97151744]]\n",
            "627          [[0.049392883, 0.7168744, 0.23373272]]\n",
            "628         [[0.0022103707, 0.7017942, 0.29599544]]\n",
            "629         [[0.0016777099, 0.9181624, 0.08015987]]\n",
            "630       [[0.0019031188, 0.093152836, 0.90494406]]\n",
            "631        [[0.0022205235, 0.023189986, 0.9745894]]\n",
            "632        [[0.0011838408, 0.038171448, 0.9606447]]\n",
            "633        [[0.0013741576, 0.0015518076, 0.997074]]\n",
            "634      [[0.0014394539, 0.0058178753, 0.99274266]]\n",
            "635      [[0.0015429368, 0.0012640533, 0.99719304]]\n",
            "636        [[0.0031124623, 0.002147823, 0.9947397]]\n",
            "637            [[0.22627799, 0.2685636, 0.5051584]]\n",
            "638         [[0.9604934, 0.017230874, 0.022275813]]\n",
            "639         [[0.9604934, 0.017230874, 0.022275813]]\n",
            "640      [[0.0021002425, 0.0084991995, 0.98940057]]\n",
            "641         [[0.24273185, 0.74446434, 0.012803739]]\n",
            "642          [[0.15332802, 0.06467752, 0.78199446]]\n",
            "643        [[0.000922696, 0.0025779468, 0.9964994]]\n",
            "644         [[0.0038223595, 0.10586687, 0.8903107]]\n",
            "645        [[0.002070308, 0.0032629743, 0.9946667]]\n",
            "646         [[0.0034592014, 0.5579608, 0.43857998]]\n",
            "647       [[0.0023963363, 0.019001259, 0.97860247]]\n",
            "648        [[0.0065345257, 0.56333363, 0.43013185]]\n",
            "649           [[0.00994141, 0.38561514, 0.6044435]]\n",
            "650          [[0.004390716, 0.2340786, 0.76153064]]\n",
            "651       [[0.00096660975, 0.11781027, 0.88122314]]\n",
            "652          [[0.12506402, 0.7868715, 0.088064514]]\n",
            "653            [[0.2890136, 0.106875375, 0.604111]]\n",
            "654       [[0.0008625137, 0.0069250185, 0.9922125]]\n",
            "655      [[0.0009702539, 0.0030374383, 0.99599236]]\n",
            "656       [[0.0068662465, 0.93108296, 0.062050775]]\n",
            "657        [[0.0010030173, 0.012293456, 0.9867035]]\n",
            "658        [[0.003615687, 0.0044225436, 0.9919618]]\n",
            "659           [[0.004168699, 0.24253438, 0.753297]]\n",
            "660        [[0.0033232209, 0.05349823, 0.94317853]]\n",
            "661        [[0.0013738028, 0.030035963, 0.9685902]]\n",
            "662       [[0.0036389404, 0.018304087, 0.97805697]]\n",
            "663        [[0.0034566529, 0.009741893, 0.9868015]]\n",
            "664        [[0.002059516, 0.027681304, 0.97025925]]\n",
            "665         [[0.0093217585, 0.31947005, 0.6712082]]\n",
            "666           [[0.057855107, 0.5007588, 0.4413861]]\n",
            "667          [[0.013692158, 0.9000375, 0.08627033]]\n",
            "668         [[0.021881046, 0.02093588, 0.95718306]]\n",
            "669          [[0.024772145, 0.82811075, 0.1471171]]\n",
            "670        [[0.0119009875, 0.57942635, 0.40867266]]\n",
            "671        [[0.0024016018, 0.015498191, 0.9821002]]\n",
            "672         [[0.011372077, 0.87264454, 0.11598335]]\n",
            "673         [[0.062070172, 0.9256245, 0.012305326]]\n",
            "674         [[0.0093492335, 0.64525336, 0.3453974]]\n",
            "675          [[0.028204033, 0.1695725, 0.80222344]]\n",
            "676           [[0.7642427, 0.19682883, 0.03892849]]\n",
            "677            [[0.2656872, 0.5135136, 0.22079921]]\n",
            "678           [[0.06979442, 0.7139057, 0.21629989]]\n",
            "679           [[0.13543992, 0.7256259, 0.13893424]]\n",
            "680         [[0.065246366, 0.8384974, 0.096256256]]\n",
            "681         [[0.89401454, 0.06395572, 0.042029846]]\n",
            "682          [[0.69007516, 0.2592506, 0.050674193]]\n",
            "683          [[0.41723156, 0.5314254, 0.051343005]]\n",
            "684         [[0.043632697, 0.07859699, 0.87777025]]\n",
            "685        [[0.0024148417, 0.0004580703, 0.997127]]\n",
            "686            [[0.04836777, 0.2589806, 0.6926517]]\n",
            "687          [[0.021085158, 0.27078834, 0.7081265]]\n",
            "688             [[0.0252799, 0.6720906, 0.3026295]]\n",
            "689        [[0.987949, 0.0058611096, 0.0061898483]]\n",
            "690      [[0.003917232, 0.00057660136, 0.99550617]]\n",
            "691        [[0.0013154247, 0.037715185, 0.9609693]]\n",
            "692        [[0.00050887594, 0.9544469, 0.04504418]]\n",
            "693         [[0.005383001, 0.70383686, 0.29078016]]\n",
            "694          [[0.0023661626, 0.2616713, 0.7359625]]\n",
            "695         [[0.0049901754, 0.9177857, 0.07722412]]\n",
            "696          [[0.005751118, 0.18349414, 0.8107547]]\n",
            "697         [[0.0033875196, 0.3099573, 0.68665516]]\n",
            "698       [[0.0038395256, 0.044836827, 0.95132375]]\n",
            "699      [[0.0010828981, 0.0013659602, 0.99755114]]\n",
            "700        [[0.0020658034, 0.004157795, 0.9937763]]\n",
            "701         [[0.0025787647, 0.05873389, 0.9386874]]\n",
            "702         [[0.002957134, 0.18113418, 0.81590873]]\n",
            "703         [[0.0007944471, 0.00686456, 0.9923409]]\n",
            "704        [[0.0007147433, 0.009583217, 0.9897021]]\n",
            "705       [[0.0012605089, 0.0075078476, 0.9912316]]\n",
            "706         [[0.0031352974, 0.06501412, 0.9318506]]\n",
            "707          [[0.01172104, 0.89040273, 0.09787619]]\n",
            "708         [[0.0011103231, 0.8436134, 0.15527627]]\n",
            "709         [[0.002957134, 0.18113418, 0.81590873]]\n",
            "710        [[0.008155618, 0.106340885, 0.88550353]]\n",
            "711          [[0.020006072, 0.8570452, 0.12294874]]\n",
            "712          [[0.021927599, 0.22435892, 0.7537135]]\n",
            "713         [[0.003298886, 0.19529685, 0.80140424]]\n",
            "714      [[0.0012074694, 0.0048924247, 0.99390006]]\n",
            "715         [[0.0029489147, 0.19435054, 0.8027005]]\n",
            "716         [[0.003827348, 0.08573431, 0.91043836]]\n",
            "717          [[0.01172104, 0.89040273, 0.09787619]]\n",
            "718         [[0.011522294, 0.9129801, 0.075497665]]\n",
            "719       [[0.013677561, 0.0055386648, 0.98078376]]\n",
            "720         [[0.026449485, 0.78840894, 0.18514156]]\n",
            "721          [[0.0072627487, 0.8569165, 0.1358208]]\n",
            "722          [[0.020240048, 0.17265113, 0.8071088]]\n",
            "723        [[0.0015579121, 0.008501804, 0.9899402]]\n",
            "724         [[0.0252623, 0.0089861825, 0.96575147]]\n",
            "725          [[0.06590877, 0.009559413, 0.9245318]]\n",
            "726        [[0.94178724, 0.019652585, 0.038560204]]\n",
            "727           [[0.11192107, 0.07960254, 0.8084764]]\n",
            "728           [[0.00761502, 0.2717581, 0.72062683]]\n",
            "729         [[0.00809277, 0.0019210763, 0.9899861]]\n",
            "730       [[0.0049493457, 0.024548024, 0.97050256]]\n",
            "731           [[0.2621118, 0.20494242, 0.53294575]]\n",
            "732        [[0.013412641, 0.039099015, 0.94748837]]\n",
            "733          [[0.04629898, 0.71265346, 0.24104762]]\n",
            "734         [[0.028769545, 0.14407668, 0.82715374]]\n",
            "735           [[0.2621118, 0.20494242, 0.53294575]]\n",
            "736            [[0.05214618, 0.819568, 0.12828587]]\n",
            "737           [[0.06592496, 0.6390988, 0.29497617]]\n",
            "738           [[0.1134477, 0.44091225, 0.44564006]]\n",
            "739           [[0.2621118, 0.20494242, 0.53294575]]\n",
            "740          [[0.012714316, 0.6522842, 0.33500147]]\n",
            "741         [[0.0028950206, 0.40451762, 0.5925873]]\n",
            "742         [[0.0034171839, 0.29918736, 0.6973954]]\n",
            "743         [[0.001958127, 0.10732857, 0.89071333]]\n",
            "744        [[0.0022426543, 0.09986112, 0.89789623]]\n",
            "745        [[0.0035625312, 0.66264534, 0.33379215]]\n",
            "746         [[0.0028950206, 0.40451762, 0.5925873]]\n",
            "747           [[0.008164392, 0.00643064, 0.985405]]\n",
            "748         [[0.0028950206, 0.40451762, 0.5925873]]\n",
            "749       [[0.0031874296, 0.021532949, 0.97527957]]\n",
            "750        [[0.0019192573, 0.70640457, 0.29167622]]\n",
            "751         [[0.011044476, 0.014135614, 0.9748199]]\n",
            "752          [[0.20174956, 0.14808895, 0.65016156]]\n",
            "753          [[0.00327288, 0.18997338, 0.80675375]]\n",
            "754         [[0.002983903, 0.04575774, 0.95125836]]\n",
            "755        [[0.0021638186, 0.27479124, 0.72304493]]\n",
            "756         [[0.002759475, 0.71309763, 0.28414294]]\n",
            "757        [[0.002088863, 0.0013950465, 0.9965161]]\n",
            "758         [[0.0022475575, 0.8139948, 0.18375763]]\n",
            "759       [[0.0033352922, 0.006029955, 0.99063474]]\n",
            "760      [[0.0034605572, 0.0054800985, 0.99105936]]\n",
            "761         [[0.013243622, 0.94242364, 0.04433275]]\n",
            "762          [[0.01912618, 0.39195222, 0.58892155]]\n",
            "763       [[0.003264215, 0.0009167989, 0.99581903]]\n",
            "764        [[0.043560293, 0.030234821, 0.92620486]]\n",
            "765          [[0.27586216, 0.05252605, 0.67161185]]\n",
            "766         [[0.11669022, 0.103603706, 0.77970606]]\n",
            "767           [[0.5627807, 0.37086773, 0.06635162]]\n",
            "768           [[0.1496921, 0.018594507, 0.8317134]]\n",
            "769            [[0.26634914, 0.09572488, 0.637926]]\n",
            "770         [[0.023018248, 0.80956715, 0.16741455]]\n",
            "771          [[0.5700085, 0.099646114, 0.33034533]]\n",
            "772            [[0.102341935, 0.257153, 0.6405051]]\n",
            "773         [[0.008565139, 0.82737964, 0.16405524]]\n",
            "774         [[0.010759204, 0.8845643, 0.104676545]]\n",
            "775          [[0.015819749, 0.09403502, 0.8901453]]\n",
            "776       [[0.0056835664, 0.074989006, 0.91932744]]\n",
            "777          [[0.012809887, 0.07950859, 0.9076816]]\n",
            "778           [[0.024464851, 0.7375109, 0.2380242]]\n",
            "779         [[0.028217064, 0.22751455, 0.74426836]]\n",
            "780       [[0.0073779477, 0.011057617, 0.98156446]]\n",
            "781         [[0.003232535, 0.023942254, 0.9728252]]\n",
            "782        [[0.0012172393, 0.04802969, 0.95075303]]\n",
            "783       [[0.0008991898, 0.0031644993, 0.9959363]]\n",
            "784         [[0.001297958, 0.01654618, 0.98215586]]\n",
            "785         [[0.018081343, 0.11875462, 0.86316407]]\n",
            "786        [[0.006982443, 0.022382949, 0.97063464]]\n",
            "787           [[0.047914155, 0.1217689, 0.8303169]]\n",
            "788       [[0.0030639353, 0.0042185504, 0.9927175]]\n",
            "789      [[0.0014236892, 0.0027669037, 0.99580944]]\n",
            "790          [[0.91567624, 0.04856001, 0.03576383]]\n",
            "791           [[0.07890969, 0.14762491, 0.7734654]]\n",
            "792          [[0.93757206, 0.00627113, 0.05615686]]\n",
            "793          [[0.0056567374, 0.37870625, 0.615637]]\n",
            "794        [[0.004406249, 0.93382794, 0.061765846]]\n",
            "795         [[0.010227018, 0.76347846, 0.22629452]]\n",
            "796         [[0.0022289702, 0.8946118, 0.10315924]]\n",
            "797        [[0.0045314045, 0.93606025, 0.05940832]]\n",
            "798        [[0.007826669, 0.95434415, 0.037829153]]\n",
            "799         [[0.026760159, 0.26816618, 0.70507365]]\n",
            "800        [[0.0034765059, 0.70123786, 0.29528558]]\n",
            "801           [[0.15075602, 0.6954287, 0.15381527]]\n",
            "802         [[0.009245267, 0.58470774, 0.40604693]]\n",
            "803       [[0.0010705685, 0.009487063, 0.98944247]]\n",
            "804      [[0.0004819167, 0.0015678757, 0.99795026]]\n",
            "805           [[0.002865969, 0.5852384, 0.4118956]]\n",
            "806            [[0.5726703, 0.2581753, 0.16915442]]\n",
            "807          [[0.20681402, 0.58000594, 0.21318005]]\n",
            "808          [[0.003969009, 0.43375525, 0.5622757]]\n",
            "809         [[0.002752252, 0.58856267, 0.40868515]]\n",
            "810          [[0.45764494, 0.15315054, 0.38920453]]\n",
            "811          [[0.002999423, 0.001168557, 0.995832]]\n",
            "812        [[0.0058917576, 0.58730215, 0.40680608]]\n",
            "813           [[0.008706522, 0.4521379, 0.5391556]]\n",
            "814          [[0.019515613, 0.4482612, 0.53222317]]\n",
            "815         [[0.24531536, 0.65578926, 0.098895386]]\n",
            "816         [[0.24531536, 0.65578926, 0.098895386]]\n",
            "817          [[0.004730967, 0.27676773, 0.7185013]]\n",
            "818           [[0.06558508, 0.4742383, 0.46017668]]\n",
            "819       [[0.0031864226, 0.0013361132, 0.9954775]]\n",
            "820        [[0.004360341, 0.0044398624, 0.9911998]]\n",
            "821         [[0.0044571506, 0.21836504, 0.7771778]]\n",
            "822           [[0.09397338, 0.13914385, 0.7668828]]\n",
            "823       [[0.0045665735, 0.0057616765, 0.9896717]]\n",
            "824           [[0.8490322, 0.033214524, 0.1177533]]\n",
            "825          [[0.8853175, 0.044512097, 0.07017048]]\n",
            "826       [[0.004528153, 0.0011369394, 0.99433494]]\n",
            "827        [[0.00083813, 0.0007156416, 0.99844617]]\n",
            "828      [[0.0014238188, 0.0098408805, 0.98873526]]\n",
            "829        [[0.0048878826, 0.031533826, 0.9635783]]\n",
            "830       [[0.0059421286, 0.0014151863, 0.9926427]]\n",
            "831        [[0.00083813, 0.0007156416, 0.99844617]]\n",
            "832        [[0.005251629, 0.0023420183, 0.9924063]]\n",
            "833        [[0.0024036167, 0.030060459, 0.9675359]]\n",
            "834         [[0.021333558, 0.02017394, 0.95849246]]\n",
            "835        [[0.0053167865, 0.005137296, 0.9895459]]\n",
            "836          [[0.0037154257, 0.0246362, 0.9716483]]\n",
            "837         [[0.0047901073, 0.14693302, 0.8482769]]\n",
            "838        [[0.0019398312, 0.037617322, 0.9604428]]\n",
            "839        [[0.0071935146, 0.16452204, 0.82828444]]\n",
            "840         [[0.006243175, 0.106698126, 0.8870587]]\n",
            "841          [[0.7443539, 0.030223338, 0.22542275]]\n",
            "842          [[0.005325888, 0.1016271, 0.89304703]]\n",
            "843      [[0.0012256813, 0.0073883007, 0.99138606]]\n",
            "844         [[0.007456019, 0.85243773, 0.14010628]]\n",
            "845         [[0.009880422, 0.007988878, 0.9821307]]\n",
            "846        [[0.011072307, 0.006037746, 0.98288995]]\n",
            "847      [[0.0076909107, 0.0037777044, 0.98853135]]\n",
            "848         [[0.001406206, 0.01000536, 0.98858845]]\n",
            "849       [[0.0037283364, 0.014887895, 0.98138374]]\n",
            "850         [[0.004867256, 0.003356159, 0.9917766]]\n",
            "851       [[0.0010736925, 0.001431269, 0.99749506]]\n",
            "852       [[0.0032482445, 0.0028515204, 0.9939003]]\n",
            "853      [[0.00085563504, 0.0020715245, 0.9970728]]\n",
            "854          [[0.012178956, 0.07102275, 0.9167983]]\n",
            "855         [[0.014156642, 0.06943715, 0.91640615]]\n",
            "856         [[0.014666944, 0.07962497, 0.90570813]]\n",
            "857         [[0.0067591574, 0.006151754, 0.987089]]\n",
            "858         [[0.029418075, 0.02482175, 0.94576025]]\n",
            "859           [[0.01589765, 0.20871027, 0.7753921]]\n",
            "860          [[0.9654709, 0.03117846, 0.003350589]]\n",
            "861         [[0.015707871, 0.05084235, 0.93344986]]\n",
            "862        [[0.0028983126, 0.9684197, 0.028682066]]\n",
            "863          [[0.75296783, 0.15192781, 0.09510436]]\n",
            "864           [[0.010868202, 0.4145865, 0.5745453]]\n",
            "865       [[0.0010070396, 0.0046343855, 0.9943585]]\n",
            "866          [[0.014656978, 0.23323812, 0.7521049]]\n",
            "867         [[0.0045875404, 0.7109755, 0.28443694]]\n",
            "868        [[0.016128412, 0.015541442, 0.96833014]]\n",
            "869          [[0.13422021, 0.8442038, 0.021575948]]\n",
            "870          [[0.022501014, 0.7654683, 0.21203071]]\n",
            "871            [[0.1843022, 0.7357737, 0.07992411]]\n",
            "872            [[0.1843022, 0.7357737, 0.07992411]]\n",
            "873           [[0.01686644, 0.36597174, 0.6171618]]\n",
            "874            [[0.11128005, 0.4904663, 0.3982536]]\n",
            "875            [[0.5861311, 0.2819663, 0.13190266]]\n",
            "876           [[0.07261414, 0.7772354, 0.15015055]]\n",
            "877        [[0.0027316166, 0.008977599, 0.9882908]]\n",
            "878        [[0.035729468, 0.056490876, 0.90777963]]\n",
            "879        [[0.0016496348, 0.004157533, 0.9941928]]\n",
            "880          [[0.8804836, 0.07261638, 0.046900027]]\n",
            "881          [[0.6410046, 0.34148768, 0.017507682]]\n",
            "882            [[0.88328, 0.06950468, 0.047215354]]\n",
            "883           [[0.15482914, 0.15477508, 0.6903957]]\n",
            "884          [[0.03598465, 0.06511804, 0.89889723]]\n",
            "885        [[0.01070115, 0.0013738372, 0.98792505]]\n",
            "886       [[0.0016370865, 0.005381362, 0.99298155]]\n",
            "887          [[0.009629913, 0.20139064, 0.7889795]]\n",
            "888             [[0.01017011, 0.1736659, 0.816164]]\n",
            "889         [[0.03406307, 0.0113794515, 0.9545575]]\n",
            "890        [[0.0019861984, 0.011444437, 0.9865694]]\n",
            "891        [[0.0064115506, 0.008855043, 0.9847334]]\n",
            "892          [[0.015594184, 0.12426747, 0.8601384]]\n",
            "893        [[0.0017558564, 0.009576782, 0.9886673]]\n",
            "894          [[0.018185822, 0.926284, 0.055530168]]\n",
            "895           [[0.030627277, 0.6739515, 0.2954212]]\n",
            "896          [[0.005561868, 0.5032047, 0.49123344]]\n",
            "897        [[0.0053969976, 0.05819182, 0.93641114]]\n",
            "898        [[0.005788326, 0.018320274, 0.97589135]]\n",
            "899         [[0.003678737, 0.06437288, 0.93194836]]\n",
            "900      [[0.00084786274, 0.0006557579, 0.9984964]]\n",
            "901         [[0.030253438, 0.70822835, 0.26151818]]\n",
            "902           [[0.36035767, 0.15440449, 0.4852378]]\n",
            "903           [[0.4354518, 0.46252725, 0.10202097]]\n",
            "904           [[0.4354518, 0.46252725, 0.10202097]]\n",
            "905         [[0.035132892, 0.9424573, 0.022409812]]\n",
            "906          [[0.038659956, 0.5090633, 0.45227677]]\n",
            "907           [[0.45414674, 0.44060984, 0.1052434]]\n",
            "908          [[0.034589764, 0.7482347, 0.21717553]]\n",
            "909          [[0.69082797, 0.20797256, 0.10119948]]\n",
            "910          [[0.82520694, 0.11916534, 0.05562781]]\n",
            "911           [[0.11898629, 0.5127351, 0.36827862]]\n",
            "912          [[0.7928908, 0.15445456, 0.052654635]]\n",
            "913         [[0.37778813, 0.53640586, 0.085806005]]\n",
            "914          [[0.7715234, 0.096604966, 0.13187164]]\n",
            "915        [[0.0025262188, 0.0105988765, 0.986875]]\n",
            "916          [[0.9681838, 0.02477269, 0.007043471]]\n",
            "917          [[0.9681838, 0.02477269, 0.007043471]]\n",
            "918          [[0.23746462, 0.7295675, 0.032967895]]\n",
            "919        [[0.0036379462, 0.19474961, 0.80161244]]\n",
            "920           [[0.01804516, 0.17345732, 0.8084976]]\n",
            "921           [[0.85744023, 0.09531748, 0.0472423]]\n",
            "922         [[0.013179093, 0.96994597, 0.01687491]]\n",
            "923         [[0.0066414615, 0.07134533, 0.9220132]]\n",
            "924         [[0.019310534, 0.063042276, 0.9176471]]\n",
            "925         [[0.019310534, 0.063042276, 0.9176471]]\n",
            "926        [[0.0029467167, 0.84844035, 0.14861296]]\n",
            "927       [[0.0031040162, 0.94029975, 0.056596212]]\n",
            "928         [[0.002167454, 0.042692732, 0.9551398]]\n",
            "929         [[0.0032870483, 0.28557432, 0.7111386]]\n",
            "930         [[0.0030848198, 0.27246198, 0.7244532]]\n",
            "931        [[0.0018413104, 0.08282618, 0.91533244]]\n",
            "932          [[0.0062664784, 0.683713, 0.31002045]]\n",
            "933          [[0.0027067014, 0.2217855, 0.7755078]]\n",
            "934         [[0.10436946, 0.0041785794, 0.8914519]]\n",
            "935         [[0.10436946, 0.0041785794, 0.8914519]]\n",
            "936      [[0.0044920603, 0.0052685956, 0.99023926]]\n",
            "937          [[0.024695188, 0.42168346, 0.5536213]]\n",
            "938        [[0.005092186, 0.0041013984, 0.9908064]]\n",
            "939          [[0.00222803, 0.018466074, 0.9793059]]\n",
            "940          [[0.004032826, 0.27152732, 0.7244398]]\n",
            "941         [[0.005261015, 0.35114408, 0.64359486]]\n",
            "942          [[0.024695188, 0.42168346, 0.5536213]]\n",
            "943      [[0.0007415316, 0.0037506903, 0.99550784]]\n",
            "944        [[0.001905186, 0.0064408598, 0.9916539]]\n",
            "945       [[0.0018167106, 0.010053412, 0.98812985]]\n",
            "946         [[0.005415318, 0.05710272, 0.93748206]]\n",
            "947       [[0.0010448562, 0.0032570602, 0.9956981]]\n",
            "948         [[0.0027243516, 0.2276705, 0.76960516]]\n",
            "949     [[0.00076390075, 0.0026003504, 0.99663574]]\n",
            "950         [[0.005415318, 0.05710272, 0.93748206]]\n",
            "951          [[0.008076247, 0.12157151, 0.8703522]]\n",
            "952        [[0.001699782, 0.022341307, 0.97595894]]\n",
            "953         [[0.0012357368, 0.06748648, 0.9312778]]\n",
            "954             [[0.07510968, 0.3379123, 0.586978]]\n",
            "955       [[0.0043655327, 0.027433766, 0.96820056]]\n",
            "956         [[0.0076538175, 0.012392233, 0.979954]]\n",
            "957        [[0.0093982145, 0.010155508, 0.9804463]]\n",
            "958          [[0.14418654, 0.61252975, 0.24328369]]\n",
            "959          [[0.14418654, 0.61252975, 0.24328369]]\n",
            "960         [[0.0044354135, 0.014761621, 0.980803]]\n",
            "961      [[0.0017685117, 0.0016945238, 0.99653697]]\n",
            "962        [[0.007386948, 0.010451318, 0.98216176]]\n",
            "963         [[0.004456985, 0.004633674, 0.9909093]]\n",
            "964          [[0.04091804, 0.11824356, 0.84083843]]\n",
            "965         [[0.0044354135, 0.014761621, 0.980803]]\n",
            "966            [[0.1303094, 0.09725998, 0.7724306]]\n",
            "967            [[0.1303094, 0.09725998, 0.7724306]]\n",
            "968            [[0.1303094, 0.09725998, 0.7724306]]\n",
            "969       [[0.0050515602, 0.004736278, 0.99021214]]\n",
            "970            [[0.1303094, 0.09725998, 0.7724306]]\n",
            "971            [[0.1303094, 0.09725998, 0.7724306]]\n",
            "972           [[0.00372202, 0.8162101, 0.18006793]]\n",
            "973        [[0.0026067751, 0.011176313, 0.9862169]]\n",
            "974         [[0.118531466, 0.28827623, 0.59319234]]\n",
            "975         [[0.118531466, 0.28827623, 0.59319234]]\n",
            "976           [[0.006759383, 0.033920567, 0.95932]]\n",
            "977          [[0.014788363, 0.23172906, 0.7534826]]\n",
            "978         [[0.0045305104, 0.33650315, 0.6589664]]\n",
            "979          [[0.04199569, 0.09891881, 0.85908556]]\n",
            "980          [[0.04199569, 0.09891881, 0.85908556]]\n",
            "981           [[0.64193565, 0.05174449, 0.3063199]]\n",
            "982          [[0.33220905, 0.42782575, 0.23996523]]\n",
            "983        [[0.0016503509, 0.012550485, 0.9857991]]\n",
            "984           [[0.64193565, 0.05174449, 0.3063199]]\n",
            "985           [[0.64193565, 0.05174449, 0.3063199]]\n",
            "986         [[0.023155604, 0.046753824, 0.9300906]]\n",
            "987         [[0.023617156, 0.0075497916, 0.968833]]\n",
            "988         [[0.013419141, 0.003506743, 0.9830741]]\n",
            "989        [[0.0025897839, 0.001762029, 0.9956481]]\n",
            "990            [[0.07129367, 0.0268852, 0.9018212]]\n",
            "991         [[0.0009507957, 0.7301366, 0.26891258]]\n",
            "992         [[0.0011825458, 0.13559419, 0.8632232]]\n",
            "993        [[0.0007360269, 0.05913715, 0.94012684]]\n",
            "994         [[0.0009385397, 0.10635333, 0.8927081]]\n",
            "995        [[0.00087083975, 0.5925303, 0.40659887]]\n",
            "996          [[0.0041494034, 0.889752, 0.10609863]]\n",
            "997            [[0.033079702, 0.86699, 0.09993035]]\n",
            "998        [[0.005355201, 0.076922156, 0.91772264]]\n",
            "999        [[0.0039979224, 0.029253263, 0.9667489]]\n",
            "1000       [[0.005985478, 0.047306627, 0.94670796]]\n",
            "1001       [[0.005345855, 0.006617385, 0.98803675]]\n",
            "1002         [[0.0008778313, 0.015062, 0.98406017]]\n",
            "1003        [[0.007481763, 0.08868702, 0.90383124]]\n",
            "1004     [[0.0008175079, 0.0008557039, 0.99832684]]\n",
            "1005         [[0.0024417094, 0.2206782, 0.7768801]]\n",
            "1006      [[0.0019624743, 0.025378365, 0.97265923]]\n",
            "1007      [[0.0019624743, 0.025378365, 0.97265923]]\n",
            "1008     [[0.0014424946, 0.0014248083, 0.99713266]]\n",
            "1009        [[0.018552577, 0.87552935, 0.10591801]]\n",
            "1010      [[0.0041327174, 0.0021750398, 0.9936923]]\n",
            "1011       [[0.0033539727, 0.03805122, 0.95859486]]\n",
            "1012         [[0.23671652, 0.28469864, 0.47858483]]\n",
            "1013        [[0.011028338, 0.05140876, 0.93756294]]\n",
            "1014         [[0.7490996, 0.21175806, 0.039142262]]\n",
            "1015          [[0.25034666, 0.16670191, 0.5829514]]\n",
            "1016      [[0.0015275799, 0.0010057045, 0.9974667]]\n",
            "1017        [[0.0027680837, 0.16197412, 0.8352578]]\n",
            "1018       [[0.011327066, 0.002710564, 0.98596233]]\n",
            "1019      [[0.0065727956, 0.0043000416, 0.9891271]]\n",
            "1020      [[0.009824298, 0.0025801964, 0.98759556]]\n",
            "1021        [[0.054389704, 0.33839348, 0.60721684]]\n",
            "1022       [[0.007148247, 0.007665638, 0.98518616]]\n",
            "1023         [[0.019267641, 0.14566138, 0.8350709]]\n",
            "1024        [[0.014060795, 0.37317517, 0.61276406]]\n",
            "1025         [[0.63193774, 0.22169654, 0.14636578]]\n",
            "1026          [[0.028026333, 0.4417894, 0.5301843]]\n",
            "1027      [[0.0032567685, 0.004968147, 0.99177516]]\n",
            "1028      [[0.0032567685, 0.004968147, 0.99177516]]\n",
            "1029       [[0.002799997, 0.0028935717, 0.9943064]]\n",
            "1030        [[0.015407918, 0.017598862, 0.9669932]]\n",
            "1031       [[0.0060159746, 0.32186142, 0.67212266]]\n",
            "1032        [[0.00814417, 0.036902282, 0.95495355]]\n",
            "1033         [[0.82108843, 0.07674993, 0.10216162]]\n",
            "1034       [[0.0021403532, 0.00672327, 0.99113643]]\n",
            "1035      [[0.0016059888, 0.0048285923, 0.9935655]]\n",
            "1036      [[0.0071945842, 0.0034263183, 0.9893791]]\n",
            "1037        [[0.018641528, 0.13650683, 0.84485173]]\n",
            "1038       [[0.001765407, 0.0019526819, 0.9962819]]\n",
            "1039      [[0.0021160173, 0.0049592545, 0.9929247]]\n",
            "1040         [[0.013934125, 0.03454743, 0.9515184]]\n",
            "1041        [[0.016718835, 0.78782445, 0.19545677]]\n",
            "1042         [[0.00874786, 0.88535017, 0.10590195]]\n",
            "1043         [[0.020537324, 0.6840759, 0.29538673]]\n",
            "1044         [[0.008124513, 0.43437284, 0.5575026]]\n",
            "1045      [[0.0011723079, 0.0035190424, 0.9953087]]\n",
            "1046     [[0.0023114742, 0.0030768465, 0.99461174]]\n",
            "1047      [[0.00040248234, 0.001085341, 0.9985122]]\n",
            "1048         [[0.8508351, 0.046666022, 0.10249879]]\n",
            "1049         [[0.8846103, 0.045722447, 0.06966732]]\n",
            "1050         [[0.81107646, 0.15085724, 0.03806632]]\n",
            "1051       [[0.0022738925, 0.018929536, 0.9787966]]\n",
            "1052          [[0.004795346, 0.06802758, 0.927177]]\n",
            "1053          [[0.004795346, 0.06802758, 0.927177]]\n",
            "1054      [[0.001701856, 0.0070723896, 0.99122566]]\n",
            "1055      [[0.0023069256, 0.0018393635, 0.9958538]]\n",
            "1056        [[0.011729347, 0.045726806, 0.9425438]]\n",
            "1057       [[0.0066575846, 0.24744655, 0.74589586]]\n",
            "1058      [[0.0023069256, 0.0018393635, 0.9958538]]\n",
            "1059       [[0.0014381022, 0.008898535, 0.9896633]]\n",
            "1060       [[0.002891074, 0.021411352, 0.97569764]]\n",
            "1061      [[0.0008150117, 0.007785816, 0.99139917]]\n",
            "1062      [[0.00074323657, 0.002220031, 0.9970368]]\n",
            "1063          [[0.051700413, 0.22788465, 0.720415]]\n",
            "1064          [[0.8569894, 0.08223054, 0.06078005]]\n",
            "1065        [[0.0022197764, 0.3453631, 0.65241706]]\n",
            "1066       [[0.0018788205, 0.13652018, 0.86160105]]\n",
            "1067         [[0.0019378143, 0.2046884, 0.7933738]]\n",
            "1068     [[0.00094717863, 0.023719434, 0.97533345]]\n",
            "1069     [[0.00069585344, 0.026026335, 0.97327775]]\n",
            "1070      [[0.00048441236, 0.031749047, 0.9677665]]\n",
            "1071      [[0.00053271186, 0.03717667, 0.96229064]]\n",
            "1072       [[0.00087575126, 0.31669644, 0.6824278]]\n",
            "1073         [[0.0036357169, 0.02114237, 0.975222]]\n",
            "1074       [[0.005198237, 0.033692665, 0.96110916]]\n",
            "1075        [[0.010460477, 0.008340214, 0.9811994]]\n",
            "1076         [[0.003533265, 0.19308463, 0.8033821]]\n",
            "1077     [[0.0012763558, 0.0030245646, 0.99569917]]\n",
            "1078     [[0.00088093156, 0.015141245, 0.98397785]]\n",
            "1079       [[0.0031643587, 0.08117017, 0.91566557]]\n",
            "1080         [[0.020143326, 0.5916864, 0.38817024]]\n",
            "1081        [[0.0037969279, 0.8939991, 0.10220398]]\n",
            "1082           [[0.00559235, 0.6791305, 0.3152772]]\n",
            "1083    [[0.00090007536, 0.0009783927, 0.99812144]]\n",
            "1084      [[0.0008799063, 0.0015710068, 0.9975491]]\n",
            "1085        [[0.001967019, 0.08639139, 0.91164154]]\n",
            "1086         [[0.00227625, 0.44431406, 0.55340976]]\n",
            "1087      [[0.0013042252, 0.021435052, 0.97726077]]\n",
            "1088       [[0.011486455, 0.056968894, 0.93154466]]\n",
            "1089        [[0.002733352, 0.64001787, 0.35724878]]\n",
            "1090        [[0.007350781, 0.78711647, 0.20553271]]\n",
            "1091        [[0.29351452, 0.67509013, 0.031395372]]\n",
            "1092         [[0.008213778, 0.008529314, 0.983257]]\n",
            "1093        [[0.8869282, 0.102666944, 0.010404803]]\n",
            "1094        [[0.85205805, 0.13303526, 0.014906711]]\n",
            "1095       [[0.064382784, 0.008008242, 0.92760897]]\n",
            "1096        [[0.0021014435, 0.02908825, 0.9688102]]\n",
            "1097       [[0.0014810024, 0.0015879928, 0.996931]]\n",
            "1098        [[0.009715945, 0.012214306, 0.9780698]]\n",
            "1099       [[0.00498347, 0.0011922654, 0.99382424]]\n",
            "1100       [[0.0033130916, 0.007329495, 0.9893574]]\n",
            "1101     [[0.0011495817, 0.0033471216, 0.99550325]]\n",
            "1102        [[0.002152908, 0.008553486, 0.9892937]]\n",
            "1103     [[0.0017732265, 0.0070135472, 0.99121326]]\n",
            "1104        [[0.002003642, 0.008863658, 0.9891327]]\n",
            "1105       [[0.0022012857, 0.06490894, 0.93288976]]\n",
            "1106      [[0.0004722191, 0.014844255, 0.98468345]]\n",
            "1107    [[0.00062839146, 0.0027480302, 0.99662364]]\n",
            "1108       [[0.0018582795, 0.024192475, 0.9739493]]\n",
            "1109      [[0.0010360748, 0.0075049764, 0.9914589]]\n",
            "1110     [[0.0006400342, 0.0036711004, 0.99568886]]\n",
            "1111       [[0.0060547395, 0.078248695, 0.9156965]]\n",
            "1112      [[0.0015625751, 0.039456487, 0.95898104]]\n",
            "1113      [[0.0023671454, 0.045062225, 0.95257056]]\n",
            "1114      [[0.0007482776, 0.0019016052, 0.9973501]]\n",
            "1115       [[0.0012243947, 0.002295913, 0.9964797]]\n",
            "1116         [[0.28040913, 0.46536618, 0.25422466]]\n",
            "1117       [[0.0012911871, 0.04515769, 0.95355105]]\n",
            "1118      [[0.0023671454, 0.045062225, 0.95257056]]\n",
            "1119       [[0.0020241158, 0.03423695, 0.96373904]]\n",
            "1120        [[0.017431809, 0.50703603, 0.47553217]]\n",
            "1121        [[0.012451054, 0.011130206, 0.9764188]]\n",
            "1122        [[0.75633705, 0.19588715, 0.047775764]]\n",
            "1123         [[0.10904309, 0.8266496, 0.064307325]]\n",
            "1124      [[0.00097007916, 0.025167286, 0.9738626]]\n",
            "1125       [[0.0008870918, 0.001081693, 0.9980312]]\n",
            "1126        [[0.0031786207, 0.62086177, 0.3759596]]\n",
            "1127          [[0.01194055, 0.6992258, 0.28883368]]\n",
            "1128        [[0.014010413, 0.74383986, 0.24214968]]\n",
            "1129        [[0.0050404444, 0.937773, 0.057186574]]\n",
            "1130       [[0.0058355946, 0.034569807, 0.9595946]]\n",
            "1131         [[0.020601036, 0.2522302, 0.72716874]]\n",
            "1132         [[0.016278125, 0.20896284, 0.7747591]]\n",
            "1133     [[0.0028569342, 0.0019415788, 0.99520147]]\n",
            "1134          [[0.16857758, 0.27966034, 0.5517621]]\n",
            "1135      [[0.0006062074, 0.002906146, 0.99648774]]\n",
            "1136      [[0.0005368693, 0.0030128222, 0.9964503]]\n",
            "1137      [[0.0015993223, 0.0059680324, 0.9924327]]\n",
            "1138      [[0.0005368693, 0.0030128222, 0.9964503]]\n",
            "1139       [[0.0013470658, 0.011650977, 0.9870019]]\n",
            "1140       [[0.0019299553, 0.00421316, 0.99385685]]\n",
            "1141         [[0.00656112, 0.38281378, 0.61062515]]\n",
            "1142        [[0.0032907617, 0.30804574, 0.6886634]]\n",
            "1143        [[0.009923679, 0.101681575, 0.8883948]]\n",
            "1144         [[0.45172974, 0.07257417, 0.47569612]]\n",
            "1145         [[0.45172974, 0.07257417, 0.47569612]]\n",
            "1146      [[0.003731673, 0.0065157637, 0.98975253]]\n",
            "1147        [[0.002621269, 0.0009006408, 0.996478]]\n",
            "1148     [[0.0017053171, 0.0010629804, 0.99723166]]\n",
            "1149        [[0.108798034, 0.07535993, 0.81584203]]\n",
            "1150        [[0.00926431, 0.012824667, 0.97791106]]\n",
            "1151      [[0.0029852428, 0.049024515, 0.94799024]]\n",
            "1152        [[0.108798034, 0.07535993, 0.81584203]]\n",
            "1153       [[0.015980985, 0.013506879, 0.97051215]]\n",
            "1154           [[0.3625299, 0.1698723, 0.46759778]]\n",
            "1155           [[0.3625299, 0.1698723, 0.46759778]]\n",
            "1156      [[0.0032787577, 0.0034018157, 0.9933195]]\n",
            "1157      [[0.0011595784, 0.005818079, 0.99302226]]\n",
            "1158       [[0.0021382454, 0.007994037, 0.9898677]]\n",
            "1159        [[0.0041843085, 0.07872672, 0.9170889]]\n",
            "1160        [[0.025533848, 0.113478765, 0.8609874]]\n",
            "1161       [[0.016179137, 0.014212043, 0.96960884]]\n",
            "1162        [[0.006954966, 0.007119036, 0.9859261]]\n",
            "1163        [[0.017109666, 0.048707515, 0.9341829]]\n",
            "1164      [[0.0024080302, 0.009311289, 0.98828065]]\n",
            "1165       [[0.016179137, 0.014212043, 0.96960884]]\n",
            "1166       [[0.0026378133, 0.059368376, 0.9379938]]\n",
            "1167        [[0.0009789994, 0.02174862, 0.9772724]]\n",
            "1168      [[0.0011619764, 0.025677476, 0.97316056]]\n",
            "1169      [[0.0006857109, 0.0077261203, 0.9915882]]\n",
            "1170         [[0.01424373, 0.15582289, 0.82993335]]\n",
            "1171       [[0.0009380701, 0.020418268, 0.9786436]]\n",
            "1172       [[0.0020686416, 0.022771461, 0.9751599]]\n",
            "1173       [[0.0025725914, 0.34289828, 0.65452915]]\n",
            "1174          [[0.12176279, 0.6599895, 0.21824773]]\n",
            "1175        [[0.12685508, 0.82600516, 0.047139708]]\n",
            "1176       [[0.014326996, 0.97522247, 0.010450498]]\n",
            "1177        [[0.036012303, 0.033896226, 0.9300915]]\n",
            "1178     [[0.0035083608, 0.0011198851, 0.99537176]]\n",
            "1179         [[0.04745208, 0.041715123, 0.9108328]]\n",
            "1180        [[0.005809485, 0.005640383, 0.9885501]]\n",
            "1181       [[0.010346756, 0.013434888, 0.97621846]]\n",
            "1182       [[0.011194664, 0.0050085904, 0.9837968]]\n",
            "1183     [[0.0019825483, 0.0057832142, 0.99223423]]\n",
            "1184       [[0.0010708325, 0.015854763, 0.9830745]]\n",
            "1185    [[0.0004472015, 0.00082306616, 0.99872977]]\n",
            "1186         [[0.088294074, 0.06307861, 0.8486273]]\n",
            "1187          [[0.5073173, 0.04536781, 0.44731492]]\n",
            "1188         [[0.032891627, 0.02274296, 0.9443654]]\n",
            "1189        [[0.0016784813, 0.01236354, 0.9859579]]\n",
            "1190      [[0.0029975625, 0.067227066, 0.92977536]]\n",
            "1191       [[0.0095317075, 0.12265648, 0.86781186]]\n",
            "1192        [[0.004257869, 0.021183252, 0.9745589]]\n",
            "1193          [[0.09065525, 0.05847296, 0.8508717]]\n",
            "1194        [[0.021798253, 0.005677462, 0.9725242]]\n",
            "1195      [[0.0047872756, 0.001090784, 0.99412197]]\n",
            "1196        [[0.0018641968, 0.03639237, 0.9617434]]\n",
            "1197       [[0.0013103344, 0.041183773, 0.9575058]]\n",
            "1198        [[0.002262439, 0.101090714, 0.8966469]]\n",
            "1199       [[0.0021281566, 0.08761503, 0.91025686]]\n",
            "1200         [[0.0047270562, 0.64478797, 0.350485]]\n",
            "1201      [[0.0015780282, 0.0024689315, 0.9959531]]\n",
            "1202      [[0.0015780282, 0.0024689315, 0.9959531]]\n",
            "1203       [[0.014347671, 0.0070978478, 0.9785544]]\n",
            "1204          [[0.4794996, 0.24135828, 0.27914205]]\n",
            "1205        [[0.059500534, 0.01543281, 0.92506665]]\n",
            "1206      [[0.0088228155, 0.025063971, 0.96611327]]\n",
            "1207      [[0.0033076855, 0.0012439971, 0.9954483]]\n",
            "1208       [[0.0040814886, 0.006063237, 0.9898553]]\n",
            "1209        [[0.022739368, 0.63309526, 0.34416535]]\n",
            "1210         [[0.029296925, 0.9038377, 0.06686534]]\n",
            "1211          [[0.11011008, 0.7549219, 0.13496803]]\n",
            "1212           [[0.3162699, 0.5757219, 0.10800815]]\n",
            "1213     [[0.0008566908, 0.0038479168, 0.99529546]]\n",
            "1214       [[0.0014025376, 0.014830147, 0.9837674]]\n",
            "1215      [[0.0010833249, 0.004448138, 0.99446857]]\n",
            "1216        [[0.0018997927, 0.07841891, 0.9196814]]\n",
            "1217        [[0.0027988532, 0.36507875, 0.6321224]]\n",
            "1218       [[0.001018545, 0.0010770154, 0.9979044]]\n",
            "1219       [[0.0011053057, 0.004498363, 0.9943963]]\n",
            "1220     [[0.003156232, 0.00096872746, 0.99587506]]\n",
            "1221     [[0.0018875662, 0.0039549693, 0.99415743]]\n",
            "1222     [[0.0013318812, 0.0128690675, 0.98579895]]\n",
            "1223         [[0.026752142, 0.4500619, 0.52318597]]\n",
            "1224      [[0.0026036096, 0.018060068, 0.97933644]]\n",
            "1225       [[0.0010827224, 0.000965472, 0.9979518]]\n",
            "1226        [[0.008774017, 0.044533163, 0.9466928]]\n",
            "1227      [[0.0024083368, 0.0005073129, 0.9970843]]\n",
            "1228       [[0.004234211, 0.022180505, 0.97358525]]\n",
            "1229      [[0.006519757, 0.0020934134, 0.99138683]]\n",
            "1230      [[0.006519757, 0.0020934134, 0.99138683]]\n",
            "1231       [[0.011302577, 0.0030819608, 0.9856154]]\n",
            "1232         [[0.9139776, 0.06750149, 0.018520838]]\n",
            "1233         [[0.002017864, 0.00428099, 0.9937012]]\n",
            "1234       [[0.005096108, 0.0010313416, 0.9938725]]\n",
            "1235         [[0.23952575, 0.65860456, 0.10186973]]\n",
            "1236           [[0.04704045, 0.4165734, 0.5363862]]\n",
            "1237     [[0.0045341006, 0.0010126769, 0.99445325]]\n",
            "1238       [[0.007959726, 0.064861886, 0.92717844]]\n",
            "1239          [[0.01348345, 0.21601771, 0.7704988]]\n",
            "1240         [[0.002734796, 0.0011352367, 0.99613]]\n",
            "1241       [[0.0047530374, 0.001558374, 0.9936885]]\n",
            "1242       [[0.0026499976, 0.03634103, 0.96100897]]\n",
            "1243          [[0.00524137, 0.40871593, 0.5860427]]\n",
            "1244          [[0.005555573, 0.40048635, 0.593958]]\n",
            "1245      [[0.0007938583, 0.0038739187, 0.9953322]]\n",
            "1246        [[0.0014271758, 0.5250955, 0.47347733]]\n",
            "1247       [[0.0030248626, 0.11563441, 0.88134074]]\n",
            "1248      [[0.0007938583, 0.0038739187, 0.9953322]]\n",
            "1249        [[0.095293954, 0.84273064, 0.06197548]]\n",
            "1250       [[0.0038383235, 0.83543944, 0.16072223]]\n",
            "1251           [[0.114513524, 0.5554815, 0.330005]]\n",
            "1252       [[0.0053871684, 0.03773126, 0.95688164]]\n",
            "1253         [[0.014756893, 0.16044186, 0.8248013]]\n",
            "1254       [[0.0032619257, 0.044009816, 0.9527282]]\n",
            "1255         [[0.014756893, 0.16044186, 0.8248013]]\n",
            "1256         [[0.009957714, 0.50655544, 0.4834868]]\n",
            "1257      [[0.0009561467, 0.031135349, 0.96790844]]\n",
            "1258      [[0.0012470795, 0.026647447, 0.97210556]]\n",
            "1259       [[0.001336042, 0.031111471, 0.96755254]]\n",
            "1260         [[0.030953798, 0.2630552, 0.70599097]]\n",
            "1261      [[0.0024982828, 0.0018424063, 0.9956593]]\n",
            "1262      [[0.0033350016, 0.0011769186, 0.9954881]]\n",
            "1263           [[0.372514, 0.14443877, 0.48304725]]\n",
            "1264        [[0.008124235, 0.004194358, 0.9876814]]\n",
            "1265        [[0.0040588966, 0.10774545, 0.8881957]]\n",
            "1266     [[0.0016626036, 0.0047969227, 0.99354047]]\n",
            "1267        [[0.017176818, 0.15484126, 0.82798195]]\n",
            "1268           [[0.11809177, 0.11329918, 0.768609]]\n",
            "1269          [[0.26286763, 0.6335779, 0.10355446]]\n",
            "1270          [[0.6112441, 0.18915258, 0.19960336]]\n",
            "1271         [[0.67296064, 0.16533795, 0.16170141]]\n",
            "1272         [[0.009704157, 0.8456048, 0.14469108]]\n",
            "1273         [[0.024199806, 0.7369612, 0.23883896]]\n",
            "1274         [[0.01974288, 0.029030949, 0.9512262]]\n",
            "1275     [[0.0036884411, 0.0016312039, 0.99468035]]\n",
            "1276           [[0.01813777, 0.301082, 0.68078035]]\n",
            "1277          [[0.37602353, 0.5477832, 0.07619326]]\n",
            "1278      [[0.0031006767, 0.0035806664, 0.9933187]]\n",
            "1279           [[0.09387462, 0.508972, 0.39715335]]\n",
            "1280        [[0.108315445, 0.56132495, 0.33035958]]\n",
            "1281        [[0.004953186, 0.047213625, 0.9478332]]\n",
            "1282      [[0.0011012035, 0.0026063495, 0.9962924]]\n",
            "1283       [[0.0020653529, 0.028841143, 0.9690935]]\n",
            "1284        [[0.0025060289, 0.04890215, 0.9485918]]\n",
            "1285      [[0.0016234249, 0.111985646, 0.88639086]]\n",
            "1286        [[0.006089234, 0.061899535, 0.9320113]]\n",
            "1287     [[0.0028114764, 0.00079040776, 0.9963981]]\n",
            "1288          [[0.015447164, 0.59113383, 0.393419]]\n",
            "1289          [[0.38177237, 0.3836913, 0.23453636]]\n",
            "1290          [[0.8594653, 0.06193936, 0.07859528]]\n",
            "1291          [[0.00868772, 0.05784114, 0.9334711]]\n",
            "1292        [[0.93832695, 0.03971751, 0.021955576]]\n",
            "1293        [[0.009587047, 0.018128522, 0.9722845]]\n",
            "1294         [[0.059761632, 0.06772526, 0.8725131]]\n",
            "1295          [[0.4533929, 0.31073385, 0.23587328]]\n",
            "1296      [[0.016983336, 0.0035923852, 0.97942436]]\n",
            "1297        [[0.018605044, 0.19263245, 0.78876257]]\n",
            "1298          [[0.004569881, 0.4712075, 0.5242227]]\n",
            "1299        [[0.0045747645, 0.05466443, 0.9407608]]\n",
            "1300        [[0.067907855, 0.034075897, 0.8980163]]\n",
            "1301        [[0.0045747645, 0.05466443, 0.9407608]]\n",
            "1302        [[0.0048261806, 0.02580304, 0.9693708]]\n",
            "1303         [[0.0025001268, 0.24805485, 0.749445]]\n",
            "1304       [[0.0033442639, 0.56293064, 0.43372506]]\n",
            "1305         [[0.005846057, 0.35355765, 0.6405963]]\n",
            "1306          [[0.009098693, 0.057461258, 0.93344]]\n",
            "1307      [[0.0012672542, 0.003570913, 0.99516183]]\n",
            "1308      [[0.0033206306, 0.0016916201, 0.9949877]]\n",
            "1309      [[0.0012590855, 0.003327543, 0.99541336]]\n",
            "1310       [[0.006303628, 0.0036259622, 0.9900704]]\n",
            "1311         [[0.01622984, 0.23534933, 0.74842083]]\n",
            "1312        [[0.003591355, 0.038291022, 0.9581177]]\n",
            "1313       [[0.0024520215, 0.078827776, 0.9187202]]\n",
            "1314       [[0.0009461735, 0.118923314, 0.8801306]]\n",
            "1315       [[0.0032889866, 0.84326714, 0.15344392]]\n",
            "1316      [[0.0027690742, 0.016535345, 0.98069555]]\n",
            "1317      [[0.0027690742, 0.016535345, 0.98069555]]\n",
            "1318     [[0.0009184612, 0.0011642831, 0.99791723]]\n",
            "1319     [[0.0010110349, 0.0040101567, 0.99497885]]\n",
            "1320      [[0.0017488407, 0.0033219305, 0.9949293]]\n",
            "1321       [[0.002405278, 0.038422868, 0.95917183]]\n",
            "1322         [[0.006683432, 0.6980178, 0.29529878]]\n",
            "1323       [[0.0043925405, 0.63608944, 0.35951802]]\n",
            "1324          [[0.00395376, 0.6556784, 0.34036782]]\n",
            "1325        [[0.005199714, 0.63423675, 0.36056352]]\n",
            "1326        [[0.0011433397, 0.9808303, 0.01802639]]\n",
            "1327        [[0.0036158916, 0.018870065, 0.977514]]\n",
            "1328        [[0.0019741552, 0.04466105, 0.9533649]]\n",
            "1329          [[0.003368364, 0.0817472, 0.9148844]]\n",
            "1330        [[0.009002306, 0.60446924, 0.38652846]]\n",
            "1331          [[0.002551581, 0.0650338, 0.9324146]]\n",
            "1332       [[0.006813287, 0.031108055, 0.96207863]]\n",
            "1333       [[0.0114302235, 0.04119325, 0.94737655]]\n",
            "1334          [[0.04280808, 0.8103157, 0.14687617]]\n",
            "1335        [[0.0035809297, 0.04976428, 0.9466548]]\n",
            "1336        [[0.012525727, 0.56397307, 0.42350113]]\n",
            "1337       [[0.0053048143, 0.108045295, 0.8866499]]\n",
            "1338       [[0.0021555643, 0.002810237, 0.9950342]]\n",
            "1339          [[0.01096093, 0.16580927, 0.8232298]]\n",
            "1340      [[0.0041292473, 0.016045269, 0.97982544]]\n",
            "1341         [[0.06132498, 0.015859233, 0.9228158]]\n",
            "1342       [[0.0057356246, 0.008601246, 0.9856631]]\n",
            "1343          [[0.6575049, 0.22872597, 0.11376912]]\n",
            "1344          [[0.24884193, 0.47728252, 0.2738755]]\n",
            "1345      [[0.0056256154, 0.089149944, 0.90522444]]\n",
            "1346         [[0.044718243, 0.8538104, 0.10147137]]\n",
            "1347        [[0.0035302138, 0.033682816, 0.962787]]\n",
            "1348      [[0.004297854, 0.0025902658, 0.99311197]]\n",
            "1349          [[0.0083878, 0.009268781, 0.9823433]]\n",
            "1350         [[0.004121332, 0.06553127, 0.9303473]]\n",
            "1351         [[0.006909545, 0.01789205, 0.9751983]]\n",
            "1352           [[0.007714677, 0.538693, 0.4535923]]\n",
            "1353     [[0.0019201552, 0.0013975397, 0.99668235]]\n",
            "1354     [[0.0070971786, 0.0025211088, 0.99038166]]\n",
            "1355          [[0.31882703, 0.3629047, 0.31826824]]\n",
            "1356      [[0.0073735197, 0.017902026, 0.97472453]]\n",
            "1357          [[0.6147987, 0.29897952, 0.08622179]]\n",
            "1358      [[0.005127522, 0.0019117859, 0.99296063]]\n",
            "1359        [[0.013646448, 0.03125451, 0.95509905]]\n",
            "1360       [[0.0021544679, 0.001797229, 0.9960483]]\n",
            "1361        [[0.038803622, 0.06599188, 0.89520454]]\n",
            "1362           [[0.5924234, 0.1267066, 0.28086996]]\n",
            "1363       [[0.0018434685, 0.15785833, 0.84029824]]\n",
            "1364       [[0.0018455883, 0.63915336, 0.35900107]]\n",
            "1365        [[0.0014619546, 0.4142746, 0.58426344]]\n",
            "1366         [[0.0056173946, 0.1521822, 0.8422004]]\n",
            "1367        [[0.002754246, 0.008960443, 0.9882853]]\n",
            "1368        [[0.008535723, 0.51635635, 0.47510785]]\n",
            "1369        [[0.017424326, 0.71289665, 0.26967898]]\n",
            "1370           [[0.058183603, 0.8026374, 0.139179]]\n",
            "1371         [[0.009899141, 0.7458203, 0.24428055]]\n",
            "1372    [[0.00036887807, 0.0010335996, 0.99859744]]\n",
            "1373            [[0.12042116, 0.3009458, 0.578633]]\n",
            "1374       [[0.001789173, 0.052444406, 0.94576645]]\n",
            "1375       [[0.0045365565, 0.8777361, 0.117727384]]\n",
            "1376          [[0.00174012, 0.29127565, 0.7069842]]\n",
            "1377        [[0.0013138325, 0.03992344, 0.9587627]]\n",
            "1378       [[0.0012888957, 0.051636387, 0.9470748]]\n",
            "1379        [[0.0010766094, 0.01597964, 0.9829437]]\n",
            "1380          [[0.817381, 0.16793203, 0.014686972]]\n",
            "1381      [[0.006748346, 0.0017639386, 0.99148774]]\n",
            "1382       [[0.9851103, 0.009468456, 0.0054211947]]\n",
            "1383          [[0.19672666, 0.7638386, 0.03943474]]\n",
            "1384          [[0.30111912, 0.5030917, 0.19578917]]\n",
            "1385      [[0.0019695458, 0.0022718236, 0.9957586]]\n",
            "1386        [[0.011637968, 0.004130287, 0.9842318]]\n",
            "1387      [[0.0027424423, 0.0068804133, 0.9903771]]\n",
            "1388       [[0.029905388, 0.023857126, 0.94623744]]\n",
            "1389    [[0.0044229873, 0.00093180564, 0.99464524]]\n",
            "1390        [[0.021700041, 0.017115626, 0.9611844]]\n",
            "1391        [[0.015390057, 0.007046119, 0.9775638]]\n",
            "1392       [[0.0075419196, 0.016395502, 0.9760626]]\n",
            "1393      [[0.0026111393, 0.0004875132, 0.9969014]]\n",
            "1394      [[0.016904555, 0.0034804004, 0.97961503]]\n",
            "1395          [[0.05796096, 0.2911748, 0.65086424]]\n",
            "1396         [[0.046731245, 0.23251328, 0.7207555]]\n",
            "1397        [[0.008094454, 0.58040816, 0.41149738]]\n",
            "1398         [[0.012223926, 0.38240635, 0.6053697]]\n",
            "1399         [[0.026796471, 0.47970864, 0.4934949]]\n",
            "1400           [[0.0240694, 0.33818877, 0.6377418]]\n",
            "1401      [[0.0023685433, 0.0018371167, 0.9957943]]\n",
            "1402         [[0.0064050797, 0.3086504, 0.6849445]]\n",
            "1403       [[0.0033752446, 0.00838769, 0.98823696]]\n",
            "1404         [[0.01660747, 0.57480484, 0.40858763]]\n",
            "1405         [[0.038765814, 0.8543711, 0.10686314]]\n",
            "1406         [[0.0744346, 0.85203105, 0.073534295]]\n",
            "1407         [[0.113231346, 0.8191714, 0.06759718]]\n",
            "1408         [[0.0062412773, 0.4127833, 0.5809754]]\n",
            "1409        [[0.017791081, 0.73042065, 0.25178823]]\n",
            "1410          [[0.02016957, 0.09843428, 0.8813962]]\n",
            "1411       [[0.019401142, 0.055590324, 0.92500854]]\n",
            "1412         [[0.010297225, 0.6623246, 0.32737818]]\n",
            "1413    [[0.00092300726, 0.0033263916, 0.99575055]]\n",
            "1414     [[0.0014082459, 0.0011356795, 0.99745613]]\n",
            "1415         [[0.014859504, 0.15113734, 0.8340031]]\n",
            "1416       [[0.002322061, 0.010641883, 0.98703605]]\n",
            "1417           [[0.06119202, 0.362077, 0.57673097]]\n",
            "1418      [[0.0024203435, 0.003240444, 0.99433917]]\n",
            "1419         [[0.01054298, 0.010075137, 0.9793818]]\n",
            "1420       [[0.012808353, 0.055518284, 0.93167335]]\n",
            "1421       [[0.0044421786, 0.018510517, 0.9770473]]\n",
            "1422      [[0.0010082781, 0.0023239225, 0.9966678]]\n",
            "1423          [[0.014465542, 0.552496, 0.43303847]]\n",
            "1424           [[0.10947348, 0.1437788, 0.7467477]]\n",
            "1425       [[0.0036472671, 0.066377185, 0.9299755]]\n",
            "1426         [[0.063713916, 0.33007875, 0.6062073]]\n",
            "1427          [[0.038196433, 0.6494487, 0.3123549]]\n",
            "1428         [[0.027633574, 0.7721131, 0.20025331]]\n",
            "1429         [[0.027361592, 0.7590088, 0.21362963]]\n",
            "1430          [[0.060229585, 0.2552511, 0.6845193]]\n",
            "1431         [[0.004549759, 0.03528712, 0.9601631]]\n",
            "1432        [[0.011935477, 0.03267526, 0.95538926]]\n",
            "1433         [[0.038371693, 0.23128253, 0.7303457]]\n",
            "1434            [[0.0146312, 0.1581721, 0.8271967]]\n",
            "1435        [[0.011935477, 0.03267526, 0.95538926]]\n",
            "1436        [[0.007640256, 0.07663263, 0.91572714]]\n",
            "1437      [[0.0031870315, 0.024697028, 0.97211593]]\n",
            "1438       [[0.0054047573, 0.010282409, 0.9843128]]\n",
            "1439         [[0.052938767, 0.7553169, 0.19174428]]\n",
            "1440       [[0.0057604862, 0.13592634, 0.85831326]]\n",
            "1441        [[0.0078086536, 0.6988526, 0.29333875]]\n",
            "1442          [[0.04467564, 0.6165755, 0.33874887]]\n",
            "1443       [[0.0056534098, 0.52701205, 0.46733454]]\n",
            "1444         [[0.034160323, 0.6976646, 0.26817507]]\n",
            "1445        [[0.011368902, 0.64955914, 0.33907202]]\n",
            "1446      [[0.0020105483, 0.0015978824, 0.9963915]]\n",
            "1447       [[0.002432684, 0.0031676192, 0.9943996]]\n",
            "1448       [[0.0020752854, 0.006197091, 0.9917276]]\n",
            "1449         [[0.54529965, 0.11303834, 0.34166205]]\n",
            "1450        [[0.008462473, 0.70722467, 0.28431284]]\n",
            "1451         [[0.006554526, 0.8596393, 0.13380614]]\n",
            "1452         [[0.006554526, 0.8596393, 0.13380614]]\n",
            "1453        [[0.0027739361, 0.9496751, 0.04755098]]\n",
            "1454        [[0.0025804061, 0.9535757, 0.04384388]]\n",
            "1455      [[0.0029662568, 0.045752626, 0.95128113]]\n",
            "1456        [[0.097246036, 0.34926388, 0.55349004]]\n",
            "1457          [[0.28659979, 0.5298725, 0.18352778]]\n",
            "1458          [[0.15418674, 0.6504828, 0.19533052]]\n",
            "1459      [[0.0036147567, 0.005314375, 0.99107087]]\n",
            "1460       [[0.005179265, 0.019662512, 0.97515815]]\n",
            "1461      [[0.0034464463, 0.0009256472, 0.9956279]]\n",
            "1462        [[0.0019437171, 0.007219265, 0.990837]]\n",
            "1463        [[0.0064269225, 0.28653875, 0.7070344]]\n",
            "1464       [[0.0012767316, 0.08151338, 0.91720986]]\n",
            "1465         [[0.008525781, 0.7308062, 0.26066813]]\n",
            "1466       [[0.0036296723, 0.10551068, 0.89085966]]\n",
            "1467         [[0.006333137, 0.11736952, 0.8762973]]\n",
            "1468        [[0.0051519666, 0.6973403, 0.29750773]]\n",
            "1469      [[0.0007606873, 0.010071177, 0.98916817]]\n",
            "1470       [[0.0034322548, 0.0037867674, 0.992781]]\n",
            "1471       [[0.0010300041, 0.022764176, 0.9762058]]\n",
            "1472        [[0.00429776, 0.032173764, 0.96352845]]\n",
            "1473       [[0.9867698, 0.009885094, 0.0033451286]]\n",
            "1474      [[0.0045546205, 0.00063946884, 0.994806]]\n",
            "1475      [[0.0019791075, 0.0011241895, 0.9968966]]\n",
            "1476          [[0.25807813, 0.25234947, 0.4895724]]\n",
            "1477      [[0.0015295288, 0.0011356041, 0.9973348]]\n",
            "1478        [[0.027614325, 0.085400015, 0.8869856]]\n",
            "1479         [[0.5872541, 0.36417237, 0.048573576]]\n",
            "1480         [[0.025420733, 0.7527019, 0.22187734]]\n",
            "1481         [[0.09583938, 0.009898093, 0.8942625]]\n",
            "1482          [[0.40378636, 0.56695807, 0.0292556]]\n",
            "1483          [[0.21749939, 0.7442555, 0.03824506]]\n",
            "1484       [[0.008095031, 0.0027377144, 0.9891672]]\n",
            "1485           [[0.704571, 0.16784215, 0.12758686]]\n",
            "1486          [[0.14412017, 0.79159874, 0.0642811]]\n",
            "1487       [[0.95032394, 0.032333422, 0.017342716]]\n",
            "1488           [[0.704571, 0.16784215, 0.12758686]]\n",
            "1489        [[0.13995624, 0.82052565, 0.039518148]]\n",
            "1490         [[0.27065155, 0.6945172, 0.034831222]]\n",
            "1491        [[0.01182615, 0.048502993, 0.93967086]]\n",
            "1492        [[0.010460618, 0.009297091, 0.9802422]]\n",
            "1493        [[0.01182615, 0.048502993, 0.93967086]]\n",
            "1494        [[0.0059063174, 0.020789668, 0.973304]]\n",
            "1495           [[0.016718814, 0.574932, 0.4083492]]\n",
            "1496          [[0.017370816, 0.6789208, 0.3037084]]\n",
            "1497         [[0.027465919, 0.79982275, 0.1727113]]\n",
            "1498       [[0.047487948, 0.90928423, 0.043227833]]\n",
            "1499         [[0.011895317, 0.35316357, 0.6349411]]\n",
            "1500       [[0.0020009668, 0.023143552, 0.9748555]]\n",
            "1501     [[0.00082011113, 0.0011384236, 0.9980414]]\n",
            "1502       [[0.0021071741, 0.006392356, 0.9915004]]\n",
            "1503     [[0.00077129016, 0.0033208749, 0.9959078]]\n",
            "1504     [[0.0020423087, 0.0029704294, 0.99498737]]\n",
            "1505       [[0.0013673708, 0.002844339, 0.9957883]]\n",
            "1506     [[0.0011831664, 0.00056707097, 0.9982497]]\n",
            "1507      [[0.0019223753, 0.015105295, 0.98297244]]\n",
            "1508         [[0.037507348, 0.4068264, 0.55566627]]\n",
            "1509         [[0.010844741, 0.33235195, 0.6568033]]\n",
            "1510       [[0.0024550539, 0.23363805, 0.76390696]]\n",
            "1511        [[0.005126803, 0.48782617, 0.50704706]]\n",
            "1512         [[0.002631314, 0.005204679, 0.992164]]\n",
            "1513         [[0.07035073, 0.35138476, 0.57826453]]\n",
            "1514         [[0.02105052, 0.27848685, 0.70046264]]\n",
            "1515         [[0.0059662913, 0.2703698, 0.7236639]]\n",
            "1516        [[0.011200652, 0.008210979, 0.9805884]]\n",
            "1517      [[0.0057242624, 0.027511096, 0.96676475]]\n",
            "1518      [[0.0057230806, 0.032351915, 0.96192497]]\n",
            "1519       [[0.97097415, 0.008094839, 0.020931086]]\n",
            "1520           [[0.6846558, 0.22706401, 0.0882802]]\n",
            "1521        [[0.69995975, 0.053642575, 0.24639767]]\n",
            "1522          [[0.6690886, 0.14912151, 0.18178992]]\n",
            "1523       [[0.008764647, 0.007824157, 0.98341125]]\n",
            "1524           [[0.4222502, 0.04874247, 0.5290073]]\n",
            "1525         [[0.034298588, 0.7867592, 0.17894223]]\n",
            "1526       [[0.9569921, 0.0046875374, 0.038320426]]\n",
            "1527     [[0.0036292444, 0.0017220424, 0.99464875]]\n",
            "1528         [[0.017226854, 0.02199042, 0.9607827]]\n",
            "1529         [[0.38704246, 0.27626452, 0.33669305]]\n",
            "1530         [[0.38704246, 0.27626452, 0.33669305]]\n",
            "1531      [[0.0052090227, 0.037361227, 0.95742977]]\n",
            "1532      [[0.0052090227, 0.037361227, 0.95742977]]\n",
            "1533       [[0.013527659, 0.029777104, 0.95669526]]\n",
            "1534       [[0.0064296755, 0.010599919, 0.9829705]]\n",
            "1535           [[0.03780699, 0.0822416, 0.8799515]]\n",
            "1536        [[0.43538037, 0.078634195, 0.48598543]]\n",
            "1537       [[0.93136585, 0.038666036, 0.029968143]]\n",
            "1538       [[0.94571763, 0.032851942, 0.021430459]]\n",
            "1539         [[0.6407228, 0.024519406, 0.33475778]]\n",
            "1540       [[0.009638503, 0.0038639095, 0.9864977]]\n",
            "1541        [[0.002443004, 0.018879533, 0.9786775]]\n",
            "1542       [[0.0021486229, 0.022045238, 0.9758061]]\n",
            "1543      [[0.0007600256, 0.0044733766, 0.9947666]]\n",
            "1544       [[0.0021486229, 0.022045238, 0.9758061]]\n",
            "1545        [[0.008763109, 0.25030777, 0.74092907]]\n",
            "1546     [[0.0015896725, 0.0018747943, 0.99653554]]\n",
            "1547        [[0.003775243, 0.18891947, 0.80730534]]\n",
            "1548      [[0.0014628388, 0.0049198414, 0.9936173]]\n",
            "1549         [[0.28425843, 0.23222464, 0.48351693]]\n",
            "1550          [[0.08306463, 0.42698213, 0.4899532]]\n",
            "1551          [[0.08306463, 0.42698213, 0.4899532]]\n",
            "1552          [[0.005717808, 0.05391314, 0.940369]]\n",
            "1553       [[0.0015069611, 0.0011850877, 0.997308]]\n",
            "1554       [[0.0012432291, 0.003320832, 0.9954359]]\n",
            "1555       [[0.0015069611, 0.0011850877, 0.997308]]\n",
            "1556       [[0.007355821, 0.021660453, 0.97098374]]\n",
            "1557       [[0.002755566, 0.0034490018, 0.9937954]]\n",
            "1558        [[0.027606916, 0.053860012, 0.9185331]]\n",
            "1559         [[0.0036187898, 0.6927179, 0.3036633]]\n",
            "1560         [[0.16992162, 0.59409356, 0.23598483]]\n",
            "1561         [[0.04910536, 0.57290924, 0.37798542]]\n",
            "1562          [[0.08306463, 0.42698213, 0.4899532]]\n",
            "1563       [[0.040830918, 0.022975275, 0.93619376]]\n",
            "1564           [[0.27119547, 0.370522, 0.35828257]]\n",
            "1565      [[0.0058397204, 0.016119288, 0.97804105]]\n",
            "1566         [[0.04225736, 0.89748514, 0.06025752]]\n",
            "1567            [[0.13449565, 0.6569523, 0.208552]]\n",
            "1568       [[0.0019804982, 0.93665403, 0.06136541]]\n",
            "1569       [[0.0028892674, 0.9022557, 0.094854996]]\n",
            "1570      [[0.0028081667, 0.93950194, 0.057689946]]\n",
            "1571          [[0.005045195, 0.1738131, 0.8211417]]\n",
            "1572         [[0.09141711, 0.40878195, 0.49980095]]\n",
            "1573          [[0.30642682, 0.32861093, 0.3649623]]\n",
            "1574          [[0.9027668, 0.019170193, 0.0780629]]\n",
            "1575          [[0.7802675, 0.04934539, 0.17038713]]\n",
            "1576          [[0.46121317, 0.2465518, 0.29223505]]\n",
            "1577       [[0.85879254, 0.030170582, 0.111036845]]\n",
            "1578     [[0.003773554, 0.00073031354, 0.99549615]]\n",
            "1579     [[0.0018647847, 0.00095588947, 0.9971794]]\n",
            "1580     [[0.0018647847, 0.00095588947, 0.9971794]]\n",
            "1581      [[0.0011968545, 0.0047919974, 0.9940112]]\n",
            "1582         [[0.003091031, 0.02392214, 0.9729868]]\n",
            "1583         [[0.011633393, 0.6306516, 0.35771498]]\n",
            "1584         [[0.07656321, 0.48658893, 0.43684793]]\n",
            "1585         [[0.65305007, 0.10143651, 0.24551341]]\n",
            "1586      [[0.008174643, 0.0039232112, 0.98790216]]\n",
            "1587         [[0.032914482, 0.3189096, 0.64817595]]\n",
            "1588        [[0.053823743, 0.74280745, 0.20336883]]\n",
            "1589        [[0.0072833044, 0.11279561, 0.8799211]]\n",
            "1590       [[0.0024495418, 0.014390183, 0.9831603]]\n",
            "1591       [[0.012874913, 0.030749144, 0.95637596]]\n",
            "1592          [[0.6740283, 0.26027396, 0.06569776]]\n",
            "1593          [[0.52976674, 0.3221674, 0.14806588]]\n",
            "1594       [[0.017741606, 0.015303699, 0.96695477]]\n",
            "1595         [[0.005037644, 0.13376044, 0.8612018]]\n",
            "1596         [[0.02010255, 0.06929874, 0.91059875]]\n",
            "1597         [[0.033752747, 0.5676266, 0.39862064]]\n",
            "1598        [[0.008982809, 0.88049346, 0.11052372]]\n",
            "1599       [[0.0006911781, 0.9644201, 0.034888733]]\n",
            "1600        [[0.0009224309, 0.951111, 0.047966555]]\n",
            "1601       [[0.0009776775, 0.9475177, 0.051504612]]\n",
            "1602         [[0.01497786, 0.062350005, 0.9226722]]\n",
            "1603          [[0.001637132, 0.933455, 0.06490793]]\n",
            "1604      [[0.000994798, 0.0008914724, 0.99811375]]\n",
            "1605        [[0.006583585, 0.028340733, 0.9650756]]\n",
            "1606      [[0.0007643358, 0.0015657567, 0.9976699]]\n",
            "1607      [[0.0011634664, 0.006674462, 0.99216205]]\n",
            "1608          [[0.6138759, 0.08850342, 0.29762068]]\n",
            "1609         [[0.8011738, 0.018383287, 0.18044293]]\n",
            "1610         [[0.027136525, 0.02050198, 0.9523615]]\n",
            "1611          [[0.6138759, 0.08850342, 0.29762068]]\n",
            "1612        [[0.005774519, 0.023046065, 0.9711794]]\n",
            "1613     [[0.0006716943, 0.0012556006, 0.99807274]]\n",
            "1614      [[0.0013380786, 0.009900041, 0.98876196]]\n",
            "1615          [[0.0012401643, 0.012109, 0.9866508]]\n",
            "1616        [[0.0038411892, 0.48710743, 0.5090514]]\n",
            "1617     [[0.0039353697, 0.0061965217, 0.98986816]]\n",
            "1618       [[0.0009889513, 0.061541338, 0.9374698]]\n",
            "1619       [[0.006256781, 0.011749308, 0.98199385]]\n",
            "1620       [[0.009180078, 0.0049936664, 0.9858263]]\n",
            "1621        [[0.015263263, 0.006664017, 0.9780727]]\n",
            "1622     [[0.0005224659, 0.0010186029, 0.99845886]]\n",
            "1623     [[0.0005207788, 0.0010587961, 0.99842036]]\n",
            "1624      [[0.0011369456, 0.004001444, 0.99486154]]\n",
            "1625        [[0.003224359, 0.10195699, 0.89481866]]\n",
            "1626           [[0.3353392, 0.04742007, 0.6172407]]\n",
            "1627        [[0.0147004435, 0.0332212, 0.95207834]]\n",
            "1628      [[0.0046454156, 0.0010684191, 0.9942861]]\n",
            "1629     [[0.0071521653, 0.0026406255, 0.99020725]]\n",
            "1630       [[0.002589585, 0.004022363, 0.99338794]]\n",
            "1631       [[0.020483248, 0.030746374, 0.94877034]]\n",
            "1632        [[0.017591018, 0.016285585, 0.9661234]]\n",
            "1633       [[0.0007355754, 0.019908551, 0.9793559]]\n",
            "1634       [[0.0011454023, 0.11242665, 0.88642794]]\n",
            "1635       [[0.0026531536, 0.002435977, 0.9949109]]\n",
            "1636        [[0.013126229, 0.08900292, 0.89787084]]\n",
            "1637        [[0.79314226, 0.17145161, 0.035406068]]\n",
            "1638          [[0.005854558, 0.5833127, 0.4108328]]\n",
            "1639         [[0.002892361, 0.8567609, 0.14034675]]\n",
            "1640       [[0.0022450222, 0.027263328, 0.9704917]]\n",
            "1641       [[0.0015453249, 0.064756304, 0.9336983]]\n",
            "1642          [[0.0027759, 0.78412825, 0.21309583]]\n",
            "1643          [[0.02604961, 0.04483058, 0.9291199]]\n",
            "1644            [[0.1264207, 0.542851, 0.33072832]]\n",
            "1645         [[0.13580902, 0.50456864, 0.35962233]]\n",
            "1646        [[0.030611658, 0.13592423, 0.83346415]]\n",
            "1647            [[0.17661808, 0.4425789, 0.380803]]\n",
            "1648        [[0.010648602, 0.04647675, 0.94287467]]\n",
            "1649         [[0.030997619, 0.15949021, 0.8095122]]\n",
            "1650        [[0.014204494, 0.18540886, 0.80038667]]\n",
            "1651         [[0.010106101, 0.45874152, 0.5311524]]\n",
            "1652          [[0.17479296, 0.12793458, 0.6972725]]\n",
            "1653     [[0.0030136125, 0.0026472916, 0.99433905]]\n",
            "1654       [[0.002734855, 0.0019990995, 0.9952661]]\n",
            "1655          [[0.18827859, 0.07024268, 0.7414787]]\n",
            "1656      [[0.0041238065, 0.009785501, 0.98609066]]\n",
            "1657         [[0.7826334, 0.114466585, 0.10289995]]\n",
            "1658        [[0.002798109, 0.007319519, 0.9898824]]\n",
            "1659       [[0.005642077, 0.0027855982, 0.9915724]]\n",
            "1660     [[0.00069595623, 0.0012327268, 0.9980714]]\n",
            "1661       [[0.0024952497, 0.007914173, 0.9895906]]\n",
            "1662        [[0.009520187, 0.29705656, 0.69342333]]\n",
            "1663      [[0.0046844576, 0.019429132, 0.97588634]]\n",
            "1664         [[0.0076076374, 0.0534034, 0.9389889]]\n",
            "1665      [[0.0040222458, 0.010199843, 0.98577785]]\n",
            "1666       [[0.018852297, 0.0106247645, 0.9705229]]\n",
            "1667         [[0.005825334, 0.03710776, 0.9570669]]\n",
            "1668         [[0.58154243, 0.19891249, 0.21954507]]\n",
            "1669         [[0.58154243, 0.19891249, 0.21954507]]\n",
            "1670     [[0.0014234188, 0.00090522796, 0.9976714]]\n",
            "1671      [[0.0037665556, 0.0033896896, 0.9928437]]\n",
            "1672          [[0.007615497, 0.4842924, 0.5080921]]\n",
            "1673          [[0.00951162, 0.8341527, 0.15633574]]\n",
            "1674        [[0.022107806, 0.93487895, 0.04301323]]\n",
            "1675           [[0.5136932, 0.3692101, 0.11709664]]\n",
            "1676         [[0.02564465, 0.37869698, 0.59565836]]\n",
            "1677          [[0.17737992, 0.25318372, 0.5694363]]\n",
            "1678         [[0.042091448, 0.8509967, 0.10691186]]\n",
            "1679          [[0.050251022, 0.67618495, 0.273564]]\n",
            "1680      [[0.0027879688, 0.0035315077, 0.9936805]]\n",
            "1681         [[0.05997529, 0.25459152, 0.68543315]]\n",
            "1682      [[0.0037694569, 0.012578812, 0.98365176]]\n",
            "1683      [[0.0027879688, 0.0035315077, 0.9936805]]\n",
            "1684         [[0.002940655, 0.00093892, 0.9961204]]\n",
            "1685        [[0.9506574, 0.042003457, 0.007339063]]\n",
            "1686         [[0.01729712, 0.007086103, 0.9756168]]\n",
            "1687          [[0.16938221, 0.06853668, 0.7620812]]\n",
            "1688          [[0.33853635, 0.25139847, 0.4100652]]\n",
            "1689          [[0.18097937, 0.07064899, 0.7483716]]\n",
            "1690        [[0.0061481795, 0.02337527, 0.9704765]]\n",
            "1691          [[0.35957253, 0.5408192, 0.09960829]]\n",
            "1692          [[0.8715164, 0.11668474, 0.01179877]]\n",
            "1693          [[0.02116633, 0.07242283, 0.9064109]]\n",
            "1694        [[0.9525294, 0.035172906, 0.012297784]]\n",
            "1695       [[0.010024415, 0.015768278, 0.97420734]]\n",
            "1696     [[0.0025607396, 0.0032402223, 0.99419904]]\n",
            "1697         [[0.5987101, 0.045027528, 0.35626233]]\n",
            "1698         [[0.076157756, 0.6006667, 0.32317552]]\n",
            "1699     [[0.0030159433, 0.0032314304, 0.99375254]]\n",
            "1700       [[0.0046706833, 0.17134675, 0.82398254]]\n",
            "1701        [[0.002343245, 0.023347996, 0.9743087]]\n",
            "1702        [[0.006340389, 0.17071788, 0.82294184]]\n",
            "1703        [[0.0086375605, 0.5265181, 0.46484432]]\n",
            "1704         [[0.007684145, 0.34276325, 0.6495526]]\n",
            "1705      [[0.0009495026, 0.0070023513, 0.9920481]]\n",
            "1706        [[0.008099916, 0.27545783, 0.71644217]]\n",
            "1707       [[0.0057326546, 0.27453154, 0.71973574]]\n",
            "1708        [[0.009698457, 0.70210683, 0.28819472]]\n",
            "1709          [[0.30221504, 0.4075449, 0.29024002]]\n",
            "1710         [[0.33574226, 0.5477457, 0.116512075]]\n",
            "1711         [[0.67595106, 0.17636058, 0.14768836]]\n",
            "1712         [[0.3443838, 0.53706396, 0.118552215]]\n",
            "1713      [[0.0050363573, 0.034508858, 0.96045476]]\n",
            "1714        [[0.028161978, 0.36512646, 0.60671157]]\n",
            "1715          [[0.41499314, 0.24063367, 0.3443732]]\n",
            "1716        [[0.002381718, 0.024846643, 0.9727716]]\n",
            "1717          [[0.6487977, 0.20578033, 0.14542198]]\n",
            "1718      [[0.008503166, 0.0021710703, 0.98932576]]\n",
            "1719         [[0.024805013, 0.06553815, 0.9096568]]\n",
            "1720         [[0.9281751, 0.06195844, 0.009866525]]\n",
            "1721         [[0.30058867, 0.11068365, 0.58872765]]\n",
            "1722          [[0.00948685, 0.22981289, 0.7607002]]\n",
            "1723        [[0.009098523, 0.003036631, 0.9878648]]\n",
            "1724        [[0.0037977702, 0.37082258, 0.6253796]]\n",
            "1725     [[0.0077535505, 0.0045654075, 0.98768103]]\n",
            "1726         [[0.06817856, 0.15322873, 0.77859277]]\n",
            "1727      [[0.0026550603, 0.004562537, 0.99278235]]\n",
            "1728        [[0.62927413, 0.33303955, 0.037686244]]\n",
            "1729          [[0.890291, 0.03760422, 0.072104864]]\n",
            "1730       [[0.002060925, 0.0046815844, 0.9932574]]\n",
            "1731     [[0.0011040912, 0.0019965519, 0.99689937]]\n",
            "1732     [[0.0013678619, 0.0011445639, 0.99748766]]\n",
            "1733        [[0.00408693, 0.030068459, 0.96584463]]\n",
            "1734        [[0.00408693, 0.030068459, 0.96584463]]\n",
            "1735        [[0.030936508, 0.80341786, 0.16564569]]\n",
            "1736        [[0.033803746, 0.32509115, 0.64110506]]\n",
            "1737     [[0.00082861923, 0.0009132365, 0.9982582]]\n",
            "1738     [[0.00046991406, 0.0007674838, 0.9987626]]\n",
            "1739     [[0.00076261273, 0.0032924986, 0.9959449]]\n",
            "1740        [[0.0020214529, 0.5008854, 0.49709308]]\n",
            "1741         [[0.14842902, 0.41071802, 0.44085303]]\n",
            "1742         [[0.08754888, 0.79283327, 0.11961787]]\n",
            "1743          [[0.06138464, 0.4774201, 0.46119526]]\n",
            "1744      [[0.0008519473, 0.030297866, 0.96885026]]\n",
            "1745      [[0.0016021458, 0.0018940916, 0.9965037]]\n",
            "1746    [[0.0015368954, 0.00062972755, 0.99783343]]\n",
            "1747       [[0.007672284, 0.026233835, 0.96609384]]\n",
            "1748         [[0.45441574, 0.22436394, 0.32122034]]\n",
            "1749       [[0.066876754, 0.045723774, 0.88739944]]\n",
            "1750        [[0.014513873, 0.017562866, 0.9679233]]\n",
            "1751          [[0.011256035, 0.2852179, 0.7035261]]\n",
            "1752    [[0.0022977795, 0.00075567106, 0.99694663]]\n",
            "1753           [[0.14515927, 0.31905872, 0.535782]]\n",
            "1754         [[0.8127699, 0.15007995, 0.037150152]]\n",
            "1755         [[0.8164832, 0.15461569, 0.028901126]]\n",
            "1756           [[0.0118001, 0.031661894, 0.956538]]\n",
            "1757         [[0.015663449, 0.09797728, 0.8863592]]\n",
            "1758        [[0.00944511, 0.0016300406, 0.9889248]]\n",
            "1759         [[0.022471476, 0.5639427, 0.41358587]]\n",
            "1760           [[0.004233002, 0.33642694, 0.65934]]\n",
            "1761           [[0.004233002, 0.33642694, 0.65934]]\n",
            "1762        [[0.014312481, 0.62933564, 0.35635188]]\n",
            "1763         [[0.021757733, 0.6837116, 0.29453066]]\n",
            "1764         [[0.013798849, 0.03085437, 0.9553468]]\n",
            "1765         [[0.090233475, 0.26377168, 0.6459948]]\n",
            "1766       [[0.0011534167, 0.118687615, 0.8801589]]\n",
            "1767         [[0.004368898, 0.6240246, 0.37160653]]\n",
            "1768          [[0.03960571, 0.10738668, 0.8530076]]\n",
            "1769       [[0.0009302929, 0.005465664, 0.9936041]]\n",
            "1770     [[0.0010382186, 0.0053946353, 0.99356717]]\n",
            "1771         [[0.010750055, 0.8324843, 0.15676561]]\n",
            "1772        [[0.016015185, 0.14985535, 0.83412945]]\n",
            "1773       [[0.98520654, 0.009710883, 0.005082627]]\n",
            "1774        [[0.002518062, 0.061657675, 0.9358243]]\n",
            "1775         [[0.024665665, 0.22490622, 0.7504281]]\n",
            "1776         [[0.024665665, 0.22490622, 0.7504281]]\n",
            "1777       [[0.0024240387, 0.12244888, 0.87512714]]\n",
            "1778        [[0.0017776879, 0.07349027, 0.9247321]]\n",
            "1779           [[0.756834, 0.09467393, 0.14849214]]\n",
            "1780         [[0.025419386, 0.29315168, 0.6814289]]\n",
            "1781         [[0.36831453, 0.45247424, 0.17921129]]\n",
            "1782     [[0.00051778613, 0.012850057, 0.98663217]]\n",
            "1783      [[0.004547503, 0.0029656063, 0.99248683]]\n",
            "1784          [[0.04125488, 0.36881736, 0.5899278]]\n",
            "1785        [[0.016807277, 0.076662935, 0.9065298]]\n",
            "1786         [[0.002340346, 0.058585647, 0.939074]]\n",
            "1787       [[0.0027808133, 0.06904833, 0.92817086]]\n",
            "1788        [[0.005057702, 0.050409395, 0.9445329]]\n",
            "1789         [[0.03938549, 0.24245475, 0.71815974]]\n",
            "1790         [[0.02558722, 0.23328024, 0.74113256]]\n",
            "1791          [[0.3739592, 0.40959135, 0.21644947]]\n",
            "1792            [[0.03309169, 0.2759343, 0.690974]]\n",
            "1793          [[0.03763493, 0.23886919, 0.7234959]]\n",
            "1794          [[0.03763493, 0.23886919, 0.7234959]]\n",
            "1795           [[0.34778807, 0.425497, 0.22671495]]\n",
            "1796          [[0.03763493, 0.23886919, 0.7234959]]\n",
            "1797          [[0.02982504, 0.25333747, 0.7168374]]\n",
            "1798          [[0.03880874, 0.24057744, 0.7206138]]\n",
            "1799          [[0.02879793, 0.23959808, 0.7316039]]\n",
            "1800       [[0.0089874435, 0.15756355, 0.83344907]]\n",
            "1801       [[0.0008687083, 0.0024472775, 0.996684]]\n",
            "1802           [[0.1262221, 0.6117117, 0.26206616]]\n",
            "1803       [[0.0014524941, 0.04520414, 0.95334333]]\n",
            "1804         [[0.004336893, 0.70380163, 0.2918615]]\n",
            "1805       [[0.0020244657, 0.50939983, 0.48857573]]\n",
            "1806        [[0.0040999386, 0.58949494, 0.4064051]]\n",
            "1807       [[0.0031263214, 0.64734674, 0.34952694]]\n",
            "1808        [[0.0030774747, 0.22760364, 0.7693188]]\n",
            "1809     [[0.0024686242, 0.0044232146, 0.99310815]]\n",
            "1810      [[0.0023867537, 0.007421724, 0.99019146]]\n",
            "1811         [[0.010284276, 0.965837, 0.023878764]]\n",
            "1812         [[0.021580266, 0.15535754, 0.8230622]]\n",
            "1813         [[0.01586366, 0.020184854, 0.9639514]]\n",
            "1814         [[0.004624051, 0.08955748, 0.9058185]]\n",
            "1815         [[0.31928197, 0.02206697, 0.65865105]]\n",
            "1816     [[0.0020129841, 0.0010349329, 0.99695206]]\n",
            "1817       [[0.009869556, 0.029328996, 0.96080136]]\n",
            "1818             [[0.8361569, 0.054115, 0.1097281]]\n",
            "1819          [[0.09566119, 0.07700324, 0.8273356]]\n",
            "1820       [[0.0108558135, 0.015054041, 0.9740902]]\n",
            "1821       [[0.0015108915, 0.041254744, 0.9572343]]\n",
            "1822        [[0.11365516, 0.011276155, 0.87506866]]\n",
            "1823          [[0.09858399, 0.31961963, 0.5817963]]\n",
            "1824          [[0.12537828, 0.22540042, 0.6492213]]\n",
            "1825       [[0.0027187862, 0.04804687, 0.94923437]]\n",
            "1826          [[0.050782584, 0.3940287, 0.5551887]]\n",
            "1827         [[0.043664742, 0.30740383, 0.6489314]]\n",
            "1828         [[0.04791858, 0.51704186, 0.43503955]]\n",
            "1829          [[0.09858399, 0.31961963, 0.5817963]]\n",
            "1830        [[0.050074637, 0.57439554, 0.37552977]]\n",
            "1831      [[0.005039729, 0.0067709205, 0.98818934]]\n",
            "1832        [[0.0041870372, 0.06258236, 0.9332307]]\n",
            "1833          [[0.011822604, 0.271578, 0.71659935]]\n",
            "1834         [[0.012363865, 0.25225878, 0.7353773]]\n",
            "1835          [[0.14378291, 0.00845297, 0.8477641]]\n",
            "1836          [[0.14378291, 0.00845297, 0.8477641]]\n",
            "1837         [[0.08155681, 0.014618856, 0.9038243]]\n",
            "1838          [[0.031762104, 0.6725856, 0.2956523]]\n",
            "1839           [[0.27771592, 0.6539056, 0.0683785]]\n",
            "1840      [[0.0017620829, 0.0016349818, 0.9966029]]\n",
            "1841       [[0.002292738, 0.008511267, 0.98919606]]\n",
            "1842       [[0.0034338713, 0.0027770929, 0.993789]]\n",
            "1843       [[0.0034519206, 0.0033340533, 0.993214]]\n",
            "1844        [[0.004717529, 0.004541677, 0.9907409]]\n",
            "1845      [[0.002960643, 0.0042651067, 0.99277425]]\n",
            "1846        [[0.011731494, 0.006068651, 0.9821999]]\n",
            "1847          [[0.016866837, 0.12409717, 0.859036]]\n",
            "1848         [[0.014204149, 0.1711288, 0.81466705]]\n",
            "1849       [[0.0043241307, 0.10445896, 0.89121693]]\n",
            "1850       [[0.030555591, 0.021455204, 0.94798917]]\n",
            "1851          [[0.12581718, 0.10094767, 0.7732351]]\n",
            "1852       [[0.005400473, 0.009303799, 0.98529565]]\n",
            "1853        [[0.022354873, 0.024510624, 0.9531345]]\n",
            "1854        [[0.031076271, 0.24034263, 0.72858113]]\n",
            "1855          [[0.36695442, 0.5997783, 0.03326725]]\n",
            "1856         [[0.81755984, 0.042512428, 0.1399277]]\n",
            "1857         [[0.002050165, 0.002141876, 0.995808]]\n",
            "1858    [[0.00079614366, 0.0049411105, 0.99426275]]\n",
            "1859    [[0.00048830773, 0.0020590536, 0.99745256]]\n",
            "1860         [[0.002050165, 0.002141876, 0.995808]]\n",
            "1861          [[0.00825794, 0.06784687, 0.9238952]]\n",
            "1862         [[0.003788702, 0.18753473, 0.8086766]]\n",
            "1863     [[0.00052099285, 0.0014701004, 0.9980089]]\n",
            "1864    [[0.00048830773, 0.0020590536, 0.99745256]]\n",
            "1865        [[0.016803132, 0.18684119, 0.79635566]]\n",
            "1866          [[0.004570084, 0.52130693, 0.474123]]\n",
            "1867       [[0.0017041342, 0.07333721, 0.92495865]]\n",
            "1868         [[0.0074609234, 0.2572547, 0.7352844]]\n",
            "1869         [[0.009912283, 0.26708004, 0.7230077]]\n",
            "1870         [[0.005889802, 0.7911081, 0.20300213]]\n",
            "1871       [[0.0050964435, 0.018918952, 0.9759846]]\n",
            "1872        [[0.030677386, 0.14013946, 0.82918316]]\n",
            "1873        [[0.011699063, 0.023817824, 0.9644831]]\n",
            "1874     [[0.0011437066, 0.0030915898, 0.99576473]]\n",
            "1875           [[0.003949301, 0.04260056, 0.95345]]\n",
            "1876          [[0.029621039, 0.6795851, 0.2907939]]\n",
            "1877      [[0.0005252499, 0.029634297, 0.96984047]]\n",
            "1878          [[0.008966699, 0.0374261, 0.9536072]]\n",
            "1879       [[0.0034326361, 0.008012485, 0.9885549]]\n",
            "1880          [[0.008966699, 0.0374261, 0.9536072]]\n",
            "1881      [[0.0016438841, 0.018893592, 0.97946256]]\n",
            "1882       [[0.006862385, 0.023024293, 0.97011334]]\n",
            "1883     [[0.0027560107, 0.0025769488, 0.99466705]]\n",
            "1884        [[0.034589875, 0.14718376, 0.81822634]]\n",
            "1885       [[0.044946447, 0.024915844, 0.93013775]]\n",
            "1886           [[0.5071848, 0.3998308, 0.09298436]]\n",
            "1887          [[0.4464749, 0.33766952, 0.21585561]]\n",
            "1888          [[0.0504882, 0.003110886, 0.9464009]]\n",
            "1889        [[0.9675108, 0.022492843, 0.009996285]]\n",
            "1890        [[0.76583827, 0.19310443, 0.041057326]]\n",
            "1891     [[0.0025865678, 0.00085717626, 0.9965563]]\n",
            "1892         [[0.018612217, 0.09645641, 0.8849314]]\n",
            "1893       [[0.050088454, 0.0091920905, 0.9407195]]\n",
            "1894      [[0.0031702123, 0.0025350342, 0.9942948]]\n",
            "1895        [[0.023033613, 0.13583653, 0.84112984]]\n",
            "1896     [[0.0015036898, 0.0033237129, 0.99517256]]\n",
            "1897         [[0.034037128, 0.6764299, 0.28953287]]\n",
            "1898          [[0.4501108, 0.5031737, 0.046715457]]\n",
            "1899          [[0.07047018, 0.8813565, 0.04817335]]\n",
            "1900       [[0.053386446, 0.91697234, 0.029641237]]\n",
            "1901     [[0.0043896567, 0.0014930819, 0.99411726]]\n",
            "1902       [[0.01140637, 0.0067474507, 0.98184615]]\n",
            "1903        [[0.012750506, 0.017823853, 0.9694257]]\n",
            "1904         [[0.38822186, 0.51944214, 0.09233597]]\n",
            "1905        [[0.59415025, 0.34903732, 0.056812394]]\n",
            "1906        [[0.020595599, 0.9683995, 0.011004886]]\n",
            "1907       [[0.0036145197, 0.014373844, 0.9820117]]\n",
            "1908         [[0.0035664414, 0.00782555, 0.988608]]\n",
            "1909           [[0.19868721, 0.1730411, 0.6282717]]\n",
            "1910      [[0.0027077363, 0.0010752876, 0.9962171]]\n",
            "1911      [[0.009326024, 0.0013829252, 0.98929113]]\n",
            "1912      [[0.0025020025, 0.011301985, 0.98619604]]\n",
            "1913      [[0.0025333727, 0.0052917725, 0.9921748]]\n",
            "1914        [[0.0019981333, 0.00196519, 0.9960367]]\n",
            "1915     [[0.0015115504, 0.0011343361, 0.99735415]]\n",
            "1916     [[0.0031083603, 0.0064998874, 0.99039173]]\n",
            "1917        [[0.0029847936, 0.46148646, 0.5355287]]\n",
            "1918       [[0.0028588658, 0.011229195, 0.9859119]]\n",
            "1919     [[0.0020759378, 0.0012732546, 0.99665076]]\n",
            "1920       [[0.0021269163, 0.014533797, 0.9833393]]\n",
            "1921        [[0.0076940255, 0.048757926, 0.943548]]\n",
            "1922          [[0.02567538, 0.07609602, 0.8982286]]\n",
            "1923        [[0.0021317687, 0.05957273, 0.9382954]]\n",
            "1924      [[0.0011071361, 0.014864702, 0.98402816]]\n",
            "1925      [[0.0016957951, 0.0011457314, 0.9971585]]\n",
            "1926      [[0.0012053932, 0.0021377322, 0.9966569]]\n",
            "1927       [[0.0019214528, 0.004331345, 0.9937471]]\n",
            "1928        [[0.0029520355, 0.19543059, 0.8016173]]\n",
            "1929        [[0.0064925794, 0.09510829, 0.8983992]]\n",
            "1930        [[0.034955155, 0.053759776, 0.9112851]]\n",
            "1931        [[0.013566975, 0.14223893, 0.84419405]]\n",
            "1932        [[0.0040893094, 0.18813087, 0.8077798]]\n",
            "1933         [[0.63644934, 0.23479022, 0.12876044]]\n",
            "1934      [[0.92756814, 0.060174447, 0.0122573925]]\n",
            "1935         [[0.4748653, 0.48255613, 0.042578604]]\n",
            "1936           [[0.58681613, 0.3116792, 0.1015046]]\n",
            "1937       [[0.0071163136, 0.00234919, 0.99053454]]\n",
            "1938         [[0.037872825, 0.6082829, 0.35384423]]\n",
            "1939     [[0.0017394945, 0.00052858266, 0.9977319]]\n",
            "1940        [[0.014048796, 0.52783495, 0.45811623]]\n",
            "1941         [[0.20034286, 0.35936144, 0.44029567]]\n",
            "1942       [[0.002904171, 0.019580761, 0.97751504]]\n",
            "1943          [[0.016939735, 0.290914, 0.69214624]]\n",
            "1944        [[0.010066961, 0.47569856, 0.51423454]]\n",
            "1945          [[0.1386349, 0.06978058, 0.79158455]]\n",
            "1946     [[0.0063170497, 0.0026756772, 0.99100727]]\n",
            "1947          [[0.013716561, 0.20521648, 0.781067]]\n",
            "1948         [[0.025758103, 0.19018571, 0.7840561]]\n",
            "1949          [[0.010618782, 0.6358914, 0.3534898]]\n",
            "1950       [[0.0039294832, 0.010763329, 0.9853072]]\n",
            "1951        [[0.003764379, 0.18587781, 0.81035775]]\n",
            "1952         [[0.027135868, 0.32928503, 0.6435791]]\n",
            "1953         [[0.014645932, 0.00696853, 0.9783855]]\n",
            "1954           [[0.015652413, 0.0589906, 0.925357]]\n",
            "1955       [[0.0012931888, 0.009807434, 0.9888994]]\n",
            "1956         [[0.007388864, 0.15075241, 0.8418587]]\n",
            "1957       [[0.023250025, 0.064731695, 0.91201836]]\n",
            "1958           [[0.026472768, 0.423346, 0.5501812]]\n",
            "1959         [[0.7122587, 0.27442253, 0.013318772]]\n",
            "1960           [[0.1538933, 0.840486, 0.005620687]]\n",
            "1961         [[0.003288382, 0.8489204, 0.14779116]]\n",
            "1962        [[0.006701356, 0.33503574, 0.65826297]]\n",
            "1963           [[0.009583216, 0.3577058, 0.632711]]\n",
            "1964        [[0.05914152, 0.032325428, 0.90853304]]\n",
            "1965        [[0.05914152, 0.032325428, 0.90853304]]\n",
            "1966       [[0.0034415268, 0.05286884, 0.94368964]]\n",
            "1967         [[0.013107294, 0.6641124, 0.32278028]]\n",
            "1968        [[0.08818113, 0.047449395, 0.86436945]]\n",
            "1969          [[0.08518862, 0.7384524, 0.17635901]]\n",
            "1970         [[0.013344623, 0.7997544, 0.18690097]]\n",
            "1971      [[0.0027694462, 0.0059817866, 0.9912487]]\n",
            "1972      [[0.0021533319, 0.002267595, 0.99557906]]\n",
            "1973        [[0.00868622, 0.037124824, 0.95418894]]\n",
            "1974      [[0.0023285714, 0.0051680147, 0.9925034]]\n",
            "1975     [[0.0025715085, 0.0031779113, 0.99425066]]\n",
            "1976        [[0.0044611753, 0.0098756, 0.98566324]]\n",
            "1977          [[0.09731936, 0.31049982, 0.5921808]]\n",
            "1978         [[0.020147393, 0.08535989, 0.8944927]]\n",
            "1979        [[0.010298935, 0.73313844, 0.25656262]]\n",
            "1980       [[0.0031133383, 0.008631094, 0.9882556]]\n",
            "1981        [[0.019996222, 0.59882313, 0.38118058]]\n",
            "1982       [[0.0055711917, 0.123807065, 0.8706217]]\n",
            "1983      [[0.0012952223, 0.0047687027, 0.9939361]]\n",
            "1984      [[0.0037190898, 0.0022254765, 0.9940554]]\n",
            "1985        [[0.03525262, 0.015113826, 0.94963354]]\n",
            "1986        [[0.012798803, 0.04098298, 0.94621813]]\n",
            "1987      [[0.0059453077, 0.016256832, 0.97779787]]\n",
            "1988         [[0.011425176, 0.6688425, 0.31973234]]\n",
            "1989        [[0.012798803, 0.04098298, 0.94621813]]\n",
            "1990        [[0.015938504, 0.77212095, 0.21194054]]\n",
            "1991         [[0.052467965, 0.6925663, 0.25496572]]\n",
            "1992         [[0.007768107, 0.26913455, 0.7230974]]\n",
            "1993       [[0.004055261, 0.0017751954, 0.9941695]]\n",
            "1994          [[0.005500333, 0.2224173, 0.7720823]]\n",
            "1995       [[0.0050667636, 0.12237218, 0.87256104]]\n",
            "1996         [[0.003741653, 0.53456223, 0.4616961]]\n",
            "1997          [[0.040500104, 0.206887, 0.75261295]]\n",
            "1998          [[0.018475316, 0.4943492, 0.4871755]]\n",
            "1999         [[0.002999081, 0.114205025, 0.882796]]\n",
            "2000        [[0.0055434024, 0.121120535, 0.873336]]\n",
            "2001        [[0.0059245867, 0.07838853, 0.9156869]]\n",
            "2002         [[0.0061776885, 0.901245, 0.09257738]]\n",
            "2003       [[0.0028752536, 0.9522555, 0.044869218]]\n",
            "2004         [[0.0039034723, 0.7306569, 0.2654396]]\n",
            "2005        [[0.005237194, 0.92897725, 0.06578555]]\n",
            "2006        [[0.0038406956, 0.5960807, 0.40007856]]\n",
            "2007          [[0.015805831, 0.2141395, 0.7700547]]\n",
            "2008          [[0.011464824, 0.728247, 0.26028815]]\n",
            "2009         [[0.016469074, 0.5383052, 0.44522575]]\n",
            "2010          [[0.6711241, 0.24826825, 0.08060773]]\n",
            "2011          [[0.01923051, 0.21274786, 0.7680216]]\n",
            "2012       [[0.005143842, 0.014020007, 0.98083615]]\n",
            "2013        [[0.018314207, 0.20825489, 0.77343094]]\n",
            "2014     [[0.0069898404, 0.0041799247, 0.98883027]]\n",
            "2015       [[0.068584085, 0.073194586, 0.85822135]]\n",
            "2016       [[0.007879241, 0.007657268, 0.98446345]]\n",
            "2017        [[0.008647616, 0.45734674, 0.53400564]]\n",
            "2018         [[0.039948512, 0.09333627, 0.8667153]]\n",
            "2019        [[0.010242231, 0.010564212, 0.9791935]]\n",
            "2020        [[0.001929259, 0.038408913, 0.9596619]]\n",
            "2021       [[0.0020076558, 0.022025956, 0.9759664]]\n",
            "2022          [[0.27573967, 0.2571339, 0.46712643]]\n",
            "2023       [[0.008410904, 0.003318201, 0.98827094]]\n",
            "2024        [[0.025310185, 0.11771473, 0.85697514]]\n",
            "2025          [[0.007233024, 0.35137293, 0.641394]]\n",
            "2026        [[0.0033492744, 0.01163566, 0.9850151]]\n",
            "2027       [[0.0117341755, 0.045520697, 0.9427452]]\n",
            "2028      [[0.0024103671, 0.021289466, 0.97630024]]\n",
            "2029         [[0.004192514, 0.18477625, 0.8110312]]\n",
            "2030      [[0.0015357791, 0.008917952, 0.98954636]]\n",
            "2031         [[0.02320976, 0.035313703, 0.9414766]]\n",
            "2032       [[0.0021212567, 0.14396551, 0.85391325]]\n",
            "2033         [[0.0024256087, 0.17322637, 0.824348]]\n",
            "2034       [[0.0018062388, 0.038557637, 0.9596362]]\n",
            "2035          [[0.00219862, 0.7767585, 0.22104292]]\n",
            "2036         [[0.002908727, 0.8225532, 0.17453805]]\n",
            "2037        [[0.0022842274, 0.8563366, 0.14137916]]\n",
            "2038        [[0.0011165028, 0.88068426, 0.1181993]]\n",
            "2039         [[0.002836814, 0.8233749, 0.17378822]]\n",
            "2040        [[0.14747508, 0.102118626, 0.75040627]]\n",
            "2041           [[0.13172174, 0.0758281, 0.7924501]]\n",
            "2042        [[0.14747508, 0.102118626, 0.75040627]]\n",
            "2043       [[0.009346028, 0.010719229, 0.97993463]]\n",
            "2044         [[0.00475821, 0.76399606, 0.23124574]]\n",
            "2045         [[0.004715321, 0.8928493, 0.10243537]]\n",
            "2046       [[0.0036885152, 0.90758634, 0.08872522]]\n",
            "2047        [[0.003738811, 0.81215626, 0.18410484]]\n",
            "2048        [[0.85183096, 0.10114722, 0.047021892]]\n",
            "2049           [[0.5031942, 0.3147555, 0.18205021]]\n",
            "2050        [[0.0028164997, 0.00725315, 0.9899303]]\n",
            "2051        [[0.008527182, 0.17088276, 0.82059014]]\n",
            "2052         [[0.013171052, 0.5639951, 0.42283383]]\n",
            "2053        [[0.008527182, 0.17088276, 0.82059014]]\n",
            "2054          [[0.010718157, 0.6941121, 0.2951697]]\n",
            "2055     [[0.0010050318, 0.0009518811, 0.99804306]]\n",
            "2056         [[0.002355833, 0.10195015, 0.8956939]]\n",
            "2057      [[0.0025128257, 0.036839362, 0.96064776]]\n",
            "2058       [[0.0044256477, 0.116170034, 0.8794043]]\n",
            "2059        [[0.0022407668, 0.14153853, 0.8562208]]\n",
            "2060         [[0.00807534, 0.015156047, 0.9767686]]\n",
            "2061          [[0.6425079, 0.07397516, 0.28351694]]\n",
            "2062         [[0.64074844, 0.08093195, 0.27831963]]\n",
            "2063       [[0.005255849, 0.0020719836, 0.9926722]]\n",
            "2064      [[0.0043065622, 0.042712446, 0.95298105]]\n",
            "2065       [[0.004514085, 0.008376447, 0.98710954]]\n",
            "2066          [[0.66827166, 0.22217289, 0.1095555]]\n",
            "2067         [[0.6949266, 0.26518464, 0.039888725]]\n",
            "2068      [[0.003423656, 0.0028191688, 0.99375725]]\n",
            "2069         [[0.008302828, 0.13277844, 0.8589188]]\n",
            "2070         [[0.009407118, 0.06778305, 0.9228099]]\n",
            "2071        [[0.9791701, 0.01663935, 0.0041905525]]\n",
            "2072      [[0.0028047778, 0.018316919, 0.97887826]]\n",
            "2073       [[0.004347884, 0.042838104, 0.95281404]]\n",
            "2074         [[0.43146688, 0.09694674, 0.47158644]]\n",
            "2075         [[0.09981004, 0.32762295, 0.57256705]]\n",
            "2076           [[0.2257215, 0.29076755, 0.4835109]]\n",
            "2077          [[0.3305049, 0.56766784, 0.10182724]]\n",
            "2078         [[0.02070641, 0.18047813, 0.79881555]]\n",
            "2079      [[0.0018898274, 0.005582315, 0.99252796]]\n",
            "2080         [[0.00065357, 0.004244585, 0.9951018]]\n",
            "2081      [[0.00081348914, 0.009965413, 0.9892211]]\n",
            "2082       [[0.0009858297, 0.014174811, 0.9848394]]\n",
            "2083        [[0.0016996533, 0.1657241, 0.83257616]]\n",
            "2084         [[0.0014622823, 0.0273815, 0.9711562]]\n",
            "2085      [[0.0016426649, 0.015443349, 0.98291403]]\n",
            "2086         [[0.0038891518, 0.11674787, 0.879363]]\n",
            "2087      [[0.0013101576, 0.0011214407, 0.9975684]]\n",
            "2088         [[0.8952397, 0.03798565, 0.066774614]]\n",
            "2089         [[0.008918261, 0.34958827, 0.6414935]]\n",
            "2090        [[0.0027688679, 0.00962004, 0.9876111]]\n",
            "2091        [[0.0048202574, 0.02776247, 0.9674173]]\n",
            "2092       [[0.0039673545, 0.15188697, 0.84414566]]\n",
            "2093           [[0.03197748, 0.1323752, 0.8356474]]\n",
            "2094       [[0.004228194, 0.004206536, 0.99156535]]\n",
            "2095         [[0.018732065, 0.09387615, 0.8873918]]\n",
            "2096         [[0.005065303, 0.8820804, 0.11285431]]\n",
            "2097        [[0.016361486, 0.89594793, 0.08769058]]\n",
            "2098        [[0.024521576, 0.23783141, 0.73764706]]\n",
            "2099        [[0.0011140687, 0.011591919, 0.987294]]\n",
            "2100      [[0.0006606239, 0.0038126945, 0.9955266]]\n",
            "2101      [[0.0004490174, 0.0019585527, 0.9975924]]\n",
            "2102      [[0.00051955506, 0.0040054354, 0.995475]]\n",
            "2103         [[0.0046918667, 0.1973135, 0.7979947]]\n",
            "2104      [[0.0053126514, 0.0014267048, 0.9932607]]\n",
            "2105      [[0.0009354775, 0.0047100554, 0.9943545]]\n",
            "2106        [[0.002644921, 0.03429637, 0.96305877]]\n",
            "2107        [[0.9621839, 0.011267643, 0.026548462]]\n",
            "2108       [[0.92905754, 0.0037215515, 0.06722104]]\n",
            "2109          [[0.006090595, 0.9495717, 0.0443376]]\n",
            "2110        [[0.109212585, 0.044756886, 0.8460305]]\n",
            "2111       [[0.0042112865, 0.61201966, 0.38376904]]\n",
            "2112        [[0.0021543233, 0.41747442, 0.5803713]]\n",
            "2113         [[0.005649632, 0.881183, 0.113167286]]\n",
            "2114        [[0.026052281, 0.13884516, 0.83510256]]\n",
            "2115       [[0.0023214216, 0.22563718, 0.77204144]]\n",
            "2116       [[0.0016836026, 0.05296154, 0.94535494]]\n",
            "2117       [[0.020360207, 0.015650367, 0.96398944]]\n",
            "2118         [[0.001157622, 0.10812914, 0.8907132]]\n",
            "2119        [[0.0019569837, 0.11170916, 0.8863338]]\n",
            "2120       [[0.0005578782, 0.005760907, 0.9936812]]\n",
            "2121       [[0.0006334317, 0.012903456, 0.9864631]]\n",
            "2122          [[0.011570581, 0.2907535, 0.6976759]]\n",
            "2123        [[0.007208717, 0.29844996, 0.69434136]]\n",
            "2124       [[0.004266584, 0.018764447, 0.97696906]]\n",
            "2125         [[0.22489943, 0.50154257, 0.27355802]]\n",
            "2126         [[0.001677579, 0.06657625, 0.9317462]]\n",
            "2127      [[0.0014537952, 0.006177113, 0.99236906]]\n",
            "2128       [[0.0035049866, 0.037835665, 0.9586594]]\n",
            "2129     [[0.0065793055, 0.0029054417, 0.99051523]]\n",
            "2130         [[0.75433433, 0.21921057, 0.02645507]]\n",
            "2131         [[0.75433433, 0.21921057, 0.02645507]]\n",
            "2132        [[0.0049431836, 0.04174642, 0.9533104]]\n",
            "2133      [[0.0033833447, 0.0060891784, 0.9905275]]\n",
            "2134     [[0.0011979124, 0.0071018273, 0.99170023]]\n",
            "2135          [[0.00886576, 0.03712537, 0.9540088]]\n",
            "2136          [[0.059471533, 0.32242143, 0.618107]]\n",
            "2137        [[0.0019080661, 0.17439903, 0.8236929]]\n",
            "2138       [[0.034836598, 0.0021455232, 0.9630179]]\n",
            "2139       [[0.034836598, 0.0021455232, 0.9630179]]\n",
            "2140        [[0.046803035, 0.12950556, 0.82369137]]\n",
            "2141         [[0.010497314, 0.37096834, 0.6185344]]\n",
            "2142          [[0.006347982, 0.5449056, 0.4487464]]\n",
            "2143      [[0.0020650097, 0.033664543, 0.96427053]]\n",
            "2144       [[0.001004627, 0.0014094623, 0.9975859]]\n",
            "2145         [[0.010238872, 0.009973019, 0.979788]]\n",
            "2146         [[0.33968282, 0.057745863, 0.6025713]]\n",
            "2147           [[0.6573605, 0.07611305, 0.2665265]]\n",
            "2148       [[0.0071704653, 0.027183933, 0.9656456]]\n",
            "2149         [[0.74282414, 0.14543785, 0.11173809]]\n",
            "2150         [[0.33968282, 0.057745863, 0.6025713]]\n",
            "2151        [[0.02799111, 0.0050556683, 0.9669533]]\n",
            "2152          [[0.54898185, 0.2966777, 0.15434049]]\n",
            "2153     [[0.0027835693, 0.0047146636, 0.99250174]]\n",
            "2154        [[0.0069207465, 0.45879215, 0.5342871]]\n",
            "2155        [[0.20481879, 0.046437886, 0.74874336]]\n",
            "2156        [[0.002665372, 0.020195479, 0.9771392]]\n",
            "2157       [[0.0062448005, 0.015813334, 0.9779418]]\n",
            "2158         [[0.00462857, 0.015541508, 0.9798299]]\n",
            "2159        [[0.003218579, 0.05436856, 0.94241285]]\n",
            "2160       [[0.0022987947, 0.012477941, 0.9852233]]\n",
            "2161         [[0.41741148, 0.12625858, 0.45632997]]\n",
            "2162         [[0.5182932, 0.110689506, 0.37101728]]\n",
            "2163          [[0.4614618, 0.118834764, 0.4197034]]\n",
            "2164           [[0.1348774, 0.77579415, 0.0893284]]\n",
            "2165         [[0.117439516, 0.7541586, 0.12840188]]\n",
            "2166      [[0.0030741151, 0.0024576543, 0.9944682]]\n",
            "2167        [[0.003539432, 0.018353814, 0.9781068]]\n",
            "2168        [[0.0038744893, 0.011493513, 0.984632]]\n",
            "2169       [[0.004099919, 0.0020780428, 0.9938221]]\n",
            "2170          [[0.014382932, 0.670067, 0.31555006]]\n",
            "2171      [[0.97971946, 0.017679952, 0.0026005674]]\n",
            "2172          [[0.027870974, 0.32928202, 0.642847]]\n",
            "2173         [[0.018116511, 0.6577566, 0.32412684]]\n",
            "2174        [[0.014482487, 0.72629213, 0.25922537]]\n",
            "2175        [[0.057314705, 0.00843873, 0.93424666]]\n",
            "2176        [[0.009023957, 0.024381768, 0.9665942]]\n",
            "2177        [[0.057314705, 0.00843873, 0.93424666]]\n",
            "2178        [[0.057314705, 0.00843873, 0.93424666]]\n",
            "2179       [[0.043588437, 0.029245794, 0.92716575]]\n",
            "2180       [[0.013353535, 0.0073092305, 0.9793372]]\n",
            "2181      [[0.0020444903, 0.004234154, 0.99372137]]\n",
            "2182        [[0.002504782, 0.015274047, 0.9822212]]\n",
            "2183        [[0.045249876, 0.74081576, 0.21393439]]\n",
            "2184         [[0.021398583, 0.6275058, 0.35109565]]\n",
            "2185         [[0.0128259165, 0.5664149, 0.4207592]]\n",
            "2186       [[0.0014040526, 0.009518705, 0.9890773]]\n",
            "2187          [[0.1666254, 0.032136448, 0.8012382]]\n",
            "2188          [[0.1666254, 0.032136448, 0.8012382]]\n",
            "2189     [[0.0010974306, 0.0014862875, 0.99741626]]\n",
            "2190       [[0.002464931, 0.002989076, 0.99454594]]\n",
            "2191     [[0.0010974306, 0.0014862875, 0.99741626]]\n",
            "2192        [[0.003742113, 0.01171085, 0.98454696]]\n",
            "2193        [[0.048294738, 0.12962057, 0.82208467]]\n",
            "2194         [[0.00477156, 0.19194733, 0.80328107]]\n",
            "2195          [[0.03072976, 0.62830293, 0.3409673]]\n",
            "2196        [[0.0025556725, 0.09999416, 0.8974502]]\n",
            "2197         [[0.023884928, 0.07009932, 0.9060157]]\n",
            "2198       [[0.0145906815, 0.39221042, 0.59319896]]\n",
            "2199        [[0.011854683, 0.40786535, 0.58027995]]\n",
            "2200         [[0.008342696, 0.43193483, 0.5597225]]\n",
            "2201         [[0.009751567, 0.24677029, 0.7434782]]\n",
            "2202         [[0.015637154, 0.39867935, 0.5856835]]\n",
            "2203     [[0.0018022764, 0.0012136927, 0.99698406]]\n",
            "2204      [[0.0012663517, 0.004779248, 0.99395436]]\n",
            "2205        [[0.001371682, 0.008013096, 0.9906151]]\n",
            "2206        [[0.027854715, 0.46574304, 0.50640225]]\n",
            "2207     [[0.0046916744, 0.0026953302, 0.99261296]]\n",
            "2208          [[0.21882002, 0.11027411, 0.6709058]]\n",
            "2209          [[0.001854899, 0.436376, 0.56176907]]\n",
            "2210          [[0.21882002, 0.11027411, 0.6709058]]\n",
            "2211    [[0.00068753073, 0.0024931214, 0.99681926]]\n",
            "2212       [[0.0027052166, 0.080781065, 0.9165137]]\n",
            "2213         [[0.002627857, 0.7269169, 0.27045518]]\n",
            "2214         [[0.000614199, 0.9276646, 0.07172125]]\n",
            "2215        [[0.015728781, 0.89366335, 0.09060784]]\n",
            "2216         [[0.0044184686, 0.5143553, 0.4812263]]\n",
            "2217        [[0.87080616, 0.09425697, 0.034936856]]\n",
            "2218         [[0.9318555, 0.021446554, 0.04669797]]\n",
            "2219       [[0.006979754, 0.0017135178, 0.9913067]]\n",
            "2220          [[0.4492498, 0.061484773, 0.4892654]]\n",
            "2221     [[0.00045641954, 0.0030326678, 0.9965109]]\n",
            "2222          [[0.006533728, 0.06387227, 0.929594]]\n",
            "2223        [[0.60781926, 0.034296736, 0.35788396]]\n",
            "2224     [[0.00045641954, 0.0030326678, 0.9965109]]\n",
            "2225      [[0.0014770237, 0.0057833353, 0.9927396]]\n",
            "2226      [[0.0014770237, 0.0057833353, 0.9927396]]\n",
            "2227          [[0.00186293, 0.07526297, 0.9228741]]\n",
            "2228    [[0.00090713246, 0.0056176325, 0.99347514]]\n",
            "2229       [[0.001211992, 0.013349064, 0.98543894]]\n",
            "2230      [[0.0014770237, 0.0057833353, 0.9927396]]\n",
            "2231        [[0.008282711, 0.005068559, 0.9866486]]\n",
            "2232          [[0.008005229, 0.009854725, 0.98214]]\n",
            "2233       [[0.007905591, 0.027076948, 0.96501744]]\n",
            "2234     [[0.0030671735, 0.0035314264, 0.99340135]]\n",
            "2235       [[0.0057997797, 0.04090827, 0.95329195]]\n",
            "2236     [[0.0035895677, 0.0010264145, 0.99538404]]\n",
            "2237      [[0.0014042221, 0.0021065068, 0.9964893]]\n",
            "2238         [[0.056764577, 0.29313067, 0.6501047]]\n",
            "2239         [[0.06043216, 0.15100339, 0.78856444]]\n",
            "2240        [[0.048668683, 0.23001668, 0.72131467]]\n",
            "2241        [[0.8989616, 0.056711465, 0.044326935]]\n",
            "2242          [[0.33057413, 0.23260151, 0.4368244]]\n",
            "2243       [[0.0126286475, 0.53606474, 0.45130664]]\n",
            "2244        [[0.0054716873, 0.12069953, 0.8738288]]\n",
            "2245        [[0.005224148, 0.14872253, 0.84605336]]\n",
            "2246      [[0.0017643331, 0.003560596, 0.99467504]]\n",
            "2247     [[0.00070864573, 0.009213028, 0.99007833]]\n",
            "2248      [[0.0010348381, 0.0034201955, 0.9955449]]\n",
            "2249     [[0.00057126343, 0.0073518744, 0.9920769]]\n",
            "2250      [[0.0012934685, 0.010487987, 0.98821855]]\n",
            "2251         [[0.6899368, 0.013325121, 0.29673797]]\n",
            "2252         [[0.13737762, 0.7563325, 0.106289916]]\n",
            "2253         [[0.09592786, 0.21362688, 0.69044524]]\n",
            "2254         [[0.12942606, 0.36807773, 0.50249624]]\n",
            "2255        [[0.010747532, 0.011538102, 0.9777143]]\n",
            "2256      [[0.0075312452, 0.015423204, 0.97704554]]\n",
            "2257         [[0.6899368, 0.013325121, 0.29673797]]\n",
            "2258         [[0.7097774, 0.045189273, 0.24503334]]\n",
            "2259         [[0.04417781, 0.054005325, 0.9018169]]\n",
            "2260        [[0.005405359, 0.004514146, 0.9900804]]\n",
            "2261        [[0.056379545, 0.13708167, 0.80653876]]\n",
            "2262        [[0.003249051, 0.038874224, 0.9578767]]\n",
            "2263     [[0.0014209333, 0.0019708064, 0.99660826]]\n",
            "2264          [[0.03279401, 0.46618494, 0.5010211]]\n",
            "2265        [[0.8634381, 0.118589416, 0.017972518]]\n",
            "2266         [[0.7068009, 0.047891792, 0.24530737]]\n",
            "2267       [[0.036670752, 0.028877132, 0.93445206]]\n",
            "2268      [[0.001616802, 0.0066883885, 0.99169487]]\n",
            "2269      [[0.0015715141, 0.010647965, 0.98778045]]\n",
            "2270          [[0.00427283, 0.6568662, 0.33886093]]\n",
            "2271        [[0.0060274987, 0.7432321, 0.25074047]]\n",
            "2272        [[0.0009264221, 0.01258622, 0.9864873]]\n",
            "2273     [[0.00068893743, 0.0070656464, 0.9922455]]\n",
            "2274      [[0.0019706972, 0.021752682, 0.97627664]]\n",
            "2275           [[0.28438708, 0.342015, 0.37359792]]\n",
            "2276         [[0.0026340857, 0.849303, 0.14806296]]\n",
            "2277     [[0.0034510163, 0.00086926005, 0.9956797]]\n",
            "2278     [[0.0026107074, 0.00085151335, 0.9965378]]\n",
            "2279        [[0.063231386, 0.19543608, 0.74133253]]\n",
            "2280     [[0.0011034821, 0.0041131787, 0.99478334]]\n",
            "2281      [[0.00070649816, 0.003823588, 0.9954698]]\n",
            "2282      [[0.0011113059, 0.0047699246, 0.9941188]]\n",
            "2283       [[0.0022465992, 0.007944107, 0.9898093]]\n",
            "2284     [[0.0008141184, 0.0014487095, 0.99773717]]\n",
            "2285         [[0.0053322595, 0.00338568, 0.991282]]\n",
            "2286       [[0.001105132, 0.0028016819, 0.9960932]]\n",
            "2287      [[0.0018018843, 0.026132517, 0.97206557]]\n",
            "2288        [[0.0043709725, 0.1305296, 0.86509943]]\n",
            "2289        [[0.004149225, 0.004003314, 0.9918475]]\n",
            "2290        [[0.0033708964, 0.33529818, 0.6613309]]\n",
            "2291        [[0.0020304455, 0.02680206, 0.9711675]]\n",
            "2292         [[0.014080406, 0.21648905, 0.7694305]]\n",
            "2293       [[0.0063533196, 0.11182189, 0.88182473]]\n",
            "2294       [[0.0016014386, 0.054624062, 0.9437746]]\n",
            "2295         [[0.0019583588, 0.0682479, 0.9297938]]\n",
            "2296       [[0.0026666624, 0.06155588, 0.93577737]]\n",
            "2297       [[0.0035634828, 0.31956363, 0.67687285]]\n",
            "2298      [[0.0010830287, 0.0022775964, 0.9966394]]\n",
            "2299      [[0.011093957, 0.0038222661, 0.98508376]]\n",
            "2300        [[0.0042854957, 0.0272694, 0.96844506]]\n",
            "2301         [[0.096126586, 0.23557307, 0.6683003]]\n",
            "2302         [[0.096126586, 0.23557307, 0.6683003]]\n",
            "2303     [[0.0017943671, 0.0019713233, 0.99623436]]\n",
            "2304         [[0.01370431, 0.039241232, 0.9470545]]\n",
            "2305     [[0.0017943671, 0.0019713233, 0.99623436]]\n",
            "2306         [[0.10701061, 0.23258287, 0.66040653]]\n",
            "2307       [[0.0017453635, 0.001191607, 0.9970631]]\n",
            "2308       [[0.0043262765, 0.005006895, 0.9906668]]\n",
            "2309     [[0.00086089276, 0.0022809876, 0.9968581]]\n",
            "2310       [[0.0024342206, 0.012174424, 0.9853914]]\n",
            "2311      [[0.0045856186, 0.043884322, 0.95153016]]\n",
            "2312         [[0.006696425, 0.00287926, 0.9904242]]\n",
            "2313         [[0.037217833, 0.30634084, 0.6564414]]\n",
            "2314         [[0.9408627, 0.025948351, 0.03318894]]\n",
            "2315        [[0.0017276263, 0.7572835, 0.24098884]]\n",
            "2316        [[0.0025882062, 0.7521382, 0.24527363]]\n",
            "2317        [[0.0021221538, 0.7568487, 0.24102916]]\n",
            "2318          [[0.012684563, 0.6039372, 0.3833782]]\n",
            "2319        [[0.0081391055, 0.13594334, 0.8559175]]\n",
            "2320        [[0.0035336376, 0.20214164, 0.7943247]]\n",
            "2321        [[0.010589041, 0.9067982, 0.082612745]]\n",
            "2322        [[0.010589041, 0.9067982, 0.082612745]]\n",
            "2323       [[0.004705714, 0.006304711, 0.98898953]]\n",
            "2324       [[0.0027086432, 0.003362576, 0.9939287]]\n",
            "2325       [[0.0021877058, 0.044022337, 0.9537899]]\n",
            "2326        [[0.016788656, 0.008627686, 0.9745837]]\n",
            "2327    [[0.00090514694, 0.0061555007, 0.99293935]]\n",
            "2328        [[0.0023406264, 0.009705394, 0.987954]]\n",
            "2329       [[0.0051144455, 0.048959337, 0.9459262]]\n",
            "2330     [[0.0009710577, 0.0083895065, 0.99063945]]\n",
            "2331        [[0.0023406264, 0.009705394, 0.987954]]\n",
            "2332      [[0.0005679889, 0.0013374295, 0.9980945]]\n",
            "2333      [[0.0010218871, 0.0061068526, 0.9928712]]\n",
            "2334       [[0.00357649, 0.0030894848, 0.99333405]]\n",
            "2335        [[0.0023406264, 0.009705394, 0.987954]]\n",
            "2336        [[0.004313447, 0.018586056, 0.9771005]]\n",
            "2337      [[0.0019805077, 0.00089746446, 0.997122]]\n",
            "2338         [[0.00631098, 0.009125856, 0.9845633]]\n",
            "2339       [[0.004082375, 0.010369166, 0.98554844]]\n",
            "2340        [[0.028756052, 0.048243754, 0.9230002]]\n",
            "2341        [[0.004313447, 0.018586056, 0.9771005]]\n",
            "2342      [[0.0005372146, 0.004869348, 0.99459344]]\n",
            "2343      [[0.0023490225, 0.019400984, 0.97824997]]\n",
            "2344        [[0.0027264247, 0.04054475, 0.9567288]]\n",
            "2345       [[0.000693031, 0.0012842233, 0.9980228]]\n",
            "2346     [[0.0012316173, 0.0017826051, 0.99698573]]\n",
            "2347     [[0.00079600204, 0.0039669503, 0.9952371]]\n",
            "2348     [[0.001231777, 0.00042104235, 0.99834716]]\n",
            "2349      [[0.0018529481, 0.030268228, 0.96787876]]\n",
            "2350         [[0.014511773, 0.27747893, 0.7080093]]\n",
            "2351        [[0.014000484, 0.48613536, 0.49986413]]\n",
            "2352        [[0.014075702, 0.37861156, 0.60731274]]\n",
            "2353      [[0.0018536521, 0.0017804618, 0.9963659]]\n",
            "2354      [[0.0010746694, 0.0019621355, 0.9969632]]\n",
            "2355        [[0.10496757, 0.86381185, 0.031220559]]\n",
            "2356         [[0.62379444, 0.27657837, 0.09962718]]\n",
            "2357      [[0.00055815664, 0.020310186, 0.9791317]]\n",
            "2358      [[0.0008923031, 0.026698228, 0.97240937]]\n",
            "2359     [[0.0005205654, 0.0024605682, 0.99701893]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_padanan_select_val_f1_0.7783'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_padanan_select_val_f1_0.7783\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "gmelnRNvKu0W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5z5liKWl1_c"
      },
      "source": [
        "## concat state_dict/bert_spc_padanan_trim_know_val_f1_0.7504"
      ],
      "id": "Q5z5liKWl1_c"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/b_padanan_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "crkWZVnXl1_e"
      },
      "execution_count": null,
      "outputs": [],
      "id": "crkWZVnXl1_e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f0e8176f-c915-4d3e-9501-6c346056414c",
        "id": "mG6AUL7Kl1_e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (None), or the `sep_token_id` (None), and your input is not padded.\n",
            "0              [[0.39073315, 0.23127052, 0.3779963]]\n",
            "1               [[0.15573487, 0.5824884, 0.2617767]]\n",
            "2              [[0.34957865, 0.3532587, 0.29716268]]\n",
            "3              [[0.3585843, 0.24206029, 0.39935535]]\n",
            "4              [[0.3585843, 0.24206029, 0.39935535]]\n",
            "5              [[0.11137887, 0.10579071, 0.7828304]]\n",
            "6             [[0.010830455, 0.20030057, 0.7888689]]\n",
            "7             [[0.010830455, 0.20030057, 0.7888689]]\n",
            "8            [[0.002260809, 0.116658956, 0.8810802]]\n",
            "9             [[0.009954768, 0.11014949, 0.8798958]]\n",
            "10             [[0.00872731, 0.20292516, 0.7883475]]\n",
            "11           [[0.021008765, 0.9412411, 0.037750077]]\n",
            "12           [[0.021008765, 0.9412411, 0.037750077]]\n",
            "13          [[0.0056430935, 0.89799726, 0.09635967]]\n",
            "14           [[0.021008765, 0.9412411, 0.037750077]]\n",
            "15          [[0.007859227, 0.0017795195, 0.9903612]]\n",
            "16           [[0.9259721, 0.050427962, 0.023599926]]\n",
            "17         [[0.0010040015, 0.0070457025, 0.9919503]]\n",
            "18        [[0.0013025157, 0.0013331675, 0.99736434]]\n",
            "19         [[0.0012657552, 0.056216802, 0.94251746]]\n",
            "20             [[0.045491382, 0.02069162, 0.933817]]\n",
            "21          [[0.013633302, 0.0038702632, 0.9824964]]\n",
            "22          [[0.002071596, 0.0016065456, 0.9963219]]\n",
            "23             [[0.045491382, 0.02069162, 0.933817]]\n",
            "24             [[0.045491382, 0.02069162, 0.933817]]\n",
            "25            [[0.038858745, 0.14135371, 0.8197876]]\n",
            "26        [[0.0026635341, 0.00031350032, 0.9970229]]\n",
            "27         [[0.0012015642, 0.0024931573, 0.9963052]]\n",
            "28         [[0.0018568662, 0.0028507798, 0.9952924]]\n",
            "29          [[0.0018894171, 0.10318445, 0.89492613]]\n",
            "30              [[0.008823225, 0.25779, 0.73338675]]\n",
            "31           [[0.0077197286, 0.23304361, 0.7592367]]\n",
            "32           [[0.003283231, 0.009543045, 0.9871737]]\n",
            "33          [[0.001486821, 0.0004144112, 0.9980988]]\n",
            "34             [[0.06824704, 0.11805647, 0.8136965]]\n",
            "35         [[0.0014601971, 0.009744757, 0.98879504]]\n",
            "36           [[0.017118748, 0.30017993, 0.68270135]]\n",
            "37             [[0.7133205, 0.21469197, 0.07198759]]\n",
            "38            [[0.06727087, 0.017049331, 0.9156798]]\n",
            "39          [[0.0057284636, 0.0010895104, 0.993182]]\n",
            "40           [[0.0038992856, 0.7940899, 0.20201081]]\n",
            "41            [[0.03467897, 0.29331854, 0.67200243]]\n",
            "42            [[0.007956187, 0.06409911, 0.9279447]]\n",
            "43          [[0.011514731, 0.89334875, 0.095136546]]\n",
            "44           [[0.071335755, 0.55140036, 0.37726384]]\n",
            "45           [[0.030659297, 0.88430476, 0.08503595]]\n",
            "46             [[0.44097316, 0.2190622, 0.33996463]]\n",
            "47             [[0.03156269, 0.8304253, 0.13801199]]\n",
            "48           [[0.023798138, 0.27944463, 0.69675726]]\n",
            "49            [[0.004754646, 0.9221479, 0.07309749]]\n",
            "50            [[0.0030096131, 0.417203, 0.57978743]]\n",
            "51             [[0.036735974, 0.3224887, 0.6407753]]\n",
            "52           [[0.023798138, 0.27944463, 0.69675726]]\n",
            "53            [[0.19492388, 0.58008116, 0.22499494]]\n",
            "54            [[0.004525878, 0.7881771, 0.20729709]]\n",
            "55           [[0.34834927, 0.54107475, 0.110575974]]\n",
            "56           [[0.34834927, 0.54107475, 0.110575974]]\n",
            "57            [[0.5633971, 0.40305743, 0.033545393]]\n",
            "58            [[0.032641657, 0.6915253, 0.27583307]]\n",
            "59            [[0.20434153, 0.7647052, 0.030953277]]\n",
            "60          [[0.005605489, 0.0058698566, 0.9885246]]\n",
            "61          [[0.0015524179, 0.027251268, 0.9711963]]\n",
            "62            [[0.009108946, 0.44072065, 0.5501704]]\n",
            "63          [[0.008920019, 0.042748056, 0.94833195]]\n",
            "64           [[0.007309423, 0.023764076, 0.9689265]]\n",
            "65             [[0.03824822, 0.6709978, 0.29075396]]\n",
            "66            [[0.049394544, 0.6013268, 0.34927857]]\n",
            "67             [[0.5490652, 0.3654414, 0.085493386]]\n",
            "68             [[0.2360476, 0.52284163, 0.24111074]]\n",
            "69             [[0.34105334, 0.50713235, 0.1518143]]\n",
            "70            [[0.4552088, 0.49666387, 0.048127294]]\n",
            "71            [[0.40069357, 0.45560846, 0.14369792]]\n",
            "72           [[0.007572718, 0.18401447, 0.80841285]]\n",
            "73            [[0.020469667, 0.3846323, 0.59489805]]\n",
            "74           [[0.0062986705, 0.19405648, 0.7996448]]\n",
            "75            [[0.38868994, 0.13714577, 0.47416428]]\n",
            "76            [[0.042360585, 0.32684708, 0.6307924]]\n",
            "77            [[0.09491743, 0.08871947, 0.81636316]]\n",
            "78            [[0.22949189, 0.31479546, 0.45571265]]\n",
            "79            [[0.09491743, 0.08871947, 0.81636316]]\n",
            "80             [[0.01914103, 0.20676224, 0.7740968]]\n",
            "81           [[0.0018019069, 0.00107714, 0.9971209]]\n",
            "82          [[0.009917232, 0.0051043695, 0.9849783]]\n",
            "83            [[0.58145005, 0.27554858, 0.14300136]]\n",
            "84            [[0.032561015, 0.43835807, 0.5290809]]\n",
            "85           [[0.124257386, 0.83128214, 0.04446046]]\n",
            "86            [[0.05909214, 0.8986696, 0.042238295]]\n",
            "87          [[0.01708046, 0.0043406677, 0.97857887]]\n",
            "88             [[0.30367684, 0.4969131, 0.19940999]]\n",
            "89           [[0.005543327, 0.17608966, 0.81836706]]\n",
            "90        [[0.0014940219, 0.00066366454, 0.9978423]]\n",
            "91           [[0.14389355, 0.84977204, 0.006334412]]\n",
            "92          [[0.0036304547, 0.73057914, 0.26579043]]\n",
            "93             [[0.29398146, 0.2078156, 0.49820295]]\n",
            "94             [[0.4710809, 0.34753156, 0.18138756]]\n",
            "95             [[0.37878382, 0.2045128, 0.41670337]]\n",
            "96             [[0.32506365, 0.23329748, 0.4416389]]\n",
            "97         [[0.0023053782, 0.0011683947, 0.9965263]]\n",
            "98         [[0.0009905222, 0.0009895993, 0.9980198]]\n",
            "99         [[0.0021851165, 0.0015134698, 0.9963014]]\n",
            "100       [[0.00082580314, 0.00046819585, 0.998706]]\n",
            "101         [[0.0056631938, 0.19432864, 0.80000824]]\n",
            "102         [[0.0010200163, 0.000458647, 0.9985214]]\n",
            "103           [[0.001186441, 0.05812381, 0.9406898]]\n",
            "104         [[0.0026503936, 0.020555383, 0.9767942]]\n",
            "105           [[0.17176211, 0.057525977, 0.7707119]]\n",
            "106         [[0.0009936525, 0.010231964, 0.9887744]]\n",
            "107            [[0.026772147, 0.688156, 0.28507182]]\n",
            "108       [[0.0006188216, 0.00035355188, 0.9990276]]\n",
            "109        [[0.0014957339, 0.047235046, 0.95126927]]\n",
            "110          [[0.0054687643, 0.18355618, 0.8109751]]\n",
            "111         [[0.0003385783, 0.002501302, 0.9971602]]\n",
            "112            [[0.016523309, 0.3423348, 0.6411419]]\n",
            "113           [[0.21269731, 0.28292754, 0.50437516]]\n",
            "114              [[0.28561577, 0.465948, 0.2484362]]\n",
            "115              [[0.28561577, 0.465948, 0.2484362]]\n",
            "116              [[0.28561577, 0.465948, 0.2484362]]\n",
            "117        [[0.0016915424, 0.0008307079, 0.9974777]]\n",
            "118           [[0.005951554, 0.8017858, 0.19226263]]\n",
            "119           [[0.023294427, 0.8676443, 0.10906132]]\n",
            "120         [[0.0084179845, 0.54182917, 0.44975287]]\n",
            "121         [[0.015549548, 0.090031154, 0.89441925]]\n",
            "122           [[0.011402326, 0.20834051, 0.7802572]]\n",
            "123        [[0.0026792062, 0.008917191, 0.98840374]]\n",
            "124        [[0.0026792062, 0.008917191, 0.98840374]]\n",
            "125         [[0.0020948718, 0.016312934, 0.9815922]]\n",
            "126          [[0.003579685, 0.29703924, 0.69938105]]\n",
            "127          [[0.0036287978, 0.3224501, 0.67392117]]\n",
            "128            [[0.0088893175, 0.681055, 0.3100556]]\n",
            "129        [[0.0050712326, 0.009270963, 0.98565775]]\n",
            "130         [[0.0079080295, 0.006613432, 0.9854785]]\n",
            "131          [[0.9220011, 0.029889321, 0.048109498]]\n",
            "132           [[0.9156232, 0.03886834, 0.045508504]]\n",
            "133            [[0.01201645, 0.30266064, 0.6853228]]\n",
            "134          [[0.091656126, 0.8904308, 0.017913098]]\n",
            "135           [[0.32649153, 0.6436063, 0.029902175]]\n",
            "136         [[0.005613261, 0.025039412, 0.96934736]]\n",
            "137        [[0.0016330273, 0.0015503938, 0.9968166]]\n",
            "138      [[0.0011361543, 0.00036721653, 0.99849665]]\n",
            "139          [[0.009468856, 0.37968686, 0.61084425]]\n",
            "140         [[0.024487676, 0.009536666, 0.96597564]]\n",
            "141            [[0.6192021, 0.27417022, 0.10662768]]\n",
            "142          [[0.043698926, 0.9037693, 0.052531753]]\n",
            "143           [[0.010013591, 0.09446275, 0.8955236]]\n",
            "144             [[0.23922272, 0.353099, 0.40767825]]\n",
            "145       [[0.0024547689, 0.0007210771, 0.99682415]]\n",
            "146         [[0.0010563185, 0.0031786214, 0.995765]]\n",
            "147           [[0.016877627, 0.45656502, 0.5265574]]\n",
            "148          [[0.20202288, 0.70770264, 0.090274505]]\n",
            "149           [[0.016877627, 0.45656502, 0.5265574]]\n",
            "150         [[0.0037000831, 0.0026278875, 0.993672]]\n",
            "151          [[0.039789226, 0.89826804, 0.06194278]]\n",
            "152         [[0.0037000831, 0.0026278875, 0.993672]]\n",
            "153         [[0.048963167, 0.91856086, 0.032476004]]\n",
            "154         [[0.0042090863, 0.61054015, 0.38525075]]\n",
            "155         [[0.005594194, 0.97744125, 0.016964601]]\n",
            "156             [[0.0162984, 0.9241897, 0.05951195]]\n",
            "157             [[0.0162984, 0.9241897, 0.05951195]]\n",
            "158         [[0.034655612, 0.9627945, 0.0025498744]]\n",
            "159           [[0.11208159, 0.8774529, 0.010465458]]\n",
            "160            [[0.0153457, 0.94395363, 0.04070068]]\n",
            "161         [[0.0043138973, 0.021132072, 0.9745541]]\n",
            "162         [[0.00269737, 0.0011644918, 0.99613816]]\n",
            "163         [[0.0043138973, 0.021132072, 0.9745541]]\n",
            "164         [[0.0043208557, 0.12900019, 0.86667895]]\n",
            "165             [[0.3474268, 0.11004232, 0.5425309]]\n",
            "166             [[0.3474268, 0.11004232, 0.5425309]]\n",
            "167          [[0.002605918, 0.000783423, 0.9966107]]\n",
            "168            [[0.35413554, 0.45668972, 0.1891747]]\n",
            "169            [[0.13454916, 0.7826638, 0.08278698]]\n",
            "170           [[0.029310329, 0.34214306, 0.6285466]]\n",
            "171          [[0.0028879798, 0.00157188, 0.9955401]]\n",
            "172           [[0.12584692, 0.59019333, 0.28395972]]\n",
            "173           [[0.68769646, 0.13340043, 0.17890313]]\n",
            "174          [[0.065075696, 0.8931269, 0.041797344]]\n",
            "175        [[0.00084086746, 0.004551345, 0.9946078]]\n",
            "176           [[0.0047273203, 0.1338227, 0.8614499]]\n",
            "177        [[0.0010672902, 0.014685216, 0.98424757]]\n",
            "178         [[0.0023374343, 0.070804976, 0.9268576]]\n",
            "179            [[0.07378438, 0.34338132, 0.5828343]]\n",
            "180          [[0.9370217, 0.039089978, 0.023888288]]\n",
            "181           [[0.03118758, 0.049382012, 0.9194304]]\n",
            "182            [[0.14797233, 0.3829489, 0.46907878]]\n",
            "183         [[0.0013097475, 0.020271765, 0.9784185]]\n",
            "184           [[0.03993958, 0.062017642, 0.8980428]]\n",
            "185           [[0.029821323, 0.1294894, 0.84068924]]\n",
            "186             [[0.4118187, 0.10097231, 0.4872089]]\n",
            "187           [[0.029821323, 0.1294894, 0.84068924]]\n",
            "188         [[0.005220446, 0.0030893297, 0.9916903]]\n",
            "189         [[0.0052883816, 0.75494814, 0.23976342]]\n",
            "190          [[0.002789337, 0.9448461, 0.052364547]]\n",
            "191         [[0.0014572155, 0.9747293, 0.023813458]]\n",
            "192         [[0.0019280276, 0.092711166, 0.9053608]]\n",
            "193      [[0.00061104255, 0.00057981844, 0.9988091]]\n",
            "194       [[0.00043830814, 0.0014701597, 0.9980915]]\n",
            "195           [[0.026764562, 0.20439418, 0.7688412]]\n",
            "196          [[0.0031222035, 0.46642825, 0.5304495]]\n",
            "197        [[0.0014875464, 0.88854223, 0.109970205]]\n",
            "198         [[0.0075621298, 0.067863144, 0.9245747]]\n",
            "199         [[0.0013925137, 0.01718094, 0.98142654]]\n",
            "200         [[0.0064017233, 0.0021423842, 0.991456]]\n",
            "201             [[0.535989, 0.17440665, 0.28960434]]\n",
            "202          [[0.014394592, 0.0068193497, 0.978786]]\n",
            "203         [[0.89917994, 0.044246443, 0.056573607]]\n",
            "204           [[0.017174907, 0.9132762, 0.06954885]]\n",
            "205         [[0.0023537483, 0.004704887, 0.9929414]]\n",
            "206            [[0.07209797, 0.8023538, 0.12554827]]\n",
            "207          [[0.018087344, 0.14143524, 0.84047735]]\n",
            "208           [[0.02109151, 0.014453924, 0.9644546]]\n",
            "209           [[0.02109151, 0.014453924, 0.9644546]]\n",
            "210         [[0.004168706, 0.049255695, 0.94657564]]\n",
            "211        [[0.0021449423, 0.0020886671, 0.9957663]]\n",
            "212       [[0.0023728672, 0.00032180912, 0.9973053]]\n",
            "213            [[0.009367802, 0.0185963, 0.9720358]]\n",
            "214         [[0.001761643, 0.0077784206, 0.9904599]]\n",
            "215          [[0.001222147, 0.09308813, 0.90568966]]\n",
            "216          [[0.003481122, 0.11292069, 0.88359815]]\n",
            "217        [[0.0005335503, 0.030623097, 0.96884334]]\n",
            "218        [[0.0005335503, 0.030623097, 0.96884334]]\n",
            "219        [[0.0030137715, 0.014652924, 0.98233336]]\n",
            "220        [[0.0041010333, 0.019197164, 0.97670174]]\n",
            "221          [[0.00923172, 0.021134526, 0.96963376]]\n",
            "222        [[0.0025513114, 0.007428603, 0.99002004]]\n",
            "223            [[0.23910108, 0.47706565, 0.2838332]]\n",
            "224        [[0.0025513114, 0.007428603, 0.99002004]]\n",
            "225          [[0.054966565, 0.25214064, 0.69289273]]\n",
            "226            [[0.7309525, 0.21667339, 0.05237415]]\n",
            "227          [[0.005160952, 0.83259916, 0.16223986]]\n",
            "228        [[0.00060528907, 0.96222454, 0.03717017]]\n",
            "229          [[0.005160952, 0.83259916, 0.16223986]]\n",
            "230          [[0.0031298243, 0.7422781, 0.25459206]]\n",
            "231           [[0.013810036, 0.12930734, 0.8568826]]\n",
            "232           [[0.36574584, 0.25005564, 0.38419852]]\n",
            "233           [[0.013810036, 0.12930734, 0.8568826]]\n",
            "234             [[0.53834087, 0.417332, 0.04432713]]\n",
            "235              [[0.09638123, 0.4018148, 0.501804]]\n",
            "236       [[0.0011451935, 0.0012596858, 0.99759513]]\n",
            "237         [[0.0032425895, 0.005604076, 0.9911533]]\n",
            "238           [[0.68157136, 0.28520814, 0.03322042]]\n",
            "239           [[0.023850568, 0.03329401, 0.9428554]]\n",
            "240            [[0.20311582, 0.51760334, 0.2792808]]\n",
            "241         [[0.087720186, 0.097414136, 0.81486577]]\n",
            "242            [[0.06384049, 0.23958983, 0.6965696]]\n",
            "243           [[0.12260141, 0.48261783, 0.39478073]]\n",
            "244            [[0.1013637, 0.51194286, 0.38669342]]\n",
            "245         [[0.0038339663, 0.92319626, 0.07296973]]\n",
            "246         [[0.020143084, 0.0030701929, 0.9767867]]\n",
            "247           [[0.022855919, 0.18808186, 0.7890622]]\n",
            "248          [[0.117334865, 0.09117892, 0.79148614]]\n",
            "249         [[0.0015030414, 0.008412411, 0.9900845]]\n",
            "250        [[0.0013161169, 0.004261146, 0.99442273]]\n",
            "251       [[0.0013733648, 0.0004096387, 0.99821705]]\n",
            "252       [[0.0013733648, 0.0004096387, 0.99821705]]\n",
            "253       [[0.00075980526, 0.0019335946, 0.9973066]]\n",
            "254           [[0.032671712, 0.8903502, 0.07697806]]\n",
            "255        [[0.0014977537, 0.008193727, 0.99030846]]\n",
            "256           [[0.032671712, 0.8903502, 0.07697806]]\n",
            "257          [[0.019320758, 0.25501972, 0.72565943]]\n",
            "258       [[0.0011043525, 0.0030520896, 0.99584347]]\n",
            "259          [[0.023111332, 0.9269792, 0.049909506]]\n",
            "260         [[0.013413989, 0.9806414, 0.0059445333]]\n",
            "261            [[0.027819354, 0.7967307, 0.1754499]]\n",
            "262           [[0.032671712, 0.8903502, 0.07697806]]\n",
            "263           [[0.37111023, 0.5985019, 0.030387864]]\n",
            "264          [[0.52953917, 0.018591365, 0.45186946]]\n",
            "265           [[0.07237593, 0.71661913, 0.21100494]]\n",
            "266           [[0.16176243, 0.14731427, 0.69092333]]\n",
            "267             [[0.6915213, 0.12641329, 0.1820655]]\n",
            "268             [[0.6915213, 0.12641329, 0.1820655]]\n",
            "269            [[0.5891324, 0.16086146, 0.25000614]]\n",
            "270             [[0.4711355, 0.2473709, 0.28149357]]\n",
            "271           [[0.88874453, 0.05248045, 0.05877501]]\n",
            "272            [[0.011082038, 0.4565343, 0.5323837]]\n",
            "273           [[0.05743434, 0.82067406, 0.12189159]]\n",
            "274        [[0.0007693562, 0.0022751593, 0.9969554]]\n",
            "275       [[0.00038524566, 0.012759617, 0.98685515]]\n",
            "276             [[0.001750387, 0.530853, 0.4673966]]\n",
            "277          [[0.0022896435, 0.12949592, 0.8682144]]\n",
            "278         [[0.0060529327, 0.004674546, 0.9892726]]\n",
            "279          [[0.003631697, 0.008406802, 0.9879615]]\n",
            "280           [[0.009436892, 0.36283252, 0.6277306]]\n",
            "281          [[0.0053170384, 0.8270698, 0.16761312]]\n",
            "282       [[0.0010218736, 0.0005320312, 0.99844617]]\n",
            "283        [[0.0018328915, 0.056562565, 0.94160455]]\n",
            "284            [[0.027519947, 0.7534722, 0.2190079]]\n",
            "285          [[0.0010885504, 0.9926098, 0.00630166]]\n",
            "286        [[0.0031866562, 0.97775686, 0.019056557]]\n",
            "287        [[0.0023775992, 0.028253214, 0.96936923]]\n",
            "288            [[0.22239533, 0.4393298, 0.33827487]]\n",
            "289         [[0.0015871237, 0.004550982, 0.9938619]]\n",
            "290            [[0.22239533, 0.4393298, 0.33827487]]\n",
            "291          [[0.002183952, 0.049898405, 0.9479176]]\n",
            "292          [[0.0013097146, 0.027759219, 0.970931]]\n",
            "293         [[0.0070456266, 0.003464138, 0.9894902]]\n",
            "294          [[0.0032980205, 0.7649379, 0.23176411]]\n",
            "295          [[0.0010814957, 0.8727565, 0.12616204]]\n",
            "296           [[0.0038616238, 0.909481, 0.08665739]]\n",
            "297          [[0.005714298, 0.81894696, 0.17533877]]\n",
            "298         [[0.0013988109, 0.96046454, 0.03813663]]\n",
            "299          [[0.62738925, 0.016964633, 0.35564616]]\n",
            "300           [[0.005298461, 0.03399231, 0.9607093]]\n",
            "301          [[0.0050473474, 0.09143504, 0.9035176]]\n",
            "302           [[0.011352801, 0.956133, 0.032514196]]\n",
            "303          [[0.0050473474, 0.09143504, 0.9035176]]\n",
            "304          [[0.62738925, 0.016964633, 0.35564616]]\n",
            "305          [[0.030920465, 0.9157608, 0.053318758]]\n",
            "306           [[0.019353682, 0.29353282, 0.6871135]]\n",
            "307           [[0.022722282, 0.32148555, 0.6557921]]\n",
            "308           [[0.021997735, 0.31233835, 0.6656639]]\n",
            "309          [[0.020890562, 0.33313367, 0.64597577]]\n",
            "310         [[0.0014879117, 0.05876159, 0.93975043]]\n",
            "311        [[0.0038734034, 0.021043645, 0.97508293]]\n",
            "312            [[0.016633565, 0.3397989, 0.6435675]]\n",
            "313        [[0.0051040594, 0.032423735, 0.96247226]]\n",
            "314           [[0.005918832, 0.12716043, 0.8669207]]\n",
            "315            [[0.2865821, 0.029881652, 0.6835362]]\n",
            "316        [[0.0016126081, 0.0047002737, 0.9936872]]\n",
            "317      [[0.00058516406, 0.0040465132, 0.99536824]]\n",
            "318           [[0.0009951001, 0.0753565, 0.9236484]]\n",
            "319           [[0.009815986, 0.6977631, 0.29242095]]\n",
            "320          [[0.0015753722, 0.14682218, 0.8516025]]\n",
            "321           [[0.009815986, 0.6977631, 0.29242095]]\n",
            "322       [[0.0012489446, 0.0004796452, 0.99827135]]\n",
            "323       [[0.0014480634, 0.0004328496, 0.99811906]]\n",
            "324           [[0.03364966, 0.21047133, 0.75587904]]\n",
            "325           [[0.007324603, 0.00449352, 0.9881819]]\n",
            "326           [[0.41778737, 0.15084447, 0.43136817]]\n",
            "327           [[0.008105924, 0.3586038, 0.63329023]]\n",
            "328           [[0.7601644, 0.18628417, 0.053551476]]\n",
            "329           [[0.063050546, 0.4653019, 0.47164765]]\n",
            "330           [[0.7601644, 0.18628417, 0.053551476]]\n",
            "331           [[0.063050546, 0.4653019, 0.47164765]]\n",
            "332           [[0.7601644, 0.18628417, 0.053551476]]\n",
            "333         [[0.001932127, 0.053263724, 0.94480413]]\n",
            "334          [[0.31528553, 0.67459536, 0.010119137]]\n",
            "335         [[0.015845323, 0.004745571, 0.97940904]]\n",
            "336            [[0.16311224, 0.14550355, 0.6913842]]\n",
            "337            [[0.16311224, 0.14550355, 0.6913842]]\n",
            "338         [[0.015845323, 0.004745571, 0.97940904]]\n",
            "339          [[0.86710644, 0.019541783, 0.11335174]]\n",
            "340            [[0.16311224, 0.14550355, 0.6913842]]\n",
            "341            [[0.004077916, 0.1301207, 0.8658014]]\n",
            "342         [[0.0006466375, 0.005129636, 0.9942238]]\n",
            "343       [[0.00041126247, 0.0011506466, 0.9984382]]\n",
            "344           [[0.45896903, 0.15916881, 0.38186216]]\n",
            "345           [[0.029107843, 0.013704222, 0.957188]]\n",
            "346        [[0.0045671216, 0.035136156, 0.96029663]]\n",
            "347            [[0.7113158, 0.14004646, 0.14863771]]\n",
            "348           [[0.045575194, 0.27388892, 0.6805359]]\n",
            "349           [[0.045575194, 0.27388892, 0.6805359]]\n",
            "350            [[0.1408737, 0.55150443, 0.30762187]]\n",
            "351          [[0.8505857, 0.13575742, 0.0136568975]]\n",
            "352        [[0.0040426096, 0.029768448, 0.96618897]]\n",
            "353           [[0.005579001, 0.5040332, 0.49038774]]\n",
            "354        [[0.0019372121, 0.0021805165, 0.9958823]]\n",
            "355            [[0.0679815, 0.17178881, 0.76022965]]\n",
            "356           [[0.0150733795, 0.6607859, 0.3241407]]\n",
            "357          [[0.010602881, 0.015285486, 0.9741116]]\n",
            "358            [[0.07567604, 0.7267538, 0.19757022]]\n",
            "359           [[0.070773184, 0.16043761, 0.7687892]]\n",
            "360           [[0.48596784, 0.16723119, 0.34680095]]\n",
            "361           [[0.035296112, 0.77370596, 0.1909979]]\n",
            "362           [[0.016506873, 0.6062785, 0.37721464]]\n",
            "363          [[0.00394531, 0.0060225124, 0.9900322]]\n",
            "364         [[0.005902054, 0.98598796, 0.008109982]]\n",
            "365        [[0.0014152044, 0.9973839, 0.0012009395]]\n",
            "366       [[0.0017152013, 0.99729735, 0.0009874561]]\n",
            "367            [[0.56619287, 0.2803526, 0.15345453]]\n",
            "368           [[0.06476204, 0.31087992, 0.62435806]]\n",
            "369          [[0.0064072395, 0.08390293, 0.9096898]]\n",
            "370         [[0.0018027428, 0.041538473, 0.9566588]]\n",
            "371         [[0.001585766, 0.004522852, 0.99389136]]\n",
            "372           [[0.005297491, 0.8122421, 0.18246043]]\n",
            "373        [[0.0010117863, 0.00080420915, 0.998184]]\n",
            "374          [[0.0016665121, 0.56931776, 0.4290158]]\n",
            "375         [[0.0046680677, 0.29341617, 0.70191574]]\n",
            "376        [[0.0027343857, 0.007940535, 0.98932505]]\n",
            "377          [[0.044753913, 0.033056572, 0.9221895]]\n",
            "378              [[0.3107467, 0.5271342, 0.1621191]]\n",
            "379        [[0.0027343857, 0.007940535, 0.98932505]]\n",
            "380             [[0.5089528, 0.3264572, 0.16459005]]\n",
            "381         [[0.027820118, 0.026062213, 0.94611764]]\n",
            "382             [[0.5089528, 0.3264572, 0.16459005]]\n",
            "383           [[0.028025586, 0.24535373, 0.7266207]]\n",
            "384           [[0.028025586, 0.24535373, 0.7266207]]\n",
            "385            [[0.12440132, 0.2989156, 0.57668304]]\n",
            "386       [[0.0042137206, 0.0011874305, 0.99459887]]\n",
            "387         [[0.013331433, 0.018439405, 0.96822906]]\n",
            "388            [[0.27359864, 0.15634878, 0.5700525]]\n",
            "389              [[0.3560128, 0.113142, 0.53084517]]\n",
            "390           [[0.026111724, 0.3595733, 0.61431503]]\n",
            "391          [[0.002103184, 0.023965983, 0.9739308]]\n",
            "392        [[0.0024962146, 0.0044299024, 0.9930738]]\n",
            "393       [[0.0022736394, 0.0007506876, 0.99697566]]\n",
            "394         [[0.0018540899, 0.0051829964, 0.992963]]\n",
            "395           [[0.008678575, 0.15974395, 0.8315774]]\n",
            "396           [[0.008678575, 0.15974395, 0.8315774]]\n",
            "397           [[0.0028978477, 0.884812, 0.11229015]]\n",
            "398           [[0.018670734, 0.5495146, 0.43181467]]\n",
            "399           [[0.005742196, 0.18616435, 0.8080934]]\n",
            "400          [[0.013264939, 0.96527505, 0.02145996]]\n",
            "401           [[0.018670734, 0.5495146, 0.43181467]]\n",
            "402           [[0.025120137, 0.31185776, 0.6630221]]\n",
            "403          [[0.0049964897, 0.9245852, 0.07041835]]\n",
            "404           [[0.007791352, 0.8753568, 0.11685186]]\n",
            "405           [[0.007791352, 0.8753568, 0.11685186]]\n",
            "406           [[0.0044402704, 0.7833617, 0.2121981]]\n",
            "407          [[0.006500457, 0.9841352, 0.009364363]]\n",
            "408          [[0.0022016733, 0.6745047, 0.32329363]]\n",
            "409          [[0.0022016733, 0.6745047, 0.32329363]]\n",
            "410          [[0.000918668, 0.06532716, 0.93375415]]\n",
            "411         [[0.0011420419, 0.16710296, 0.83175504]]\n",
            "412         [[0.0024161404, 0.026658218, 0.9709256]]\n",
            "413           [[0.024918897, 0.9088451, 0.06623598]]\n",
            "414            [[0.020126743, 0.2076639, 0.7722094]]\n",
            "415           [[0.10372891, 0.084517434, 0.8117536]]\n",
            "416        [[0.0040221023, 0.0011802742, 0.9947976]]\n",
            "417            [[0.00975966, 0.33053148, 0.6597088]]\n",
            "418           [[0.012286978, 0.2529177, 0.73479533]]\n",
            "419           [[0.012000589, 0.14904475, 0.8389547]]\n",
            "420           [[0.012000589, 0.14904475, 0.8389547]]\n",
            "421         [[0.0025832267, 0.04714905, 0.95026773]]\n",
            "422            [[0.020908423, 0.5657038, 0.4133878]]\n",
            "423           [[0.012286978, 0.2529177, 0.73479533]]\n",
            "424          [[0.0081038885, 0.06782282, 0.9240733]]\n",
            "425            [[0.5336055, 0.14357361, 0.32282084]]\n",
            "426         [[0.093573235, 0.016654598, 0.88977224]]\n",
            "427           [[0.08533316, 0.07705408, 0.83761275]]\n",
            "428         [[0.009252705, 0.037534725, 0.95321256]]\n",
            "429        [[0.008383288, 0.0039596977, 0.98765707]]\n",
            "430           [[0.008143944, 0.3016275, 0.69022864]]\n",
            "431           [[0.023167845, 0.22157425, 0.7552579]]\n",
            "432           [[0.001249587, 0.003131483, 0.995619]]\n",
            "433        [[0.0063018873, 0.080481604, 0.91321653]]\n",
            "434           [[0.059741147, 0.0255566, 0.91470224]]\n",
            "435           [[0.009347876, 0.14004938, 0.8506028]]\n",
            "436       [[0.0017801431, 0.0013622172, 0.99685764]]\n",
            "437          [[0.0029430157, 0.16109692, 0.8359601]]\n",
            "438            [[0.20882379, 0.6053338, 0.18584241]]\n",
            "439          [[0.0005780165, 0.9345794, 0.06484262]]\n",
            "440           [[0.008124558, 0.8469909, 0.14488459]]\n",
            "441          [[0.0017798523, 0.008295115, 0.989925]]\n",
            "442          [[0.018389687, 0.37431723, 0.60729307]]\n",
            "443       [[0.00087718037, 0.014391354, 0.98473155]]\n",
            "444          [[0.0017798523, 0.008295115, 0.989925]]\n",
            "445        [[0.0006870803, 0.0009721596, 0.9983407]]\n",
            "446          [[0.0037965397, 0.09940365, 0.8967998]]\n",
            "447        [[0.0009057553, 0.011676166, 0.98741806]]\n",
            "448          [[0.0017798523, 0.008295115, 0.989925]]\n",
            "449          [[0.024347607, 0.9606456, 0.015006768]]\n",
            "450          [[0.008485462, 0.9426938, 0.048820756]]\n",
            "451           [[0.0035276718, 0.735298, 0.26117432]]\n",
            "452           [[0.0035276718, 0.735298, 0.26117432]]\n",
            "453          [[0.024112338, 0.67432535, 0.30156234]]\n",
            "454         [[0.0020213947, 0.8946063, 0.103372246]]\n",
            "455           [[0.0035276718, 0.735298, 0.26117432]]\n",
            "456           [[0.00822203, 0.012677058, 0.9791008]]\n",
            "457          [[0.016618857, 0.37046194, 0.61291915]]\n",
            "458          [[0.016618857, 0.37046194, 0.61291915]]\n",
            "459          [[0.003354898, 0.08054094, 0.91610426]]\n",
            "460       [[0.0012117298, 0.00069621496, 0.9980921]]\n",
            "461            [[0.08635514, 0.18514797, 0.7284969]]\n",
            "462        [[0.0009147963, 0.019637018, 0.97944814]]\n",
            "463          [[0.003354898, 0.08054094, 0.91610426]]\n",
            "464           [[0.014120217, 0.12143853, 0.8644413]]\n",
            "465        [[0.0016367257, 0.0005565929, 0.9978067]]\n",
            "466          [[0.0064171855, 0.47168767, 0.5218951]]\n",
            "467          [[0.009592692, 0.046756092, 0.9436513]]\n",
            "468             [[0.683028, 0.10438459, 0.21258748]]\n",
            "469         [[0.0026389635, 0.01965144, 0.97770953]]\n",
            "470            [[0.056914307, 0.43309972, 0.509986]]\n",
            "471           [[0.6908127, 0.23489457, 0.074292704]]\n",
            "472              [[0.1514088, 0.2312625, 0.6173287]]\n",
            "473           [[0.6908127, 0.23489457, 0.074292704]]\n",
            "474            [[0.04998796, 0.07933694, 0.8706751]]\n",
            "475              [[0.1514088, 0.2312625, 0.6173287]]\n",
            "476              [[0.1514088, 0.2312625, 0.6173287]]\n",
            "477              [[0.1514088, 0.2312625, 0.6173287]]\n",
            "478            [[0.10217692, 0.5835112, 0.31431192]]\n",
            "479          [[0.009965495, 0.10606388, 0.88397074]]\n",
            "480          [[0.009965495, 0.10606388, 0.88397074]]\n",
            "481        [[0.0015162172, 0.0022015537, 0.9962823]]\n",
            "482            [[0.005983655, 0.6848718, 0.3091446]]\n",
            "483       [[0.0011304852, 0.0014000435, 0.99746954]]\n",
            "484       [[0.0011280188, 0.0012294721, 0.99764246]]\n",
            "485       [[0.00082878926, 0.0006452715, 0.9985259]]\n",
            "486         [[0.0017008084, 0.13749954, 0.86079955]]\n",
            "487            [[0.0016165809, 0.3020644, 0.696319]]\n",
            "488         [[0.00083189586, 0.8711915, 0.12797661]]\n",
            "489          [[0.004183619, 0.04108899, 0.95472735]]\n",
            "490          [[0.0072023855, 0.054598548, 0.938199]]\n",
            "491          [[0.0064413943, 0.02687871, 0.9666799]]\n",
            "492          [[0.0064413943, 0.02687871, 0.9666799]]\n",
            "493        [[0.0017616987, 0.0031204144, 0.9951179]]\n",
            "494         [[0.0053975796, 0.029446213, 0.9651562]]\n",
            "495          [[0.004183619, 0.04108899, 0.95472735]]\n",
            "496           [[0.016711226, 0.42152986, 0.5617589]]\n",
            "497         [[0.082771875, 0.045058113, 0.87217003]]\n",
            "498           [[0.016711226, 0.42152986, 0.5617589]]\n",
            "499           [[0.048429344, 0.7212638, 0.23030679]]\n",
            "500           [[0.034890488, 0.7335531, 0.23155648]]\n",
            "501           [[0.16087393, 0.19712394, 0.64200217]]\n",
            "502           [[0.034266215, 0.5945746, 0.37115914]]\n",
            "503            [[0.13176383, 0.09177357, 0.7764626]]\n",
            "504           [[0.056011934, 0.15087524, 0.7931128]]\n",
            "505          [[0.032288082, 0.77823615, 0.18947582]]\n",
            "506            [[0.0023151194, 0.14447, 0.85321486]]\n",
            "507           [[0.03485381, 0.8604385, 0.104707606]]\n",
            "508          [[0.045128644, 0.69642466, 0.25844672]]\n",
            "509         [[0.0027282934, 0.08873599, 0.90853566]]\n",
            "510         [[0.0024721175, 0.017920218, 0.9796077]]\n",
            "511         [[0.0015232159, 0.012116962, 0.9863599]]\n",
            "512        [[0.0006174678, 0.0015779125, 0.9978046]]\n",
            "513         [[0.0022677698, 0.002601824, 0.9951304]]\n",
            "514         [[0.0015232159, 0.012116962, 0.9863599]]\n",
            "515          [[0.028455948, 0.67841566, 0.29312837]]\n",
            "516            [[0.10735515, 0.55945647, 0.3331884]]\n",
            "517            [[0.038988672, 0.7182974, 0.2427139]]\n",
            "518           [[0.034933425, 0.9504615, 0.01460511]]\n",
            "519         [[0.00467634, 0.0032835114, 0.99204016]]\n",
            "520            [[0.10735515, 0.55945647, 0.3331884]]\n",
            "521            [[0.009905197, 0.37222883, 0.617866]]\n",
            "522       [[0.0013186445, 0.0028770494, 0.99580437]]\n",
            "523        [[0.000978121, 0.0011330689, 0.99788886]]\n",
            "524       [[0.0033762334, 0.0058075297, 0.99081624]]\n",
            "525        [[0.0024612239, 0.003724377, 0.99381435]]\n",
            "526         [[0.012509373, 0.041733876, 0.94575673]]\n",
            "527        [[0.000978121, 0.0011330689, 0.99788886]]\n",
            "528            [[0.023220243, 0.3409066, 0.6358732]]\n",
            "529           [[0.035754245, 0.12667921, 0.8375666]]\n",
            "530           [[0.45989525, 0.18246983, 0.35763493]]\n",
            "531          [[0.10107882, 0.055187088, 0.84373415]]\n",
            "532        [[0.0017289158, 0.007173702, 0.99109745]]\n",
            "533          [[0.0089276135, 0.09506168, 0.8960107]]\n",
            "534         [[0.0019289942, 0.021844361, 0.9762266]]\n",
            "535        [[0.0017289158, 0.007173702, 0.99109745]]\n",
            "536          [[0.0020816994, 0.38650972, 0.6114086]]\n",
            "537        [[0.0063845767, 0.004832978, 0.98878247]]\n",
            "538           [[0.16011427, 0.76825684, 0.07162885]]\n",
            "539         [[0.027524998, 0.93665236, 0.035822682]]\n",
            "540            [[0.1732472, 0.60612404, 0.22062872]]\n",
            "541            [[0.16962785, 0.7154857, 0.11488647]]\n",
            "542           [[0.13955136, 0.46668303, 0.39376563]]\n",
            "543        [[0.0049969405, 0.058075383, 0.93692774]]\n",
            "544          [[0.00045420037, 0.00264877, 0.996897]]\n",
            "545        [[0.0005014872, 0.0017972935, 0.9977012]]\n",
            "546        [[0.00063413236, 0.89531326, 0.10405261]]\n",
            "547        [[0.011139337, 0.0013157023, 0.98754495]]\n",
            "548            [[0.06349771, 0.7948928, 0.14160949]]\n",
            "549            [[0.008565767, 0.1631416, 0.8282926]]\n",
            "550          [[0.8598986, 0.061486986, 0.078614324]]\n",
            "551            [[0.02021527, 0.36661285, 0.6131719]]\n",
            "552          [[0.86793643, 0.047919795, 0.08414374]]\n",
            "553           [[0.005170818, 0.48707652, 0.5077527]]\n",
            "554            [[0.008565767, 0.1631416, 0.8282926]]\n",
            "555            [[0.008565767, 0.1631416, 0.8282926]]\n",
            "556           [[0.0117297545, 0.4684778, 0.5197925]]\n",
            "557         [[0.0042128735, 0.028341897, 0.9674453]]\n",
            "558      [[0.0013656012, 0.00093730906, 0.99769706]]\n",
            "559           [[0.025556874, 0.22065122, 0.7537919]]\n",
            "560         [[0.0026176935, 0.69963884, 0.29774344]]\n",
            "561         [[0.0026176935, 0.69963884, 0.29774344]]\n",
            "562          [[0.0023724895, 0.48872912, 0.5088984]]\n",
            "563          [[0.0015111902, 0.070969835, 0.927519]]\n",
            "564        [[0.0066192974, 0.0014920082, 0.9918887]]\n",
            "565         [[0.0147183705, 0.28934875, 0.69593287]]\n",
            "566         [[0.0064985715, 0.16499755, 0.82850385]]\n",
            "567          [[0.021861872, 0.30082524, 0.67731285]]\n",
            "568           [[0.006919298, 0.29511094, 0.6979698]]\n",
            "569          [[0.002309249, 0.006223065, 0.9914677]]\n",
            "570        [[0.0028651173, 0.0023441343, 0.9947908]]\n",
            "571        [[0.0009799572, 0.0039806226, 0.9950395]]\n",
            "572        [[0.0008335757, 0.0015369192, 0.9976295]]\n",
            "573        [[0.0019856486, 0.0006647878, 0.9973496]]\n",
            "574        [[0.0022412266, 0.0014219295, 0.9963368]]\n",
            "575         [[0.0025568327, 0.020134326, 0.9773089]]\n",
            "576            [[0.011079722, 0.2532249, 0.7356954]]\n",
            "577         [[0.0034921933, 0.034010317, 0.9624975]]\n",
            "578          [[0.073601685, 0.48037422, 0.44602412]]\n",
            "579          [[0.073601685, 0.48037422, 0.44602412]]\n",
            "580         [[0.9420752, 0.050714266, 0.0072104633]]\n",
            "581           [[0.59927577, 0.31984556, 0.08087867]]\n",
            "582          [[0.0052775233, 0.09155091, 0.9031716]]\n",
            "583        [[0.00082072435, 0.0028702922, 0.996309]]\n",
            "584           [[0.7472065, 0.23366962, 0.019123869]]\n",
            "585         [[0.0031755585, 0.012669907, 0.9841546]]\n",
            "586          [[0.069132976, 0.84818405, 0.08268292]]\n",
            "587             [[0.07465097, 0.2239454, 0.7014036]]\n",
            "588             [[0.07465097, 0.2239454, 0.7014036]]\n",
            "589       [[0.0050379545, 0.98945504, 0.0055070026]]\n",
            "590         [[0.0025796117, 0.002616761, 0.9948036]]\n",
            "591          [[0.005982233, 0.0039237007, 0.990094]]\n",
            "592            [[0.028561262, 0.3357575, 0.6356812]]\n",
            "593          [[0.009304256, 0.0003667327, 0.990329]]\n",
            "594       [[0.0022742976, 0.0004928738, 0.99723285]]\n",
            "595           [[0.025588809, 0.71699405, 0.2574171]]\n",
            "596           [[0.14481977, 0.02994521, 0.82523507]]\n",
            "597       [[0.0025152108, 0.0008384072, 0.99664634]]\n",
            "598           [[0.0034629544, 0.0757923, 0.9207448]]\n",
            "599          [[0.0074964995, 0.23310965, 0.7593938]]\n",
            "600       [[0.0027011812, 0.0014093941, 0.99588937]]\n",
            "601           [[0.46749172, 0.36146784, 0.17104039]]\n",
            "602          [[0.009850773, 0.012244174, 0.9779051]]\n",
            "603       [[0.0006643635, 0.0017875672, 0.99754804]]\n",
            "604           [[0.26801723, 0.35933745, 0.37264532]]\n",
            "605                [[0.30150086, 0.5927, 0.1057991]]\n",
            "606           [[0.007011828, 0.13187377, 0.8611144]]\n",
            "607           [[0.14260308, 0.06989787, 0.78749907]]\n",
            "608          [[0.005642931, 0.008624516, 0.9857326]]\n",
            "609            [[0.01498595, 0.8189296, 0.16608442]]\n",
            "610        [[0.002949131, 0.0023481508, 0.99470264]]\n",
            "611           [[0.042215396, 0.8454541, 0.11233052]]\n",
            "612          [[0.03834723, 0.038803846, 0.92284894]]\n",
            "613         [[0.0051738163, 0.016027538, 0.9787987]]\n",
            "614         [[0.057410546, 0.89282244, 0.049767036]]\n",
            "615           [[0.54195553, 0.4262582, 0.031786267]]\n",
            "616              [[0.2914541, 0.6557038, 0.0528421]]\n",
            "617             [[0.3072868, 0.04376287, 0.6489503]]\n",
            "618         [[0.025353104, 0.88281184, 0.091835074]]\n",
            "619           [[0.00571938, 0.91639036, 0.07789024]]\n",
            "620        [[0.0008959431, 0.97923845, 0.019865643]]\n",
            "621        [[0.0051629352, 0.92218155, 0.072655484]]\n",
            "622           [[0.0057961587, 0.6215203, 0.3726836]]\n",
            "623           [[0.0057961587, 0.6215203, 0.3726836]]\n",
            "624          [[0.0010646295, 0.9230272, 0.07590819]]\n",
            "625         [[0.0005773873, 0.9711755, 0.028247146]]\n",
            "626            [[0.015070545, 0.5453001, 0.4396293]]\n",
            "627         [[0.009920804, 0.97075236, 0.019326799]]\n",
            "628          [[0.0055934056, 0.2478574, 0.74654925]]\n",
            "629          [[0.0052973605, 0.69318235, 0.3015203]]\n",
            "630          [[0.0011005338, 0.6885176, 0.31038192]]\n",
            "631        [[0.00062365545, 0.011818193, 0.9875581]]\n",
            "632          [[0.001719389, 0.17299356, 0.82528704]]\n",
            "633         [[0.0004233126, 0.002779156, 0.9967976]]\n",
            "634         [[0.0028859319, 0.37754676, 0.61956733]]\n",
            "635        [[0.0028922006, 0.0003433782, 0.9967644]]\n",
            "636          [[0.010216699, 0.049786862, 0.9399964]]\n",
            "637             [[0.04494147, 0.24251364, 0.712545]]\n",
            "638          [[0.91870165, 0.034185257, 0.04711317]]\n",
            "639          [[0.91870165, 0.034185257, 0.04711317]]\n",
            "640          [[0.019382866, 0.29523364, 0.68538344]]\n",
            "641         [[0.0037259075, 0.9862938, 0.009980364]]\n",
            "642           [[0.24737746, 0.05777795, 0.69484466]]\n",
            "643       [[0.00079845433, 0.0010674772, 0.9981342]]\n",
            "644            [[0.005575083, 0.2458213, 0.7486036]]\n",
            "645         [[0.002246303, 0.016009199, 0.98174447]]\n",
            "646           [[0.010560524, 0.4759684, 0.51347107]]\n",
            "647          [[0.019382866, 0.29523364, 0.68538344]]\n",
            "648            [[0.0067094564, 0.8803965, 0.112894]]\n",
            "649            [[0.0067094564, 0.8803965, 0.112894]]\n",
            "650            [[0.005575083, 0.2458213, 0.7486036]]\n",
            "651         [[0.0017220177, 0.48403943, 0.51423854]]\n",
            "652           [[0.05196815, 0.9415051, 0.006526726]]\n",
            "653           [[0.75853384, 0.16061744, 0.08084875]]\n",
            "654         [[0.0034568708, 0.018621974, 0.9779212]]\n",
            "655        [[0.0016764431, 0.00029960467, 0.998024]]\n",
            "656          [[0.034396023, 0.9396233, 0.025980659]]\n",
            "657         [[0.0034568708, 0.018621974, 0.9779212]]\n",
            "658        [[0.0056231273, 0.0027455685, 0.9916313]]\n",
            "659         [[0.00079057197, 0.26794004, 0.7312694]]\n",
            "660        [[0.00073909695, 0.29358277, 0.70567816]]\n",
            "661          [[0.0009212662, 0.13589884, 0.8631799]]\n",
            "662         [[0.0060094944, 0.025933625, 0.9680569]]\n",
            "663           [[0.009763623, 0.01891252, 0.9713239]]\n",
            "664          [[0.0026588836, 0.00915473, 0.9881863]]\n",
            "665         [[0.0016415087, 0.04959361, 0.94876486]]\n",
            "666            [[0.07394776, 0.6484922, 0.27756006]]\n",
            "667            [[0.028917203, 0.8774981, 0.0935847]]\n",
            "668           [[0.01175407, 0.07937468, 0.90887123]]\n",
            "669          [[0.041026175, 0.21038562, 0.74858826]]\n",
            "670         [[0.0073133437, 0.024845976, 0.9678407]]\n",
            "671       [[0.0035377822, 0.0051774406, 0.99128485]]\n",
            "672           [[0.051997956, 0.28682733, 0.6611747]]\n",
            "673         [[0.066106886, 0.91819805, 0.015695076]]\n",
            "674           [[0.037894156, 0.42380807, 0.5382977]]\n",
            "675          [[0.60040545, 0.35888055, 0.040713944]]\n",
            "676            [[0.4776422, 0.5011159, 0.021241885]]\n",
            "677           [[0.34689248, 0.6397751, 0.013332439]]\n",
            "678           [[0.03302023, 0.9469934, 0.019986397]]\n",
            "679           [[0.07671132, 0.9056208, 0.017667916]]\n",
            "680           [[0.7403886, 0.24268328, 0.016928166]]\n",
            "681           [[0.57763237, 0.38054073, 0.04182688]]\n",
            "682           [[0.9027687, 0.08222272, 0.015008527]]\n",
            "683           [[0.41439858, 0.57009345, 0.01550792]]\n",
            "684          [[0.60040545, 0.35888055, 0.040713944]]\n",
            "685      [[0.0046119597, 0.00040369402, 0.99498427]]\n",
            "686            [[0.052676033, 0.053983916, 0.89334]]\n",
            "687            [[0.06515029, 0.16943052, 0.7654192]]\n",
            "688         [[0.0013805145, 0.93231547, 0.06630408]]\n",
            "689           [[0.85194194, 0.08099053, 0.06706751]]\n",
            "690      [[0.0046119597, 0.00040369402, 0.99498427]]\n",
            "691             [[0.013387323, 0.4510097, 0.535603]]\n",
            "692        [[0.00068004814, 0.9705914, 0.028728511]]\n",
            "693         [[0.00072364014, 0.24811025, 0.7511661]]\n",
            "694             [[0.013387323, 0.4510097, 0.535603]]\n",
            "695            [[0.20103444, 0.16485949, 0.6341061]]\n",
            "696        [[0.0046150293, 0.009329229, 0.98605573]]\n",
            "697        [[0.0046150293, 0.009329229, 0.98605573]]\n",
            "698          [[0.026680302, 0.059323993, 0.9139956]]\n",
            "699           [[0.007975438, 0.19551899, 0.7965056]]\n",
            "700        [[0.001534784, 0.0013205088, 0.99714464]]\n",
            "701           [[0.005449628, 0.07991356, 0.9146368]]\n",
            "702           [[0.005554469, 0.50048536, 0.4939602]]\n",
            "703           [[0.067861415, 0.6500652, 0.28207344]]\n",
            "704          [[0.0030013062, 0.6180176, 0.37898108]]\n",
            "705         [[0.0019284624, 0.16687721, 0.83119434]]\n",
            "706          [[0.0063230377, 0.9255725, 0.06810449]]\n",
            "707         [[0.026476737, 0.87432045, 0.099202774]]\n",
            "708           [[0.005488911, 0.5445495, 0.44996157]]\n",
            "709           [[0.005554469, 0.50048536, 0.4939602]]\n",
            "710           [[0.055191815, 0.64413565, 0.3006725]]\n",
            "711           [[0.04061145, 0.80686986, 0.15251867]]\n",
            "712            [[0.01437022, 0.23665665, 0.7489731]]\n",
            "713           [[0.005554469, 0.50048536, 0.4939602]]\n",
            "714         [[0.002190479, 0.009353176, 0.98845637]]\n",
            "715           [[0.005554469, 0.50048536, 0.4939602]]\n",
            "716           [[0.005554469, 0.50048536, 0.4939602]]\n",
            "717         [[0.026476737, 0.87432045, 0.099202774]]\n",
            "718          [[0.022976333, 0.9209072, 0.056116533]]\n",
            "719         [[0.053203914, 0.83243227, 0.114363804]]\n",
            "720           [[0.010902631, 0.944579, 0.044518378]]\n",
            "721        [[0.0025215775, 0.9937279, 0.0037504954]]\n",
            "722             [[0.34806162, 0.07653038, 0.575408]]\n",
            "723           [[0.1167572, 0.043739036, 0.83950377]]\n",
            "724         [[0.053203914, 0.83243227, 0.114363804]]\n",
            "725         [[0.053203914, 0.83243227, 0.114363804]]\n",
            "726          [[0.84558564, 0.058104858, 0.09630948]]\n",
            "727             [[0.44218963, 0.10371634, 0.454094]]\n",
            "728           [[0.053208824, 0.15160891, 0.7951823]]\n",
            "729        [[0.009468701, 0.0012986864, 0.98923254]]\n",
            "730            [[0.012188546, 0.0896965, 0.8981149]]\n",
            "731           [[0.20313866, 0.35105154, 0.44580975]]\n",
            "732            [[0.012188546, 0.0896965, 0.8981149]]\n",
            "733             [[0.01897294, 0.606392, 0.37463504]]\n",
            "734          [[0.012500548, 0.03151675, 0.95598274]]\n",
            "735           [[0.20313866, 0.35105154, 0.44580975]]\n",
            "736            [[0.10051789, 0.8254242, 0.07405792]]\n",
            "737          [[0.10032076, 0.86526406, 0.034415137]]\n",
            "738            [[0.071342975, 0.7102071, 0.2184499]]\n",
            "739           [[0.20313866, 0.35105154, 0.44580975]]\n",
            "740           [[0.007477428, 0.7811692, 0.21135336]]\n",
            "741          [[0.0017655302, 0.7837797, 0.21445478]]\n",
            "742          [[0.005025978, 0.34469837, 0.65027565]]\n",
            "743             [[0.03786009, 0.580574, 0.38156596]]\n",
            "744             [[0.03786009, 0.580574, 0.38156596]]\n",
            "745           [[0.0010259681, 0.7294792, 0.2694949]]\n",
            "746          [[0.0017655302, 0.7837797, 0.21445478]]\n",
            "747            [[0.048576463, 0.6142709, 0.3371526]]\n",
            "748          [[0.0017655302, 0.7837797, 0.21445478]]\n",
            "749         [[0.0031606648, 0.018735215, 0.9781041]]\n",
            "750         [[0.0014200786, 0.81014764, 0.18843228]]\n",
            "751            [[0.19669132, 0.4640145, 0.33929422]]\n",
            "752            [[0.4209025, 0.45307532, 0.12602212]]\n",
            "753         [[0.005004812, 0.94561446, 0.049380735]]\n",
            "754         [[0.0031606648, 0.018735215, 0.9781041]]\n",
            "755          [[0.0045256624, 0.34260002, 0.6528743]]\n",
            "756          [[0.0025464376, 0.54141015, 0.4560434]]\n",
            "757          [[0.0036882516, 0.09370497, 0.9026068]]\n",
            "758         [[0.0020461038, 0.91403776, 0.08391614]]\n",
            "759        [[0.0014112763, 0.0029848681, 0.9956039]]\n",
            "760        [[0.0013779375, 0.0021878483, 0.9964342]]\n",
            "761           [[0.045792826, 0.8911295, 0.06307768]]\n",
            "762          [[0.0028247521, 0.3405901, 0.65658516]]\n",
            "763        [[0.016470399, 0.00084621075, 0.9826834]]\n",
            "764           [[0.22814576, 0.016845712, 0.7550085]]\n",
            "765            [[0.10531164, 0.5300567, 0.36463165]]\n",
            "766            [[0.08978779, 0.7082053, 0.20200694]]\n",
            "767            [[0.27204803, 0.54839784, 0.1795541]]\n",
            "768           [[0.014026523, 0.49648485, 0.4894886]]\n",
            "769          [[0.050570335, 0.69475687, 0.25467283]]\n",
            "770             [[0.014885367, 0.845914, 0.1392006]]\n",
            "771            [[0.12310148, 0.08881225, 0.7880863]]\n",
            "772          [[0.034975868, 0.07795891, 0.88706523]]\n",
            "773           [[0.002972916, 0.961947, 0.035080075]]\n",
            "774         [[0.0040663322, 0.9548927, 0.041041054]]\n",
            "775         [[0.0023902596, 0.02071248, 0.97689724]]\n",
            "776         [[0.0036307587, 0.016753485, 0.9796157]]\n",
            "777           [[0.01663685, 0.011680074, 0.9716831]]\n",
            "778           [[0.011170657, 0.56830394, 0.4205254]]\n",
            "779          [[0.016427614, 0.11134117, 0.87223125]]\n",
            "780          [[0.050861403, 0.041430198, 0.9077084]]\n",
            "781           [[0.00561585, 0.006099498, 0.9882846]]\n",
            "782           [[0.018515753, 0.1533662, 0.82811797]]\n",
            "783           [[0.01317332, 0.17789185, 0.80893475]]\n",
            "784         [[0.0036173486, 0.029259976, 0.9671226]]\n",
            "785          [[0.018311186, 0.17326427, 0.80842453]]\n",
            "786          [[0.26289994, 0.105498746, 0.63160133]]\n",
            "787           [[0.8809328, 0.07428119, 0.044785973]]\n",
            "788         [[0.007548563, 0.016081417, 0.97637004]]\n",
            "789            [[0.29445562, 0.20757322, 0.4979711]]\n",
            "790          [[0.9730549, 0.013327267, 0.013617836]]\n",
            "791           [[0.8809328, 0.07428119, 0.044785973]]\n",
            "792         [[0.9624875, 0.0052497135, 0.032262746]]\n",
            "793           [[0.031047635, 0.7636581, 0.20529425]]\n",
            "794          [[0.010656288, 0.8722885, 0.117055126]]\n",
            "795          [[0.014005841, 0.87920654, 0.10678766]]\n",
            "796         [[0.0015728511, 0.9740592, 0.024367912]]\n",
            "797        [[0.0016053384, 0.97170705, 0.026687562]]\n",
            "798         [[0.0038878527, 0.9898493, 0.006262794]]\n",
            "799          [[0.0033550519, 0.09730913, 0.8993359]]\n",
            "800         [[0.0039138854, 0.9710259, 0.025060192]]\n",
            "801           [[0.082593724, 0.8734762, 0.04393002]]\n",
            "802           [[0.031047635, 0.7636581, 0.20529425]]\n",
            "803        [[0.0006942335, 0.0012731384, 0.9980326]]\n",
            "804     [[0.00066343497, 0.00035246156, 0.99898404]]\n",
            "805         [[0.0015458765, 0.84809667, 0.15035747]]\n",
            "806           [[0.23505852, 0.25207153, 0.51286995]]\n",
            "807           [[0.019368721, 0.41857377, 0.5620575]]\n",
            "808           [[0.004529741, 0.5225284, 0.47294188]]\n",
            "809            [[0.010073222, 0.2831661, 0.7067607]]\n",
            "810           [[0.026284277, 0.7647902, 0.20892555]]\n",
            "811         [[0.039299216, 0.0012240801, 0.9594767]]\n",
            "812           [[0.026284277, 0.7647902, 0.20892555]]\n",
            "813          [[0.017574906, 0.77806354, 0.20436157]]\n",
            "814            [[0.07338955, 0.37728405, 0.5493264]]\n",
            "815           [[0.24988794, 0.6534433, 0.096668825]]\n",
            "816           [[0.24988794, 0.6534433, 0.096668825]]\n",
            "817          [[0.035644915, 0.38768375, 0.57667136]]\n",
            "818           [[0.25936872, 0.35445604, 0.38617522]]\n",
            "819           [[0.053082015, 0.1268024, 0.82011557]]\n",
            "820           [[0.010435472, 0.08261832, 0.9069462]]\n",
            "821            [[0.15020819, 0.39603835, 0.4537535]]\n",
            "822          [[0.077276595, 0.091787875, 0.8309356]]\n",
            "823        [[0.0033855939, 0.0014115786, 0.9952029]]\n",
            "824         [[0.9729901, 0.0066663837, 0.020343507]]\n",
            "825           [[0.8672738, 0.014009582, 0.11871661]]\n",
            "826        [[0.003111164, 0.00049650046, 0.9963923]]\n",
            "827       [[0.0019129885, 0.0002947026, 0.99779224]]\n",
            "828           [[0.0022130986, 0.05647392, 0.941313]]\n",
            "829       [[0.0025494497, 0.0030710953, 0.99437946]]\n",
            "830            [[0.26462758, 0.5740301, 0.16134231]]\n",
            "831       [[0.0019129885, 0.0002947026, 0.99779224]]\n",
            "832      [[0.0016107509, 0.00078128855, 0.99760795]]\n",
            "833            [[0.05780825, 0.23267233, 0.7095194]]\n",
            "834            [[0.8318167, 0.02083008, 0.14735329]]\n",
            "835        [[0.0056979493, 0.0021713413, 0.9921307]]\n",
            "836            [[0.19818695, 0.5864195, 0.21539357]]\n",
            "837           [[0.023360962, 0.23362276, 0.7430163]]\n",
            "838            [[0.05780825, 0.23267233, 0.7095194]]\n",
            "839         [[0.013565126, 0.010835542, 0.97559935]]\n",
            "840            [[0.20131779, 0.15718345, 0.6414988]]\n",
            "841           [[0.93891895, 0.013249829, 0.0478313]]\n",
            "842            [[0.023347415, 0.6630654, 0.3135872]]\n",
            "843         [[0.0013702422, 0.006683303, 0.9919464]]\n",
            "844         [[0.008019945, 0.96506417, 0.026915886]]\n",
            "845          [[0.022134399, 0.9479379, 0.029927688]]\n",
            "846       [[0.0017749756, 0.0023273744, 0.99589765]]\n",
            "847         [[0.0035786857, 0.006292069, 0.9901293]]\n",
            "848           [[0.0036831284, 0.2968084, 0.6995084]]\n",
            "849         [[0.020134594, 0.102454804, 0.87741053]]\n",
            "850          [[0.035933416, 0.093078874, 0.8709877]]\n",
            "851          [[0.026858803, 0.070896015, 0.9022452]]\n",
            "852           [[0.049829885, 0.1618371, 0.78833306]]\n",
            "853        [[0.0017539887, 0.0033527298, 0.9948933]]\n",
            "854          [[0.037969816, 0.11769019, 0.84433997]]\n",
            "855           [[0.035434723, 0.13067386, 0.8338914]]\n",
            "856          [[0.032735948, 0.17616884, 0.79109526]]\n",
            "857          [[0.034534458, 0.12283972, 0.84262574]]\n",
            "858           [[0.042356864, 0.15428899, 0.8033541]]\n",
            "859          [[0.043851987, 0.15859643, 0.79755163]]\n",
            "860          [[0.9061351, 0.066585466, 0.027279401]]\n",
            "861          [[0.005031921, 0.046196647, 0.9487714]]\n",
            "862          [[0.0041068764, 0.9178387, 0.07805444]]\n",
            "863             [[0.04261378, 0.575141, 0.38224524]]\n",
            "864           [[0.011516012, 0.25748393, 0.7310001]]\n",
            "865        [[0.0012532105, 0.0010535995, 0.9976931]]\n",
            "866        [[0.0028999262, 0.030816594, 0.96628356]]\n",
            "867          [[0.004440844, 0.115874484, 0.8796847]]\n",
            "868           [[0.015530519, 0.06683989, 0.9176296]]\n",
            "869         [[0.053537752, 0.9431576, 0.0033046133]]\n",
            "870           [[0.008746089, 0.39648035, 0.5947735]]\n",
            "871             [[0.12920313, 0.647616, 0.22318082]]\n",
            "872             [[0.12920313, 0.647616, 0.22318082]]\n",
            "873         [[0.013626731, 0.88184834, 0.104524925]]\n",
            "874             [[0.23981914, 0.5016103, 0.2585706]]\n",
            "875           [[0.21142165, 0.36833292, 0.42024544]]\n",
            "876          [[0.035447605, 0.32289162, 0.64166087]]\n",
            "877        [[0.003050202, 0.0016054012, 0.99534434]]\n",
            "878        [[0.0021583163, 0.007743039, 0.99009866]]\n",
            "879      [[0.0011705733, 0.00045919136, 0.99837023]]\n",
            "880           [[0.7764101, 0.19420876, 0.029381124]]\n",
            "881          [[0.044547334, 0.9510077, 0.004444998]]\n",
            "882           [[0.7764101, 0.19420876, 0.029381124]]\n",
            "883          [[0.035238307, 0.009226411, 0.9555353]]\n",
            "884             [[0.07168095, 0.630719, 0.29760006]]\n",
            "885          [[0.17992805, 0.012008889, 0.80806303]]\n",
            "886        [[0.0013212117, 0.0023234596, 0.9963553]]\n",
            "887         [[0.0020069655, 0.17920774, 0.81878525]]\n",
            "888         [[0.008090721, 0.93968034, 0.052228983]]\n",
            "889         [[0.015589554, 0.014444838, 0.96996564]]\n",
            "890         [[0.0020963526, 0.005000806, 0.9929028]]\n",
            "891       [[0.0039282404, 0.0020766186, 0.99399513]]\n",
            "892          [[0.006577108, 0.17572832, 0.81769454]]\n",
            "893         [[0.003598094, 0.014848439, 0.98155344]]\n",
            "894          [[0.0023496784, 0.9773368, 0.02031348]]\n",
            "895            [[0.011651605, 0.44708735, 0.541261]]\n",
            "896           [[0.037243064, 0.7610981, 0.20165883]]\n",
            "897         [[0.001222418, 0.012694026, 0.98608357]]\n",
            "898         [[0.000896246, 0.0012698235, 0.9978339]]\n",
            "899         [[0.002232574, 0.036450125, 0.96131724]]\n",
            "900          [[0.0006161361, 0.00129571, 0.9980882]]\n",
            "901              [[0.1913211, 0.5201616, 0.2885173]]\n",
            "902          [[0.0064517725, 0.23989007, 0.7536581]]\n",
            "903           [[0.47159833, 0.5060527, 0.022349045]]\n",
            "904           [[0.47159833, 0.5060527, 0.022349045]]\n",
            "905          [[0.008736117, 0.98600566, 0.00525825]]\n",
            "906          [[0.050103486, 0.57433987, 0.37555662]]\n",
            "907           [[0.47159833, 0.5060527, 0.022349045]]\n",
            "908              [[0.1913211, 0.5201616, 0.2885173]]\n",
            "909           [[0.68695444, 0.15558998, 0.15745562]]\n",
            "910           [[0.68695444, 0.15558998, 0.15745562]]\n",
            "911            [[0.30878648, 0.5341496, 0.15706392]]\n",
            "912           [[0.74654824, 0.19079041, 0.06266133]]\n",
            "913              [[0.49119, 0.4933637, 0.015446251]]\n",
            "914          [[0.77430385, 0.102895014, 0.12280114]]\n",
            "915         [[0.0018510995, 0.002475308, 0.9956735]]\n",
            "916          [[0.9401035, 0.046767384, 0.013129164]]\n",
            "917          [[0.9401035, 0.046767384, 0.013129164]]\n",
            "918         [[0.010262616, 0.98143196, 0.008305469]]\n",
            "919           [[0.14145327, 0.77602124, 0.08252549]]\n",
            "920           [[0.025673045, 0.6256606, 0.34866634]]\n",
            "921            [[0.47734115, 0.4275974, 0.09506146]]\n",
            "922        [[0.0034588266, 0.9940937, 0.0024474624]]\n",
            "923          [[0.00811517, 0.045759168, 0.94612575]]\n",
            "924          [[0.013367876, 0.35240963, 0.63422245]]\n",
            "925          [[0.013367876, 0.35240963, 0.63422245]]\n",
            "926            [[0.019650133, 0.7073196, 0.2730302]]\n",
            "927         [[0.004721048, 0.93313944, 0.062139545]]\n",
            "928           [[0.002296728, 0.07022148, 0.9274818]]\n",
            "929           [[0.002296728, 0.07022148, 0.9274818]]\n",
            "930          [[0.0011712498, 0.02164103, 0.9771877]]\n",
            "931        [[0.0036862877, 0.122945264, 0.87336844]]\n",
            "932           [[0.014149558, 0.8897378, 0.09611267]]\n",
            "933         [[0.0026430918, 0.29498023, 0.70237666]]\n",
            "934         [[0.24531463, 0.0036859438, 0.75099945]]\n",
            "935         [[0.24531463, 0.0036859438, 0.75099945]]\n",
            "936           [[0.09184598, 0.75866723, 0.14948677]]\n",
            "937           [[0.090644225, 0.40944895, 0.4999068]]\n",
            "938           [[0.022295177, 0.6538832, 0.32382157]]\n",
            "939          [[0.0054104147, 0.049271584, 0.945318]]\n",
            "940         [[0.0012737187, 0.10480362, 0.89392257]]\n",
            "941          [[0.001264303, 0.27484462, 0.72389114]]\n",
            "942           [[0.090644225, 0.40944895, 0.4999068]]\n",
            "943         [[0.002671119, 0.0005565517, 0.9967722]]\n",
            "944       [[0.0037255406, 0.0007351067, 0.99553937]]\n",
            "945        [[0.0041608973, 0.017075133, 0.97876406]]\n",
            "946           [[0.011056366, 0.06525132, 0.9236922]]\n",
            "947        [[0.0022966152, 0.001247697, 0.99645567]]\n",
            "948           [[0.007489489, 0.29597417, 0.6965364]]\n",
            "949        [[0.0022966152, 0.001247697, 0.99645567]]\n",
            "950           [[0.011056366, 0.06525132, 0.9236922]]\n",
            "951           [[0.058944944, 0.50420713, 0.4368479]]\n",
            "952         [[0.0039188163, 0.20976683, 0.78631437]]\n",
            "953           [[0.0006199423, 0.4455569, 0.5538232]]\n",
            "954           [[0.023108123, 0.8303234, 0.14656848]]\n",
            "955         [[0.0033705106, 0.86728173, 0.12934776]]\n",
            "956           [[0.0064182593, 0.1710014, 0.8225803]]\n",
            "957       [[0.0062884805, 0.0071381815, 0.98657334]]\n",
            "958           [[0.44894168, 0.4948493, 0.056209054]]\n",
            "959           [[0.44894168, 0.4948493, 0.056209054]]\n",
            "960          [[0.0049295444, 0.02478115, 0.9702893]]\n",
            "961        [[0.001211083, 0.0008812943, 0.99790764]]\n",
            "962          [[0.00247951, 0.0037873385, 0.9937331]]\n",
            "963         [[0.0013104718, 0.006028018, 0.9926615]]\n",
            "964          [[0.013994552, 0.09322329, 0.89278215]]\n",
            "965          [[0.0049295444, 0.02478115, 0.9702893]]\n",
            "966            [[0.36224243, 0.5498622, 0.08789532]]\n",
            "967            [[0.36224243, 0.5498622, 0.08789532]]\n",
            "968            [[0.36224243, 0.5498622, 0.08789532]]\n",
            "969             [[0.17203987, 0.35446614, 0.473494]]\n",
            "970            [[0.36224243, 0.5498622, 0.08789532]]\n",
            "971            [[0.36224243, 0.5498622, 0.08789532]]\n",
            "972         [[0.0026575977, 0.15732782, 0.84001464]]\n",
            "973           [[0.015327827, 0.28460437, 0.7000678]]\n",
            "974            [[0.25195467, 0.18411891, 0.5639264]]\n",
            "975            [[0.25195467, 0.18411891, 0.5639264]]\n",
            "976         [[0.002719318, 0.007932164, 0.98934853]]\n",
            "977         [[0.0072800256, 0.13488686, 0.85783315]]\n",
            "978             [[0.025074, 0.33477148, 0.64015454]]\n",
            "979          [[0.007854705, 0.03594377, 0.95620155]]\n",
            "980          [[0.007854705, 0.03594377, 0.95620155]]\n",
            "981          [[0.009370771, 0.011627804, 0.9790014]]\n",
            "982            [[0.22239454, 0.40254197, 0.3750635]]\n",
            "983       [[0.0008415824, 0.0043702377, 0.99478817]]\n",
            "984          [[0.009370771, 0.011627804, 0.9790014]]\n",
            "985          [[0.009370771, 0.011627804, 0.9790014]]\n",
            "986          [[0.047299065, 0.045284923, 0.9074161]]\n",
            "987          [[0.047299065, 0.045284923, 0.9074161]]\n",
            "988         [[0.013834188, 0.0020546827, 0.9841112]]\n",
            "989        [[0.0007432578, 0.00034267138, 0.998914]]\n",
            "990        [[0.0026114404, 0.0024685438, 0.9949201]]\n",
            "991          [[0.0019971216, 0.27700007, 0.7210028]]\n",
            "992           [[0.002490332, 0.12958896, 0.8679207]]\n",
            "993            [[0.004908473, 0.3644456, 0.6306459]]\n",
            "994        [[0.00056699174, 0.004240726, 0.9951923]]\n",
            "995         [[0.0007523819, 0.9050821, 0.094165444]]\n",
            "996          [[0.0015788372, 0.9021404, 0.09628085]]\n",
            "997            [[0.08065816, 0.7197507, 0.19959112]]\n",
            "998           [[0.066826485, 0.8704335, 0.06274004]]\n",
            "999        [[0.0038888964, 0.023700014, 0.97241104]]\n",
            "1000         [[0.0030337349, 0.06494329, 0.9320229]]\n",
            "1001       [[0.0013271855, 0.005931798, 0.99274105]]\n",
            "1002        [[0.002676962, 0.006921591, 0.99040145]]\n",
            "1003          [[0.077578336, 0.5291062, 0.39331546]]\n",
            "1004        [[0.0006367136, 0.00207208, 0.99729115]]\n",
            "1005          [[0.0066216565, 0.5676927, 0.4256856]]\n",
            "1006       [[0.0036182224, 0.044349097, 0.95203274]]\n",
            "1007       [[0.0036182224, 0.044349097, 0.95203274]]\n",
            "1008     [[0.00064577564, 0.00026448772, 0.9990897]]\n",
            "1009           [[0.12947549, 0.6561601, 0.21436438]]\n",
            "1010         [[0.015192855, 0.30927074, 0.67553645]]\n",
            "1011         [[0.011854824, 0.23116453, 0.75698066]]\n",
            "1012         [[0.066483125, 0.049855486, 0.8836614]]\n",
            "1013        [[0.0037671821, 0.061187297, 0.9350455]]\n",
            "1014            [[0.627576, 0.30066565, 0.07175837]]\n",
            "1015         [[0.059098043, 0.34470713, 0.59619486]]\n",
            "1016      [[0.0009831641, 0.0013318838, 0.99768484]]\n",
            "1017        [[0.0018108787, 0.024728587, 0.9734605]]\n",
            "1018          [[0.014710178, 0.26880512, 0.7164847]]\n",
            "1019        [[0.0032144638, 0.002768706, 0.9940169]]\n",
            "1020          [[0.014710178, 0.26880512, 0.7164847]]\n",
            "1021           [[0.4728361, 0.20109867, 0.32606515]]\n",
            "1022         [[0.031460047, 0.022951495, 0.9455884]]\n",
            "1023         [[0.0037715018, 0.22162044, 0.7746081]]\n",
            "1024         [[0.0020236252, 0.18838847, 0.8095879]]\n",
            "1025           [[0.8137021, 0.10848606, 0.07781182]]\n",
            "1026          [[0.05572278, 0.8451005, 0.099176705]]\n",
            "1027        [[0.025030125, 0.016725408, 0.95824444]]\n",
            "1028        [[0.025030125, 0.016725408, 0.95824444]]\n",
            "1029          [[0.021033699, 0.05299361, 0.9259727]]\n",
            "1030         [[0.006067822, 0.01310013, 0.98083216]]\n",
            "1031           [[0.016510777, 0.1792484, 0.8042408]]\n",
            "1032          [[0.017712478, 0.39270282, 0.5895847]]\n",
            "1033         [[0.79747474, 0.08600254, 0.116522714]]\n",
            "1034      [[0.0031195271, 0.0011970594, 0.99568343]]\n",
            "1035       [[0.0020451606, 0.0008137896, 0.9971411]]\n",
            "1036       [[0.0041176416, 0.0011604514, 0.9947219]]\n",
            "1037          [[0.030971972, 0.7959126, 0.17311542]]\n",
            "1038           [[0.03264364, 0.72944075, 0.2379156]]\n",
            "1039          [[0.025657149, 0.5335234, 0.44081947]]\n",
            "1040         [[0.036640316, 0.49709246, 0.46626726]]\n",
            "1041           [[0.05039556, 0.61607975, 0.3335247]]\n",
            "1042         [[0.004170188, 0.9801444, 0.015685406]]\n",
            "1043          [[0.03295724, 0.83518654, 0.13185616]]\n",
            "1044          [[0.012720059, 0.7710818, 0.21619819]]\n",
            "1045       [[0.0026131829, 0.015759962, 0.98162687]]\n",
            "1046      [[0.0024268953, 0.0010968427, 0.99647623]]\n",
            "1047     [[0.00073618157, 0.00032348445, 0.9989404]]\n",
            "1048         [[0.8764862, 0.083123565, 0.040390212]]\n",
            "1049          [[0.02098433, 0.47217244, 0.50684327]]\n",
            "1050             [[0.668355, 0.2612528, 0.07039214]]\n",
            "1051          [[0.024563668, 0.24309824, 0.7323381]]\n",
            "1052            [[0.02902309, 0.168036, 0.80294096]]\n",
            "1053            [[0.02902309, 0.168036, 0.80294096]]\n",
            "1054           [[0.048007097, 0.3836621, 0.5683309]]\n",
            "1055          [[0.0036776515, 0.0651586, 0.9311637]]\n",
            "1056         [[0.062146485, 0.013968688, 0.9238848]]\n",
            "1057         [[0.011340752, 0.24265476, 0.74600446]]\n",
            "1058          [[0.0036776515, 0.0651586, 0.9311637]]\n",
            "1059          [[0.08879389, 0.64088166, 0.27032447]]\n",
            "1060       [[0.0056328196, 0.021977976, 0.97238916]]\n",
            "1061       [[0.0019251533, 0.012558438, 0.98551637]]\n",
            "1062       [[0.001265566, 0.0012111333, 0.99752325]]\n",
            "1063          [[0.44113815, 0.20909823, 0.34976363]]\n",
            "1064          [[0.51619846, 0.38397205, 0.09982954]]\n",
            "1065          [[0.01190705, 0.22500399, 0.76308894]]\n",
            "1066          [[0.01190705, 0.22500399, 0.76308894]]\n",
            "1067          [[0.01190705, 0.22500399, 0.76308894]]\n",
            "1068        [[0.00095465564, 0.00817316, 0.9908722]]\n",
            "1069         [[0.002211483, 0.10379846, 0.89399004]]\n",
            "1070      [[0.0004980993, 0.0007281995, 0.99877375]]\n",
            "1071         [[0.0004959659, 0.007180009, 0.992324]]\n",
            "1072         [[0.002211483, 0.10379846, 0.89399004]]\n",
            "1073            [[0.062380128, 0.5227639, 0.414856]]\n",
            "1074         [[0.006760589, 0.09363755, 0.89960194]]\n",
            "1075           [[0.01590032, 0.010201726, 0.973898]]\n",
            "1076         [[0.0051918323, 0.11604537, 0.8787628]]\n",
            "1077      [[0.00040243054, 0.0023114372, 0.9972861]]\n",
            "1078      [[0.00059941655, 0.0044261706, 0.9949744]]\n",
            "1079       [[0.0010719567, 0.0053843977, 0.9935436]]\n",
            "1080         [[0.008787304, 0.65034926, 0.34086344]]\n",
            "1081        [[0.0044238386, 0.84874135, 0.14683479]]\n",
            "1082        [[0.0033794814, 0.76857173, 0.22804873]]\n",
            "1083        [[0.0046678423, 0.026981464, 0.9683508]]\n",
            "1084        [[0.067372605, 0.037227415, 0.89540005]]\n",
            "1085         [[0.009678269, 0.14323457, 0.84708714]]\n",
            "1086         [[0.0011374307, 0.10143865, 0.8974239]]\n",
            "1087       [[0.0011087967, 0.0038648471, 0.9950263]]\n",
            "1088         [[0.0024213288, 0.06503103, 0.9325476]]\n",
            "1089         [[0.0016780961, 0.17545933, 0.8228626]]\n",
            "1090          [[0.005224662, 0.35708398, 0.6376914]]\n",
            "1091         [[0.16598986, 0.81129336, 0.022716783]]\n",
            "1092        [[0.004794721, 0.0021754876, 0.9930299]]\n",
            "1093          [[0.7303248, 0.25933713, 0.010337997]]\n",
            "1094           [[0.84996325, 0.1441936, 0.00584316]]\n",
            "1095           [[0.16582033, 0.11676856, 0.7174111]]\n",
            "1096        [[0.0072847623, 0.083102874, 0.9096125]]\n",
            "1097       [[0.0013689529, 0.0005433395, 0.9980876]]\n",
            "1098        [[0.015191209, 0.024567543, 0.96024126]]\n",
            "1099           [[0.023991583, 0.4810602, 0.4949482]]\n",
            "1100         [[0.001228275, 0.01264453, 0.98612726]]\n",
            "1101            [[0.00529327, 0.01043871, 0.984268]]\n",
            "1102        [[0.0067671733, 0.14433424, 0.84889853]]\n",
            "1103            [[0.00529327, 0.01043871, 0.984268]]\n",
            "1104            [[0.00529327, 0.01043871, 0.984268]]\n",
            "1105        [[0.0015818342, 0.042298716, 0.9561195]]\n",
            "1106          [[0.02780078, 0.07825818, 0.89394104]]\n",
            "1107     [[0.0005858544, 0.00064042135, 0.99877363]]\n",
            "1108      [[0.00048352504, 0.008391315, 0.99112517]]\n",
            "1109     [[0.00045765177, 0.0017162515, 0.99782616]]\n",
            "1110     [[0.0005858544, 0.00064042135, 0.99877363]]\n",
            "1111       [[0.0028700645, 0.0067937374, 0.9903362]]\n",
            "1112         [[0.001362367, 0.00515038, 0.99348724]]\n",
            "1113          [[0.0255487, 0.091556355, 0.88289493]]\n",
            "1114     [[0.0013227585, 0.00051588746, 0.99816126]]\n",
            "1115         [[0.026111245, 0.31184193, 0.66204685]]\n",
            "1116           [[0.26747963, 0.0466693, 0.68585104]]\n",
            "1117        [[0.0017093417, 0.013568096, 0.9847227]]\n",
            "1118          [[0.0255487, 0.091556355, 0.88289493]]\n",
            "1119          [[0.0255487, 0.091556355, 0.88289493]]\n",
            "1120         [[0.041456133, 0.034653123, 0.9238908]]\n",
            "1121         [[0.010910133, 0.0027409494, 0.986349]]\n",
            "1122         [[0.75560766, 0.21747418, 0.026918149]]\n",
            "1123         [[0.12617455, 0.84120035, 0.032625105]]\n",
            "1124            [[0.015000337, 0.117153, 0.8678467]]\n",
            "1125      [[0.0011532584, 0.00029303922, 0.9985537]]\n",
            "1126           [[0.025091073, 0.2648855, 0.7100234]]\n",
            "1127          [[0.020973941, 0.7657456, 0.21328044]]\n",
            "1128          [[0.012081415, 0.7779302, 0.20998842]]\n",
            "1129        [[0.0028933126, 0.88531655, 0.11179014]]\n",
            "1130       [[0.0019523298, 0.0022046939, 0.9958429]]\n",
            "1131         [[0.005207982, 0.92474276, 0.07004927]]\n",
            "1132          [[0.017996613, 0.23124927, 0.7507541]]\n",
            "1133          [[0.016653847, 0.54437006, 0.4389761]]\n",
            "1134             [[0.41798183, 0.266086, 0.3159322]]\n",
            "1135       [[0.0026091486, 0.009005384, 0.98838556]]\n",
            "1136       [[0.0026091486, 0.009005384, 0.98838556]]\n",
            "1137         [[0.017728431, 0.45360628, 0.52866536]]\n",
            "1138       [[0.0026091486, 0.009005384, 0.98838556]]\n",
            "1139          [[0.022396415, 0.7403247, 0.23727886]]\n",
            "1140           [[0.045030616, 0.3652326, 0.5897368]]\n",
            "1141        [[0.0034959146, 0.79999626, 0.19650784]]\n",
            "1142          [[0.003064107, 0.7416515, 0.25528434]]\n",
            "1143         [[0.010484502, 0.04863182, 0.94088376]]\n",
            "1144          [[0.6707615, 0.28267547, 0.046562962]]\n",
            "1145          [[0.6707615, 0.28267547, 0.046562962]]\n",
            "1146      [[0.0033956233, 0.0067639085, 0.98984045]]\n",
            "1147          [[0.01029343, 0.08169734, 0.90800923]]\n",
            "1148      [[0.0017013554, 0.00028580907, 0.9980129]]\n",
            "1149         [[0.09277171, 0.092221074, 0.81500715]]\n",
            "1150        [[0.0025773305, 0.043401383, 0.9540213]]\n",
            "1151        [[0.0050650383, 0.16499276, 0.82994217]]\n",
            "1152         [[0.09277171, 0.092221074, 0.81500715]]\n",
            "1153        [[0.0025773305, 0.043401383, 0.9540213]]\n",
            "1154           [[0.5204515, 0.26587507, 0.21367347]]\n",
            "1155           [[0.5204515, 0.26587507, 0.21367347]]\n",
            "1156       [[0.001087284, 0.0021353783, 0.99677736]]\n",
            "1157        [[0.0020265442, 0.0011894706, 0.996784]]\n",
            "1158          [[0.0022284577, 0.0013716116, 0.9964]]\n",
            "1159        [[0.0033715428, 0.013663112, 0.9829653]]\n",
            "1160        [[0.0062137963, 0.01671225, 0.97707397]]\n",
            "1161           [[0.014296397, 0.4175857, 0.5681179]]\n",
            "1162         [[0.006986542, 0.006610718, 0.9864028]]\n",
            "1163       [[0.0032051373, 0.0024012928, 0.9943936]]\n",
            "1164        [[0.0056895423, 0.79926336, 0.19504705]]\n",
            "1165           [[0.014296397, 0.4175857, 0.5681179]]\n",
            "1166          [[0.009511812, 0.955057, 0.035431143]]\n",
            "1167           [[0.020315196, 0.7288141, 0.2508707]]\n",
            "1168           [[0.020315196, 0.7288141, 0.2508707]]\n",
            "1169       [[0.0012115171, 0.0030433815, 0.9957451]]\n",
            "1170         [[0.004354297, 0.10191895, 0.89372677]]\n",
            "1171           [[0.020315196, 0.7288141, 0.2508707]]\n",
            "1172         [[0.004549476, 0.025942381, 0.9695081]]\n",
            "1173          [[0.006815488, 0.24451533, 0.7486692]]\n",
            "1174           [[0.31341088, 0.6217678, 0.06482129]]\n",
            "1175            [[0.4804316, 0.4882175, 0.03135094]]\n",
            "1176          [[0.04241476, 0.9046404, 0.052944917]]\n",
            "1177         [[0.009870361, 0.020627433, 0.9695022]]\n",
            "1178          [[0.00953252, 0.028097587, 0.9623699]]\n",
            "1179        [[0.0076956055, 0.021257238, 0.9710472]]\n",
            "1180       [[0.0076747052, 0.0011302527, 0.9911951]]\n",
            "1181          [[0.00620158, 0.003503923, 0.9902946]]\n",
            "1182       [[0.004573424, 0.00046743505, 0.9949591]]\n",
            "1183      [[0.0028659352, 0.0004371257, 0.99669695]]\n",
            "1184        [[0.0012619616, 0.013495397, 0.9852426]]\n",
            "1185    [[0.00065848965, 0.00031550284, 0.99902606]]\n",
            "1186         [[0.0024850788, 0.009533937, 0.987981]]\n",
            "1187          [[0.013406027, 0.15592864, 0.8306653]]\n",
            "1188        [[0.0012612491, 0.002403781, 0.9963349]]\n",
            "1189        [[0.0053416616, 0.029459417, 0.9651989]]\n",
            "1190      [[0.0013152978, 0.0024336388, 0.99625105]]\n",
            "1191        [[0.0016690545, 0.005499309, 0.9928316]]\n",
            "1192         [[0.019100325, 0.53417695, 0.44672272]]\n",
            "1193        [[0.026921785, 0.009612053, 0.96346617]]\n",
            "1194       [[0.009002595, 0.0012782997, 0.98971903]]\n",
            "1195       [[0.005487011, 0.00046258743, 0.9940503]]\n",
            "1196         [[0.002989128, 0.044154406, 0.9528564]]\n",
            "1197         [[0.0008365223, 0.04081863, 0.9583448]]\n",
            "1198         [[0.0008733157, 0.09504837, 0.9040783]]\n",
            "1199        [[0.0010215226, 0.66685563, 0.33212283]]\n",
            "1200        [[0.0024610157, 0.16746306, 0.83007586]]\n",
            "1201        [[0.011554609, 0.005182302, 0.98326313]]\n",
            "1202        [[0.011554609, 0.005182302, 0.98326313]]\n",
            "1203          [[0.07613686, 0.077086665, 0.8467765]]\n",
            "1204          [[0.16111022, 0.42547017, 0.41341963]]\n",
            "1205        [[0.004979273, 0.035586767, 0.95943403]]\n",
            "1206         [[0.0009150424, 0.02041866, 0.9786663]]\n",
            "1207          [[0.15395615, 0.70999706, 0.13604681]]\n",
            "1208           [[0.20236988, 0.5501293, 0.24750084]]\n",
            "1209          [[0.25315687, 0.7299387, 0.016904403]]\n",
            "1210         [[0.03793687, 0.93303996, 0.029023184]]\n",
            "1211          [[0.09534369, 0.8679085, 0.036747783]]\n",
            "1212           [[0.5517257, 0.4225608, 0.025713483]]\n",
            "1213         [[0.002401052, 0.005358787, 0.9922402]]\n",
            "1214          [[0.032691684, 0.47781888, 0.4894894]]\n",
            "1215         [[0.00261818, 0.057259988, 0.94012177]]\n",
            "1216          [[0.032691684, 0.47781888, 0.4894894]]\n",
            "1217         [[0.0011144041, 0.30295527, 0.6959303]]\n",
            "1218     [[0.0010126409, 0.00030593702, 0.99868137]]\n",
            "1219       [[0.001003383, 0.0026235278, 0.99637306]]\n",
            "1220         [[0.054958653, 0.33520532, 0.60983604]]\n",
            "1221       [[0.0020269742, 0.0049355133, 0.9930375]]\n",
            "1222          [[0.015079923, 0.04116693, 0.9437531]]\n",
            "1223           [[0.26358005, 0.0492716, 0.68714833]]\n",
            "1224         [[0.05336258, 0.068755575, 0.87788177]]\n",
            "1225         [[0.009707531, 0.40075195, 0.58954054]]\n",
            "1226       [[0.006185263, 0.0020798747, 0.99173486]]\n",
            "1227          [[0.013757969, 0.090228125, 0.896014]]\n",
            "1228           [[0.04267778, 0.12764838, 0.8296739]]\n",
            "1229           [[0.060993694, 0.5974293, 0.3415771]]\n",
            "1230           [[0.060993694, 0.5974293, 0.3415771]]\n",
            "1231       [[0.0060032816, 0.0012175546, 0.9927792]]\n",
            "1232          [[0.8557047, 0.12430349, 0.019991705]]\n",
            "1233         [[0.009236652, 0.017885847, 0.9728775]]\n",
            "1234         [[0.00324672, 0.045777846, 0.95097536]]\n",
            "1235            [[0.044996895, 0.478016, 0.4769871]]\n",
            "1236       [[0.0049689687, 0.070289314, 0.92474174]]\n",
            "1237         [[0.00324672, 0.045777846, 0.95097536]]\n",
            "1238         [[0.002585465, 0.007676891, 0.9897377]]\n",
            "1239       [[0.0006784276, 0.0083854105, 0.9909362]]\n",
            "1240       [[0.004564681, 0.0042731757, 0.99116206]]\n",
            "1241         [[0.005916048, 0.19287008, 0.80121386]]\n",
            "1242         [[0.0137244975, 0.5324021, 0.45387337]]\n",
            "1243          [[0.0054403264, 0.764783, 0.22977664]]\n",
            "1244        [[0.0054620896, 0.95140517, 0.04313272]]\n",
            "1245        [[0.0011913725, 0.004863986, 0.9939446]]\n",
            "1246        [[0.0009761816, 0.9346353, 0.064388454]]\n",
            "1247         [[0.0037544232, 0.5754513, 0.42079422]]\n",
            "1248        [[0.0011913725, 0.004863986, 0.9939446]]\n",
            "1249        [[0.013714731, 0.97837603, 0.007909224]]\n",
            "1250         [[0.0051937075, 0.32246462, 0.6723417]]\n",
            "1251            [[0.09087896, 0.72462505, 0.184496]]\n",
            "1252           [[0.20872618, 0.5378417, 0.25343212]]\n",
            "1253          [[0.01268674, 0.107436225, 0.8798771]]\n",
            "1254        [[0.0019843706, 0.032970108, 0.9650455]]\n",
            "1255          [[0.01268674, 0.107436225, 0.8798771]]\n",
            "1256          [[0.01458879, 0.054467067, 0.9309441]]\n",
            "1257        [[0.0119888745, 0.14132617, 0.84668493]]\n",
            "1258      [[0.0016514423, 0.0032701115, 0.99507844]]\n",
            "1259      [[0.0003126883, 0.0055871964, 0.99410003]]\n",
            "1260         [[0.043941863, 0.73993504, 0.21612307]]\n",
            "1261        [[0.0055887448, 0.009214414, 0.9851968]]\n",
            "1262        [[0.0052954284, 0.0011675613, 0.993537]]\n",
            "1263           [[0.11160794, 0.28662717, 0.6017649]]\n",
            "1264       [[0.0023472088, 0.0056753485, 0.9919775]]\n",
            "1265        [[0.0021381187, 0.023282217, 0.9745796]]\n",
            "1266       [[0.0014376675, 0.006951996, 0.99161035]]\n",
            "1267         [[0.002431576, 0.039117735, 0.9584506]]\n",
            "1268           [[0.14568949, 0.27548158, 0.5788289]]\n",
            "1269          [[0.07300997, 0.75352216, 0.17346784]]\n",
            "1270          [[0.11937025, 0.74310267, 0.13752705]]\n",
            "1271             [[0.844277, 0.096327, 0.059396017]]\n",
            "1272         [[0.0043853605, 0.72946215, 0.2661525]]\n",
            "1273       [[0.0035537782, 0.96231616, 0.034130093]]\n",
            "1274          [[0.06551332, 0.19320776, 0.74127895]]\n",
            "1275           [[0.027936218, 0.45467177, 0.517392]]\n",
            "1276           [[0.031288482, 0.9356891, 0.0330224]]\n",
            "1277         [[0.19896269, 0.77750653, 0.023530798]]\n",
            "1278          [[0.003339763, 0.014534203, 0.982126]]\n",
            "1279          [[0.025420247, 0.9028411, 0.07173869]]\n",
            "1280          [[0.025420247, 0.9028411, 0.07173869]]\n",
            "1281        [[0.0079506235, 0.12307465, 0.86897475]]\n",
            "1282          [[0.007745985, 0.40239593, 0.5898581]]\n",
            "1283        [[0.0018394736, 0.012542756, 0.9856177]]\n",
            "1284         [[0.0033233657, 0.013204625, 0.983472]]\n",
            "1285        [[0.005336311, 0.061985623, 0.93267816]]\n",
            "1286         [[0.025296925, 0.52528584, 0.44941726]]\n",
            "1287     [[0.0018913953, 0.00046836532, 0.99764025]]\n",
            "1288         [[0.010850165, 0.981546, 0.0076037957]]\n",
            "1289            [[0.26194882, 0.726928, 0.01112318]]\n",
            "1290          [[0.20319642, 0.066706344, 0.7300972]]\n",
            "1291        [[0.0031475765, 0.00462396, 0.99222845]]\n",
            "1292          [[0.44919688, 0.17604752, 0.37475565]]\n",
            "1293         [[0.0038821022, 0.03425776, 0.9618601]]\n",
            "1294         [[0.0028677306, 0.007386335, 0.989746]]\n",
            "1295         [[0.048163805, 0.59857285, 0.35326335]]\n",
            "1296      [[0.0055584563, 0.0029666917, 0.99147487]]\n",
            "1297        [[0.007773496, 0.044438694, 0.94778776]]\n",
            "1298         [[0.005673307, 0.9652618, 0.029064849]]\n",
            "1299           [[0.010677884, 0.18072514, 0.808597]]\n",
            "1300          [[0.027513972, 0.19579713, 0.7766889]]\n",
            "1301           [[0.010677884, 0.18072514, 0.808597]]\n",
            "1302           [[0.08805103, 0.22906919, 0.6828798]]\n",
            "1303         [[0.0047073155, 0.7302747, 0.26501805]]\n",
            "1304          [[0.009478568, 0.29120922, 0.6993122]]\n",
            "1305          [[0.009478568, 0.29120922, 0.6993122]]\n",
            "1306            [[0.020794662, 0.065422, 0.9137834]]\n",
            "1307      [[0.0022494642, 0.00088303105, 0.9968675]]\n",
            "1308        [[0.0026787478, 0.002589309, 0.9947319]]\n",
            "1309      [[0.0015437369, 0.0012560923, 0.99720025]]\n",
            "1310       [[0.008263218, 0.0015245717, 0.99021226]]\n",
            "1311          [[0.02477534, 0.21913145, 0.75609326]]\n",
            "1312         [[0.029063752, 0.03532012, 0.93561614]]\n",
            "1313         [[0.0098465085, 0.14443615, 0.8457173]]\n",
            "1314         [[0.0098465085, 0.14443615, 0.8457173]]\n",
            "1315         [[0.0036199212, 0.08905999, 0.9073201]]\n",
            "1316          [[0.009324341, 0.15783927, 0.8328364]]\n",
            "1317          [[0.009324341, 0.15783927, 0.8328364]]\n",
            "1318      [[0.0011122723, 0.00046220692, 0.9984256]]\n",
            "1319      [[0.00091607176, 0.0035435522, 0.9955403]]\n",
            "1320     [[0.00089497847, 0.00061811757, 0.9984869]]\n",
            "1321       [[0.0005792386, 0.0025555962, 0.9968652]]\n",
            "1322          [[0.041805424, 0.6791586, 0.27903593]]\n",
            "1323          [[0.041805424, 0.6791586, 0.27903593]]\n",
            "1324          [[0.041805424, 0.6791586, 0.27903593]]\n",
            "1325          [[0.041805424, 0.6791586, 0.27903593]]\n",
            "1326          [[0.001529821, 0.985759, 0.012711237]]\n",
            "1327          [[0.008219423, 0.2686803, 0.72310024]]\n",
            "1328        [[0.0006005571, 0.023115132, 0.9762843]]\n",
            "1329       [[0.0013355124, 0.029732266, 0.96893233]]\n",
            "1330          [[0.003541174, 0.8317318, 0.16472708]]\n",
            "1331         [[0.0027503117, 0.11007212, 0.8871775]]\n",
            "1332        [[0.0048586233, 0.019296706, 0.9758447]]\n",
            "1333         [[0.004174732, 0.01666293, 0.97916245]]\n",
            "1334        [[0.0148969535, 0.9813348, 0.003768205]]\n",
            "1335          [[0.010056004, 0.18738332, 0.8025607]]\n",
            "1336          [[0.030383732, 0.7415773, 0.22803892]]\n",
            "1337       [[0.0055453777, 0.008948152, 0.98550653]]\n",
            "1338        [[0.0020804289, 0.000534201, 0.9973853]]\n",
            "1339          [[0.01682678, 0.043096527, 0.9400767]]\n",
            "1340        [[0.0037368245, 0.55340254, 0.44286063]]\n",
            "1341       [[0.033970755, 0.0077724354, 0.95825684]]\n",
            "1342          [[0.014564986, 0.11463233, 0.8708027]]\n",
            "1343           [[0.85772824, 0.11147644, 0.0307953]]\n",
            "1344           [[0.2277192, 0.42489916, 0.34738165]]\n",
            "1345           [[0.15584593, 0.32583517, 0.5183189]]\n",
            "1346           [[0.06608583, 0.5167579, 0.41715628]]\n",
            "1347           [[0.019365573, 0.1386079, 0.8420265]]\n",
            "1348       [[0.0065281736, 0.0046347785, 0.9888371]]\n",
            "1349           [[0.25585786, 0.6879051, 0.05623707]]\n",
            "1350          [[0.20728812, 0.7693678, 0.023344114]]\n",
            "1351      [[0.0027302136, 0.0009782248, 0.99629164]]\n",
            "1352          [[0.052514713, 0.3899462, 0.55753905]]\n",
            "1353      [[0.0032296025, 0.00072309864, 0.9960473]]\n",
            "1354           [[0.009766756, 0.0837284, 0.9065048]]\n",
            "1355          [[0.67138934, 0.16381316, 0.16479756]]\n",
            "1356           [[0.0466249, 0.21356232, 0.73981273]]\n",
            "1357          [[0.29714072, 0.6465462, 0.056313086]]\n",
            "1358       [[0.0022475864, 0.0036017138, 0.9941507]]\n",
            "1359           [[0.007136977, 0.2979311, 0.6949319]]\n",
            "1360       [[0.0016107609, 0.0012954774, 0.9970938]]\n",
            "1361           [[0.26140422, 0.022380752, 0.716215]]\n",
            "1362         [[0.54166275, 0.054653328, 0.40368387]]\n",
            "1363           [[0.08450167, 0.06246582, 0.8530326]]\n",
            "1364         [[0.0085540665, 0.28436276, 0.7070831]]\n",
            "1365          [[0.007897389, 0.24906944, 0.7430332]]\n",
            "1366          [[0.03413534, 0.044775803, 0.9210888]]\n",
            "1367         [[0.034659784, 0.34075567, 0.62458456]]\n",
            "1368           [[0.008408538, 0.6225242, 0.3690673]]\n",
            "1369         [[0.0048140967, 0.2926125, 0.70257336]]\n",
            "1370          [[0.059588987, 0.8212017, 0.11920936]]\n",
            "1371           [[0.048584823, 0.32050917, 0.630906]]\n",
            "1372      [[0.0010988835, 0.00067882985, 0.9982222]]\n",
            "1373          [[0.10163864, 0.031694055, 0.8666673]]\n",
            "1374          [[0.009011809, 0.32416356, 0.6668246]]\n",
            "1375          [[0.004403611, 0.9659232, 0.02967327]]\n",
            "1376        [[0.0006709454, 0.10964095, 0.88968813]]\n",
            "1377         [[0.0007355638, 0.05841318, 0.9408512]]\n",
            "1378       [[0.0007400262, 0.026446136, 0.97281384]]\n",
            "1379       [[0.00048385764, 0.003161484, 0.9963547]]\n",
            "1380           [[0.7387121, 0.22509086, 0.03619708]]\n",
            "1381          [[0.008744265, 0.16107924, 0.8301765]]\n",
            "1382        [[0.95925045, 0.022887541, 0.017861975]]\n",
            "1383           [[0.7038218, 0.26025426, 0.03592405]]\n",
            "1384             [[0.54789, 0.4313003, 0.020809663]]\n",
            "1385       [[0.001835971, 0.00054970785, 0.9976144]]\n",
            "1386       [[0.019487843, 0.0038657677, 0.97664636]]\n",
            "1387       [[0.0019970327, 0.010759913, 0.98724306]]\n",
            "1388          [[0.21474789, 0.31343296, 0.47181916]]\n",
            "1389          [[0.028299948, 0.14672078, 0.8249793]]\n",
            "1390           [[0.033039704, 0.06212327, 0.904837]]\n",
            "1391           [[0.033039704, 0.06212327, 0.904837]]\n",
            "1392            [[0.05949069, 0.5454139, 0.3950954]]\n",
            "1393       [[0.0027358674, 0.0003522983, 0.9969119]]\n",
            "1394        [[0.017066132, 0.0101770405, 0.9727569]]\n",
            "1395       [[0.0038586806, 0.96726114, 0.028880173]]\n",
            "1396         [[0.007742061, 0.91247964, 0.07977826]]\n",
            "1397           [[0.03571415, 0.67985624, 0.2844296]]\n",
            "1398        [[0.0041116676, 0.04633897, 0.94954926]]\n",
            "1399         [[0.0068142265, 0.9041256, 0.08906021]]\n",
            "1400          [[0.013686523, 0.8427295, 0.14358398]]\n",
            "1401       [[0.0033781605, 0.008900743, 0.98772115]]\n",
            "1402         [[0.010233392, 0.92766476, 0.06210182]]\n",
            "1403           [[0.013251624, 0.1718979, 0.8148505]]\n",
            "1404          [[0.14670867, 0.51716197, 0.33612934]]\n",
            "1405          [[0.03374915, 0.33011156, 0.63613933]]\n",
            "1406            [[0.22668648, 0.5291169, 0.2441966]]\n",
            "1407            [[0.14933808, 0.5888465, 0.2618154]]\n",
            "1408          [[0.024728583, 0.6690501, 0.30622134]]\n",
            "1409          [[0.030204777, 0.8666603, 0.10313491]]\n",
            "1410           [[0.029175667, 0.4043396, 0.5664847]]\n",
            "1411           [[0.012920834, 0.5038858, 0.4831934]]\n",
            "1412          [[0.022896854, 0.7564723, 0.22063088]]\n",
            "1413        [[0.0017319175, 0.039947413, 0.9583206]]\n",
            "1414         [[0.0056863725, 0.18035331, 0.8139603]]\n",
            "1415         [[0.058882315, 0.22602426, 0.71509343]]\n",
            "1416          [[0.062100694, 0.2724394, 0.66545993]]\n",
            "1417            [[0.08686733, 0.2827476, 0.6303851]]\n",
            "1418          [[0.007422013, 0.04312589, 0.9494521]]\n",
            "1419       [[0.0021284171, 0.0011017405, 0.9967699]]\n",
            "1420         [[0.008419392, 0.036800295, 0.9547803]]\n",
            "1421      [[0.00095345377, 0.002358518, 0.99668807]]\n",
            "1422       [[0.0013405234, 0.0022459885, 0.9964134]]\n",
            "1423        [[0.013330365, 0.95984167, 0.026827993]]\n",
            "1424          [[0.14249209, 0.64220685, 0.21530105]]\n",
            "1425        [[0.0053834612, 0.09873751, 0.89587903]]\n",
            "1426           [[0.02506854, 0.29359075, 0.6813407]]\n",
            "1427         [[0.035418767, 0.42377955, 0.54080164]]\n",
            "1428        [[0.0047973963, 0.9375964, 0.057606217]]\n",
            "1429        [[0.0049625547, 0.93276733, 0.06227012]]\n",
            "1430           [[0.02506854, 0.29359075, 0.6813407]]\n",
            "1431          [[0.01512355, 0.23129672, 0.75357974]]\n",
            "1432          [[0.01566885, 0.018129066, 0.9662021]]\n",
            "1433          [[0.017124278, 0.68398184, 0.2988939]]\n",
            "1434           [[0.060316406, 0.3752334, 0.5644502]]\n",
            "1435          [[0.01566885, 0.018129066, 0.9662021]]\n",
            "1436          [[0.15266597, 0.59018636, 0.25714767]]\n",
            "1437           [[0.28046414, 0.35491946, 0.3646164]]\n",
            "1438       [[0.0156082325, 0.041290045, 0.94310164]]\n",
            "1439          [[0.08400451, 0.40588957, 0.51010597]]\n",
            "1440        [[0.0033641753, 0.10890834, 0.88772744]]\n",
            "1441         [[0.014149458, 0.84562504, 0.14022554]]\n",
            "1442          [[0.50140345, 0.44505298, 0.05354362]]\n",
            "1443           [[0.046922956, 0.8978145, 0.0552625]]\n",
            "1444         [[0.058184776, 0.8903361, 0.051479165]]\n",
            "1445           [[0.45496652, 0.4472909, 0.09774262]]\n",
            "1446         [[0.037035998, 0.027327126, 0.9356369]]\n",
            "1447           [[0.16750132, 0.16398415, 0.6685146]]\n",
            "1448          [[0.22012612, 0.19733949, 0.58253443]]\n",
            "1449           [[0.8422333, 0.048862346, 0.1089044]]\n",
            "1450            [[0.2677507, 0.2904959, 0.44175336]]\n",
            "1451           [[0.25053212, 0.21023437, 0.5392335]]\n",
            "1452           [[0.25053212, 0.21023437, 0.5392335]]\n",
            "1453       [[0.0023566473, 0.9919293, 0.0057141357]]\n",
            "1454           [[0.0336289, 0.9299115, 0.036459643]]\n",
            "1455       [[0.0013107196, 0.0051603382, 0.9935289]]\n",
            "1456          [[0.04872142, 0.9405619, 0.010716699]]\n",
            "1457         [[0.026176192, 0.81796473, 0.15585907]]\n",
            "1458           [[0.02859357, 0.8448873, 0.12651914]]\n",
            "1459        [[0.0016228969, 0.0013000732, 0.997077]]\n",
            "1460        [[0.003755155, 0.0125409495, 0.9837039]]\n",
            "1461          [[0.005197789, 0.10807447, 0.8867278]]\n",
            "1462      [[0.00088905974, 0.0009544666, 0.9981565]]\n",
            "1463        [[0.0022935106, 0.079754345, 0.9179521]]\n",
            "1464       [[0.0018221592, 0.018700609, 0.97947717]]\n",
            "1465         [[0.0030982988, 0.7856213, 0.21128036]]\n",
            "1466        [[0.0017354802, 0.29594135, 0.70232314]]\n",
            "1467       [[0.0011640057, 0.008657035, 0.99017894]]\n",
            "1468         [[0.0019352187, 0.03941348, 0.9586513]]\n",
            "1469         [[0.022588426, 0.74222726, 0.23518431]]\n",
            "1470       [[0.0049038716, 0.0088479975, 0.9862482]]\n",
            "1471       [[0.0010110092, 0.0023788589, 0.9966101]]\n",
            "1472       [[0.0029981048, 0.022274775, 0.97472715]]\n",
            "1473        [[0.94035894, 0.047680866, 0.011960254]]\n",
            "1474         [[0.005374474, 0.11087658, 0.88374895]]\n",
            "1475       [[0.0017147814, 0.0012784817, 0.9970067]]\n",
            "1476        [[0.0040232143, 0.023841264, 0.9721354]]\n",
            "1477       [[0.0018669406, 0.0041982676, 0.9939347]]\n",
            "1478          [[0.00198349, 0.22206837, 0.77594817]]\n",
            "1479           [[0.3471238, 0.5741372, 0.078738995]]\n",
            "1480         [[0.007648223, 0.9758355, 0.016516255]]\n",
            "1481         [[0.028477203, 0.65760523, 0.31391758]]\n",
            "1482       [[0.91673017, 0.075810574, 0.0074592843]]\n",
            "1483         [[0.87305903, 0.11792118, 0.009019788]]\n",
            "1484         [[0.08923876, 0.008649073, 0.90211225]]\n",
            "1485           [[0.47267634, 0.29245782, 0.2348658]]\n",
            "1486          [[0.31740212, 0.6538565, 0.028741391]]\n",
            "1487          [[0.7868064, 0.16185462, 0.051338937]]\n",
            "1488           [[0.47267634, 0.29245782, 0.2348658]]\n",
            "1489         [[0.39064953, 0.53055257, 0.078797914]]\n",
            "1490          [[0.44613382, 0.36739177, 0.18647434]]\n",
            "1491          [[0.16062023, 0.64720094, 0.19217882]]\n",
            "1492         [[0.016789608, 0.006848565, 0.9763618]]\n",
            "1493          [[0.16062023, 0.64720094, 0.19217882]]\n",
            "1494        [[0.011033553, 0.008721584, 0.98024493]]\n",
            "1495           [[0.004439812, 0.61335915, 0.382201]]\n",
            "1496         [[0.20884097, 0.74475276, 0.046406277]]\n",
            "1497         [[0.20884097, 0.74475276, 0.046406277]]\n",
            "1498           [[0.3065836, 0.6804831, 0.012933256]]\n",
            "1499           [[0.01175263, 0.51919156, 0.4690558]]\n",
            "1500         [[0.012817305, 0.065008104, 0.9221747]]\n",
            "1501     [[0.0023623833, 0.00063901435, 0.99699855]]\n",
            "1502          [[0.009010591, 0.37034485, 0.6206445]]\n",
            "1503      [[0.0010056723, 0.0012566942, 0.99773765]]\n",
            "1504         [[0.0039354116, 0.002872541, 0.993192]]\n",
            "1505          [[0.008320588, 0.37172002, 0.6199595]]\n",
            "1506       [[0.0040072394, 0.0005104525, 0.9954823]]\n",
            "1507         [[0.00465792, 0.0008780116, 0.9944641]]\n",
            "1508         [[0.035254057, 0.71024215, 0.25450382]]\n",
            "1509        [[0.0029463887, 0.06599009, 0.93106353]]\n",
            "1510         [[0.001701455, 0.011731825, 0.9865667]]\n",
            "1511       [[0.0024593999, 0.022932103, 0.97460854]]\n",
            "1512       [[0.0013081143, 0.0025699874, 0.9961218]]\n",
            "1513        [[0.0019869434, 0.010072183, 0.9879409]]\n",
            "1514        [[0.0029463887, 0.06599009, 0.93106353]]\n",
            "1515         [[0.004406691, 0.02759206, 0.96800125]]\n",
            "1516       [[0.0016453243, 0.0038181038, 0.9945365]]\n",
            "1517      [[0.0021720459, 0.0033135635, 0.99451435]]\n",
            "1518       [[0.0012402742, 0.008053562, 0.99070615]]\n",
            "1519             [[0.19950533, 0.521563, 0.2789317]]\n",
            "1520         [[0.74664664, 0.20463318, 0.048720174]]\n",
            "1521           [[0.7093919, 0.1672402, 0.123367906]]\n",
            "1522         [[0.72675633, 0.23590408, 0.037339572]]\n",
            "1523           [[0.08340474, 0.03214287, 0.8844524]]\n",
            "1524           [[0.6622776, 0.06590336, 0.27181903]]\n",
            "1525          [[0.24441275, 0.57171756, 0.18386964]]\n",
            "1526           [[0.05111285, 0.54036564, 0.4085215]]\n",
            "1527      [[0.0038296934, 0.0018826554, 0.99428767]]\n",
            "1528           [[0.11365587, 0.5584559, 0.32788825]]\n",
            "1529           [[0.3799557, 0.25018516, 0.36985916]]\n",
            "1530           [[0.3799557, 0.25018516, 0.36985916]]\n",
            "1531         [[0.008463967, 0.022813762, 0.9687223]]\n",
            "1532         [[0.008463967, 0.022813762, 0.9687223]]\n",
            "1533        [[0.0015434431, 0.0060286066, 0.992428]]\n",
            "1534        [[0.0035717173, 0.100790575, 0.8956377]]\n",
            "1535       [[0.0026622848, 0.0013629746, 0.9959747]]\n",
            "1536            [[0.2903032, 0.07508354, 0.6346133]]\n",
            "1537           [[0.71544784, 0.1497693, 0.13478291]]\n",
            "1538           [[0.8565041, 0.052525345, 0.0909705]]\n",
            "1539          [[0.30748472, 0.038830366, 0.6536849]]\n",
            "1540      [[0.0069001378, 0.0011576056, 0.99194217]]\n",
            "1541      [[0.0019108233, 0.0027614331, 0.99532783]]\n",
            "1542      [[0.0019108233, 0.0027614331, 0.99532783]]\n",
            "1543      [[0.00056983606, 0.0065873545, 0.9928428]]\n",
            "1544      [[0.0019108233, 0.0027614331, 0.99532783]]\n",
            "1545         [[0.058965042, 0.38784075, 0.55319417]]\n",
            "1546         [[0.075079836, 0.45126686, 0.47365335]]\n",
            "1547         [[0.058965042, 0.38784075, 0.55319417]]\n",
            "1548          [[0.009836119, 0.30386752, 0.6862963]]\n",
            "1549           [[0.53984123, 0.436625, 0.023533802]]\n",
            "1550          [[0.17684028, 0.65324336, 0.16991632]]\n",
            "1551          [[0.17684028, 0.65324336, 0.16991632]]\n",
            "1552          [[0.008791666, 0.27496657, 0.7162418]]\n",
            "1553          [[0.097585835, 0.4118361, 0.49057811]]\n",
            "1554      [[0.0008692655, 0.0011836658, 0.99794704]]\n",
            "1555          [[0.097585835, 0.4118361, 0.49057811]]\n",
            "1556          [[0.010800333, 0.07044488, 0.9187548]]\n",
            "1557         [[0.083630234, 0.31008348, 0.60628635]]\n",
            "1558           [[0.23910531, 0.5401047, 0.22078995]]\n",
            "1559           [[0.21389176, 0.6200267, 0.16608152]]\n",
            "1560          [[0.11985934, 0.8711695, 0.008971141]]\n",
            "1561         [[0.14894693, 0.83823264, 0.012820439]]\n",
            "1562          [[0.17684028, 0.65324336, 0.16991632]]\n",
            "1563      [[0.00091126515, 0.0013064566, 0.9977823]]\n",
            "1564          [[0.11453086, 0.7847642, 0.100704946]]\n",
            "1565          [[0.010508998, 0.6402853, 0.34920567]]\n",
            "1566          [[0.016161308, 0.974495, 0.009343631]]\n",
            "1567             [[0.3762446, 0.4438709, 0.1798845]]\n",
            "1568        [[0.0020308006, 0.92637897, 0.07159027]]\n",
            "1569        [[0.0012766597, 0.9727903, 0.025933009]]\n",
            "1570        [[0.0033908305, 0.9896898, 0.006919401]]\n",
            "1571         [[0.0021073623, 0.9192536, 0.07863905]]\n",
            "1572          [[0.06562579, 0.86578375, 0.06859053]]\n",
            "1573          [[0.11453086, 0.7847642, 0.100704946]]\n",
            "1574          [[0.031231841, 0.05662347, 0.9121447]]\n",
            "1575         [[0.9442639, 0.013219125, 0.042517036]]\n",
            "1576         [[0.9163491, 0.056305394, 0.027345458]]\n",
            "1577          [[0.031231841, 0.05662347, 0.9121447]]\n",
            "1578      [[0.0028428386, 0.0003335136, 0.99682367]]\n",
            "1579        [[0.001663551, 0.045866817, 0.95246965]]\n",
            "1580        [[0.001663551, 0.045866817, 0.95246965]]\n",
            "1581       [[0.0016317549, 0.079594724, 0.91877353]]\n",
            "1582       [[0.0019196741, 0.069884755, 0.92819554]]\n",
            "1583          [[0.027352499, 0.6739811, 0.29866642]]\n",
            "1584           [[0.10959522, 0.7187605, 0.17164432]]\n",
            "1585          [[0.5870795, 0.37742612, 0.035494406]]\n",
            "1586          [[0.031468347, 0.31769532, 0.6508363]]\n",
            "1587           [[0.11685775, 0.6404054, 0.24273677]]\n",
            "1588          [[0.008904808, 0.9798037, 0.01129144]]\n",
            "1589          [[0.011173627, 0.086612396, 0.902214]]\n",
            "1590          [[0.01377493, 0.18580009, 0.80042493]]\n",
            "1591           [[0.20726475, 0.5281562, 0.26457906]]\n",
            "1592           [[0.29374993, 0.6171688, 0.08908131]]\n",
            "1593            [[0.2163412, 0.44130388, 0.3423549]]\n",
            "1594          [[0.02119182, 0.073797405, 0.9050108]]\n",
            "1595           [[0.03791567, 0.5744363, 0.38764805]]\n",
            "1596             [[0.10653866, 0.5704284, 0.323033]]\n",
            "1597           [[0.11670845, 0.70760036, 0.1756912]]\n",
            "1598         [[0.019851288, 0.93280154, 0.04734716]]\n",
            "1599          [[0.0081972815, 0.8674983, 0.1243044]]\n",
            "1600          [[0.0081972815, 0.8674983, 0.1243044]]\n",
            "1601          [[0.0081972815, 0.8674983, 0.1243044]]\n",
            "1602         [[0.09508325, 0.042078905, 0.86283785]]\n",
            "1603         [[0.0015727427, 0.9609424, 0.03748492]]\n",
            "1604        [[0.0029728895, 0.045817558, 0.9512095]]\n",
            "1605           [[0.4649599, 0.22390582, 0.31113434]]\n",
            "1606         [[0.008406884, 0.010159001, 0.9814341]]\n",
            "1607          [[0.05342396, 0.24765415, 0.69892186]]\n",
            "1608           [[0.49145818, 0.3547305, 0.15381137]]\n",
            "1609          [[0.21943237, 0.56720656, 0.21336108]]\n",
            "1610         [[0.91867864, 0.012646694, 0.06867464]]\n",
            "1611           [[0.49145818, 0.3547305, 0.15381137]]\n",
            "1612           [[0.12434161, 0.3643109, 0.51134753]]\n",
            "1613         [[0.008406884, 0.010159001, 0.9814341]]\n",
            "1614           [[0.4649599, 0.22390582, 0.31113434]]\n",
            "1615       [[0.0014686917, 0.00064535666, 0.997886]]\n",
            "1616       [[0.0016785223, 0.013198044, 0.98512346]]\n",
            "1617        [[0.0031909833, 0.10652641, 0.89028263]]\n",
            "1618     [[0.00034468636, 0.0025508048, 0.99710447]]\n",
            "1619      [[0.0010597773, 0.0010849832, 0.99785525]]\n",
            "1620          [[0.04469864, 0.02451335, 0.93078804]]\n",
            "1621          [[0.04469864, 0.02451335, 0.93078804]]\n",
            "1622      [[0.00080290274, 0.0003161892, 0.9988809]]\n",
            "1623      [[0.00080290274, 0.0003161892, 0.9988809]]\n",
            "1624       [[0.0005263444, 0.0014619807, 0.9980117]]\n",
            "1625          [[0.004426905, 0.24341938, 0.7521537]]\n",
            "1626         [[0.016109787, 0.008405396, 0.9754847]]\n",
            "1627        [[0.029493678, 0.036680225, 0.93382615]]\n",
            "1628       [[0.0031529285, 0.0069568176, 0.9898902]]\n",
            "1629        [[0.004987269, 0.011383463, 0.98362917]]\n",
            "1630         [[0.006023056, 0.022952793, 0.9710241]]\n",
            "1631        [[0.006211602, 0.109252796, 0.88453555]]\n",
            "1632           [[0.007981954, 0.1694211, 0.8225969]]\n",
            "1633        [[0.004248608, 0.005305435, 0.99044585]]\n",
            "1634        [[0.004248608, 0.005305435, 0.99044585]]\n",
            "1635           [[0.489763, 0.014380693, 0.49585629]]\n",
            "1636          [[0.31611505, 0.10482291, 0.57906204]]\n",
            "1637          [[0.8151177, 0.13992554, 0.044956785]]\n",
            "1638         [[0.026254665, 0.48701662, 0.48672867]]\n",
            "1639          [[0.031947937, 0.43960863, 0.5284434]]\n",
            "1640           [[0.13786446, 0.28585574, 0.5762798]]\n",
            "1641         [[0.008070496, 0.032492314, 0.9594372]]\n",
            "1642          [[0.031947937, 0.43960863, 0.5284434]]\n",
            "1643           [[0.054787137, 0.32843876, 0.616774]]\n",
            "1644         [[0.045477815, 0.58346194, 0.37106022]]\n",
            "1645         [[0.0071942424, 0.89745724, 0.0953486]]\n",
            "1646        [[0.011990094, 0.028499596, 0.95951027]]\n",
            "1647          [[0.051465087, 0.46150354, 0.4870313]]\n",
            "1648         [[0.008049492, 0.43219328, 0.55975723]]\n",
            "1649         [[0.017141778, 0.53962046, 0.44323778]]\n",
            "1650          [[0.015748253, 0.6714431, 0.31280863]]\n",
            "1651         [[0.007738122, 0.83240706, 0.15985478]]\n",
            "1652          [[0.23250803, 0.54168344, 0.22580852]]\n",
            "1653        [[0.0071756872, 0.29507533, 0.69774896]]\n",
            "1654        [[0.0071756872, 0.29507533, 0.69774896]]\n",
            "1655          [[0.23250803, 0.54168344, 0.22580852]]\n",
            "1656         [[0.00782767, 0.053014994, 0.93915737]]\n",
            "1657           [[0.7553876, 0.20981319, 0.03479919]]\n",
            "1658         [[0.0082815075, 0.13244188, 0.8592767]]\n",
            "1659          [[0.03678896, 0.38172984, 0.58148116]]\n",
            "1660      [[0.00069694594, 0.0005868929, 0.9987161]]\n",
            "1661        [[0.0034211676, 0.022675619, 0.9739032]]\n",
            "1662         [[0.018445186, 0.91695875, 0.06459606]]\n",
            "1663         [[0.013424863, 0.08654147, 0.90003365]]\n",
            "1664         [[0.013424863, 0.08654147, 0.90003365]]\n",
            "1665      [[0.0022739838, 0.0029351106, 0.99479103]]\n",
            "1666       [[0.0049923165, 0.007105266, 0.98790246]]\n",
            "1667        [[0.002213576, 0.022310656, 0.97547567]]\n",
            "1668            [[0.2855331, 0.5948808, 0.11958613]]\n",
            "1669            [[0.2855331, 0.5948808, 0.11958613]]\n",
            "1670       [[0.0035225814, 0.0018347584, 0.9946426]]\n",
            "1671          [[0.004737636, 0.07991152, 0.9153509]]\n",
            "1672          [[0.18628946, 0.58792394, 0.22578657]]\n",
            "1673           [[0.00838179, 0.8849896, 0.10662861]]\n",
            "1674          [[0.017450491, 0.8799476, 0.10260194]]\n",
            "1675           [[0.48802847, 0.27846378, 0.2335077]]\n",
            "1676         [[0.004565684, 0.60089874, 0.39453557]]\n",
            "1677           [[0.09961762, 0.7268081, 0.17357425]]\n",
            "1678          [[0.09774413, 0.76162094, 0.14063495]]\n",
            "1679          [[0.49709862, 0.34372354, 0.15917782]]\n",
            "1680          [[0.009647759, 0.31421915, 0.6761331]]\n",
            "1681         [[0.00301369, 0.032633945, 0.96435237]]\n",
            "1682        [[0.0075581265, 0.038027834, 0.9544141]]\n",
            "1683          [[0.009647759, 0.31421915, 0.6761331]]\n",
            "1684     [[0.0024433103, 0.00049224414, 0.99706453]]\n",
            "1685          [[0.7393099, 0.22805937, 0.032630738]]\n",
            "1686          [[0.027888628, 0.8117906, 0.16032082]]\n",
            "1687           [[0.7365471, 0.07195012, 0.19150281]]\n",
            "1688           [[0.6676121, 0.24738215, 0.08500573]]\n",
            "1689           [[0.7365471, 0.07195012, 0.19150281]]\n",
            "1690          [[0.04107218, 0.24644668, 0.71248114]]\n",
            "1691            [[0.762886, 0.21628933, 0.02082467]]\n",
            "1692          [[0.74115986, 0.17698291, 0.08185721]]\n",
            "1693            [[0.011561066, 0.278909, 0.7095299]]\n",
            "1694          [[0.51647806, 0.4690052, 0.014516731]]\n",
            "1695        [[0.011064674, 0.015914088, 0.97302115]]\n",
            "1696            [[0.09488643, 0.32031065, 0.584803]]\n",
            "1697          [[0.7729655, 0.13351816, 0.093516335]]\n",
            "1698         [[0.066255175, 0.86933786, 0.06440694]]\n",
            "1699      [[0.0007349449, 0.00076089107, 0.9985043]]\n",
            "1700       [[0.00062718446, 0.02531874, 0.97405416]]\n",
            "1701       [[0.0007813626, 0.043232102, 0.95598656]]\n",
            "1702        [[0.0013744611, 0.30351585, 0.69510967]]\n",
            "1703         [[0.0016186862, 0.7861199, 0.21226141]]\n",
            "1704         [[0.0020541067, 0.5290003, 0.46894562]]\n",
            "1705      [[0.00086179137, 0.0012449013, 0.9978934]]\n",
            "1706          [[0.0023388164, 0.5407676, 0.4568936]]\n",
            "1707         [[0.0013783858, 0.6213249, 0.37729672]]\n",
            "1708         [[0.0011625368, 0.08405712, 0.9147803]]\n",
            "1709           [[0.24522366, 0.6509206, 0.10385577]]\n",
            "1710           [[0.24522366, 0.6509206, 0.10385577]]\n",
            "1711           [[0.5523424, 0.26651892, 0.18113865]]\n",
            "1712           [[0.1868317, 0.66812444, 0.14504388]]\n",
            "1713         [[0.019649955, 0.096264854, 0.8840852]]\n",
            "1714          [[0.053233128, 0.25369546, 0.6930715]]\n",
            "1715            [[0.8498666, 0.08074895, 0.0693844]]\n",
            "1716      [[0.0031423196, 0.0033562712, 0.99350137]]\n",
            "1717          [[0.66988534, 0.20935753, 0.12075712]]\n",
            "1718         [[0.024896959, 0.64895594, 0.32614708]]\n",
            "1719           [[0.01180492, 0.09928156, 0.8889136]]\n",
            "1720        [[0.9535848, 0.040277094, 0.0061381627]]\n",
            "1721          [[0.42363122, 0.36026195, 0.21610683]]\n",
            "1722          [[0.013632196, 0.6926803, 0.29368746]]\n",
            "1723          [[0.010750118, 0.10667576, 0.8825741]]\n",
            "1724        [[0.0036601468, 0.65316916, 0.34317073]]\n",
            "1725      [[0.0037681672, 0.0017878886, 0.99444395]]\n",
            "1726          [[0.07126488, 0.54213136, 0.38660377]]\n",
            "1727        [[0.061582796, 0.099318154, 0.83909905]]\n",
            "1728           [[0.10984847, 0.10441027, 0.7857412]]\n",
            "1729            [[0.2432249, 0.13786618, 0.6189089]]\n",
            "1730     [[0.00039908828, 0.0016859516, 0.99791497]]\n",
            "1731      [[0.00037114348, 0.0003922665, 0.9992366]]\n",
            "1732     [[0.0014660063, 0.00024915417, 0.99828476]]\n",
            "1733        [[0.0120473225, 0.07788416, 0.91006845]]\n",
            "1734        [[0.0120473225, 0.07788416, 0.91006845]]\n",
            "1735          [[0.030390767, 0.7478052, 0.22180398]]\n",
            "1736           [[0.1298822, 0.14887682, 0.72124094]]\n",
            "1737       [[0.0012317835, 0.034467146, 0.96430117]]\n",
            "1738       [[0.0032530413, 0.0014023061, 0.9953447]]\n",
            "1739         [[0.009278851, 0.40931886, 0.58140224]]\n",
            "1740          [[0.0026335074, 0.8947971, 0.1025694]]\n",
            "1741         [[0.049652122, 0.8547586, 0.095589295]]\n",
            "1742         [[0.049652122, 0.8547586, 0.095589295]]\n",
            "1743           [[0.05302393, 0.8611412, 0.08583485]]\n",
            "1744         [[0.00419096, 0.090718724, 0.90509033]]\n",
            "1745         [[0.003925582, 0.007017903, 0.9890564]]\n",
            "1746       [[0.0021052463, 0.0006350691, 0.9972596]]\n",
            "1747       [[0.005821664, 0.0010359662, 0.99314237]]\n",
            "1748           [[0.39077044, 0.5377203, 0.07150922]]\n",
            "1749           [[0.08796043, 0.6893221, 0.22271748]]\n",
            "1750          [[0.009440826, 0.7562766, 0.23428261]]\n",
            "1751          [[0.008282861, 0.22452034, 0.7671968]]\n",
            "1752         [[0.0020837379, 0.019068314, 0.978848]]\n",
            "1753         [[0.015681865, 0.47046497, 0.51385313]]\n",
            "1754          [[0.48700735, 0.47504556, 0.03794707]]\n",
            "1755          [[0.48700735, 0.47504556, 0.03794707]]\n",
            "1756           [[0.0897957, 0.41981372, 0.49039054]]\n",
            "1757          [[0.14024143, 0.36823064, 0.49152797]]\n",
            "1758           [[0.016302127, 0.1389718, 0.8447261]]\n",
            "1759        [[0.0010502639, 0.9789013, 0.020048387]]\n",
            "1760          [[0.008970121, 0.9610989, 0.02993092]]\n",
            "1761          [[0.008970121, 0.9610989, 0.02993092]]\n",
            "1762           [[0.02179299, 0.9495522, 0.02865487]]\n",
            "1763          [[0.025617832, 0.869519, 0.104863204]]\n",
            "1764        [[0.0018915957, 0.007002971, 0.9911055]]\n",
            "1765         [[0.002999166, 0.27468032, 0.72232044]]\n",
            "1766         [[0.0037629558, 0.25588647, 0.7403505]]\n",
            "1767           [[0.04064826, 0.33241126, 0.6269405]]\n",
            "1768           [[0.18737207, 0.2790037, 0.53362423]]\n",
            "1769        [[0.0023457771, 0.02369169, 0.97396255]]\n",
            "1770         [[0.00030307745, 0.0327807, 0.9669163]]\n",
            "1771          [[0.005867754, 0.8486383, 0.14549398]]\n",
            "1772          [[0.10794569, 0.74408346, 0.14797087]]\n",
            "1773         [[0.88099474, 0.07129524, 0.047710065]]\n",
            "1774           [[0.009515214, 0.2687822, 0.7217026]]\n",
            "1775         [[0.015076602, 0.12401906, 0.86090434]]\n",
            "1776         [[0.015076602, 0.12401906, 0.86090434]]\n",
            "1777            [[0.21063183, 0.3181703, 0.4711979]]\n",
            "1778           [[0.17905174, 0.42464647, 0.3963018]]\n",
            "1779          [[0.018265987, 0.22200039, 0.7597336]]\n",
            "1780            [[0.08893023, 0.3130133, 0.5980565]]\n",
            "1781           [[0.512912, 0.44233498, 0.044753045]]\n",
            "1782     [[0.00083227997, 0.0062901876, 0.99287754]]\n",
            "1783        [[0.012212786, 0.037252463, 0.95053476]]\n",
            "1784           [[0.02546603, 0.4508116, 0.52372235]]\n",
            "1785          [[0.53901774, 0.14383999, 0.31714234]]\n",
            "1786       [[0.0049719224, 0.080745004, 0.91428304]]\n",
            "1787       [[0.0049719224, 0.080745004, 0.91428304]]\n",
            "1788           [[0.04104566, 0.38200212, 0.5769523]]\n",
            "1789       [[0.0004142207, 0.018429546, 0.98115635]]\n",
            "1790            [[0.0117563, 0.3053537, 0.68288994]]\n",
            "1791          [[0.23581488, 0.32315543, 0.44102976]]\n",
            "1792         [[0.051058516, 0.54935193, 0.39958954]]\n",
            "1793         [[0.008835825, 0.9696088, 0.021555407]]\n",
            "1794          [[0.029321479, 0.17992973, 0.7907488]]\n",
            "1795          [[0.23581488, 0.32315543, 0.44102976]]\n",
            "1796         [[0.037762262, 0.20468323, 0.75755453]]\n",
            "1797       [[0.00049721356, 0.008644877, 0.9908579]]\n",
            "1798       [[0.0004142207, 0.018429546, 0.98115635]]\n",
            "1799       [[0.00049721356, 0.008644877, 0.9908579]]\n",
            "1800        [[0.0045174933, 0.011655469, 0.9838271]]\n",
            "1801       [[0.001512756, 0.00045280132, 0.9980344]]\n",
            "1802           [[0.10792037, 0.31401247, 0.5780672]]\n",
            "1803        [[0.0028105683, 0.49906036, 0.49812913]]\n",
            "1804         [[0.0022163633, 0.8281184, 0.16966528]]\n",
            "1805         [[0.001348192, 0.9834331, 0.015218613]]\n",
            "1806         [[0.001348192, 0.9834331, 0.015218613]]\n",
            "1807         [[0.001348192, 0.9834331, 0.015218613]]\n",
            "1808           [[0.008960665, 0.6911942, 0.2998452]]\n",
            "1809       [[0.0021047522, 0.0017387175, 0.9961565]]\n",
            "1810       [[0.0018779726, 0.0021597631, 0.9959623]]\n",
            "1811         [[0.02425138, 0.96254635, 0.013202299]]\n",
            "1812          [[0.023093132, 0.21037629, 0.7665306]]\n",
            "1813       [[0.007857173, 0.0050461707, 0.98709667]]\n",
            "1814         [[0.0014584981, 0.011707549, 0.986834]]\n",
            "1815         [[0.68375295, 0.098916985, 0.21733005]]\n",
            "1816       [[0.0018630011, 0.0005766764, 0.9975604]]\n",
            "1817         [[0.047342394, 0.24109273, 0.71156496]]\n",
            "1818          [[0.43490466, 0.33122468, 0.23387066]]\n",
            "1819         [[0.016161187, 0.17269571, 0.81114316]]\n",
            "1820          [[0.028076665, 0.2181406, 0.75378275]]\n",
            "1821          [[0.09224449, 0.09769204, 0.81006354]]\n",
            "1822          [[0.04782574, 0.056348037, 0.8958262]]\n",
            "1823           [[0.102113225, 0.4111508, 0.4867359]]\n",
            "1824            [[0.3901499, 0.4205638, 0.18928635]]\n",
            "1825          [[0.058516674, 0.23922962, 0.7022537]]\n",
            "1826          [[0.6404079, 0.29354313, 0.066048935]]\n",
            "1827          [[0.6404079, 0.29354313, 0.066048935]]\n",
            "1828          [[0.6404079, 0.29354313, 0.066048935]]\n",
            "1829           [[0.102113225, 0.4111508, 0.4867359]]\n",
            "1830            [[0.17976853, 0.562775, 0.25745645]]\n",
            "1831        [[0.0016461744, 0.00473202, 0.99362177]]\n",
            "1832         [[0.011715214, 0.15450794, 0.83377695]]\n",
            "1833         [[0.026011582, 0.099296056, 0.8746924]]\n",
            "1834          [[0.27118847, 0.48555043, 0.24326107]]\n",
            "1835              [[0.33438, 0.36133683, 0.3042831]]\n",
            "1836              [[0.33438, 0.36133683, 0.3042831]]\n",
            "1837         [[0.010495096, 0.006425688, 0.9830792]]\n",
            "1838           [[0.37501663, 0.42603657, 0.1989468]]\n",
            "1839           [[0.24604943, 0.57473826, 0.1792123]]\n",
            "1840         [[0.009009119, 0.009408647, 0.9815823]]\n",
            "1841          [[0.03072732, 0.10613748, 0.86313516]]\n",
            "1842         [[0.017248183, 0.015286522, 0.9674653]]\n",
            "1843        [[0.0036241387, 0.012092513, 0.9842833]]\n",
            "1844          [[0.015707845, 0.01710608, 0.9671861]]\n",
            "1845        [[0.002062869, 0.0011942716, 0.9967429]]\n",
            "1846        [[0.002062869, 0.0011942716, 0.9967429]]\n",
            "1847        [[0.0071036634, 0.065079406, 0.9278169]]\n",
            "1848          [[0.007133289, 0.5083258, 0.48454088]]\n",
            "1849        [[0.0031571975, 0.52921915, 0.46762362]]\n",
            "1850          [[0.019159323, 0.18129891, 0.7995417]]\n",
            "1851       [[0.002182641, 0.0070965653, 0.99072075]]\n",
            "1852       [[0.0010157977, 0.0013344573, 0.9976497]]\n",
            "1853     [[0.0051398687, 0.00090631057, 0.99395376]]\n",
            "1854          [[0.062719196, 0.15103668, 0.7862441]]\n",
            "1855          [[0.39892465, 0.5902365, 0.010838856]]\n",
            "1856        [[0.026470201, 0.046064183, 0.92746556]]\n",
            "1857       [[0.0030514477, 0.0030364683, 0.9939121]]\n",
            "1858          [[0.015042341, 0.069988586, 0.914969]]\n",
            "1859         [[0.004941443, 0.005414081, 0.9896444]]\n",
            "1860       [[0.0030514477, 0.0030364683, 0.9939121]]\n",
            "1861          [[0.17920569, 0.32832342, 0.49247092]]\n",
            "1862           [[0.12215877, 0.5405806, 0.33726063]]\n",
            "1863         [[0.007525715, 0.019557334, 0.9729169]]\n",
            "1864         [[0.004941443, 0.005414081, 0.9896444]]\n",
            "1865         [[0.004110799, 0.049516406, 0.9463728]]\n",
            "1866            [[0.02220412, 0.0902715, 0.8875243]]\n",
            "1867           [[0.023883274, 0.8066731, 0.1694436]]\n",
            "1868          [[0.012750742, 0.12573944, 0.8615099]]\n",
            "1869          [[0.007254737, 0.6566065, 0.33613878]]\n",
            "1870          [[0.007709483, 0.63542885, 0.3568617]]\n",
            "1871         [[0.005295553, 0.025530629, 0.9691739]]\n",
            "1872         [[0.0030237546, 0.05586555, 0.9411107]]\n",
            "1873       [[0.0018087093, 0.0033255678, 0.9948657]]\n",
            "1874      [[0.0011471548, 0.0005696413, 0.99828315]]\n",
            "1875          [[0.05384807, 0.74509966, 0.20105226]]\n",
            "1876          [[0.029693423, 0.8898382, 0.08046833]]\n",
            "1877          [[0.005993562, 0.3083484, 0.68565804]]\n",
            "1878          [[0.010130869, 0.59549665, 0.3943724]]\n",
            "1879        [[0.0015615554, 0.01671212, 0.98172635]]\n",
            "1880          [[0.010130869, 0.59549665, 0.3943724]]\n",
            "1881         [[0.0042740544, 0.10191346, 0.8938125]]\n",
            "1882        [[0.0108689675, 0.47553787, 0.51359314]]\n",
            "1883       [[0.0019603635, 0.020322004, 0.97771764]]\n",
            "1884        [[0.0054813637, 0.02052319, 0.97399545]]\n",
            "1885       [[0.0149707245, 0.030561352, 0.95446795]]\n",
            "1886          [[0.4885575, 0.49470046, 0.016742064]]\n",
            "1887         [[0.20627557, 0.75943404, 0.034290392]]\n",
            "1888         [[0.031086233, 0.083602265, 0.8853115]]\n",
            "1889         [[0.9130639, 0.015783131, 0.071152925]]\n",
            "1890          [[0.45644718, 0.21332574, 0.33022717]]\n",
            "1891          [[0.01758274, 0.24831088, 0.73410636]]\n",
            "1892          [[0.018404737, 0.19050191, 0.7910934]]\n",
            "1893         [[0.33819544, 0.024054945, 0.63774955]]\n",
            "1894             [[0.024798311, 0.15210162, 0.8231]]\n",
            "1895        [[0.024565741, 0.040910114, 0.93452424]]\n",
            "1896        [[0.0059667462, 0.025004419, 0.9690289]]\n",
            "1897         [[0.47490397, 0.49486396, 0.030232063]]\n",
            "1898          [[0.42651328, 0.55118006, 0.02230663]]\n",
            "1899            [[0.6170747, 0.3624114, 0.02051387]]\n",
            "1900           [[0.27374488, 0.6864976, 0.03975749]]\n",
            "1901            [[0.5215008, 0.3881819, 0.09031731]]\n",
            "1902        [[0.013612962, 0.0037795706, 0.9826074]]\n",
            "1903          [[0.5642591, 0.39879733, 0.036943603]]\n",
            "1904           [[0.6446565, 0.30324134, 0.05210222]]\n",
            "1905         [[0.85334647, 0.13557072, 0.011082877]]\n",
            "1906          [[0.3626222, 0.62595963, 0.011418139]]\n",
            "1907         [[0.009737559, 0.016635668, 0.9736268]]\n",
            "1908      [[0.004440826, 0.00085649296, 0.99470264]]\n",
            "1909           [[0.03455819, 0.9210568, 0.04438503]]\n",
            "1910      [[0.0024423783, 0.0009094697, 0.99664813]]\n",
            "1911        [[0.0052478085, 0.069315694, 0.9254365]]\n",
            "1912           [[0.020737726, 0.2128217, 0.7664406]]\n",
            "1913           [[0.020737726, 0.2128217, 0.7664406]]\n",
            "1914       [[0.0068921684, 0.0014880406, 0.9916198]]\n",
            "1915           [[0.021492343, 0.18451962, 0.793988]]\n",
            "1916           [[0.020737726, 0.2128217, 0.7664406]]\n",
            "1917         [[0.018421428, 0.35878012, 0.62279844]]\n",
            "1918         [[0.025681695, 0.108572945, 0.8657453]]\n",
            "1919           [[0.021492343, 0.18451962, 0.793988]]\n",
            "1920            [[0.0409697, 0.38303903, 0.5759912]]\n",
            "1921           [[0.04112985, 0.8255925, 0.13327762]]\n",
            "1922          [[0.10279609, 0.49103913, 0.40616485]]\n",
            "1923         [[0.003945794, 0.88982874, 0.10622549]]\n",
            "1924        [[0.002168167, 0.030832535, 0.96699923]]\n",
            "1925    [[0.00093225215, 0.00041826905, 0.99864954]]\n",
            "1926       [[0.0008153396, 0.015805198, 0.98337954]]\n",
            "1927    [[0.00054910063, 0.00041356645, 0.99903727]]\n",
            "1928        [[0.0006725018, 0.9511967, 0.048130848]]\n",
            "1929       [[0.00062743586, 0.032105356, 0.9672673]]\n",
            "1930        [[0.0024202638, 0.014590144, 0.9829896]]\n",
            "1931          [[0.0020697936, 0.1584555, 0.8394746]]\n",
            "1932       [[0.00062743586, 0.032105356, 0.9672673]]\n",
            "1933           [[0.8193953, 0.11116604, 0.06943865]]\n",
            "1934          [[0.66112715, 0.27075213, 0.06812073]]\n",
            "1935          [[0.73617464, 0.21704371, 0.04678159]]\n",
            "1936           [[0.15523018, 0.7236832, 0.12108669]]\n",
            "1937      [[0.0034997945, 0.0032653513, 0.99323493]]\n",
            "1938         [[0.0063772737, 0.9406933, 0.05292943]]\n",
            "1939        [[0.0021017725, 0.016346538, 0.9815517]]\n",
            "1940         [[0.0058287964, 0.1342838, 0.85988736]]\n",
            "1941          [[0.016003987, 0.34560263, 0.6383934]]\n",
            "1942        [[0.0059612333, 0.010820569, 0.9832182]]\n",
            "1943            [[0.0254778, 0.37420887, 0.6003133]]\n",
            "1944          [[0.012273864, 0.04349733, 0.9442288]]\n",
            "1945           [[0.30729783, 0.15975563, 0.5329466]]\n",
            "1946        [[0.008527545, 0.0032913568, 0.9881811]]\n",
            "1947            [[0.5017928, 0.12837136, 0.3698359]]\n",
            "1948             [[0.08693431, 0.45562, 0.45744568]]\n",
            "1949       [[0.0034071335, 0.95377296, 0.042819846]]\n",
            "1950          [[0.006532813, 0.03604799, 0.9574193]]\n",
            "1951          [[0.003220631, 0.17546046, 0.8213189]]\n",
            "1952            [[0.5017928, 0.12837136, 0.3698359]]\n",
            "1953       [[0.0024366928, 0.0009040859, 0.9966593]]\n",
            "1954        [[0.008276057, 0.050702933, 0.94102097]]\n",
            "1955       [[0.0007969886, 0.0018336253, 0.9973694]]\n",
            "1956        [[0.0024413583, 0.13901637, 0.85854226]]\n",
            "1957           [[0.04744636, 0.5832199, 0.36933377]]\n",
            "1958          [[0.038811114, 0.5191726, 0.44201624]]\n",
            "1959          [[0.5068946, 0.46204382, 0.031061627]]\n",
            "1960       [[0.0043193405, 0.9933514, 0.0023292953]]\n",
            "1961         [[0.0074393433, 0.8757443, 0.11681636]]\n",
            "1962        [[0.0024413583, 0.13901637, 0.85854226]]\n",
            "1963         [[0.009513196, 0.05495864, 0.93552816]]\n",
            "1964            [[0.15489973, 0.09792525, 0.747175]]\n",
            "1965            [[0.15489973, 0.09792525, 0.747175]]\n",
            "1966        [[0.0011165764, 0.035095904, 0.9637876]]\n",
            "1967        [[0.0045528812, 0.86575836, 0.12968881]]\n",
            "1968            [[0.15489973, 0.09792525, 0.747175]]\n",
            "1969           [[0.6411325, 0.3370373, 0.021830264]]\n",
            "1970          [[0.010251146, 0.8109363, 0.17881261]]\n",
            "1971         [[0.0036888337, 0.00613635, 0.9901749]]\n",
            "1972      [[0.0012294967, 0.00077272166, 0.9979978]]\n",
            "1973        [[0.0020044262, 0.005272898, 0.9927226]]\n",
            "1974      [[0.0023774286, 0.0064366376, 0.99118584]]\n",
            "1975        [[0.008269398, 0.0055100597, 0.9862205]]\n",
            "1976         [[0.0035153853, 0.6573865, 0.33909813]]\n",
            "1977          [[0.08254643, 0.58307725, 0.33437634]]\n",
            "1978          [[0.37235752, 0.18348822, 0.44415423]]\n",
            "1979          [[0.009587235, 0.8616173, 0.12879546]]\n",
            "1980            [[0.08993125, 0.09689173, 0.813177]]\n",
            "1981          [[0.023105338, 0.19519521, 0.7816995]]\n",
            "1982          [[0.020465089, 0.13946322, 0.8400717]]\n",
            "1983            [[0.015025, 0.037692487, 0.9472825]]\n",
            "1984      [[0.0053579337, 0.0016874343, 0.99295455]]\n",
            "1985          [[0.07968537, 0.01782472, 0.90248996]]\n",
            "1986          [[0.00834137, 0.050935898, 0.9407227]]\n",
            "1987          [[0.00510249, 0.019437933, 0.9754596]]\n",
            "1988          [[0.065323144, 0.8215528, 0.11312406]]\n",
            "1989          [[0.00834137, 0.050935898, 0.9407227]]\n",
            "1990          [[0.012076354, 0.8335414, 0.15438229]]\n",
            "1991          [[0.078964606, 0.49670485, 0.4243305]]\n",
            "1992         [[0.023923216, 0.65416414, 0.32191265]]\n",
            "1993         [[0.009796142, 0.004933435, 0.9852705]]\n",
            "1994         [[0.0022347842, 0.12657925, 0.8711859]]\n",
            "1995           [[0.0346314, 0.74125284, 0.22411577]]\n",
            "1996         [[0.0071423673, 0.7543865, 0.23847115]]\n",
            "1997          [[0.033750404, 0.8102434, 0.15600616]]\n",
            "1998         [[0.010280095, 0.9656776, 0.024042247]]\n",
            "1999         [[0.012125123, 0.8766134, 0.111261524]]\n",
            "2000        [[0.0026601218, 0.51914704, 0.47819287]]\n",
            "2001           [[0.046302423, 0.7935545, 0.1601431]]\n",
            "2002           [[0.0090794, 0.9507412, 0.040179472]]\n",
            "2003          [[0.00210933, 0.9795371, 0.018353565]]\n",
            "2004        [[0.0043937783, 0.91159457, 0.08401162]]\n",
            "2005         [[0.008359731, 0.9677646, 0.023875639]]\n",
            "2006         [[0.014374732, 0.79179984, 0.19382544]]\n",
            "2007         [[0.031053312, 0.069095574, 0.8998511]]\n",
            "2008          [[0.011215753, 0.9532831, 0.03550121]]\n",
            "2009          [[0.017691987, 0.6324562, 0.34985185]]\n",
            "2010          [[0.9311156, 0.05915639, 0.009727926]]\n",
            "2011        [[0.0039227763, 0.28736022, 0.70871705]]\n",
            "2012       [[0.0012821105, 0.0057521528, 0.9929658]]\n",
            "2013           [[0.03679994, 0.1590139, 0.80418617]]\n",
            "2014        [[0.009315684, 0.0073776944, 0.9833067]]\n",
            "2015           [[0.3881652, 0.12468541, 0.48714945]]\n",
            "2016        [[0.021949813, 0.016915051, 0.96113515]]\n",
            "2017           [[0.08308579, 0.5357243, 0.38118994]]\n",
            "2018           [[0.5076353, 0.11434003, 0.37802467]]\n",
            "2019        [[0.021949813, 0.016915051, 0.96113515]]\n",
            "2020       [[0.0055691446, 0.032177124, 0.96225375]]\n",
            "2021       [[0.0055691446, 0.032177124, 0.96225375]]\n",
            "2022           [[0.8900932, 0.01239373, 0.09751299]]\n",
            "2023       [[0.016989024, 0.0016225618, 0.98138845]]\n",
            "2024         [[0.088740095, 0.043756075, 0.8675039]]\n",
            "2025          [[0.0022355113, 0.6166532, 0.3811113]]\n",
            "2026        [[0.0015355449, 0.023001269, 0.9754632]]\n",
            "2027        [[0.0027413333, 0.026085004, 0.9711736]]\n",
            "2028       [[0.0025186904, 0.023927182, 0.97355413]]\n",
            "2029         [[0.0020785858, 0.07396874, 0.9239526]]\n",
            "2030        [[0.0050123567, 0.022611389, 0.9723762]]\n",
            "2031            [[0.23726217, 0.2160101, 0.5467277]]\n",
            "2032          [[0.028794846, 0.8597988, 0.11140638]]\n",
            "2033        [[0.007049791, 0.88760155, 0.105348654]]\n",
            "2034        [[0.0050123567, 0.022611389, 0.9723762]]\n",
            "2035        [[0.0076041995, 0.22264852, 0.76974726]]\n",
            "2036         [[0.0076378635, 0.34504694, 0.6473152]]\n",
            "2037         [[0.0076378635, 0.34504694, 0.6473152]]\n",
            "2038          [[0.013504117, 0.47189742, 0.5145984]]\n",
            "2039         [[0.0076378635, 0.34504694, 0.6473152]]\n",
            "2040           [[0.3472294, 0.20680897, 0.44596168]]\n",
            "2041           [[0.3472294, 0.20680897, 0.44596168]]\n",
            "2042           [[0.3472294, 0.20680897, 0.44596168]]\n",
            "2043      [[0.0035372875, 0.0061941883, 0.99026847]]\n",
            "2044        [[0.0066420943, 0.54895824, 0.44439965]]\n",
            "2045         [[0.008127012, 0.95289725, 0.03897569]]\n",
            "2046            [[0.01134326, 0.5147795, 0.4738772]]\n",
            "2047          [[0.6746831, 0.29368424, 0.031632703]]\n",
            "2048          [[0.7994371, 0.19435579, 0.006207116]]\n",
            "2049          [[0.17143054, 0.73699355, 0.09157587]]\n",
            "2050          [[0.036906544, 0.8067833, 0.15631013]]\n",
            "2051         [[0.006389726, 0.26457754, 0.72903275]]\n",
            "2052          [[0.039263923, 0.8647418, 0.09599422]]\n",
            "2053         [[0.006389726, 0.26457754, 0.72903275]]\n",
            "2054            [[0.029552, 0.9530833, 0.017364709]]\n",
            "2055      [[0.0008608799, 0.00050473964, 0.9986344]]\n",
            "2056          [[0.001713546, 0.5382431, 0.46004337]]\n",
            "2057      [[0.00087699946, 0.0030007237, 0.9961223]]\n",
            "2058       [[0.0013107229, 0.013585183, 0.98510414]]\n",
            "2059        [[0.00045807866, 0.2086681, 0.79087377]]\n",
            "2060        [[0.0037111128, 0.010675363, 0.9856135]]\n",
            "2061         [[0.006132415, 0.007965879, 0.9859017]]\n",
            "2062         [[0.006132415, 0.007965879, 0.9859017]]\n",
            "2063         [[0.006635631, 0.04784376, 0.94552064]]\n",
            "2064       [[0.0028960516, 0.004291468, 0.99281245]]\n",
            "2065         [[0.028304337, 0.006421309, 0.9652743]]\n",
            "2066          [[0.7033631, 0.26459935, 0.032037556]]\n",
            "2067           [[0.88989174, 0.07428643, 0.0358218]]\n",
            "2068        [[0.005261232, 0.004248349, 0.99049044]]\n",
            "2069         [[0.008631763, 0.9524088, 0.038959447]]\n",
            "2070        [[0.0056935027, 0.008342738, 0.9859638]]\n",
            "2071         [[0.96853024, 0.01643831, 0.015031399]]\n",
            "2072           [[0.18702675, 0.25820547, 0.5547678]]\n",
            "2073        [[0.012617837, 0.036844317, 0.95053786]]\n",
            "2074            [[0.7094394, 0.1602775, 0.13028306]]\n",
            "2075           [[0.5832142, 0.3395576, 0.077228114]]\n",
            "2076           [[0.5832142, 0.3395576, 0.077228114]]\n",
            "2077         [[0.61432314, 0.36935225, 0.016324565]]\n",
            "2078           [[0.25477093, 0.21424721, 0.5309819]]\n",
            "2079         [[0.0073153996, 0.14754729, 0.8451373]]\n",
            "2080      [[0.0015298047, 0.0027978285, 0.99567235]]\n",
            "2081     [[0.00084822153, 0.0030382816, 0.99611354]]\n",
            "2082         [[0.093965575, 0.47795203, 0.42808238]]\n",
            "2083           [[0.015006264, 0.726389, 0.25860476]]\n",
            "2084          [[0.008911005, 0.24823427, 0.7428547]]\n",
            "2085        [[0.0041522295, 0.018241582, 0.9776062]]\n",
            "2086        [[0.0032329638, 0.16735992, 0.82940716]]\n",
            "2087     [[0.0015372164, 0.00053326366, 0.99792945]]\n",
            "2088            [[0.788233, 0.07421025, 0.13755684]]\n",
            "2089          [[0.005042192, 0.6093761, 0.38558173]]\n",
            "2090       [[0.0040148622, 0.027353091, 0.96863204]]\n",
            "2091         [[0.002660425, 0.015708374, 0.9816312]]\n",
            "2092       [[0.0013878532, 0.057599068, 0.94101304]]\n",
            "2093        [[0.0024399152, 0.007495412, 0.9900647]]\n",
            "2094         [[0.007185938, 0.012972255, 0.9798418]]\n",
            "2095          [[0.042367544, 0.42465124, 0.5329812]]\n",
            "2096       [[0.0028617932, 0.9931411, 0.0039970926]]\n",
            "2097         [[0.0070953975, 0.50964236, 0.4832622]]\n",
            "2098        [[0.0024399152, 0.007495412, 0.9900647]]\n",
            "2099          [[0.007826652, 0.11850668, 0.8736667]]\n",
            "2100       [[0.0012052587, 0.0034658539, 0.9953289]]\n",
            "2101      [[0.0012971014, 0.0008561584, 0.99784684]]\n",
            "2102       [[0.0012052587, 0.0034658539, 0.9953289]]\n",
            "2103           [[0.003175192, 0.1286323, 0.8681925]]\n",
            "2104          [[0.014596208, 0.5091267, 0.47627705]]\n",
            "2105       [[0.0021794604, 0.0023574564, 0.9954631]]\n",
            "2106           [[0.02169392, 0.16748288, 0.8108232]]\n",
            "2107         [[0.9260269, 0.021577183, 0.052396014]]\n",
            "2108         [[0.9389966, 0.0068371915, 0.05416616]]\n",
            "2109          [[0.16528633, 0.73782265, 0.09689103]]\n",
            "2110         [[0.009313568, 0.23451872, 0.75616765]]\n",
            "2111         [[0.0073539247, 0.8194095, 0.17323662]]\n",
            "2112            [[0.010943514, 0.289662, 0.6993944]]\n",
            "2113        [[0.0015515801, 0.9878122, 0.010636203]]\n",
            "2114          [[0.017603617, 0.5513718, 0.43102455]]\n",
            "2115            [[0.0049162, 0.09239622, 0.9026876]]\n",
            "2116         [[0.002376306, 0.051654395, 0.9459693]]\n",
            "2117          [[0.056372263, 0.8642123, 0.07941543]]\n",
            "2118        [[0.0021796126, 0.033294857, 0.9645256]]\n",
            "2119       [[0.0005725222, 0.014844773, 0.98458266]]\n",
            "2120        [[0.0034063605, 0.19239202, 0.80420166]]\n",
            "2121          [[0.0009467286, 0.0048347, 0.9942186]]\n",
            "2122         [[0.012955748, 0.45371738, 0.53332686]]\n",
            "2123           [[0.01243294, 0.7407598, 0.24680728]]\n",
            "2124         [[0.007953452, 0.23940684, 0.75263965]]\n",
            "2125           [[0.755308, 0.21107139, 0.033620678]]\n",
            "2126          [[0.002151137, 0.07866697, 0.9191818]]\n",
            "2127        [[0.0025089318, 0.011231977, 0.9862591]]\n",
            "2128          [[0.020744989, 0.59803563, 0.3812194]]\n",
            "2129     [[0.0017207861, 0.00093840656, 0.99734086]]\n",
            "2130          [[0.82086456, 0.13483667, 0.04429869]]\n",
            "2131          [[0.82086456, 0.13483667, 0.04429869]]\n",
            "2132         [[0.0021189412, 0.11380323, 0.8840777]]\n",
            "2133        [[0.001643584, 0.0106891785, 0.9876672]]\n",
            "2134       [[0.0019334888, 0.0046536396, 0.9934129]]\n",
            "2135         [[0.0021189412, 0.11380323, 0.8840777]]\n",
            "2136         [[0.0061250133, 0.3697299, 0.62414515]]\n",
            "2137         [[0.0074025164, 0.08141526, 0.9111822]]\n",
            "2138        [[0.007487861, 0.011982897, 0.98052925]]\n",
            "2139        [[0.007487861, 0.011982897, 0.98052925]]\n",
            "2140          [[0.18088192, 0.21762936, 0.60148877]]\n",
            "2141        [[0.0019915358, 0.03634731, 0.96166116]]\n",
            "2142           [[0.003248577, 0.21879743, 0.777954]]\n",
            "2143        [[0.0011788417, 0.024128903, 0.9746923]]\n",
            "2144     [[0.0010268415, 0.00045992268, 0.99851316]]\n",
            "2145           [[0.1265026, 0.049137536, 0.8243599]]\n",
            "2146          [[0.8313454, 0.028253935, 0.14040066]]\n",
            "2147         [[0.9045034, 0.042605978, 0.052890677]]\n",
            "2148         [[0.0041483464, 0.10319657, 0.8926551]]\n",
            "2149          [[0.81926966, 0.09223137, 0.08849895]]\n",
            "2150          [[0.8313454, 0.028253935, 0.14040066]]\n",
            "2151      [[0.0032666547, 0.00054070447, 0.9961927]]\n",
            "2152          [[0.075242005, 0.7754031, 0.14935493]]\n",
            "2153            [[0.0627198, 0.8258625, 0.11141768]]\n",
            "2154        [[0.0050125537, 0.081793614, 0.9131939]]\n",
            "2155           [[0.064211085, 0.3534113, 0.5823776]]\n",
            "2156          [[0.0014089161, 0.1390794, 0.8595116]]\n",
            "2157          [[0.026464108, 0.7032047, 0.27033123]]\n",
            "2158          [[0.059493724, 0.16074276, 0.7797635]]\n",
            "2159          [[0.019060388, 0.58585656, 0.3950831]]\n",
            "2160        [[0.0018600464, 0.017584143, 0.9805557]]\n",
            "2161          [[0.65934336, 0.22132567, 0.11933096]]\n",
            "2162          [[0.65934336, 0.22132567, 0.11933096]]\n",
            "2163          [[0.65934336, 0.22132567, 0.11933096]]\n",
            "2164          [[0.049534876, 0.8097069, 0.14075822]]\n",
            "2165          [[0.06583677, 0.32024503, 0.61391824]]\n",
            "2166       [[0.0056302724, 0.013915855, 0.98045385]]\n",
            "2167        [[0.0031282406, 0.02399836, 0.97287345]]\n",
            "2168       [[0.0034262077, 0.005725203, 0.99084854]]\n",
            "2169        [[0.012043231, 0.002964593, 0.98499215]]\n",
            "2170         [[0.049024977, 0.63552654, 0.31544846]]\n",
            "2171        [[0.96724194, 0.024855768, 0.007902307]]\n",
            "2172          [[0.064390175, 0.6853151, 0.25029477]]\n",
            "2173         [[0.049024977, 0.63552654, 0.31544846]]\n",
            "2174         [[0.049024977, 0.63552654, 0.31544846]]\n",
            "2175           [[0.53473467, 0.19204871, 0.2732166]]\n",
            "2176           [[0.05206323, 0.3274032, 0.62053365]]\n",
            "2177           [[0.53473467, 0.19204871, 0.2732166]]\n",
            "2178           [[0.53473467, 0.19204871, 0.2732166]]\n",
            "2179           [[0.40328017, 0.24788195, 0.3488379]]\n",
            "2180           [[0.018365823, 0.3812993, 0.6003349]]\n",
            "2181        [[0.001951965, 0.0034411657, 0.9946069]]\n",
            "2182          [[0.01264906, 0.090439156, 0.8969117]]\n",
            "2183         [[0.029491972, 0.9021738, 0.068334244]]\n",
            "2184           [[0.12505794, 0.835277, 0.039665025]]\n",
            "2185          [[0.21049531, 0.74856794, 0.04093674]]\n",
            "2186        [[0.0022762732, 0.036274537, 0.9614492]]\n",
            "2187          [[0.059306145, 0.01001396, 0.9306799]]\n",
            "2188          [[0.059306145, 0.01001396, 0.9306799]]\n",
            "2189         [[0.00073695, 0.00027601884, 0.998987]]\n",
            "2190       [[0.0008851765, 0.0004315038, 0.9986834]]\n",
            "2191         [[0.00073695, 0.00027601884, 0.998987]]\n",
            "2192         [[0.0036358158, 0.01986847, 0.9764956]]\n",
            "2193          [[0.016153444, 0.2707268, 0.71311975]]\n",
            "2194          [[0.002612744, 0.6817763, 0.31561095]]\n",
            "2195        [[0.0019128608, 0.95738137, 0.04070583]]\n",
            "2196          [[0.003984176, 0.1862682, 0.80974764]]\n",
            "2197           [[0.1016671, 0.25923103, 0.63910186]]\n",
            "2198         [[0.009642041, 0.75532144, 0.23503655]]\n",
            "2199        [[0.0013144608, 0.01402294, 0.98466265]]\n",
            "2200          [[0.037420325, 0.4784133, 0.48416635]]\n",
            "2201          [[0.015043308, 0.29204327, 0.6929134]]\n",
            "2202        [[0.0047132317, 0.42109847, 0.57418835]]\n",
            "2203          [[0.02127095, 0.32231125, 0.65641785]]\n",
            "2204         [[0.005145799, 0.090461016, 0.9043932]]\n",
            "2205        [[0.0016464529, 0.005774131, 0.9925794]]\n",
            "2206        [[0.0047132317, 0.42109847, 0.57418835]]\n",
            "2207       [[0.0029669942, 0.0010112858, 0.9960218]]\n",
            "2208          [[0.14323565, 0.75070626, 0.10605809]]\n",
            "2209          [[0.0039254497, 0.7735293, 0.2225453]]\n",
            "2210          [[0.14323565, 0.75070626, 0.10605809]]\n",
            "2211      [[0.0016027726, 0.0014047476, 0.99699247]]\n",
            "2212         [[0.0013245231, 0.011066431, 0.987609]]\n",
            "2213         [[0.022238523, 0.33264172, 0.64511985]]\n",
            "2214           [[0.010488272, 0.8619954, 0.1275164]]\n",
            "2215          [[0.0076182443, 0.3209432, 0.6714385]]\n",
            "2216         [[0.0032913312, 0.9003412, 0.09636745]]\n",
            "2217        [[0.89468724, 0.070931375, 0.034381434]]\n",
            "2218           [[0.8063724, 0.14733331, 0.04629429]]\n",
            "2219           [[0.24645874, 0.36646143, 0.3870799]]\n",
            "2220           [[0.24645874, 0.36646143, 0.3870799]]\n",
            "2221     [[0.0007832911, 0.00061040575, 0.99860626]]\n",
            "2222           [[0.08493372, 0.5778066, 0.33725965]]\n",
            "2223         [[0.085488446, 0.49918735, 0.41532424]]\n",
            "2224     [[0.0007832911, 0.00061040575, 0.99860626]]\n",
            "2225        [[0.005024662, 0.009106395, 0.98586893]]\n",
            "2226        [[0.005024662, 0.009106395, 0.98586893]]\n",
            "2227           [[0.024799732, 0.2776726, 0.6975276]]\n",
            "2228          [[0.029187988, 0.17472404, 0.7960879]]\n",
            "2229       [[0.0010157353, 0.006444776, 0.99253947]]\n",
            "2230        [[0.005024662, 0.009106395, 0.98586893]]\n",
            "2231         [[0.013794138, 0.008290952, 0.9779149]]\n",
            "2232        [[0.007989697, 0.005977673, 0.98603255]]\n",
            "2233          [[0.02438489, 0.62467784, 0.35093728]]\n",
            "2234         [[0.005826172, 0.017483026, 0.9766908]]\n",
            "2235         [[0.005826172, 0.017483026, 0.9766908]]\n",
            "2236      [[0.0017406482, 0.0004754276, 0.99778396]]\n",
            "2237      [[0.0010715666, 0.00040839097, 0.9985201]]\n",
            "2238          [[0.03091523, 0.15992907, 0.80915564]]\n",
            "2239           [[0.01663442, 0.8654045, 0.11796114]]\n",
            "2240         [[0.0035415227, 0.06909437, 0.9273642]]\n",
            "2241         [[0.88250446, 0.030375963, 0.08711968]]\n",
            "2242           [[0.07966335, 0.886881, 0.033455648]]\n",
            "2243          [[0.008649016, 0.7940823, 0.19726874]]\n",
            "2244           [[0.01765197, 0.22756654, 0.7547815]]\n",
            "2245           [[0.01765197, 0.22756654, 0.7547815]]\n",
            "2246       [[0.0026754134, 0.0015343751, 0.9957902]]\n",
            "2247       [[0.0011597124, 0.0012407885, 0.9975994]]\n",
            "2248       [[0.0006952267, 0.0010203642, 0.9982844]]\n",
            "2249      [[0.0005481986, 0.0007735943, 0.99867815]]\n",
            "2250      [[0.0005298195, 0.00039920682, 0.9990709]]\n",
            "2251          [[0.42472497, 0.10446033, 0.47081473]]\n",
            "2252          [[0.05002872, 0.86992574, 0.08004549]]\n",
            "2253           [[0.012182472, 0.4332722, 0.5545453]]\n",
            "2254            [[0.12575063, 0.23254032, 0.641709]]\n",
            "2255           [[0.19555068, 0.21110347, 0.5933459]]\n",
            "2256           [[0.03539301, 0.03291377, 0.9316932]]\n",
            "2257          [[0.42472497, 0.10446033, 0.47081473]]\n",
            "2258           [[0.3624829, 0.23906869, 0.39844838]]\n",
            "2259          [[0.010139321, 0.05005997, 0.9398007]]\n",
            "2260        [[0.0049890685, 0.19989406, 0.79511696]]\n",
            "2261         [[0.037080687, 0.27255642, 0.69036293]]\n",
            "2262        [[0.0051051527, 0.31548342, 0.67941135]]\n",
            "2263         [[0.0042934357, 0.064331494, 0.931375]]\n",
            "2264         [[0.008616021, 0.60342336, 0.38796064]]\n",
            "2265           [[0.21929315, 0.762636, 0.018070808]]\n",
            "2266            [[0.6803918, 0.0535799, 0.26602829]]\n",
            "2267            [[0.291806, 0.42674634, 0.28144762]]\n",
            "2268      [[0.0032015936, 0.0025039706, 0.99429446]]\n",
            "2269        [[0.008041028, 0.018686475, 0.97327256]]\n",
            "2270           [[0.14665335, 0.6570973, 0.19624938]]\n",
            "2271           [[0.14665335, 0.6570973, 0.19624938]]\n",
            "2272        [[0.001704923, 0.008206009, 0.99008906]]\n",
            "2273          [[0.13591781, 0.22829013, 0.63579214]]\n",
            "2274         [[0.0020548801, 0.03268773, 0.9652574]]\n",
            "2275           [[0.4202118, 0.28269464, 0.29709357]]\n",
            "2276           [[0.14665335, 0.6570973, 0.19624938]]\n",
            "2277          [[0.004829403, 0.14480847, 0.8503621]]\n",
            "2278      [[0.0016945439, 0.00042712028, 0.9978783]]\n",
            "2279            [[0.0241603, 0.49343413, 0.4824056]]\n",
            "2280          [[0.007837368, 0.05199093, 0.9401717]]\n",
            "2281       [[0.0018775755, 0.0035399895, 0.9945825]]\n",
            "2282          [[0.007837368, 0.05199093, 0.9401717]]\n",
            "2283       [[0.0043999637, 0.009209114, 0.98639095]]\n",
            "2284         [[0.004521215, 0.25901344, 0.73646533]]\n",
            "2285          [[0.003215423, 0.1328433, 0.86394125]]\n",
            "2286        [[0.0010415071, 0.001165737, 0.9977927]]\n",
            "2287           [[0.0013745915, 0.0551614, 0.943464]]\n",
            "2288       [[0.0014622643, 0.015888268, 0.98264945]]\n",
            "2289        [[0.0014220837, 0.0021730105, 0.996405]]\n",
            "2290         [[0.020352053, 0.91297036, 0.06667758]]\n",
            "2291           [[0.02782296, 0.8705647, 0.10161231]]\n",
            "2292           [[0.02782296, 0.8705647, 0.10161231]]\n",
            "2293          [[0.005375755, 0.38032413, 0.6143001]]\n",
            "2294       [[0.0017427613, 0.002963149, 0.99529415]]\n",
            "2295         [[0.020352053, 0.91297036, 0.06667758]]\n",
            "2296           [[0.02782296, 0.8705647, 0.10161231]]\n",
            "2297         [[0.020352053, 0.91297036, 0.06667758]]\n",
            "2298       [[0.0041978885, 0.0026162458, 0.9931859]]\n",
            "2299      [[0.0045701093, 0.0023979517, 0.99303186]]\n",
            "2300          [[0.0056340164, 0.0086281, 0.9857379]]\n",
            "2301              [[0.039221, 0.3416497, 0.6191293]]\n",
            "2302              [[0.039221, 0.3416497, 0.6191293]]\n",
            "2303        [[0.003032574, 0.011170041, 0.98579735]]\n",
            "2304           [[0.03311284, 0.1450899, 0.82179725]]\n",
            "2305        [[0.003032574, 0.011170041, 0.98579735]]\n",
            "2306           [[0.043470077, 0.5105662, 0.4459638]]\n",
            "2307        [[0.0024082272, 0.04020808, 0.95738363]]\n",
            "2308         [[0.008594392, 0.17585048, 0.81555516]]\n",
            "2309      [[0.00094946986, 0.00041348397, 0.998637]]\n",
            "2310         [[0.004081641, 0.09235343, 0.90356493]]\n",
            "2311            [[0.09081111, 0.0898652, 0.8193236]]\n",
            "2312       [[0.0046941363, 0.0077495333, 0.9875564]]\n",
            "2313          [[0.014680947, 0.6083835, 0.37693554]]\n",
            "2314        [[0.95805043, 0.018437244, 0.023512384]]\n",
            "2315         [[0.012330534, 0.87987745, 0.10779208]]\n",
            "2316          [[0.0017823225, 0.5306904, 0.4675273]]\n",
            "2317         [[0.012330534, 0.87987745, 0.10779208]]\n",
            "2318           [[0.5184532, 0.39952338, 0.08202347]]\n",
            "2319           [[0.119270906, 0.5842037, 0.2965254]]\n",
            "2320           [[0.020775022, 0.6768086, 0.3024164]]\n",
            "2321         [[0.05083358, 0.93601596, 0.013150404]]\n",
            "2322         [[0.05083358, 0.93601596, 0.013150404]]\n",
            "2323         [[0.0052584037, 0.00206522, 0.9926764]]\n",
            "2324         [[0.051391482, 0.66408944, 0.28451902]]\n",
            "2325       [[0.0008100023, 0.017794875, 0.98139507]]\n",
            "2326         [[0.011347459, 0.04433138, 0.94432116]]\n",
            "2327       [[0.0015433027, 0.0029426413, 0.9955141]]\n",
            "2328           [[0.012417167, 0.511054, 0.47652885]]\n",
            "2329         [[0.025120169, 0.39246273, 0.58241713]]\n",
            "2330         [[0.0061943587, 0.7048606, 0.28894496]]\n",
            "2331           [[0.012417167, 0.511054, 0.47652885]]\n",
            "2332      [[0.0005450163, 0.0007821702, 0.99867284]]\n",
            "2333         [[0.0061943587, 0.7048606, 0.28894496]]\n",
            "2334            [[0.06047025, 0.3463861, 0.5931437]]\n",
            "2335           [[0.012417167, 0.511054, 0.47652885]]\n",
            "2336        [[0.010108314, 0.016207125, 0.97368455]]\n",
            "2337     [[0.0022834742, 0.00080756895, 0.99690896]]\n",
            "2338           [[0.014578127, 0.704383, 0.28103882]]\n",
            "2339          [[0.01656186, 0.73465896, 0.24877916]]\n",
            "2340         [[0.005055745, 0.67842466, 0.31651965]]\n",
            "2341        [[0.010108314, 0.016207125, 0.97368455]]\n",
            "2342         [[0.0015083617, 0.00626281, 0.9922288]]\n",
            "2343        [[0.0010611519, 0.013859015, 0.9850798]]\n",
            "2344        [[0.0013705248, 0.057972882, 0.9406566]]\n",
            "2345        [[0.000827491, 0.0010173727, 0.9981552]]\n",
            "2346       [[0.0011961721, 0.010263455, 0.98854035]]\n",
            "2347       [[0.0016641302, 0.010220254, 0.98811555]]\n",
            "2348     [[0.0014467835, 0.00034957065, 0.99820364]]\n",
            "2349       [[0.00070879265, 0.032778338, 0.9665129]]\n",
            "2350          [[0.047151618, 0.7980029, 0.15484552]]\n",
            "2351          [[0.031170046, 0.880396, 0.088433884]]\n",
            "2352          [[0.061430197, 0.6328373, 0.30573246]]\n",
            "2353       [[0.0011273902, 0.001064595, 0.99780804]]\n",
            "2354      [[0.0006281067, 0.0023847974, 0.99698704]]\n",
            "2355          [[0.032749444, 0.9591135, 0.00813703]]\n",
            "2356         [[0.045747172, 0.9365733, 0.017679514]]\n",
            "2357         [[0.0010737873, 0.01123451, 0.9876917]]\n",
            "2358      [[0.0010859312, 0.0009300109, 0.99798405]]\n",
            "2359          [[0.008764379, 0.09185005, 0.8993856]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_padanan_trim_know_val_f1_0.7504'\n",
        "pretrained_bert_name = 'indolem/indobert-base-uncased'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_padanan_trim_know_val_f1_0.7504\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "mG6AUL7Kl1_e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuFQ3Bwimwoy"
      },
      "source": [
        "## large state_dict/bert_spc_combined_raw_know_val_f1_0.7602"
      ],
      "id": "QuFQ3Bwimwoy"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/x_insert_raw_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "YqXLnOgtmwo4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YqXLnOgtmwo4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9d033bc5-9aa9-4b67-a086-1a83e4f50457",
        "id": "UYemAJugmwo4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "0              [[0.002651149, 0.05830442, 0.9390445]]\n",
            "1             [[0.0016101117, 0.12402483, 0.8743651]]\n",
            "2                [[0.02872117, 0.2501617, 0.7211172]]\n",
            "3                 [[0.76358145, 0.1820906, 0.054328]]\n",
            "4             [[0.029899381, 0.26063102, 0.70946956]]\n",
            "5               [[0.03170313, 0.25382233, 0.7144745]]\n",
            "6          [[0.00019325853, 0.0015642593, 0.9982425]]\n",
            "7            [[0.0002135492, 0.004428059, 0.9953584]]\n",
            "8          [[0.0001519039, 0.0024770335, 0.99737096]]\n",
            "9             [[0.027183425, 0.24529073, 0.72752583]]\n",
            "10           [[0.0010751185, 0.006373793, 0.9925511]]\n",
            "11            [[0.0006966896, 0.8163453, 0.18295802]]\n",
            "12                [[0.00065902, 0.81862, 0.18072094]]\n",
            "13           [[0.0005545922, 0.85539937, 0.14404604]]\n",
            "14            [[0.0008317926, 0.8656108, 0.13355738]]\n",
            "15        [[0.00083435414, 0.0016290162, 0.99753666]]\n",
            "16               [[0.5677525, 0.4082672, 0.02398033]]\n",
            "17          [[0.00021373712, 0.0004813077, 0.999305]]\n",
            "18       [[0.00011155431, 0.00034151314, 0.99954695]]\n",
            "19          [[0.0003367174, 0.021457989, 0.97820526]]\n",
            "20            [[0.007955933, 0.077572264, 0.9144718]]\n",
            "21            [[0.0010349606, 0.004192926, 0.994772]]\n",
            "22            [[0.003120838, 0.003033165, 0.9938459]]\n",
            "23            [[0.007955933, 0.077572264, 0.9144718]]\n",
            "24            [[0.007955933, 0.077572264, 0.9144718]]\n",
            "25            [[0.028409889, 0.26325074, 0.70833933]]\n",
            "26       [[0.00020176891, 0.00023770652, 0.99956053]]\n",
            "27        [[0.00015887005, 0.00014895083, 0.9996922]]\n",
            "28            [[0.0009780632, 0.22078748, 0.7782344]]\n",
            "29           [[0.0003823545, 0.11696394, 0.88265365]]\n",
            "30             [[0.011395102, 0.62260234, 0.3660026]]\n",
            "31             [[0.026775617, 0.24324101, 0.7299833]]\n",
            "32        [[0.00020856145, 0.0017549292, 0.99803656]]\n",
            "33        [[0.00019819476, 0.00020609719, 0.9995957]]\n",
            "34             [[0.006760122, 0.48012772, 0.5131122]]\n",
            "35          [[0.00045959308, 0.002380179, 0.9971603]]\n",
            "36             [[0.006854569, 0.2585142, 0.73463124]]\n",
            "37               [[0.032537136, 0.24707283, 0.72039]]\n",
            "38              [[0.03221572, 0.25197062, 0.7158137]]\n",
            "39          [[0.00063919567, 0.003520651, 0.9958402]]\n",
            "40            [[0.028645441, 0.25647604, 0.71487844]]\n",
            "41       [[0.00068202015, 0.00060953444, 0.99870837]]\n",
            "42        [[0.00028148666, 0.00029810672, 0.9994204]]\n",
            "43         [[0.00028089026, 0.002196527, 0.99752253]]\n",
            "44            [[0.0035721886, 0.04221384, 0.9542139]]\n",
            "45             [[0.0034517543, 0.17810921, 0.818439]]\n",
            "46          [[0.0013128533, 0.0041026296, 0.9945845]]\n",
            "47            [[0.000736619, 0.21300343, 0.78625995]]\n",
            "48             [[0.026775617, 0.24324101, 0.7299833]]\n",
            "49           [[0.0020867954, 0.13160166, 0.86631155]]\n",
            "50         [[0.00025993137, 0.0012308449, 0.9985092]]\n",
            "51             [[0.028423868, 0.23898593, 0.7325902]]\n",
            "52            [[0.030007256, 0.25090018, 0.71909255]]\n",
            "53            [[0.005940766, 0.39710146, 0.59695774]]\n",
            "54            [[0.0011043609, 0.11757003, 0.8813257]]\n",
            "55             [[0.03217775, 0.25210923, 0.71571296]]\n",
            "56             [[0.031275857, 0.25436494, 0.7143593]]\n",
            "57            [[0.051568553, 0.48814148, 0.46028998]]\n",
            "58             [[0.000903957, 0.81340384, 0.1856922]]\n",
            "59             [[0.011658369, 0.68162584, 0.3067158]]\n",
            "60        [[0.00023964711, 0.0005394452, 0.99922085]]\n",
            "61         [[0.00014400066, 0.0029335958, 0.9969223]]\n",
            "62          [[0.0002417966, 0.0004513142, 0.9993068]]\n",
            "63         [[0.00022795882, 0.0009183562, 0.9988537]]\n",
            "64        [[0.00067972176, 0.00036587898, 0.9989544]]\n",
            "65             [[0.030910593, 0.03899858, 0.9300908]]\n",
            "66        [[0.00048836664, 0.00012767134, 0.9993839]]\n",
            "67            [[0.033894043, 0.38832495, 0.57778096]]\n",
            "68             [[0.02794812, 0.24786654, 0.72418535]]\n",
            "69              [[0.013513304, 0.8204039, 0.1660828]]\n",
            "70           [[0.047590766, 0.93476737, 0.017641881]]\n",
            "71           [[0.016843375, 0.95727515, 0.025881475]]\n",
            "72          [[0.00013559315, 0.006685985, 0.9931785]]\n",
            "73            [[0.0010535325, 0.05053435, 0.9484122]]\n",
            "74            [[0.0005788472, 0.1045965, 0.89482474]]\n",
            "75         [[0.0015029137, 0.0041493275, 0.99434775]]\n",
            "76            [[0.0007681859, 0.08644707, 0.9127847]]\n",
            "77             [[0.029137207, 0.2625054, 0.70835733]]\n",
            "78           [[0.0004273099, 0.010966795, 0.9886059]]\n",
            "79              [[0.03303771, 0.2609903, 0.70597196]]\n",
            "80           [[0.00024625708, 0.04955181, 0.9502019]]\n",
            "81        [[0.00011650951, 0.00044650314, 0.9994369]]\n",
            "82           [[0.00018159441, 0.00251531, 0.9973031]]\n",
            "83             [[0.010478562, 0.05745363, 0.9320679]]\n",
            "84          [[0.0002031497, 0.0052792514, 0.9945175]]\n",
            "85             [[0.027953196, 0.21271522, 0.7593316]]\n",
            "86            [[0.9658581, 0.03297093, 0.0011709748]]\n",
            "87        [[0.00015447568, 0.0003959209, 0.99944955]]\n",
            "88            [[0.015719755, 0.050698597, 0.9335817]]\n",
            "89             [[0.029512906, 0.24844885, 0.7220382]]\n",
            "90        [[0.00022860861, 0.00042526922, 0.9993461]]\n",
            "91             [[0.008521817, 0.9468393, 0.04463886]]\n",
            "92          [[0.00030735068, 0.033452142, 0.9662406]]\n",
            "93           [[0.011938099, 0.022881085, 0.96518075]]\n",
            "94            [[0.028271982, 0.24733445, 0.72439355]]\n",
            "95            [[0.023742333, 0.10735758, 0.86890006]]\n",
            "96             [[0.026961224, 0.24221866, 0.7308202]]\n",
            "97        [[0.00033531192, 0.0010286086, 0.99863607]]\n",
            "98         [[0.0005597618, 0.0030256684, 0.99641454]]\n",
            "99       [[0.00011283382, 0.00063797703, 0.99924916]]\n",
            "100         [[0.0002110781, 0.00068094756, 0.999108]]\n",
            "101          [[0.00044006872, 0.4206201, 0.57893986]]\n",
            "102          [[0.0001718787, 0.007562285, 0.9922659]]\n",
            "103       [[0.00023555385, 0.0054332563, 0.99433124]]\n",
            "104         [[0.0005520111, 0.0027676877, 0.9966804]]\n",
            "105            [[0.30621442, 0.21829402, 0.47549152]]\n",
            "106         [[0.0016313208, 0.019737514, 0.97863114]]\n",
            "107            [[0.002191912, 0.9375461, 0.06026206]]\n",
            "108       [[0.00020684449, 0.00053774985, 0.9992555]]\n",
            "109       [[0.00020632843, 0.0014490007, 0.99834466]]\n",
            "110            [[0.02662618, 0.25486857, 0.71850526]]\n",
            "111        [[0.00016169745, 0.00042238622, 0.999416]]\n",
            "112             [[0.027985098, 0.2558358, 0.7161791]]\n",
            "113           [[0.0022081817, 0.0439269, 0.95386493]]\n",
            "114            [[0.029508894, 0.24105386, 0.7294372]]\n",
            "115           [[0.028724814, 0.24061197, 0.73066324]]\n",
            "116            [[0.028921718, 0.24094169, 0.7301366]]\n",
            "117      [[0.00023011136, 0.00023505483, 0.99953485]]\n",
            "118           [[0.002187039, 0.030898618, 0.9669143]]\n",
            "119           [[0.023494016, 0.92840964, 0.04809636]]\n",
            "120           [[0.0068555013, 0.6790385, 0.31410596]]\n",
            "121        [[0.00021133128, 0.0012351074, 0.9985536]]\n",
            "122               [[0.03334733, 0.278574, 0.6880787]]\n",
            "123         [[0.0004027192, 0.0027549367, 0.9968424]]\n",
            "124         [[0.00085625896, 0.040158134, 0.9589856]]\n",
            "125       [[0.00047325573, 0.0035227402, 0.99600405]]\n",
            "126         [[0.00023772113, 0.040633038, 0.9591293]]\n",
            "127        [[0.00062319014, 0.035744738, 0.96363205]]\n",
            "128             [[0.02916506, 0.25238267, 0.7184522]]\n",
            "129        [[0.00035190358, 0.0003312375, 0.9993168]]\n",
            "130        [[0.0003386982, 0.00054143363, 0.9991198]]\n",
            "131              [[0.4690074, 0.23318425, 0.2978084]]\n",
            "132           [[0.051450703, 0.034984633, 0.9135646]]\n",
            "133           [[0.027167855, 0.25013742, 0.72269475]]\n",
            "134             [[0.01815477, 0.8579016, 0.12394366]]\n",
            "135            [[0.0029120734, 0.925208, 0.07187995]]\n",
            "136          [[0.0016584592, 0.023080396, 0.9752611]]\n",
            "137          [[0.0004091691, 0.0011487924, 0.998442]]\n",
            "138      [[0.00018392892, 0.00035044595, 0.99946564]]\n",
            "139           [[0.026860643, 0.24072134, 0.73241806]]\n",
            "140        [[0.0010719699, 0.0015481117, 0.99737984]]\n",
            "141            [[0.009129923, 0.37394223, 0.6169279]]\n",
            "142          [[0.0008522699, 0.009910239, 0.9892374]]\n",
            "143        [[0.00032438204, 0.044330947, 0.95534474]]\n",
            "144        [[0.00094203785, 0.009027829, 0.99003005]]\n",
            "145         [[0.0003493677, 0.0006064324, 0.9990441]]\n",
            "146         [[0.00023219522, 0.002152782, 0.9976151]]\n",
            "147          [[0.0011679616, 0.01210277, 0.98672926]]\n",
            "148            [[0.030311208, 0.23935021, 0.7303386]]\n",
            "149        [[0.0002934527, 0.0014961615, 0.99821043]]\n",
            "150        [[0.0003199879, 0.0016059345, 0.99807405]]\n",
            "151             [[0.027389372, 0.23553258, 0.737078]]\n",
            "152         [[0.00020970196, 0.000363701, 0.9994266]]\n",
            "153            [[0.033644617, 0.8742427, 0.09211263]]\n",
            "154         [[0.00034910563, 0.08748412, 0.91216683]]\n",
            "155          [[0.0009729657, 0.16215529, 0.83687174]]\n",
            "156            [[0.0022401162, 0.6777054, 0.3200545]]\n",
            "157           [[0.0009612024, 0.06495087, 0.9340879]]\n",
            "158           [[0.022263782, 0.90800786, 0.06972835]]\n",
            "159             [[0.06032166, 0.8629377, 0.07674064]]\n",
            "160        [[0.00095820567, 0.97468895, 0.024352854]]\n",
            "161            [[0.028647386, 0.2539781, 0.71737444]]\n",
            "162      [[0.000110833775, 0.00071360334, 0.9991755]]\n",
            "163          [[0.0018387507, 0.53907996, 0.45908135]]\n",
            "164            [[0.026309557, 0.23612407, 0.7375664]]\n",
            "165         [[0.0022723356, 0.002248852, 0.99547887]]\n",
            "166          [[0.010617003, 0.030445298, 0.95893764]]\n",
            "167         [[0.00020506399, 0.00018494371, 0.99961]]\n",
            "168            [[0.0012548685, 0.3732448, 0.6255004]]\n",
            "169         [[0.00064336456, 0.08511597, 0.91424066]]\n",
            "170          [[0.0010155846, 0.009216927, 0.9897675]]\n",
            "171         [[0.00021175615, 0.001458496, 0.9983298]]\n",
            "172           [[0.030981585, 0.25074622, 0.71827215]]\n",
            "173            [[0.021214692, 0.01953808, 0.9592473]]\n",
            "174            [[0.019930044, 0.922234, 0.057835955]]\n",
            "175        [[0.00047193747, 0.0003764076, 0.9991517]]\n",
            "176         [[0.00017228817, 0.05349565, 0.94633204]]\n",
            "177          [[0.0001380968, 0.003542401, 0.9963194]]\n",
            "178          [[0.0009502752, 0.008499184, 0.9905505]]\n",
            "179           [[0.0008921107, 0.01986566, 0.9792422]]\n",
            "180        [[0.98297656, 0.0130053945, 0.0040179933]]\n",
            "181        [[0.0007730858, 0.0026803426, 0.99654657]]\n",
            "182            [[0.002215572, 0.14334327, 0.8544411]]\n",
            "183            [[0.009885543, 0.30837384, 0.6817406]]\n",
            "184            [[0.029655725, 0.23451066, 0.7358336]]\n",
            "185       [[0.0003190217, 0.00032015913, 0.99936086]]\n",
            "186        [[0.00020883858, 0.0001702033, 0.9996209]]\n",
            "187       [[0.0003190217, 0.00032015913, 0.99936086]]\n",
            "188        [[0.00080802984, 0.0027675838, 0.9964244]]\n",
            "189         [[0.0010847735, 0.024286857, 0.97462827]]\n",
            "190          [[0.0054521183, 0.39714277, 0.59740514]]\n",
            "191           [[0.0007009116, 0.004513116, 0.994786]]\n",
            "192         [[0.0003817096, 0.020400062, 0.97921824]]\n",
            "193          [[0.000335446, 0.0011488041, 0.9985158]]\n",
            "194        [[0.00038757778, 0.0026065053, 0.9970059]]\n",
            "195             [[0.008400285, 0.21328174, 0.778318]]\n",
            "196            [[0.017852278, 0.9586277, 0.02352003]]\n",
            "197         [[0.00043145253, 0.26536894, 0.73419964]]\n",
            "198         [[0.0006549075, 0.007763825, 0.99158126]]\n",
            "199       [[0.00021420479, 0.0009040109, 0.99888176]]\n",
            "200              [[0.0309665, 0.24635033, 0.7226832]]\n",
            "201          [[0.0031869684, 0.027033718, 0.9697794]]\n",
            "202        [[0.0011630245, 0.0076852827, 0.99115175]]\n",
            "203          [[0.9685269, 0.024143685, 0.0073294668]]\n",
            "204           [[0.030091643, 0.24608198, 0.72382635]]\n",
            "205           [[0.0016077932, 0.020844264, 0.977548]]\n",
            "206             [[0.257133, 0.72544587, 0.017421078]]\n",
            "207         [[0.0006199547, 0.0006855752, 0.9986945]]\n",
            "208        [[0.0002331224, 0.0010869373, 0.99867994]]\n",
            "209      [[0.00020541063, 0.00096700806, 0.99882764]]\n",
            "210        [[0.00017556237, 0.0043376125, 0.9954869]]\n",
            "211        [[0.000114840586, 0.001069301, 0.9988159]]\n",
            "212         [[0.00022236863, 0.000231767, 0.9995459]]\n",
            "213          [[0.0037338503, 0.022555279, 0.9737109]]\n",
            "214            [[0.031093309, 0.25002876, 0.7188779]]\n",
            "215       [[0.00022593045, 0.0028531742, 0.99692094]]\n",
            "216          [[0.00069990417, 0.0861208, 0.91317934]]\n",
            "217         [[0.00015336476, 0.012319893, 0.9875267]]\n",
            "218        [[0.00017747353, 0.015493195, 0.98432946]]\n",
            "219         [[0.00023673687, 0.005712541, 0.9940507]]\n",
            "220        [[0.0005972851, 0.0044958084, 0.99490684]]\n",
            "221            [[0.025012026, 0.21644674, 0.7585412]]\n",
            "222          [[0.0006807544, 0.008947799, 0.9903715]]\n",
            "223             [[0.028314665, 0.24668431, 0.725001]]\n",
            "224        [[0.00056046975, 0.0055461805, 0.9938933]]\n",
            "225        [[0.0002869471, 0.0010348072, 0.99867827]]\n",
            "226             [[0.035977606, 0.2555438, 0.7084786]]\n",
            "227             [[0.00058636, 0.2999511, 0.69946253]]\n",
            "228         [[0.00047572126, 0.9422548, 0.057269443]]\n",
            "229          [[0.00058699923, 0.7297849, 0.26962814]]\n",
            "230           [[0.0011968267, 0.8241276, 0.17467555]]\n",
            "231        [[0.00041293912, 0.0038388704, 0.9957482]]\n",
            "232             [[0.04496183, 0.7054421, 0.24959609]]\n",
            "233         [[0.00052635535, 0.010014227, 0.9894595]]\n",
            "234            [[0.25866726, 0.23350248, 0.50783026]]\n",
            "235              [[0.03306899, 0.2546712, 0.7122599]]\n",
            "236            [[0.032125846, 0.2487655, 0.71910864]]\n",
            "237          [[0.0004539679, 0.00226321, 0.99728274]]\n",
            "238              [[0.8334213, 0.0898879, 0.07669074]]\n",
            "239          [[0.0009227095, 0.0039033222, 0.995174]]\n",
            "240          [[0.0018184459, 0.04075529, 0.95742613]]\n",
            "241          [[0.0024103103, 0.047778588, 0.9498111]]\n",
            "242             [[0.027200164, 0.242136, 0.73066384]]\n",
            "243            [[0.030525459, 0.24089964, 0.7285748]]\n",
            "244             [[0.03236087, 0.24424607, 0.7233931]]\n",
            "245          [[0.005281353, 0.97685575, 0.017862897]]\n",
            "246        [[0.0030408704, 0.00077237934, 0.9961868]]\n",
            "247        [[0.0007186316, 0.0045809047, 0.99470055]]\n",
            "248            [[0.005896106, 0.05564259, 0.9384614]]\n",
            "249        [[9.701307e-05, 0.00020955443, 0.9996935]]\n",
            "250        [[0.00028802035, 0.0022496015, 0.9974624]]\n",
            "251       [[0.00086525886, 0.0012028085, 0.99793196]]\n",
            "252       [[0.00086525886, 0.0012028085, 0.99793196]]\n",
            "253        [[0.00016734922, 0.0036770268, 0.9961557]]\n",
            "254            [[0.0006065923, 0.3603333, 0.6390602]]\n",
            "255         [[0.00031562673, 0.09207133, 0.90761304]]\n",
            "256            [[0.030500064, 0.24888273, 0.7206172]]\n",
            "257           [[0.030930018, 0.26063442, 0.70843554]]\n",
            "258        [[0.00015611465, 0.0006891632, 0.9991547]]\n",
            "259         [[0.00059433916, 0.76504093, 0.23436476]]\n",
            "260           [[0.0004989559, 0.81810045, 0.1814006]]\n",
            "261             [[0.02889531, 0.26361197, 0.7074927]]\n",
            "262           [[0.030810151, 0.25165862, 0.71753126]]\n",
            "263           [[0.14351054, 0.83452475, 0.021964699]]\n",
            "264             [[0.9106822, 0.02236749, 0.06695025]]\n",
            "265           [[0.021939527, 0.86814415, 0.10991634]]\n",
            "266              [[0.01071821, 0.3745941, 0.6146877]]\n",
            "267            [[0.031568285, 0.2519655, 0.71646625]]\n",
            "268            [[0.031568285, 0.2519655, 0.71646625]]\n",
            "269             [[0.033026725, 0.2652072, 0.7017661]]\n",
            "270             [[0.03072976, 0.24091685, 0.7283534]]\n",
            "271          [[0.97479564, 0.017103065, 0.008101202]]\n",
            "272          [[0.0041662557, 0.029780056, 0.9660538]]\n",
            "273         [[0.00013411073, 0.014665381, 0.9852005]]\n",
            "274       [[0.00022250097, 0.00032887247, 0.9994486]]\n",
            "275       [[0.00018139879, 0.0038775767, 0.99594104]]\n",
            "276             [[0.000979215, 0.1380355, 0.8609852]]\n",
            "277            [[0.026865935, 0.24147272, 0.7316614]]\n",
            "278       [[0.00018598553, 0.0006471823, 0.99916697]]\n",
            "279           [[0.0006925387, 0.016141528, 0.983166]]\n",
            "280           [[0.027533025, 0.24718769, 0.72527933]]\n",
            "281           [[0.0004328595, 0.3876899, 0.61187726]]\n",
            "282        [[0.00019424496, 0.0013400103, 0.9984658]]\n",
            "283          [[0.00041152403, 0.07901388, 0.9205746]]\n",
            "284            [[0.029640565, 0.24521759, 0.7251419]]\n",
            "285         [[0.0009980336, 0.98319143, 0.015810482]]\n",
            "286          [[0.0009184698, 0.89643574, 0.10264579]]\n",
            "287          [[0.001069524, 0.008592556, 0.99033797]]\n",
            "288          [[0.0020345903, 0.04193115, 0.95603424]]\n",
            "289        [[0.00062594004, 0.0011778641, 0.9981963]]\n",
            "290          [[0.0020345903, 0.04193115, 0.95603424]]\n",
            "291            [[0.028544098, 0.2289082, 0.74254775]]\n",
            "292         [[0.00043263432, 0.016467752, 0.9830996]]\n",
            "293       [[0.00040199282, 0.0032191414, 0.99637896]]\n",
            "294            [[0.029369058, 0.26503307, 0.7055979]]\n",
            "295            [[0.0004491317, 0.3822182, 0.6173327]]\n",
            "296            [[0.002540154, 0.8523496, 0.14511026]]\n",
            "297            [[0.0023481846, 0.8298863, 0.1677655]]\n",
            "298           [[0.0011431392, 0.40306735, 0.5957895]]\n",
            "299       [[0.00058094214, 0.00050486607, 0.9989141]]\n",
            "300         [[0.00048482697, 0.004451431, 0.9950637]]\n",
            "301        [[0.00031642616, 0.0060268985, 0.9936567]]\n",
            "302           [[0.002871838, 0.56740236, 0.42972577]]\n",
            "303            [[0.007477566, 0.5914037, 0.40111873]]\n",
            "304          [[0.0006804766, 0.002204145, 0.9971154]]\n",
            "305           [[0.041672867, 0.76007426, 0.19825284]]\n",
            "306           [[0.035593007, 0.24932845, 0.71507853]]\n",
            "307             [[0.03304244, 0.24586245, 0.7210951]]\n",
            "308             [[0.038439732, 0.257403, 0.70415723]]\n",
            "309           [[0.0037053006, 0.37668195, 0.6196128]]\n",
            "310        [[0.00025424335, 0.0062303683, 0.9935154]]\n",
            "311        [[0.00019552157, 0.0067525776, 0.9930519]]\n",
            "312           [[0.014155781, 0.95595276, 0.02989144]]\n",
            "313          [[0.0027314096, 0.029023942, 0.9682446]]\n",
            "314        [[0.00022834382, 0.027649423, 0.97212225]]\n",
            "315           [[0.013622459, 0.05853225, 0.92784524]]\n",
            "316        [[9.883006e-05, 0.0015249625, 0.99837625]]\n",
            "317          [[8.431243e-05, 0.008774772, 0.9911409]]\n",
            "318        [[7.824914e-05, 0.0022846062, 0.99763715]]\n",
            "319             [[0.008112847, 0.5483923, 0.4434949]]\n",
            "320          [[0.0032309846, 0.67262036, 0.32414868]]\n",
            "321         [[0.0010926041, 0.107106075, 0.89180136]]\n",
            "322      [[0.00024327915, 0.00019486828, 0.99956185]]\n",
            "323       [[0.00026906675, 0.00024544713, 0.9994855]]\n",
            "324            [[0.026900541, 0.24189065, 0.7312088]]\n",
            "325         [[0.0004302389, 0.0030300696, 0.9965397]]\n",
            "326         [[0.0022805382, 0.002030629, 0.99568886]]\n",
            "327            [[0.027433632, 0.24393594, 0.7286304]]\n",
            "328            [[0.8011723, 0.16949898, 0.029328687]]\n",
            "329             [[0.008188469, 0.31271857, 0.679093]]\n",
            "330              [[0.2181406, 0.7146235, 0.06723592]]\n",
            "331             [[0.008188469, 0.31271857, 0.679093]]\n",
            "332             [[0.16614078, 0.5137957, 0.32006356]]\n",
            "333        [[0.00018917654, 0.00041780996, 0.999393]]\n",
            "334           [[0.07255846, 0.9242362, 0.0032053925]]\n",
            "335            [[0.007390125, 0.77413654, 0.2184733]]\n",
            "336            [[0.02770372, 0.83343166, 0.13886459]]\n",
            "337           [[0.0033556812, 0.013813392, 0.982831]]\n",
            "338        [[0.00032508516, 0.0007507555, 0.9989241]]\n",
            "339           [[0.0066056345, 0.00481675, 0.9885776]]\n",
            "340             [[0.18766753, 0.6878183, 0.12451417]]\n",
            "341              [[0.026855147, 0.245917, 0.7272278]]\n",
            "342       [[0.00014830427, 0.00038399943, 0.9994677]]\n",
            "343     [[0.000109922905, 0.00034765527, 0.99954236]]\n",
            "344         [[0.0008076539, 0.010063779, 0.98912853]]\n",
            "345       [[0.00052443705, 0.0009123372, 0.99856323]]\n",
            "346        [[0.0003555584, 0.00095225766, 0.9986921]]\n",
            "347             [[0.23332563, 0.16442072, 0.6022537]]\n",
            "348           [[0.026889546, 0.23934816, 0.73376226]]\n",
            "349           [[0.026731418, 0.24190952, 0.73135906]]\n",
            "350           [[0.005422647, 0.058238395, 0.9363389]]\n",
            "351           [[0.91847664, 0.06800267, 0.013520678]]\n",
            "352        [[0.00026501325, 0.008816801, 0.99091816]]\n",
            "353             [[0.02951383, 0.25983474, 0.7106514]]\n",
            "354       [[0.00020664069, 0.0024035834, 0.99738985]]\n",
            "355            [[0.030687442, 0.25136364, 0.7179489]]\n",
            "356          [[0.0015389441, 0.06939509, 0.92906594]]\n",
            "357             [[0.026664441, 0.1806603, 0.7926752]]\n",
            "358            [[0.032209214, 0.25658995, 0.7112009]]\n",
            "359          [[0.0019658536, 0.087093875, 0.9109403]]\n",
            "360             [[0.03396229, 0.24739288, 0.7186448]]\n",
            "361             [[0.02881685, 0.24915205, 0.7220311]]\n",
            "362          [[0.0010639247, 0.054708574, 0.9442275]]\n",
            "363         [[0.00022466872, 0.005268554, 0.9945068]]\n",
            "364         [[0.00090478477, 0.9630328, 0.036062457]]\n",
            "365         [[0.0002563685, 0.98529804, 0.014445547]]\n",
            "366          [[0.00042446918, 0.9940479, 0.00552766]]\n",
            "367           [[0.017470917, 0.90696967, 0.07555944]]\n",
            "368             [[0.0005231326, 0.089991, 0.9094858]]\n",
            "369            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "370         [[0.00036411735, 0.047957104, 0.9516787]]\n",
            "371         [[0.00044785673, 0.013309334, 0.9862429]]\n",
            "372          [[0.00084061007, 0.8941223, 0.10503706]]\n",
            "373       [[0.00010980312, 0.0012581004, 0.99863213]]\n",
            "374          [[0.00049246475, 0.19673157, 0.8027759]]\n",
            "375             [[0.02715071, 0.25098252, 0.7218668]]\n",
            "376           [[0.005896195, 0.022364732, 0.9717391]]\n",
            "377            [[0.05610034, 0.15243503, 0.79146457]]\n",
            "378            [[0.022082226, 0.23744099, 0.7404768]]\n",
            "379         [[0.0030182218, 0.018638961, 0.97834283]]\n",
            "380           [[0.022428146, 0.59056103, 0.38701084]]\n",
            "381           [[0.001229617, 0.0026684196, 0.996102]]\n",
            "382              [[0.5971769, 0.30966398, 0.0931591]]\n",
            "383            [[0.0112764435, 0.8106723, 0.1780513]]\n",
            "384            [[0.0112764435, 0.8106723, 0.1780513]]\n",
            "385            [[0.011664306, 0.7457656, 0.24257007]]\n",
            "386        [[0.0001970955, 0.00026714007, 0.9995358]]\n",
            "387          [[0.0009967458, 0.52954066, 0.46946266]]\n",
            "388             [[0.02915924, 0.2333398, 0.73750097]]\n",
            "389          [[0.00045069322, 0.07090388, 0.9286454]]\n",
            "390             [[0.02771945, 0.23649551, 0.7357851]]\n",
            "391            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "392         [[0.0004599312, 0.0010121599, 0.9985279]]\n",
            "393       [[0.00022679615, 0.00092309044, 0.9988501]]\n",
            "394      [[0.00040886988, 0.00035679154, 0.99923444]]\n",
            "395           [[0.003847097, 0.49835256, 0.49780038]]\n",
            "396             [[0.004169636, 0.788584, 0.20724636]]\n",
            "397            [[0.02164441, 0.48665515, 0.49170044]]\n",
            "398           [[0.0009010124, 0.34840328, 0.6506956]]\n",
            "399            [[0.026528671, 0.25048292, 0.7229884]]\n",
            "400            [[0.02230624, 0.50280327, 0.47489047]]\n",
            "401           [[0.0010344329, 0.28691265, 0.7120529]]\n",
            "402            [[0.0033455007, 0.0680791, 0.9285754]]\n",
            "403           [[0.028995315, 0.25644132, 0.71456337]]\n",
            "404        [[0.00065755536, 0.97677803, 0.022564359]]\n",
            "405           [[0.0006693941, 0.8255515, 0.17377912]]\n",
            "406         [[0.0006012651, 0.97525054, 0.024148175]]\n",
            "407            [[0.028893923, 0.25582996, 0.7152761]]\n",
            "408           [[0.0008981655, 0.9398132, 0.05928868]]\n",
            "409            [[0.026831677, 0.24797659, 0.7251917]]\n",
            "410          [[0.0023637984, 0.18896078, 0.80867547]]\n",
            "411            [[0.027565079, 0.25506133, 0.7173736]]\n",
            "412             [[0.007148347, 0.4802379, 0.5126138]]\n",
            "413          [[0.0013459823, 0.9647474, 0.033906635]]\n",
            "414           [[0.0050536213, 0.8346035, 0.16034292]]\n",
            "415            [[0.030402247, 0.25072324, 0.7188745]]\n",
            "416         [[0.0020693433, 0.017565079, 0.98036546]]\n",
            "417            [[0.027241735, 0.24865814, 0.7241001]]\n",
            "418        [[0.0005548973, 0.0046951524, 0.99474996]]\n",
            "419       [[0.00019192568, 0.0005033748, 0.99930465]]\n",
            "420       [[0.00019192568, 0.0005033748, 0.99930465]]\n",
            "421        [[0.00017086083, 0.0012124691, 0.9986167]]\n",
            "422        [[0.00054851366, 0.054935366, 0.94451606]]\n",
            "423           [[0.001468339, 0.018936241, 0.9795955]]\n",
            "424         [[0.00071738486, 0.032443166, 0.9668395]]\n",
            "425           [[0.028343564, 0.24922158, 0.72243494]]\n",
            "426        [[0.0008013446, 0.0004335253, 0.99876523]]\n",
            "427          [[0.0008218876, 0.041171744, 0.9580063]]\n",
            "428           [[0.000954185, 0.75487834, 0.24416745]]\n",
            "429        [[0.00039779022, 0.0034487473, 0.9961534]]\n",
            "430            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "431          [[0.0002870608, 0.043339383, 0.9563736]]\n",
            "432         [[0.005072903, 0.0032242641, 0.99170285]]\n",
            "433         [[0.00015835749, 0.0011087098, 0.998733]]\n",
            "434           [[0.070904516, 0.09261924, 0.83647627]]\n",
            "435             [[0.0010132664, 0.7499377, 0.249049]]\n",
            "436        [[0.00010997017, 0.013122003, 0.98676807]]\n",
            "437           [[0.026433356, 0.23741405, 0.73615265]]\n",
            "438        [[0.0003364334, 0.0010483252, 0.99861526]]\n",
            "439           [[0.0008537906, 0.5575882, 0.44155797]]\n",
            "440          [[0.0005601756, 0.9531268, 0.046313085]]\n",
            "441         [[0.0002392402, 0.009850207, 0.98991054]]\n",
            "442             [[0.028996892, 0.2615588, 0.7094443]]\n",
            "443        [[0.00024157092, 0.0060208337, 0.9937376]]\n",
            "444           [[0.0002642852, 0.04614242, 0.9535933]]\n",
            "445         [[0.0002411705, 0.0023910482, 0.9973678]]\n",
            "446            [[0.027219402, 0.24961424, 0.7231664]]\n",
            "447        [[0.00020403048, 0.0031674088, 0.9966286]]\n",
            "448         [[0.00026832908, 0.030750846, 0.9689808]]\n",
            "449          [[0.0019697163, 0.92132956, 0.07670067]]\n",
            "450          [[0.0018206963, 0.90081567, 0.09736364]]\n",
            "451           [[0.00047135522, 0.1771678, 0.8223609]]\n",
            "452           [[0.0006082161, 0.36774364, 0.6316482]]\n",
            "453           [[0.0015783232, 0.09155845, 0.9068632]]\n",
            "454          [[0.0006142334, 0.31244883, 0.68693686]]\n",
            "455         [[0.00035373558, 0.45719528, 0.54245096]]\n",
            "456        [[0.00020689766, 0.00019108153, 0.999602]]\n",
            "457            [[0.02700256, 0.23723753, 0.73575985]]\n",
            "458            [[0.026851393, 0.23665841, 0.7364902]]\n",
            "459            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "460      [[0.00024346598, 0.00040243406, 0.99935406]]\n",
            "461             [[0.029884782, 0.2286636, 0.7414516]]\n",
            "462           [[0.00046751372, 0.0937946, 0.9057379]]\n",
            "463            [[0.026680896, 0.23639275, 0.7369264]]\n",
            "464           [[0.000579586, 0.027576039, 0.9718444]]\n",
            "465      [[0.00027818317, 0.00024310654, 0.99947876]]\n",
            "466             [[0.029058795, 0.2510089, 0.7199323]]\n",
            "467       [[0.00034513234, 0.00061017665, 0.9990447]]\n",
            "468            [[0.002753286, 0.04712882, 0.9501179]]\n",
            "469         [[0.00075615454, 0.029298086, 0.9699458]]\n",
            "470            [[0.0016444989, 0.04313654, 0.955219]]\n",
            "471           [[0.38184473, 0.107027896, 0.51112735]]\n",
            "472         [[0.0019777475, 0.017033802, 0.98098844]]\n",
            "473           [[0.38184473, 0.107027896, 0.51112735]]\n",
            "474          [[0.0022195594, 0.005747507, 0.9920328]]\n",
            "475          [[0.0013228285, 0.019947344, 0.9787298]]\n",
            "476       [[0.00018107396, 0.00045115515, 0.9993678]]\n",
            "477         [[0.001113197, 0.0032643205, 0.99562246]]\n",
            "478        [[0.0010337523, 0.0054290337, 0.99353725]]\n",
            "479       [[0.00018513811, 0.0022242004, 0.99759066]]\n",
            "480        [[0.00020472395, 0.027928034, 0.97186726]]\n",
            "481          [[0.00017161694, 0.0031128, 0.99671566]]\n",
            "482          [[0.00069983426, 0.14624193, 0.8530582]]\n",
            "483          [[0.00015021217, 0.00652767, 0.9933221]]\n",
            "484       [[0.00017755119, 0.0020973503, 0.99772507]]\n",
            "485         [[9.441861e-05, 0.0010003222, 0.9989052]]\n",
            "486         [[0.00027001832, 0.017537476, 0.9821926]]\n",
            "487        [[0.000102836246, 0.009343785, 0.9905533]]\n",
            "488         [[0.00017109152, 0.099248655, 0.9005803]]\n",
            "489           [[0.0010413007, 0.10444481, 0.8945139]]\n",
            "490          [[0.0069004465, 0.057872187, 0.9352274]]\n",
            "491              [[0.0270289, 0.25129318, 0.7216779]]\n",
            "492            [[0.028066033, 0.24995871, 0.7219753]]\n",
            "493         [[0.0005458711, 0.0006953077, 0.9987588]]\n",
            "494            [[0.032494523, 0.25700265, 0.7105028]]\n",
            "495           [[0.0010413007, 0.10444481, 0.8945139]]\n",
            "496           [[0.0018117148, 0.009633238, 0.988555]]\n",
            "497           [[0.019322263, 0.012273618, 0.9684041]]\n",
            "498            [[0.029546311, 0.24566647, 0.7247872]]\n",
            "499          [[0.0011829074, 0.16661668, 0.83220035]]\n",
            "500            [[0.027598046, 0.24660137, 0.7258005]]\n",
            "501         [[0.0007099687, 0.0007369215, 0.9985531]]\n",
            "502           [[0.0009957642, 0.22918531, 0.7698189]]\n",
            "503            [[0.18047732, 0.051432073, 0.7680906]]\n",
            "504           [[0.003761143, 0.27741534, 0.71882355]]\n",
            "505            [[0.027458616, 0.23362327, 0.7389181]]\n",
            "506         [[0.0002563085, 0.002310458, 0.99743325]]\n",
            "507            [[0.029359048, 0.24031624, 0.7303247]]\n",
            "508            [[0.029004762, 0.23615369, 0.7348415]]\n",
            "509       [[0.00019574875, 0.0023305607, 0.99747366]]\n",
            "510         [[0.00023291713, 0.002554475, 0.9972127]]\n",
            "511              [[0.026363105, 0.252181, 0.7214558]]\n",
            "512       [[0.00023224874, 0.00091633666, 0.9988514]]\n",
            "513       [[0.00010346262, 0.00019522269, 0.9997013]]\n",
            "514       [[0.00032845003, 0.00021597378, 0.9994555]]\n",
            "515            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "516        [[0.00076049974, 0.124202855, 0.87503654]]\n",
            "517           [[0.029625554, 0.23943466, 0.73093975]]\n",
            "518            [[0.013793231, 0.8441731, 0.14203365]]\n",
            "519           [[0.00128228, 0.011346745, 0.98737097]]\n",
            "520        [[0.00082932325, 0.065195486, 0.93397516]]\n",
            "521        [[0.00050000753, 0.0058778827, 0.9936221]]\n",
            "522        [[0.00017669913, 0.0007510541, 0.9990722]]\n",
            "523       [[0.0001699214, 0.00026456502, 0.99956554]]\n",
            "524         [[0.0011683858, 0.0015883379, 0.9972433]]\n",
            "525        [[0.0005970299, 0.0003012078, 0.99910176]]\n",
            "526        [[0.0006337459, 0.0047622398, 0.99460405]]\n",
            "527        [[0.00030182485, 0.0009260297, 0.9987721]]\n",
            "528            [[0.027395189, 0.24910271, 0.7235021]]\n",
            "529           [[0.0004107063, 0.0617561, 0.93783313]]\n",
            "530         [[0.0015861552, 0.0056974106, 0.9927165]]\n",
            "531           [[0.001027114, 0.011986113, 0.9869867]]\n",
            "532         [[0.00055513927, 0.044953637, 0.9544912]]\n",
            "533           [[0.030413479, 0.24947083, 0.72011566]]\n",
            "534            [[0.009791141, 0.25276816, 0.7374407]]\n",
            "535           [[0.0009371327, 0.24110363, 0.7579592]]\n",
            "536          [[0.0011798323, 0.20018052, 0.79863966]]\n",
            "537      [[0.00046882746, 0.00087327114, 0.99865794]]\n",
            "538            [[0.029728606, 0.25467816, 0.7155933]]\n",
            "539             [[0.13621663, 0.6901946, 0.17358877]]\n",
            "540            [[0.033474017, 0.26102272, 0.7055033]]\n",
            "541           [[0.80015147, 0.048442997, 0.15140554]]\n",
            "542           [[0.07268102, 0.064283416, 0.86303556]]\n",
            "543       [[0.00011474189, 0.0014900332, 0.99839526]]\n",
            "544         [[7.909976e-05, 0.0040060338, 0.9959149]]\n",
            "545       [[9.8021505e-05, 0.00027565128, 0.9996263]]\n",
            "546        [[0.00023752685, 0.045182478, 0.95458007]]\n",
            "547          [[0.0044491487, 0.10672313, 0.88882774]]\n",
            "548           [[0.030759756, 0.23571794, 0.73352236]]\n",
            "549           [[0.0010376717, 0.11007348, 0.8888888]]\n",
            "550             [[0.03170905, 0.24557276, 0.7227181]]\n",
            "551           [[0.0013950447, 0.36331633, 0.6352886]]\n",
            "552           [[0.0011067942, 0.12624653, 0.8726467]]\n",
            "553          [[0.0011988633, 0.44346553, 0.55533564]]\n",
            "554        [[0.00092109374, 0.081906356, 0.91717255]]\n",
            "555        [[0.00092109374, 0.081906356, 0.91717255]]\n",
            "556             [[0.02762095, 0.2315417, 0.74083734]]\n",
            "557        [[0.00016667372, 0.0051082894, 0.9947249]]\n",
            "558       [[0.00022383042, 0.0003297624, 0.99944633]]\n",
            "559          [[0.0003989782, 0.053011287, 0.9465897]]\n",
            "560          [[0.0003105617, 0.033727054, 0.9659624]]\n",
            "561            [[0.032417256, 0.2530139, 0.71456885]]\n",
            "562         [[0.00024559023, 0.029535718, 0.9702187]]\n",
            "563        [[0.00022268805, 0.009880818, 0.98989654]]\n",
            "564          [[0.0003787371, 0.0051982584, 0.994423]]\n",
            "565         [[0.00017453394, 0.014987595, 0.9848378]]\n",
            "566           [[0.0006048253, 0.34586036, 0.6535348]]\n",
            "567           [[0.031570297, 0.26126802, 0.70716166]]\n",
            "568         [[0.0002464549, 0.026212553, 0.97354096]]\n",
            "569        [[0.00014950868, 0.004663693, 0.99518687]]\n",
            "570         [[0.00014778259, 0.0013982404, 0.998454]]\n",
            "571        [[0.00021448455, 0.0061780973, 0.9936074]]\n",
            "572          [[0.0002058641, 0.004147417, 0.9956468]]\n",
            "573        [[0.00017431677, 0.0029792779, 0.9968464]]\n",
            "574        [[0.0007474583, 0.0008206166, 0.99843186]]\n",
            "575         [[0.00047044593, 0.042639334, 0.9568902]]\n",
            "576            [[0.027700322, 0.24973354, 0.7225661]]\n",
            "577           [[0.001004738, 0.16831404, 0.83068126]]\n",
            "578            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "579           [[0.028458912, 0.25174236, 0.71979874]]\n",
            "580          [[0.95575935, 0.032056686, 0.012183978]]\n",
            "581             [[0.42070633, 0.2105144, 0.36877924]]\n",
            "582            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "583      [[0.00020701565, 0.00094005815, 0.99885285]]\n",
            "584             [[0.5483696, 0.29011348, 0.16151692]]\n",
            "585        [[0.00030875055, 0.011426097, 0.98826516]]\n",
            "586           [[0.033327285, 0.24880612, 0.71786654]]\n",
            "587         [[0.00025694314, 0.0031520436, 0.996591]]\n",
            "588             [[0.001090094, 0.15706694, 0.841843]]\n",
            "589          [[0.0036300223, 0.84929746, 0.14707251]]\n",
            "590       [[0.00021917184, 0.0011265147, 0.99865425]]\n",
            "591       [[0.0001754807, 0.00038689846, 0.99943763]]\n",
            "592            [[0.026535619, 0.23960702, 0.7338573]]\n",
            "593      [[0.00061255245, 0.00018363887, 0.99920374]]\n",
            "594      [[0.00024753387, 0.00025337326, 0.99949896]]\n",
            "595         [[0.00079565257, 0.066932715, 0.9322716]]\n",
            "596        [[0.0006169346, 0.0006472468, 0.99873585]]\n",
            "597        [[0.00018372819, 0.00029523857, 0.999521]]\n",
            "598           [[0.030737305, 0.23996387, 0.72929883]]\n",
            "599          [[0.00034300337, 0.13694637, 0.8627107]]\n",
            "600          [[0.0014435269, 0.036713865, 0.9618426]]\n",
            "601             [[0.01778922, 0.4618395, 0.52037126]]\n",
            "602       [[0.00020193223, 0.0007651698, 0.99903286]]\n",
            "603       [[0.00015077234, 0.00057728856, 0.9992719]]\n",
            "604           [[0.060065567, 0.26931357, 0.67062086]]\n",
            "605           [[0.0015801701, 0.20502524, 0.7933946]]\n",
            "606           [[0.000507517, 0.90597427, 0.09351823]]\n",
            "607            [[0.001312674, 0.08701555, 0.9116718]]\n",
            "608         [[0.00010901484, 0.000978785, 0.9989122]]\n",
            "609        [[0.00043590536, 0.052596863, 0.94696724]]\n",
            "610        [[0.00021009405, 0.001534307, 0.99825567]]\n",
            "611         [[0.0012609323, 0.013344259, 0.98539484]]\n",
            "612        [[0.00041332256, 0.0025705744, 0.9970161]]\n",
            "613         [[0.0002322401, 0.0018495157, 0.9979183]]\n",
            "614           [[0.0024112684, 0.7406276, 0.25696114]]\n",
            "615             [[0.04409727, 0.38801724, 0.5678855]]\n",
            "616             [[0.10790892, 0.14606068, 0.7460304]]\n",
            "617            [[0.13864772, 0.37138584, 0.48996645]]\n",
            "618            [[0.027997306, 0.23446758, 0.7375351]]\n",
            "619         [[0.00074894243, 0.9474406, 0.051810425]]\n",
            "620          [[0.0006656847, 0.93940586, 0.05992848]]\n",
            "621         [[0.0060586496, 0.97618085, 0.017760491]]\n",
            "622            [[0.000990066, 0.6117397, 0.38727018]]\n",
            "623           [[0.0008709278, 0.6172792, 0.38184994]]\n",
            "624         [[0.0015676501, 0.97950304, 0.018929308]]\n",
            "625            [[0.003461265, 0.66525626, 0.3312825]]\n",
            "626        [[0.00028448575, 0.0009050618, 0.9988105]]\n",
            "627            [[0.006876587, 0.38879952, 0.6043239]]\n",
            "628           [[0.0024811549, 0.55161154, 0.4459073]]\n",
            "629         [[0.00072260486, 0.8799345, 0.119342886]]\n",
            "630       [[8.588439e-05, 0.00030754827, 0.99960655]]\n",
            "631         [[0.0002862593, 0.021867698, 0.97784597]]\n",
            "632      [[0.000103624494, 0.0006932672, 0.99920315]]\n",
            "633       [[0.00016960232, 0.00025719474, 0.9995733]]\n",
            "634            [[0.025926914, 0.24252573, 0.7315474]]\n",
            "635      [[0.00024273008, 0.00014224148, 0.99961495]]\n",
            "636            [[0.02627187, 0.23056939, 0.74315876]]\n",
            "637       [[0.00034676358, 0.00049769715, 0.9991555]]\n",
            "638          [[0.95875615, 0.03611611, 0.0051277005]]\n",
            "639          [[0.9762176, 0.019996032, 0.0037863385]]\n",
            "640           [[0.0075861383, 0.31060266, 0.6818112]]\n",
            "641            [[0.030792508, 0.24801382, 0.7211937]]\n",
            "642             [[0.5290973, 0.4331162, 0.037786555]]\n",
            "643          [[0.0012386489, 0.015007742, 0.9837536]]\n",
            "644           [[0.0030205394, 0.15104301, 0.8459365]]\n",
            "645         [[0.0003767159, 0.0029253857, 0.9966979]]\n",
            "646            [[0.028661141, 0.25252032, 0.7188186]]\n",
            "647           [[0.0075861383, 0.31060266, 0.6818112]]\n",
            "648           [[0.062452767, 0.9103036, 0.027243646]]\n",
            "649              [[0.0307167, 0.8765575, 0.09272584]]\n",
            "650           [[0.0030205394, 0.15104301, 0.8459365]]\n",
            "651          [[0.00023775837, 0.036355287, 0.963407]]\n",
            "652              [[0.2316254, 0.7450859, 0.02328871]]\n",
            "653           [[0.037447397, 0.018250212, 0.9443024]]\n",
            "654         [[0.00032077328, 0.042410895, 0.9572683]]\n",
            "655        [[0.00020903038, 0.0003144622, 0.9994766]]\n",
            "656            [[0.008274043, 0.44030613, 0.5514198]]\n",
            "657        [[0.00012107096, 0.0038518237, 0.9960271]]\n",
            "658       [[0.00023259426, 0.0024990174, 0.99726844]]\n",
            "659         [[0.00034871066, 0.012096913, 0.9875544]]\n",
            "660         [[0.00028005982, 0.00702458, 0.99269533]]\n",
            "661       [[0.00029678637, 0.0068694847, 0.99283373]]\n",
            "662       [[0.00043124205, 0.0009132739, 0.99865556]]\n",
            "663        [[0.00033013188, 0.0014644291, 0.9982054]]\n",
            "664       [[0.00012921084, 0.00051322917, 0.9993575]]\n",
            "665         [[0.00029142774, 0.006130987, 0.9935776]]\n",
            "666            [[0.0024977287, 0.1439578, 0.8535444]]\n",
            "667          [[0.0034408616, 0.52015054, 0.47640866]]\n",
            "668             [[0.13169846, 0.44293743, 0.4253641]]\n",
            "669         [[0.00050376635, 0.024282502, 0.9752137]]\n",
            "670        [[0.00025787688, 0.0074790088, 0.9922631]]\n",
            "671        [[0.0005843243, 0.0027212023, 0.99669445]]\n",
            "672           [[0.0012793057, 0.22961786, 0.7691029]]\n",
            "673          [[0.001411767, 0.97097224, 0.027616004]]\n",
            "674          [[0.00065379625, 0.15408678, 0.8452595]]\n",
            "675           [[0.8383922, 0.042570997, 0.119036734]]\n",
            "676         [[0.93696505, 0.056681227, 0.0063536223]]\n",
            "677           [[0.79846305, 0.19236386, 0.009173126]]\n",
            "678            [[0.7755342, 0.19187163, 0.032594074]]\n",
            "679            [[0.39811447, 0.5840949, 0.017790703]]\n",
            "680             [[0.868638, 0.12477976, 0.006582285]]\n",
            "681             [[0.031160813, 0.2395032, 0.7293359]]\n",
            "682            [[0.9527951, 0.014875799, 0.03232912]]\n",
            "683           [[0.9068235, 0.08943237, 0.0037441053]]\n",
            "684             [[0.57529706, 0.1194947, 0.30520824]]\n",
            "685       [[0.00023545796, 0.00028316161, 0.9994814]]\n",
            "686          [[0.000529792, 0.057294812, 0.94217545]]\n",
            "687          [[0.00074367976, 0.19052623, 0.8087301]]\n",
            "688           [[0.0028222098, 0.6004011, 0.39677668]]\n",
            "689             [[0.73973745, 0.11128427, 0.1489783]]\n",
            "690       [[0.00022826128, 0.0002277099, 0.99954396]]\n",
            "691          [[0.00025634712, 0.1446863, 0.85505736]]\n",
            "692           [[0.029444544, 0.25831884, 0.71223664]]\n",
            "693          [[0.00019988505, 0.14530529, 0.8544948]]\n",
            "694          [[0.00025634712, 0.1446863, 0.85505736]]\n",
            "695          [[0.0008221206, 0.9739512, 0.025226615]]\n",
            "696          [[0.0013486444, 0.75581175, 0.24283959]]\n",
            "697        [[0.0002914072, 0.0048965057, 0.99481213]]\n",
            "698       [[0.00037351268, 0.0112793315, 0.98834723]]\n",
            "699            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "700         [[0.00021205368, 0.001613111, 0.9981749]]\n",
            "701             [[0.02694869, 0.2347003, 0.73835105]]\n",
            "702           [[0.0010400999, 0.24055709, 0.7584028]]\n",
            "703              [[0.0282833, 0.24233751, 0.7293792]]\n",
            "704         [[0.00028637034, 0.029394258, 0.9703194]]\n",
            "705         [[0.00018991962, 0.004675356, 0.9951348]]\n",
            "706             [[0.005506561, 0.7243701, 0.2701233]]\n",
            "707         [[0.0022758972, 0.98718214, 0.010541919]]\n",
            "708            [[0.028863085, 0.25787088, 0.7132661]]\n",
            "709            [[0.0008917978, 0.38290128, 0.616207]]\n",
            "710         [[0.0024449583, 0.043090872, 0.95446414]]\n",
            "711          [[0.0051437565, 0.96202105, 0.03283522]]\n",
            "712           [[0.0024740282, 0.33176008, 0.6657659]]\n",
            "713           [[0.0011185224, 0.6487469, 0.35013455]]\n",
            "714        [[0.0047911173, 0.0030354697, 0.99217343]]\n",
            "715          [[0.0006330213, 0.14903751, 0.85032946]]\n",
            "716          [[0.0007844161, 0.15590802, 0.84330755]]\n",
            "717           [[0.072268285, 0.8600248, 0.067706905]]\n",
            "718           [[0.013597646, 0.9683791, 0.018023299]]\n",
            "719            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "720           [[0.0012204205, 0.5228856, 0.47589397]]\n",
            "721           [[0.0010735114, 0.7418859, 0.25704056]]\n",
            "722            [[0.007345468, 0.11115621, 0.8814983]]\n",
            "723          [[0.0011329787, 0.015495173, 0.9833718]]\n",
            "724            [[0.027489118, 0.24027365, 0.7322372]]\n",
            "725            [[0.02798498, 0.24426009, 0.72775495]]\n",
            "726             [[0.3889111, 0.49438885, 0.11669998]]\n",
            "727             [[0.37084612, 0.13422222, 0.4949317]]\n",
            "728          [[0.0005673966, 0.017489009, 0.9819436]]\n",
            "729       [[0.0002613682, 0.00029530568, 0.99944323]]\n",
            "730          [[0.0006302472, 0.021314908, 0.9780548]]\n",
            "731          [[0.0016240975, 0.11617107, 0.88220483]]\n",
            "732       [[0.00021871261, 0.0007748647, 0.99900633]]\n",
            "733             [[0.005673684, 0.2903086, 0.7040177]]\n",
            "734          [[0.0020431487, 0.023626437, 0.9743303]]\n",
            "735          [[0.0042261593, 0.015966238, 0.9798076]]\n",
            "736             [[0.008417916, 0.794202, 0.19738004]]\n",
            "737           [[0.022293307, 0.34145787, 0.63624877]]\n",
            "738            [[0.03243436, 0.25267228, 0.71489334]]\n",
            "739          [[0.0042261593, 0.015966238, 0.9798076]]\n",
            "740           [[0.0058633946, 0.968417, 0.025719639]]\n",
            "741              [[0.028453734, 0.26193, 0.70961624]]\n",
            "742          [[0.0001483414, 0.03232508, 0.96752656]]\n",
            "743           [[0.0004254499, 0.14198625, 0.8575883]]\n",
            "744        [[0.00019697944, 0.050719146, 0.94908386]]\n",
            "745         [[0.00031913287, 0.38273987, 0.61694103]]\n",
            "746            [[0.028818442, 0.26405916, 0.7071223]]\n",
            "747           [[0.030948063, 0.26456034, 0.70449156]]\n",
            "748           [[0.030363258, 0.25953737, 0.71009934]]\n",
            "749         [[0.00022746596, 0.009029864, 0.9907426]]\n",
            "750        [[0.00052048493, 0.078193344, 0.92128617]]\n",
            "751        [[0.0006761887, 0.00090426457, 0.9984195]]\n",
            "752             [[0.04361645, 0.31466684, 0.6417168]]\n",
            "753         [[0.00018981309, 0.009678714, 0.9901315]]\n",
            "754         [[0.00036609362, 0.02723104, 0.97240293]]\n",
            "755         [[0.00017039689, 0.004629945, 0.9951997]]\n",
            "756           [[0.0007461096, 0.9139003, 0.08535353]]\n",
            "757            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "758           [[0.0005257264, 0.8380911, 0.16138318]]\n",
            "759       [[0.00018253544, 0.0016714325, 0.99814606]]\n",
            "760         [[9.596301e-05, 0.0007056398, 0.9991984]]\n",
            "761          [[0.0006881724, 0.89980835, 0.09950347]]\n",
            "762            [[0.00425115, 0.76450753, 0.23124135]]\n",
            "763      [[0.00036526466, 0.00016332025, 0.99947137]]\n",
            "764       [[0.00072956976, 0.0012408885, 0.99802953]]\n",
            "765            [[0.010732148, 0.02461769, 0.9646501]]\n",
            "766       [[0.00085827906, 0.0043183556, 0.99482346]]\n",
            "767            [[0.0023825592, 0.03861139, 0.959006]]\n",
            "768            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "769            [[0.0032447374, 0.1042978, 0.8924574]]\n",
            "770           [[0.0014438345, 0.08120639, 0.9173498]]\n",
            "771          [[0.0036757325, 0.019079827, 0.9772445]]\n",
            "772         [[0.0009997856, 0.028532302, 0.97046787]]\n",
            "773            [[0.0014846261, 0.688785, 0.30973038]]\n",
            "774            [[0.0013092604, 0.2343785, 0.7643122]]\n",
            "775          [[0.0006737059, 0.004959604, 0.9943667]]\n",
            "776         [[0.00017190429, 0.003965414, 0.9958627]]\n",
            "777          [[0.000906569, 0.005809713, 0.99328375]]\n",
            "778          [[0.0014223411, 0.21671706, 0.78186065]]\n",
            "779         [[0.00035802874, 0.007048095, 0.9925938]]\n",
            "780         [[0.0008974701, 0.0042507085, 0.9948519]]\n",
            "781        [[0.00017551532, 0.0011940381, 0.9986305]]\n",
            "782         [[0.0001666127, 0.0022679206, 0.9975655]]\n",
            "783             [[0.026844148, 0.22948378, 0.743672]]\n",
            "784        [[0.00026853048, 0.002609778, 0.99712163]]\n",
            "785           [[0.008326067, 0.58376074, 0.40791318]]\n",
            "786         [[0.0006437009, 0.0037301104, 0.9956262]]\n",
            "787            [[0.0031644003, 0.033637, 0.96319854]]\n",
            "788          [[0.000633646, 0.0015386185, 0.9978277]]\n",
            "789        [[0.0012903903, 0.0026149212, 0.99609464]]\n",
            "790           [[0.9561595, 0.015212916, 0.028627688]]\n",
            "791               [[0.2571775, 0.3931051, 0.3497174]]\n",
            "792          [[0.89332116, 0.0060015707, 0.10067723]]\n",
            "793            [[0.0008942281, 0.777915, 0.22119081]]\n",
            "794            [[0.0003165068, 0.9130078, 0.0866757]]\n",
            "795          [[0.0008091075, 0.9898415, 0.009349345]]\n",
            "796           [[0.0005430895, 0.9254221, 0.07403481]]\n",
            "797         [[0.0015809521, 0.98082376, 0.017595317]]\n",
            "798          [[0.000656645, 0.97491336, 0.024429936]]\n",
            "799         [[0.0010558112, 0.96785295, 0.031091245]]\n",
            "800          [[0.0012163756, 0.94075435, 0.05802929]]\n",
            "801          [[0.17415679, 0.81876576, 0.0070774993]]\n",
            "802         [[0.0071401554, 0.94524425, 0.047615632]]\n",
            "803         [[0.0002981223, 0.0014867696, 0.9982152]]\n",
            "804      [[0.00022431527, 0.00021871297, 0.99955684]]\n",
            "805        [[0.00093682326, 0.036949318, 0.96211386]]\n",
            "806            [[0.021244874, 0.19870645, 0.7800487]]\n",
            "807        [[0.0004138956, 0.0035015906, 0.99608445]]\n",
            "808         [[0.00047615246, 0.10353888, 0.89598495]]\n",
            "809          [[0.00072208775, 0.04758076, 0.9516972]]\n",
            "810            [[0.053955603, 0.31251842, 0.6335259]]\n",
            "811       [[0.00027908536, 0.00026009078, 0.9994609]]\n",
            "812            [[0.0010382865, 0.7391846, 0.2597771]]\n",
            "813        [[0.0001699028, 0.0091443015, 0.99068576]]\n",
            "814           [[0.0010083455, 0.12885714, 0.8701345]]\n",
            "815           [[0.004654631, 0.97028434, 0.02506101]]\n",
            "816           [[0.0069117383, 0.9763372, 0.01675112]]\n",
            "817            [[0.0005049152, 0.0965927, 0.9029024]]\n",
            "818           [[0.0057900976, 0.12802288, 0.8661871]]\n",
            "819              [[0.03055361, 0.2465786, 0.7228678]]\n",
            "820        [[0.00025264526, 0.0010632152, 0.9986841]]\n",
            "821            [[0.000804204, 0.13558461, 0.8636111]]\n",
            "822       [[0.00016501996, 0.0008779096, 0.99895704]]\n",
            "823      [[0.00020841834, 0.00022223032, 0.99956936]]\n",
            "824          [[0.9440293, 0.053199347, 0.0027714416]]\n",
            "825            [[0.9068056, 0.08110252, 0.012091876]]\n",
            "826       [[0.00058303186, 0.0008457311, 0.99857116]]\n",
            "827         [[0.000192335, 0.00028478776, 0.9995229]]\n",
            "828              [[0.0003380878, 0.083391, 0.916271]]\n",
            "829         [[0.00017996108, 0.009024854, 0.9907952]]\n",
            "830           [[0.027949225, 0.22599453, 0.74605626]]\n",
            "831      [[0.00021703067, 0.00022861616, 0.99955434]]\n",
            "832         [[0.00043025723, 0.013066815, 0.9865029]]\n",
            "833          [[0.000335313, 0.005860226, 0.99380445]]\n",
            "834         [[0.006012069, 0.0068706716, 0.98711723]]\n",
            "835         [[0.0017982757, 0.0017515192, 0.9964502]]\n",
            "836           [[0.003836597, 0.058318697, 0.9378447]]\n",
            "837            [[0.0031893824, 0.2296089, 0.7672017]]\n",
            "838           [[0.0026984608, 0.05387159, 0.9434299]]\n",
            "839        [[0.00029118083, 0.0001576402, 0.9995511]]\n",
            "840          [[0.0009768434, 0.001117493, 0.9979056]]\n",
            "841           [[0.8569766, 0.092851005, 0.050172426]]\n",
            "842        [[0.00022741187, 0.0031995447, 0.9965731]]\n",
            "843      [[0.00054520345, 0.00066305423, 0.99879175]]\n",
            "844          [[0.00045180018, 0.03563838, 0.9639098]]\n",
            "845              [[0.02769204, 0.2386468, 0.7336611]]\n",
            "846       [[0.00042322415, 0.0007024096, 0.99887437]]\n",
            "847       [[0.00028654543, 0.0011226734, 0.99859077]]\n",
            "848        [[0.00014559644, 0.0013247298, 0.9985297]]\n",
            "849         [[0.00036943628, 0.009694373, 0.9899361]]\n",
            "850             [[0.034023624, 0.25522542, 0.710751]]\n",
            "851           [[0.030378625, 0.25274736, 0.71687406]]\n",
            "852             [[0.027820367, 0.2400912, 0.7320883]]\n",
            "853       [[0.00021458314, 0.0012154714, 0.99856985]]\n",
            "854          [[0.00068711635, 0.15478376, 0.8445291]]\n",
            "855             [[0.033501226, 0.2560786, 0.7104202]]\n",
            "856            [[0.032964457, 0.25704014, 0.7099954]]\n",
            "857             [[0.03327564, 0.2549503, 0.71177405]]\n",
            "858            [[0.031865217, 0.26041916, 0.7077156]]\n",
            "859           [[0.0032931447, 0.23117599, 0.7655309]]\n",
            "860          [[0.95768684, 0.030574217, 0.011738916]]\n",
            "861       [[0.00023332961, 0.00059348583, 0.9991731]]\n",
            "862            [[0.029356815, 0.2543043, 0.71633893]]\n",
            "863              [[0.0281461, 0.2581922, 0.71366173]]\n",
            "864        [[0.00056678796, 0.070473924, 0.92895925]]\n",
            "865        [[0.00032437875, 0.005269364, 0.99440634]]\n",
            "866           [[0.0026074045, 0.2142228, 0.78316975]]\n",
            "867          [[0.0005869948, 0.051564228, 0.9478488]]\n",
            "868          [[0.000585985, 0.004818607, 0.99459547]]\n",
            "869          [[0.0015252917, 0.94247425, 0.05600044]]\n",
            "870              [[0.0009099937, 0.744659, 0.254431]]\n",
            "871            [[0.005566551, 0.8890761, 0.10535737]]\n",
            "872            [[0.005566551, 0.8890761, 0.10535737]]\n",
            "873             [[0.2262907, 0.7320543, 0.041655015]]\n",
            "874             [[0.005353255, 0.14095764, 0.853689]]\n",
            "875         [[0.0013182657, 0.0014921604, 0.9971896]]\n",
            "876           [[0.005169188, 0.016382627, 0.9784483]]\n",
            "877         [[0.0021558835, 0.0064176256, 0.9914266]]\n",
            "878          [[0.0002918666, 0.017927984, 0.9817801]]\n",
            "879        [[0.0007030865, 0.0006234498, 0.99867344]]\n",
            "880             [[0.4454693, 0.24159636, 0.31293437]]\n",
            "881           [[0.003051765, 0.9882045, 0.008743695]]\n",
            "882             [[0.2569516, 0.52085364, 0.22219476]]\n",
            "883          [[0.0003493866, 0.012239322, 0.9874113]]\n",
            "884         [[0.0009794051, 0.053479597, 0.94554096]]\n",
            "885         [[0.0005218929, 0.0010007905, 0.9984773]]\n",
            "886       [[0.00012052213, 0.0030828987, 0.99679667]]\n",
            "887        [[0.000102535334, 0.010514708, 0.9893828]]\n",
            "888        [[0.00022417934, 0.070544094, 0.92923176]]\n",
            "889        [[0.00094371045, 0.0017107476, 0.9973456]]\n",
            "890         [[0.00013074648, 0.001253189, 0.9986161]]\n",
            "891           [[0.014798599, 0.10071553, 0.88448596]]\n",
            "892          [[0.0011391422, 0.09804874, 0.90081215]]\n",
            "893          [[0.0002633958, 0.00120512, 0.99853146]]\n",
            "894           [[0.0017769646, 0.8606475, 0.13757558]]\n",
            "895            [[0.030727644, 0.27487227, 0.6944001]]\n",
            "896       [[0.00016488649, 0.00043817508, 0.9993969]]\n",
            "897        [[0.00014197994, 0.0010262292, 0.9988318]]\n",
            "898       [[0.00024480885, 0.00023744257, 0.9995177]]\n",
            "899       [[0.00016501368, 0.0038076213, 0.99602735]]\n",
            "900         [[0.0001229248, 0.000331897, 0.99954516]]\n",
            "901            [[0.002205859, 0.36863825, 0.6291559]]\n",
            "902          [[0.026972983, 0.0105875265, 0.9624395]]\n",
            "903            [[0.13265166, 0.7639876, 0.103360765]]\n",
            "904           [[0.62363863, 0.36160067, 0.014760701]]\n",
            "905            [[0.30255184, 0.6662819, 0.031166304]]\n",
            "906          [[0.0058399467, 0.20218311, 0.79197687]]\n",
            "907             [[0.5042735, 0.4793127, 0.016413834]]\n",
            "908          [[0.0051131938, 0.14374326, 0.85114354]]\n",
            "909          [[0.0028005075, 0.022007868, 0.9751916]]\n",
            "910           [[0.007121326, 0.036277257, 0.9566014]]\n",
            "911             [[0.03601914, 0.25948516, 0.7044957]]\n",
            "912             [[0.8609208, 0.06604139, 0.07303784]]\n",
            "913                 [[0.401544, 0.54112, 0.05733602]]\n",
            "914            [[0.32658085, 0.21899012, 0.45442906]]\n",
            "915        [[0.0005077535, 0.0015647244, 0.99792755]]\n",
            "916           [[0.9639061, 0.030240266, 0.005853577]]\n",
            "917          [[0.9952701, 0.003234068, 0.0014958244]]\n",
            "918            [[0.4290782, 0.56404525, 0.006876555]]\n",
            "919              [[0.012514136, 0.57252, 0.41496584]]\n",
            "920          [[0.0065282667, 0.040981084, 0.9524906]]\n",
            "921              [[0.1718126, 0.5129144, 0.31527293]]\n",
            "922        [[0.0090091145, 0.98356783, 0.0074230772]]\n",
            "923          [[0.0006197021, 0.026995718, 0.9723846]]\n",
            "924            [[0.027618444, 0.24351846, 0.7288631]]\n",
            "925              [[0.02762836, 0.2510569, 0.7213147]]\n",
            "926          [[0.00034160595, 0.9174773, 0.08218107]]\n",
            "927         [[0.00027457596, 0.9691966, 0.030528791]]\n",
            "928           [[0.0005719813, 0.046103958, 0.953324]]\n",
            "929         [[0.0002141976, 0.029942652, 0.96984315]]\n",
            "930         [[0.00039027497, 0.006560077, 0.9930496]]\n",
            "931           [[0.000455414, 0.017374823, 0.9821697]]\n",
            "932            [[0.0020622432, 0.8598887, 0.1380491]]\n",
            "933             [[0.004700737, 0.4752385, 0.5200608]]\n",
            "934         [[0.0015469628, 0.0005056475, 0.9979474]]\n",
            "935         [[0.0015469628, 0.0005056475, 0.9979474]]\n",
            "936           [[0.029792078, 0.25318837, 0.71701956]]\n",
            "937        [[0.00023465042, 0.018772572, 0.98099273]]\n",
            "938            [[0.028718736, 0.24250522, 0.7287761]]\n",
            "939         [[0.00028225532, 0.003380371, 0.9963374]]\n",
            "940        [[0.0004521085, 0.0135573195, 0.98599064]]\n",
            "941          [[0.000367865, 0.009752995, 0.98987913]]\n",
            "942          [[0.0008579671, 0.111355945, 0.8877861]]\n",
            "943       [[0.00010646728, 0.0011184682, 0.99877506]]\n",
            "944        [[0.00014634227, 0.0005192992, 0.9993344]]\n",
            "945             [[0.02744778, 0.23747891, 0.7350733]]\n",
            "946         [[0.00029512314, 0.022064129, 0.9776408]]\n",
            "947         [[0.00031776368, 0.004064897, 0.9956174]]\n",
            "948        [[0.00039885077, 0.044143528, 0.95545757]]\n",
            "949        [[0.00034176573, 0.004262414, 0.99539584]]\n",
            "950          [[0.00046486338, 0.04739194, 0.9521432]]\n",
            "951          [[0.0007168664, 0.069793396, 0.9294897]]\n",
            "952            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "953        [[0.00024340983, 0.015085762, 0.98467076]]\n",
            "954            [[0.026649555, 0.2370929, 0.73625755]]\n",
            "955         [[0.00037715415, 0.004355397, 0.9952675]]\n",
            "956            [[0.026775617, 0.24324101, 0.7299833]]\n",
            "957       [[0.00025369917, 0.0009705715, 0.99877566]]\n",
            "958           [[0.00411298, 0.032402277, 0.96348476]]\n",
            "959              [[0.6280268, 0.3025822, 0.06939094]]\n",
            "960        [[0.00029797622, 0.009792051, 0.98990995]]\n",
            "961        [[0.00020492078, 0.0007287598, 0.9990663]]\n",
            "962        [[0.0011134737, 0.0055871117, 0.99329937]]\n",
            "963       [[0.00021680888, 0.00033752652, 0.9994456]]\n",
            "964              [[0.060759634, 0.213819, 0.7254213]]\n",
            "965        [[0.00023271849, 0.0005111616, 0.9992561]]\n",
            "966           [[0.110511005, 0.26723236, 0.62225664]]\n",
            "967           [[0.110511005, 0.26723236, 0.62225664]]\n",
            "968             [[0.042144634, 0.35429442, 0.603561]]\n",
            "969            [[0.02889181, 0.24644428, 0.72466385]]\n",
            "970           [[0.021007948, 0.17560287, 0.80338925]]\n",
            "971           [[0.105318405, 0.47069523, 0.42398635]]\n",
            "972         [[0.00027786894, 0.041132703, 0.9585894]]\n",
            "973       [[0.00016003537, 0.0014146568, 0.99842525]]\n",
            "974        [[0.00024808187, 0.0019815883, 0.9977703]]\n",
            "975        [[0.00024808187, 0.0019815883, 0.9977703]]\n",
            "976        [[0.00013656952, 0.0053944723, 0.9944689]]\n",
            "977         [[0.0014464152, 0.021146687, 0.97740686]]\n",
            "978           [[0.0010137403, 0.08893409, 0.9100522]]\n",
            "979            [[0.026955342, 0.24464792, 0.7283968]]\n",
            "980             [[0.02714052, 0.25005516, 0.7228043]]\n",
            "981             [[0.035657097, 0.2663576, 0.6979853]]\n",
            "982           [[0.035220996, 0.27169004, 0.69308895]]\n",
            "983         [[0.0002420403, 0.0011576808, 0.9986003]]\n",
            "984             [[0.034418378, 0.26784563, 0.697736]]\n",
            "985             [[0.035657097, 0.2663576, 0.6979853]]\n",
            "986           [[0.0016101273, 0.4034821, 0.59490776]]\n",
            "987          [[0.0008144763, 0.029962195, 0.9692234]]\n",
            "988        [[0.00060303515, 0.0051736827, 0.9942233]]\n",
            "989         [[0.00015847597, 0.0003125806, 0.999529]]\n",
            "990        [[0.00016625847, 0.0022975802, 0.9975362]]\n",
            "991           [[0.00033251324, 0.8961537, 0.1035138]]\n",
            "992           [[0.027106786, 0.24213597, 0.73075724]]\n",
            "993        [[0.00023898084, 0.0040829824, 0.9956781]]\n",
            "994       [[0.00027421908, 0.0028464347, 0.99687934]]\n",
            "995           [[0.0005930486, 0.8991474, 0.10025956]]\n",
            "996            [[0.0023654005, 0.9176073, 0.0800273]]\n",
            "997          [[0.0051555876, 0.66716266, 0.32768175]]\n",
            "998        [[0.00017895822, 0.0013424229, 0.9984787]]\n",
            "999        [[0.00024341384, 0.0009891508, 0.9987675]]\n",
            "1000          [[0.0003816279, 0.009573236, 0.990045]]\n",
            "1001     [[0.00035289244, 0.00069008337, 0.99895704]]\n",
            "1002     [[0.00014281683, 0.00088383217, 0.99897337]]\n",
            "1003            [[0.02197845, 0.13932398, 0.8386976]]\n",
            "1004        [[0.0002303354, 0.00016764241, 0.999602]]\n",
            "1005           [[0.028270984, 0.25587872, 0.7158503]]\n",
            "1006      [[0.00021893423, 0.0015089529, 0.99827206]]\n",
            "1007      [[0.00021893423, 0.0015089529, 0.99827206]]\n",
            "1008     [[0.00017963973, 0.00031013426, 0.99951017]]\n",
            "1009          [[0.0005058413, 0.01053702, 0.9889571]]\n",
            "1010          [[0.027846511, 0.24629574, 0.72585773]]\n",
            "1011           [[0.028096467, 0.23699275, 0.7349108]]\n",
            "1012          [[0.0006533342, 0.010027626, 0.989319]]\n",
            "1013           [[0.028048053, 0.23253167, 0.7394203]]\n",
            "1014           [[0.46323782, 0.44656467, 0.09019751]]\n",
            "1015          [[0.005409891, 0.005706466, 0.9888837]]\n",
            "1016      [[0.00015560235, 0.0008351103, 0.99900925]]\n",
            "1017        [[0.00014115543, 0.016030358, 0.9838284]]\n",
            "1018          [[0.026902063, 0.24077575, 0.73232216]]\n",
            "1019       [[0.0002953389, 0.00035396146, 0.9993507]]\n",
            "1020           [[0.02678281, 0.24310596, 0.73011124]]\n",
            "1021      [[0.00092527416, 0.0061698155, 0.99290496]]\n",
            "1022      [[0.00029892355, 0.00045877713, 0.9992424]]\n",
            "1023        [[0.00050272874, 0.65875506, 0.34074214]]\n",
            "1024          [[0.0007032837, 0.5159616, 0.48333508]]\n",
            "1025            [[0.29916564, 0.35825586, 0.3425785]]\n",
            "1026          [[0.010503721, 0.059762567, 0.9297337]]\n",
            "1027     [[0.00034816106, 0.00040262594, 0.99924916]]\n",
            "1028         [[0.004831683, 0.027908806, 0.96725947]]\n",
            "1029      [[0.00024891226, 0.0044772904, 0.99527377]]\n",
            "1030       [[0.00015826222, 0.0025810753, 0.9972607]]\n",
            "1031           [[0.0016935416, 0.04597843, 0.952328]]\n",
            "1032           [[0.02723129, 0.25340348, 0.71936524]]\n",
            "1033             [[0.0531244, 0.2005833, 0.74629235]]\n",
            "1034      [[0.00014343315, 0.0010256988, 0.99883085]]\n",
            "1035      [[0.00016479589, 0.00046920602, 0.9993661]]\n",
            "1036        [[0.0001547497, 0.0004544782, 0.9993907]]\n",
            "1037          [[0.0013271846, 0.01979882, 0.9788739]]\n",
            "1038          [[0.026909988, 0.24308223, 0.73000777]]\n",
            "1039          [[0.027615476, 0.23898636, 0.73339814]]\n",
            "1040          [[0.029135965, 0.23524448, 0.73561954]]\n",
            "1041             [[0.00691207, 0.785309, 0.20777889]]\n",
            "1042           [[0.02959732, 0.23507595, 0.73532677]]\n",
            "1043            [[0.04716995, 0.7347542, 0.21807578]]\n",
            "1044         [[0.0018071085, 0.085673705, 0.9125193]]\n",
            "1045      [[0.00015015909, 0.00023164765, 0.9996182]]\n",
            "1046        [[0.00019646167, 0.000521868, 0.9992817]]\n",
            "1047      [[0.00020127912, 0.00026352756, 0.9995352]]\n",
            "1048            [[0.07290399, 0.7481476, 0.17894839]]\n",
            "1049           [[0.027204921, 0.24140522, 0.7313899]]\n",
            "1050           [[0.009011023, 0.4338514, 0.55713755]]\n",
            "1051        [[0.00048638196, 0.027901163, 0.9716125]]\n",
            "1052       [[0.00039468097, 0.0014631677, 0.9981421]]\n",
            "1053       [[0.00049482926, 0.0019808514, 0.9975243]]\n",
            "1054           [[0.031777013, 0.26621833, 0.7020046]]\n",
            "1055           [[0.027419202, 0.24438845, 0.7281923]]\n",
            "1056         [[0.00021526545, 0.003175771, 0.996609]]\n",
            "1057         [[0.0001209336, 0.008080825, 0.9917983]]\n",
            "1058           [[0.028069623, 0.24226478, 0.7296656]]\n",
            "1059           [[0.026814487, 0.23799366, 0.7351918]]\n",
            "1060       [[0.00012390653, 0.0070419237, 0.9928342]]\n",
            "1061        [[0.00042281672, 0.002335046, 0.9972421]]\n",
            "1062       [[0.00056574645, 0.0012551735, 0.9981792]]\n",
            "1063         [[0.0014654628, 0.015852567, 0.9826819]]\n",
            "1064            [[0.7156578, 0.26972532, 0.01461696]]\n",
            "1065         [[0.0010044883, 0.21661785, 0.78237766]]\n",
            "1066         [[0.0010044883, 0.21661785, 0.78237766]]\n",
            "1067           [[0.029195601, 0.24654712, 0.7242573]]\n",
            "1068       [[0.00045164328, 0.005991838, 0.99355656]]\n",
            "1069       [[0.00018144445, 0.011767697, 0.98805094]]\n",
            "1070       [[0.00014522605, 0.002580221, 0.99727446]]\n",
            "1071      [[0.000100576886, 0.004094608, 0.99580485]]\n",
            "1072       [[0.00018144445, 0.011767697, 0.98805094]]\n",
            "1073         [[0.0072513176, 0.21164821, 0.78110045]]\n",
            "1074        [[0.0019032868, 0.079206035, 0.91889066]]\n",
            "1075       [[0.00023749264, 0.0011270078, 0.9986355]]\n",
            "1076          [[0.0004885336, 0.7368127, 0.26269874]]\n",
            "1077       [[0.00017003546, 0.0014336501, 0.9983962]]\n",
            "1078      [[0.00019325368, 0.0005340759, 0.99927276]]\n",
            "1079      [[0.0001718353, 0.00097397855, 0.99885416]]\n",
            "1080         [[0.0011345282, 0.9214611, 0.077404395]]\n",
            "1081           [[0.0005796608, 0.19108526, 0.808335]]\n",
            "1082        [[0.00046088596, 0.80404025, 0.19549893]]\n",
            "1083           [[0.029554995, 0.24796784, 0.7224772]]\n",
            "1084       [[0.0002375468, 0.0011479965, 0.99861455]]\n",
            "1085        [[0.00024018963, 0.04887449, 0.95088536]]\n",
            "1086         [[0.0002079499, 0.021443957, 0.9783481]]\n",
            "1087       [[0.00025336831, 0.004991377, 0.99475527]]\n",
            "1088           [[0.027419202, 0.24438845, 0.7281923]]\n",
            "1089        [[0.00040577364, 0.30411646, 0.69547784]]\n",
            "1090         [[0.00048026026, 0.7329733, 0.26654646]]\n",
            "1091            [[0.31581387, 0.5931087, 0.09107739]]\n",
            "1092         [[0.001837787, 0.0010580132, 0.9971042]]\n",
            "1093          [[0.38369194, 0.56959444, 0.046713565]]\n",
            "1094             [[0.13196813, 0.7756068, 0.0924251]]\n",
            "1095         [[0.004531093, 0.0030861697, 0.9923828]]\n",
            "1096      [[0.00019379905, 0.0044415276, 0.99536467]]\n",
            "1097       [[0.00024184359, 0.0008203179, 0.9989378]]\n",
            "1098       [[0.0002893824, 0.0008898463, 0.99882084]]\n",
            "1099            [[0.027259694, 0.2458955, 0.7268448]]\n",
            "1100         [[0.000578077, 0.0044310507, 0.9949909]]\n",
            "1101      [[0.00014635916, 0.00086120574, 0.9989924]]\n",
            "1102          [[0.026747812, 0.23733044, 0.73592174]]\n",
            "1103        [[0.00027834324, 0.011684468, 0.9880372]]\n",
            "1104      [[0.00013936772, 0.0013753856, 0.99848527]]\n",
            "1105         [[0.0001254218, 0.004276169, 0.9955983]]\n",
            "1106            [[0.028132126, 0.24558382, 0.726284]]\n",
            "1107       [[0.00017074577, 0.0005699024, 0.9992594]]\n",
            "1108       [[0.00013798107, 0.0011454185, 0.9987166]]\n",
            "1109      [[0.000115489376, 0.0012322961, 0.9986523]]\n",
            "1110      [[0.00016260507, 0.0009680772, 0.99886924]]\n",
            "1111       [[0.0012028957, 0.0008664555, 0.99793065]]\n",
            "1112        [[0.00048419138, 0.030792963, 0.9687228]]\n",
            "1113          [[0.0005423085, 0.48177955, 0.5176781]]\n",
            "1114      [[0.00025007446, 0.0008356606, 0.99891424]]\n",
            "1115           [[0.027452312, 0.24235743, 0.7301902]]\n",
            "1116        [[0.0005443465, 0.0051793987, 0.9942762]]\n",
            "1117       [[0.00021968727, 0.028184328, 0.97159594]]\n",
            "1118         [[0.00021893356, 0.05041031, 0.9493708]]\n",
            "1119        [[0.00026041377, 0.013830122, 0.9859094]]\n",
            "1120          [[0.0011307441, 0.15984277, 0.8390265]]\n",
            "1121        [[0.00075045385, 0.0006505866, 0.998599]]\n",
            "1122        [[0.95165086, 0.046104684, 0.0022444837]]\n",
            "1123            [[0.004884767, 0.8094715, 0.1856438]]\n",
            "1124      [[0.00024857992, 0.0073683383, 0.99238306]]\n",
            "1125       [[0.0001994172, 0.00035771256, 0.9994429]]\n",
            "1126          [[0.0003903912, 0.22247873, 0.7771309]]\n",
            "1127         [[0.0013122762, 0.87207156, 0.12661622]]\n",
            "1128          [[0.0026120665, 0.8253971, 0.17199083]]\n",
            "1129         [[0.0010529939, 0.9831524, 0.015794639]]\n",
            "1130      [[0.00028172182, 0.0007966896, 0.99892163]]\n",
            "1131        [[0.00034707907, 0.023815364, 0.9758375]]\n",
            "1132         [[0.0008806621, 0.011945977, 0.9871733]]\n",
            "1133           [[0.028010907, 0.24255194, 0.7294372]]\n",
            "1134        [[0.00091589725, 0.097270206, 0.9018138]]\n",
            "1135        [[0.0008038744, 0.0056434143, 0.9935527]]\n",
            "1136       [[0.0002967966, 0.0011025202, 0.99860066]]\n",
            "1137          [[0.027046844, 0.24244101, 0.73051214]]\n",
            "1138      [[0.00040708648, 0.0023582994, 0.99723464]]\n",
            "1139        [[0.00021459928, 0.012557611, 0.9872278]]\n",
            "1140           [[0.026446693, 0.22972476, 0.7438286]]\n",
            "1141         [[0.0058826813, 0.93399036, 0.06012694]]\n",
            "1142          [[0.0002943444, 0.19798698, 0.8017186]]\n",
            "1143        [[0.00073424866, 0.009580934, 0.9896848]]\n",
            "1144         [[0.002895781, 0.020424576, 0.97667956]]\n",
            "1145           [[0.17682524, 0.23324192, 0.58993286]]\n",
            "1146         [[0.007396119, 0.027902652, 0.96470124]]\n",
            "1147           [[0.029911583, 0.24577168, 0.7243168]]\n",
            "1148     [[0.00028008342, 0.00018072837, 0.99953914]]\n",
            "1149         [[0.0009917561, 0.004695163, 0.9943131]]\n",
            "1150           [[0.026992023, 0.24447593, 0.7285321]]\n",
            "1151        [[0.00061850075, 0.007676129, 0.9917053]]\n",
            "1152        [[0.0013948898, 0.026569052, 0.97203606]]\n",
            "1153           [[0.027169278, 0.24527422, 0.7275565]]\n",
            "1154           [[0.01392762, 0.50576144, 0.48031092]]\n",
            "1155            [[0.3839915, 0.58753616, 0.02847232]]\n",
            "1156       [[0.00037890038, 0.0008044242, 0.9988167]]\n",
            "1157       [[0.00021254757, 0.0014932357, 0.9982942]]\n",
            "1158       [[0.00024132985, 0.0006692125, 0.9990895]]\n",
            "1159           [[0.029585384, 0.25253353, 0.7178811]]\n",
            "1160          [[0.0016078063, 0.14660455, 0.8517877]]\n",
            "1161           [[0.027295128, 0.24491848, 0.7277864]]\n",
            "1162        [[0.0020060274, 0.013156238, 0.98483765]]\n",
            "1163         [[0.0012806586, 0.005103264, 0.9936161]]\n",
            "1164        [[0.00062951754, 0.01582379, 0.98354673]]\n",
            "1165           [[0.028914236, 0.23621139, 0.7348743]]\n",
            "1166       [[0.00042392494, 0.0077972217, 0.9917788]]\n",
            "1167           [[0.029588519, 0.25182933, 0.7185822]]\n",
            "1168      [[0.00046905625, 0.0045562186, 0.99497473]]\n",
            "1169        [[0.0004941889, 0.0049336697, 0.9945722]]\n",
            "1170          [[0.0020129068, 0.09979576, 0.8981914]]\n",
            "1171           [[0.030534578, 0.24941777, 0.7200476]]\n",
            "1172      [[0.00020800268, 0.0027145136, 0.99707747]]\n",
            "1173          [[0.0008228653, 0.6452621, 0.35391495]]\n",
            "1174             [[0.04167732, 0.6329571, 0.3253656]]\n",
            "1175          [[0.0028742673, 0.8705982, 0.12652755]]\n",
            "1176          [[0.016205098, 0.97254896, 0.01124595]]\n",
            "1177          [[0.0010624407, 0.012726609, 0.986211]]\n",
            "1178          [[0.028528467, 0.25796118, 0.71351033]]\n",
            "1179             [[0.03074262, 0.2508709, 0.7183865]]\n",
            "1180         [[0.00022856369, 0.0025113802, 0.99726]]\n",
            "1181      [[0.00032776056, 0.0003782029, 0.99929404]]\n",
            "1182       [[0.0001791047, 0.00015413278, 0.9996668]]\n",
            "1183      [[0.00017638737, 0.00048241246, 0.9993412]]\n",
            "1184         [[0.00012051555, 0.00820889, 0.9916706]]\n",
            "1185     [[0.00014469805, 0.00034844884, 0.99950695]]\n",
            "1186          [[0.005674784, 0.013178606, 0.9811467]]\n",
            "1187          [[0.028035758, 0.25022727, 0.72173697]]\n",
            "1188       [[0.00032406906, 0.0020701492, 0.9976058]]\n",
            "1189        [[0.0005507294, 0.046538703, 0.95291054]]\n",
            "1190       [[0.0001654558, 0.00065086765, 0.9991837]]\n",
            "1191       [[0.00030173844, 0.021155631, 0.97854257]]\n",
            "1192           [[0.0003495416, 0.02998442, 0.969666]]\n",
            "1193         [[0.00039313035, 0.008551791, 0.991055]]\n",
            "1194     [[0.00075332867, 0.00067373045, 0.99857295]]\n",
            "1195      [[0.00025975757, 0.00018816101, 0.9995521]]\n",
            "1196        [[0.0003247809, 0.0012109816, 0.9984642]]\n",
            "1197        [[0.00013307905, 0.000645723, 0.9992212]]\n",
            "1198      [[6.8641755e-05, 0.0061136396, 0.99381775]]\n",
            "1199       [[0.00010185937, 0.006481612, 0.99341655]]\n",
            "1200        [[0.0001215044, 0.011844519, 0.98803395]]\n",
            "1201        [[0.0002792832, 0.0010848491, 0.9986358]]\n",
            "1202        [[0.00025138917, 0.0016636184, 0.998085]]\n",
            "1203        [[0.0012759859, 0.0022761307, 0.9964478]]\n",
            "1204         [[0.019596793, 0.061016038, 0.91938716]]\n",
            "1205        [[0.0019990925, 0.007391806, 0.99060905]]\n",
            "1206       [[0.00059245265, 0.001959655, 0.99744785]]\n",
            "1207           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1208               [[0.02942908, 0.226093, 0.744478]]\n",
            "1209            [[0.023351798, 0.7062571, 0.2703911]]\n",
            "1210         [[0.025265334, 0.91000974, 0.064724945]]\n",
            "1211           [[0.05019536, 0.65944374, 0.29036093]]\n",
            "1212          [[0.17475954, 0.70232445, 0.122916006]]\n",
            "1213      [[0.00046432292, 0.0016817746, 0.99785393]]\n",
            "1214        [[0.00024627833, 0.009391128, 0.9903626]]\n",
            "1215      [[0.00025814306, 0.0048580025, 0.99488384]]\n",
            "1216        [[0.00024627833, 0.009391128, 0.9903626]]\n",
            "1217        [[0.00034063077, 0.9805532, 0.019106224]]\n",
            "1218     [[0.00012320168, 0.00042784642, 0.99944896]]\n",
            "1219        [[0.00041322026, 0.83104205, 0.16854475]]\n",
            "1220           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1221        [[0.00052114716, 0.0007218885, 0.998757]]\n",
            "1222         [[0.0020621317, 0.032926667, 0.9650111]]\n",
            "1223           [[0.110358655, 0.0635923, 0.82604903]]\n",
            "1224           [[0.0022434643, 0.0501064, 0.9476502]]\n",
            "1225           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1226        [[0.0011039103, 0.0060464176, 0.9928497]]\n",
            "1227           [[0.027909692, 0.25155365, 0.7205367]]\n",
            "1228         [[0.0072845737, 0.61153716, 0.38117823]]\n",
            "1229           [[0.027860634, 0.24404602, 0.7280933]]\n",
            "1230            [[0.027169377, 0.23706968, 0.735761]]\n",
            "1231         [[0.0003500383, 0.0005879486, 0.999062]]\n",
            "1232            [[0.49917036, 0.3899746, 0.11085504]]\n",
            "1233           [[0.06392916, 0.67174435, 0.26432642]]\n",
            "1234            [[0.027437774, 0.24299325, 0.729569]]\n",
            "1235           [[0.17845611, 0.61623114, 0.20531276]]\n",
            "1236           [[0.04990612, 0.095561214, 0.8545328]]\n",
            "1237          [[0.028188854, 0.24359082, 0.72822034]]\n",
            "1238         [[0.0021912407, 0.16974908, 0.82805973]]\n",
            "1239         [[0.0049391007, 0.013263689, 0.9817972]]\n",
            "1240       [[0.00024896534, 0.0001993349, 0.9995517]]\n",
            "1241         [[0.0026604722, 0.026118869, 0.9712207]]\n",
            "1242          [[0.00037076158, 0.3225419, 0.6770874]]\n",
            "1243        [[0.00076909055, 0.57880837, 0.42042252]]\n",
            "1244         [[0.00068303663, 0.7548348, 0.24448217]]\n",
            "1245       [[0.00014216371, 0.0016855535, 0.9981723]]\n",
            "1246         [[0.0003705569, 0.37240097, 0.62722844]]\n",
            "1247      [[0.00059936685, 0.0046572047, 0.99474347]]\n",
            "1248     [[0.00012977693, 0.00057743833, 0.99929285]]\n",
            "1249             [[0.395087, 0.5842772, 0.020635748]]\n",
            "1250         [[0.008581789, 0.93632334, 0.055094816]]\n",
            "1251          [[0.014648022, 0.9336556, 0.051696375]]\n",
            "1252      [[0.00019226859, 0.0026888312, 0.99711883]]\n",
            "1253         [[0.0002981794, 0.025776776, 0.9739251]]\n",
            "1254        [[0.0006114266, 0.009798965, 0.98958963]]\n",
            "1255         [[0.00026074663, 0.01822657, 0.9815128]]\n",
            "1256         [[0.0011612604, 0.18761964, 0.81121916]]\n",
            "1257        [[0.00030865404, 0.028899798, 0.9707916]]\n",
            "1258          [[0.000335115, 0.00869061, 0.99097425]]\n",
            "1259       [[0.00024310789, 0.011049942, 0.98870695]]\n",
            "1260          [[0.0013724739, 0.8485905, 0.15003705]]\n",
            "1261          [[0.0029843498, 0.7802546, 0.21676104]]\n",
            "1262     [[0.00031561323, 0.00040693735, 0.99927753]]\n",
            "1263          [[0.25077987, 0.69055897, 0.058661103]]\n",
            "1264      [[0.0002166003, 0.00039435594, 0.99938905]]\n",
            "1265          [[0.00053455983, 0.4531262, 0.5463392]]\n",
            "1266       [[0.00032134564, 0.075100325, 0.92457825]]\n",
            "1267       [[0.0002609679, 0.0020311684, 0.99770784]]\n",
            "1268        [[0.0008974458, 0.015093228, 0.98400927]]\n",
            "1269          [[0.16313018, 0.82512015, 0.011749645]]\n",
            "1270           [[0.07154537, 0.8801689, 0.048285745]]\n",
            "1271         [[0.9144368, 0.080925226, 0.0046380702]]\n",
            "1272        [[0.009141329, 0.97925603, 0.0116026485]]\n",
            "1273          [[0.0033952512, 0.9487976, 0.04780711]]\n",
            "1274       [[0.0004684104, 0.0007615278, 0.99877006]]\n",
            "1275           [[0.027428586, 0.25388375, 0.7186876]]\n",
            "1276          [[0.0008533702, 0.056540705, 0.942606]]\n",
            "1277            [[0.056988932, 0.5259113, 0.4170998]]\n",
            "1278       [[0.00021071392, 0.0010810907, 0.9987081]]\n",
            "1279       [[0.00046943393, 0.021768881, 0.97776175]]\n",
            "1280       [[0.00053070526, 0.018758867, 0.98071045]]\n",
            "1281      [[0.00030731765, 0.0029112946, 0.99678135]]\n",
            "1282           [[0.028179156, 0.24423094, 0.7275899]]\n",
            "1283       [[0.00018130925, 0.013031112, 0.98678756]]\n",
            "1284       [[0.00044462457, 0.005782924, 0.99377245]]\n",
            "1285      [[0.00025158003, 0.0100708725, 0.98967755]]\n",
            "1286             [[0.006452104, 0.380757, 0.6127909]]\n",
            "1287       [[0.00016748163, 0.0006014284, 0.9992311]]\n",
            "1288          [[0.002458245, 0.9729709, 0.024570834]]\n",
            "1289          [[0.014379446, 0.94230264, 0.04331792]]\n",
            "1290          [[0.013924655, 0.02849173, 0.95758355]]\n",
            "1291      [[0.00021368204, 0.0002232696, 0.99956304]]\n",
            "1292           [[0.10246904, 0.18560624, 0.71192473]]\n",
            "1293        [[0.00033101, 0.00048690994, 0.99918205]]\n",
            "1294       [[0.0004714277, 0.0019066202, 0.99762195]]\n",
            "1295            [[0.02847114, 0.25289416, 0.7186347]]\n",
            "1296      [[0.00028994962, 0.00048214066, 0.9992279]]\n",
            "1297         [[0.0007774333, 0.005717692, 0.9935049]]\n",
            "1298        [[0.0019420359, 0.94865745, 0.049400553]]\n",
            "1299      [[0.00016394642, 0.0015502009, 0.99828583]]\n",
            "1300          [[0.027952492, 0.25598586, 0.71606165]]\n",
            "1301         [[0.0006306008, 0.049922977, 0.9494463]]\n",
            "1302        [[0.0006046711, 0.0066881133, 0.9927072]]\n",
            "1303            [[0.00057757, 0.42395574, 0.5754667]]\n",
            "1304         [[0.00073684787, 0.3340585, 0.66520464]]\n",
            "1305          [[0.0007876999, 0.8433184, 0.15589389]]\n",
            "1306        [[0.0012892686, 0.003430235, 0.99528056]]\n",
            "1307        [[8.335773e-05, 0.00046854108, 0.999448]]\n",
            "1308       [[0.00031319863, 0.0007980108, 0.9988888]]\n",
            "1309      [[0.00028551187, 0.0005606111, 0.99915385]]\n",
            "1310       [[0.00031408685, 0.0015012588, 0.9981846]]\n",
            "1311        [[0.00030320548, 0.011647584, 0.9880492]]\n",
            "1312          [[0.0012277588, 0.07860078, 0.9201714]]\n",
            "1313       [[0.00017738546, 0.0031837767, 0.9966388]]\n",
            "1314      [[0.00011213156, 0.00075653003, 0.9991314]]\n",
            "1315         [[0.00069582154, 0.52581733, 0.4734868]]\n",
            "1316          [[0.028148899, 0.24923836, 0.72261274]]\n",
            "1317           [[0.028399872, 0.24523833, 0.7263619]]\n",
            "1318      [[0.00017826198, 0.0014148043, 0.99840695]]\n",
            "1319       [[0.00014575581, 0.0008566893, 0.9989975]]\n",
            "1320       [[0.00032955495, 0.010144287, 0.98952615]]\n",
            "1321          [[0.0002281747, 0.01696867, 0.9828031]]\n",
            "1322          [[0.0012534793, 0.44341347, 0.5553331]]\n",
            "1323          [[0.0045933933, 0.8712308, 0.12417583]]\n",
            "1324           [[0.0009891742, 0.6367772, 0.3622336]]\n",
            "1325          [[0.0008358893, 0.7557153, 0.24344878]]\n",
            "1326          [[0.00039010207, 0.9733342, 0.0262757]]\n",
            "1327            [[0.027622266, 0.2485695, 0.7238083]]\n",
            "1328        [[0.00015942559, 0.019294998, 0.9805455]]\n",
            "1329       [[0.00019771392, 0.028232291, 0.97156996]]\n",
            "1330         [[0.0007627382, 0.56871486, 0.43052235]]\n",
            "1331         [[0.0004897342, 0.017001392, 0.9825089]]\n",
            "1332          [[0.0010277395, 0.07407466, 0.9248977]]\n",
            "1333          [[0.0026064664, 0.12747946, 0.8699141]]\n",
            "1334         [[0.00067261845, 0.9836166, 0.01571072]]\n",
            "1335       [[0.00025709948, 0.001278013, 0.99846494]]\n",
            "1336           [[0.026907785, 0.7788303, 0.19426197]]\n",
            "1337            [[0.006151454, 0.2570022, 0.7368463]]\n",
            "1338      [[0.00029050946, 0.00054480135, 0.9991647]]\n",
            "1339          [[0.027029917, 0.24580401, 0.72716606]]\n",
            "1340          [[0.000748249, 0.014621927, 0.9846298]]\n",
            "1341         [[0.004167529, 0.0018306209, 0.9940018]]\n",
            "1342       [[0.0005787245, 0.00025660536, 0.9991647]]\n",
            "1343             [[0.10136966, 0.1057129, 0.7929175]]\n",
            "1344            [[0.028521892, 0.2474048, 0.7240733]]\n",
            "1345            [[0.027244933, 0.2442842, 0.7284709]]\n",
            "1346         [[0.0015812598, 0.049917433, 0.9485013]]\n",
            "1347      [[0.00012862202, 0.00038820042, 0.9994831]]\n",
            "1348        [[0.00027180839, 0.000441495, 0.9992867]]\n",
            "1349           [[0.027448665, 0.2539882, 0.71856314]]\n",
            "1350            [[0.031516895, 0.2475284, 0.7209547]]\n",
            "1351        [[0.0013012382, 0.0036534956, 0.9950453]]\n",
            "1352          [[0.0027645903, 0.03378624, 0.9634491]]\n",
            "1353       [[0.00021993052, 0.00022402605, 0.999556]]\n",
            "1354           [[0.027392235, 0.23786995, 0.7347379]]\n",
            "1355      [[0.00057163445, 0.0024786342, 0.99694973]]\n",
            "1356         [[0.0010063858, 0.008865419, 0.9901282]]\n",
            "1357          [[0.005950175, 0.14373516, 0.85031474]]\n",
            "1358      [[0.00039416662, 0.00022860178, 0.9993772]]\n",
            "1359        [[0.0009046647, 0.006546404, 0.99254894]]\n",
            "1360      [[0.0003538145, 0.00026928674, 0.99937695]]\n",
            "1361         [[0.0007847636, 0.030009417, 0.9692058]]\n",
            "1362           [[0.016212625, 0.05748624, 0.9263011]]\n",
            "1363        [[0.00015131268, 0.0065936735, 0.993255]]\n",
            "1364        [[0.00053070294, 0.8790629, 0.120406434]]\n",
            "1365        [[0.0011040654, 0.018747991, 0.98014796]]\n",
            "1366         [[0.0012529802, 0.005959738, 0.9927873]]\n",
            "1367            [[0.03461657, 0.2642273, 0.70115614]]\n",
            "1368          [[0.0017541732, 0.6300097, 0.36823612]]\n",
            "1369         [[0.00081150245, 0.18436307, 0.8148255]]\n",
            "1370           [[0.022771876, 0.23312286, 0.7441052]]\n",
            "1371          [[0.0004303608, 0.10753258, 0.8920371]]\n",
            "1372        [[0.00022855593, 0.0002755226, 0.999496]]\n",
            "1373       [[0.0013458204, 0.0123781655, 0.98627603]]\n",
            "1374        [[0.00023567534, 0.070274666, 0.9294897]]\n",
            "1375        [[0.0006965587, 0.97779787, 0.021505542]]\n",
            "1376         [[0.00016185813, 0.01744816, 0.9823899]]\n",
            "1377           [[0.027913602, 0.24354386, 0.7285425]]\n",
            "1378      [[0.00015547304, 0.0018404184, 0.99800414]]\n",
            "1379       [[0.0001274001, 0.00056322117, 0.9993094]]\n",
            "1380           [[0.35402662, 0.6348688, 0.011104583]]\n",
            "1381           [[0.027230753, 0.24634698, 0.7264223]]\n",
            "1382         [[0.98301184, 0.00810512, 0.0088830665]]\n",
            "1383         [[0.91551316, 0.08237014, 0.0021167404]]\n",
            "1384          [[0.82509655, 0.16399929, 0.010904218]]\n",
            "1385          [[0.00040026708, 0.00651269, 0.993087]]\n",
            "1386         [[0.005592082, 0.007664342, 0.98674357]]\n",
            "1387          [[0.0027164093, 0.6244957, 0.37278792]]\n",
            "1388          [[0.0013423744, 0.00732659, 0.9913311]]\n",
            "1389           [[0.029269127, 0.24689445, 0.7238364]]\n",
            "1390         [[0.0008219378, 0.06315993, 0.93601817]]\n",
            "1391        [[0.00036512146, 0.003124098, 0.9965107]]\n",
            "1392       [[0.0011023222, 0.0048196707, 0.99407804]]\n",
            "1393      [[0.00023187375, 0.00036156582, 0.9994066]]\n",
            "1394            [[0.03001833, 0.2332201, 0.73676157]]\n",
            "1395            [[0.004229891, 0.3334797, 0.6622904]]\n",
            "1396         [[0.0096563315, 0.54042816, 0.44991553]]\n",
            "1397          [[0.028267035, 0.24791865, 0.72381437]]\n",
            "1398         [[0.0012905411, 0.17770875, 0.82100075]]\n",
            "1399          [[0.0015665995, 0.6270762, 0.37135714]]\n",
            "1400         [[0.0009630755, 0.90102243, 0.09801449]]\n",
            "1401      [[0.00047112466, 0.00063632196, 0.9988926]]\n",
            "1402          [[0.0014506133, 0.37759227, 0.6209571]]\n",
            "1403       [[0.00025923477, 0.0036101004, 0.9961307]]\n",
            "1404           [[0.00388293, 0.50817466, 0.48794237]]\n",
            "1405        [[0.0011147239, 0.044043224, 0.95484215]]\n",
            "1406            [[0.03361066, 0.25240493, 0.7139844]]\n",
            "1407           [[0.05112524, 0.53589654, 0.41297826]]\n",
            "1408           [[0.033773974, 0.2535317, 0.71269435]]\n",
            "1409                  [[0.038455, 0.25431, 0.707235]]\n",
            "1410            [[0.041482285, 0.2599874, 0.6985303]]\n",
            "1411        [[0.0025979117, 0.046595514, 0.95080656]]\n",
            "1412          [[0.039856445, 0.25362584, 0.70651776]]\n",
            "1413       [[0.00029543406, 0.0006093142, 0.9990952]]\n",
            "1414           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1415        [[0.00050722307, 0.011238757, 0.9882541]]\n",
            "1416           [[0.030521538, 0.25476804, 0.7147104]]\n",
            "1417             [[0.03386509, 0.2605815, 0.7055534]]\n",
            "1418            [[0.03408651, 0.26115593, 0.7047576]]\n",
            "1419      [[0.00019664962, 0.0035583035, 0.99624497]]\n",
            "1420      [[0.00022162656, 0.0040942817, 0.99568415]]\n",
            "1421       [[0.00014127685, 0.004187766, 0.99567103]]\n",
            "1422      [[0.00016240617, 0.0020740249, 0.99776363]]\n",
            "1423         [[0.0018595923, 0.31507412, 0.68306637]]\n",
            "1424          [[0.026957551, 0.24831337, 0.72472906]]\n",
            "1425       [[0.0005048151, 0.0019253002, 0.99756986]]\n",
            "1426       [[0.00047667342, 0.0068162847, 0.9927071]]\n",
            "1427           [[0.029828839, 0.22954279, 0.7406283]]\n",
            "1428         [[0.0027969321, 0.28459552, 0.71260756]]\n",
            "1429         [[0.0014504816, 0.024738908, 0.9738106]]\n",
            "1430        [[0.0007790623, 0.0033972478, 0.9958236]]\n",
            "1431          [[0.0006012787, 0.004982748, 0.994416]]\n",
            "1432       [[0.00087125436, 0.0045570233, 0.9945716]]\n",
            "1433         [[0.0010763294, 0.21791925, 0.78100437]]\n",
            "1434       [[0.00033954112, 0.011452156, 0.98820835]]\n",
            "1435        [[0.0008583513, 0.0060989615, 0.9930427]]\n",
            "1436        [[0.00087950536, 0.07410845, 0.92501205]]\n",
            "1437         [[0.0006285256, 0.060386624, 0.9389849]]\n",
            "1438           [[0.027860634, 0.24404602, 0.7280933]]\n",
            "1439          [[0.050009977, 0.72009623, 0.22989379]]\n",
            "1440        [[0.0006182921, 0.007680179, 0.99170154]]\n",
            "1441          [[0.008971402, 0.9154431, 0.075585455]]\n",
            "1442            [[0.014117439, 0.4791297, 0.5067529]]\n",
            "1443           [[0.07158967, 0.70357203, 0.22483821]]\n",
            "1444           [[0.09945409, 0.75907767, 0.14146829]]\n",
            "1445          [[0.0029532637, 0.4533935, 0.54365325]]\n",
            "1446           [[0.031932425, 0.2398683, 0.72819924]]\n",
            "1447          [[0.034081664, 0.24971765, 0.71620065]]\n",
            "1448            [[0.035654433, 0.2585741, 0.7057715]]\n",
            "1449          [[0.9303369, 0.045282297, 0.024380744]]\n",
            "1450         [[0.0032760832, 0.76722234, 0.22950163]]\n",
            "1451           [[0.03309811, 0.25075072, 0.71615124]]\n",
            "1452           [[0.028651306, 0.25933522, 0.7120135]]\n",
            "1453          [[0.0007913506, 0.9296638, 0.06954488]]\n",
            "1454        [[0.0033288687, 0.87170506, 0.124966055]]\n",
            "1455        [[0.0003154081, 0.018256862, 0.98142767]]\n",
            "1456          [[0.008489099, 0.24832894, 0.74318194]]\n",
            "1457             [[0.028458463, 0.245372, 0.7261695]]\n",
            "1458            [[0.0063059, 0.9047563, 0.088937804]]\n",
            "1459        [[0.0004190886, 0.0004449735, 0.9991359]]\n",
            "1460       [[0.00016234102, 0.0024391506, 0.9973986]]\n",
            "1461            [[0.02684216, 0.24410287, 0.7290549]]\n",
            "1462       [[0.00015706473, 0.0009872831, 0.9988557]]\n",
            "1463         [[0.0002949228, 0.005575151, 0.9941299]]\n",
            "1464     [[0.000115596136, 0.00085975515, 0.9990246]]\n",
            "1465         [[0.0012333831, 0.13936587, 0.85940075]]\n",
            "1466     [[0.00018205045, 0.00036770207, 0.99945027]]\n",
            "1467       [[0.00023690549, 0.029843235, 0.96991986]]\n",
            "1468      [[0.00021102396, 0.00021116991, 0.9995778]]\n",
            "1469             [[0.028444903, 0.2431941, 0.728361]]\n",
            "1470       [[0.00012210506, 0.0011454301, 0.9987324]]\n",
            "1471       [[0.00055901066, 0.0031537525, 0.9962872]]\n",
            "1472          [[0.0004829817, 0.0021271107, 0.99739]]\n",
            "1473         [[0.9829268, 0.012739236, 0.0043338635]]\n",
            "1474           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1475       [[0.00026488374, 0.0014066688, 0.9983284]]\n",
            "1476              [[0.6104614, 0.0950848, 0.2944538]]\n",
            "1477      [[0.00021348264, 0.0035361443, 0.99625033]]\n",
            "1478        [[0.00044183063, 0.011372869, 0.9881853]]\n",
            "1479          [[0.030599449, 0.23876937, 0.73063123]]\n",
            "1480          [[0.004966237, 0.90669256, 0.08834124]]\n",
            "1481           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1482            [[0.1066401, 0.8882926, 0.005067327]]\n",
            "1483             [[0.13782907, 0.8531783, 0.0089926]]\n",
            "1484        [[0.0012034223, 0.0010743267, 0.9977222]]\n",
            "1485            [[0.6166387, 0.3122423, 0.071118936]]\n",
            "1486           [[0.03259857, 0.25851747, 0.70888394]]\n",
            "1487             [[0.8317428, 0.14605366, 0.0222035]]\n",
            "1488         [[0.0036234397, 0.013562446, 0.9828142]]\n",
            "1489            [[0.031668313, 0.2508719, 0.7174598]]\n",
            "1490          [[0.030814225, 0.25257453, 0.71661127]]\n",
            "1491          [[0.027932622, 0.25349766, 0.71856976]]\n",
            "1492         [[0.000254715, 0.0005122661, 0.9992331]]\n",
            "1493            [[0.027602365, 0.24976464, 0.722633]]\n",
            "1494       [[0.00035576313, 0.0043673124, 0.9952768]]\n",
            "1495         [[0.0015123433, 0.86899763, 0.12949003]]\n",
            "1496         [[0.0062912116, 0.9380336, 0.055675253]]\n",
            "1497         [[0.0062912116, 0.9380336, 0.055675253]]\n",
            "1498          [[0.033381667, 0.93184465, 0.03477368]]\n",
            "1499           [[0.028745633, 0.24904321, 0.7222111]]\n",
            "1500        [[0.0001956013, 0.0034574943, 0.9963469]]\n",
            "1501      [[0.00024704973, 0.0003594676, 0.99939346]]\n",
            "1502        [[0.0004329834, 0.007307679, 0.99225944]]\n",
            "1503       [[0.00019956686, 0.0014457852, 0.9983546]]\n",
            "1504        [[0.0003155252, 0.003906502, 0.99577796]]\n",
            "1505           [[0.026541555, 0.23098138, 0.7424771]]\n",
            "1506       [[0.00028080476, 0.00019515642, 0.999524]]\n",
            "1507      [[0.00021101187, 0.0006087156, 0.99918026]]\n",
            "1508          [[0.0007317919, 0.12796052, 0.8713078]]\n",
            "1509      [[0.00014351001, 0.0028948796, 0.99696153]]\n",
            "1510         [[0.00024537343, 0.07816746, 0.9215873]]\n",
            "1511         [[0.0004092696, 0.032169238, 0.9674214]]\n",
            "1512       [[0.00013798605, 0.0008197002, 0.9990422]]\n",
            "1513           [[0.031279266, 0.26095122, 0.7077696]]\n",
            "1514      [[0.00014351001, 0.0028948796, 0.99696153]]\n",
            "1515       [[0.00014643923, 0.0017272745, 0.9981262]]\n",
            "1516          [[0.028281108, 0.25095108, 0.72076774]]\n",
            "1517          [[0.000787707, 0.008542828, 0.9906695]]\n",
            "1518          [[0.0001201797, 0.00394257, 0.9959372]]\n",
            "1519           [[0.029384138, 0.25275534, 0.7178605]]\n",
            "1520          [[0.8969195, 0.0143666705, 0.08871388]]\n",
            "1521             [[0.839271, 0.09946616, 0.06126282]]\n",
            "1522           [[0.34308383, 0.6378144, 0.019101797]]\n",
            "1523      [[0.00076466665, 0.0005012067, 0.99873406]]\n",
            "1524           [[0.060059346, 0.06508506, 0.8748556]]\n",
            "1525           [[0.030747563, 0.27022317, 0.6990292]]\n",
            "1526           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1527      [[0.00039623387, 0.0016742792, 0.99792945]]\n",
            "1528        [[0.0011538316, 0.0036620763, 0.9951841]]\n",
            "1529        [[0.00028238434, 0.0011236486, 0.998594]]\n",
            "1530        [[0.00028238434, 0.0011236486, 0.998594]]\n",
            "1531      [[0.00028981574, 0.0029646663, 0.99674547]]\n",
            "1532       [[0.00024694187, 0.0024855894, 0.9972675]]\n",
            "1533       [[0.0002630261, 0.0011034848, 0.99863356]]\n",
            "1534            [[0.028754022, 0.24863392, 0.722612]]\n",
            "1535            [[0.02376576, 0.03624981, 0.9399845]]\n",
            "1536           [[0.0034686967, 0.12216921, 0.874362]]\n",
            "1537           [[0.045905106, 0.53401554, 0.4200793]]\n",
            "1538           [[0.0021946537, 0.11449734, 0.883308]]\n",
            "1539      [[0.00016807491, 0.00087636086, 0.9989556]]\n",
            "1540      [[0.00074391824, 0.0071250848, 0.99213094]]\n",
            "1541        [[0.00013245085, 0.006210773, 0.9936568]]\n",
            "1542       [[0.00014343117, 0.012011149, 0.98784536]]\n",
            "1543      [[0.00018484038, 0.0007264591, 0.99908864]]\n",
            "1544       [[0.00018128743, 0.026185684, 0.97363305]]\n",
            "1545            [[0.0003386073, 0.0784335, 0.921228]]\n",
            "1546        [[0.0023712593, 0.006293443, 0.99133533]]\n",
            "1547        [[0.0003310184, 0.015787788, 0.98388124]]\n",
            "1548          [[0.027097736, 0.23998466, 0.73291755]]\n",
            "1549             [[0.01608328, 0.855287, 0.12862967]]\n",
            "1550         [[0.0014377724, 0.62920237, 0.36935982]]\n",
            "1551          [[0.0003451021, 0.01781681, 0.9818381]]\n",
            "1552          [[0.0005044288, 0.05013591, 0.9493597]]\n",
            "1553          [[0.032551344, 0.24419379, 0.72325486]]\n",
            "1554        [[0.00063028716, 0.008955489, 0.9904143]]\n",
            "1555            [[0.03375046, 0.24567549, 0.7205741]]\n",
            "1556       [[0.00055856607, 0.014751036, 0.98469037]]\n",
            "1557           [[0.033033803, 0.24915494, 0.7178113]]\n",
            "1558            [[0.021877985, 0.0985587, 0.8795633]]\n",
            "1559           [[0.03895001, 0.26335663, 0.69769335]]\n",
            "1560           [[0.0025196134, 0.5965526, 0.4009278]]\n",
            "1561           [[0.040786963, 0.25727722, 0.7019358]]\n",
            "1562          [[0.0014907843, 0.8418126, 0.15669662]]\n",
            "1563         [[0.0046410444, 0.038494483, 0.9568645]]\n",
            "1564          [[0.011921362, 0.85713196, 0.13094665]]\n",
            "1565          [[0.027708514, 0.25213557, 0.72015584]]\n",
            "1566          [[0.002230085, 0.98602724, 0.01174271]]\n",
            "1567            [[0.06771321, 0.39215672, 0.5401301]]\n",
            "1568          [[0.0017934781, 0.9587337, 0.03947286]]\n",
            "1569         [[0.0016651925, 0.9752891, 0.023045683]]\n",
            "1570          [[0.0024660472, 0.9306801, 0.06685386]]\n",
            "1571          [[0.028937845, 0.24181399, 0.72924817]]\n",
            "1572         [[0.0013940242, 0.79118353, 0.20742248]]\n",
            "1573           [[0.08523801, 0.8759801, 0.038781825]]\n",
            "1574             [[0.22819962, 0.09754638, 0.674254]]\n",
            "1575         [[0.95112234, 0.015758706, 0.033118937]]\n",
            "1576           [[0.7330085, 0.25992468, 0.007066801]]\n",
            "1577             [[0.22819962, 0.09754638, 0.674254]]\n",
            "1578     [[0.00035756195, 0.00024477293, 0.99939764]]\n",
            "1579           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1580            [[0.02706842, 0.24682981, 0.7261017]]\n",
            "1581         [[0.00025644604, 0.09681013, 0.9029335]]\n",
            "1582       [[0.000106046726, 0.019619523, 0.9802745]]\n",
            "1583          [[0.0028161786, 0.5710428, 0.42614108]]\n",
            "1584        [[0.0037087572, 0.075977765, 0.92031354]]\n",
            "1585              [[0.5142395, 0.1298771, 0.3558834]]\n",
            "1586           [[0.031034328, 0.2746324, 0.69433326]]\n",
            "1587             [[0.03250335, 0.2498113, 0.7176853]]\n",
            "1588          [[0.0021854846, 0.25450486, 0.7433097]]\n",
            "1589        [[0.0015133359, 0.014283779, 0.98420286]]\n",
            "1590          [[0.022746094, 0.03497263, 0.94228125]]\n",
            "1591          [[0.026488677, 0.24725693, 0.72625434]]\n",
            "1592          [[0.027958298, 0.25184655, 0.72019523]]\n",
            "1593             [[0.03207438, 0.2672965, 0.7006292]]\n",
            "1594          [[0.014064592, 0.019952217, 0.9659832]]\n",
            "1595       [[0.00071496284, 0.0038646045, 0.9954204]]\n",
            "1596            [[0.035690792, 0.2835271, 0.6807821]]\n",
            "1597            [[0.03678296, 0.28450456, 0.6787125]]\n",
            "1598          [[0.040069602, 0.80724853, 0.15268189]]\n",
            "1599          [[0.0003873031, 0.9046238, 0.09498896]]\n",
            "1600         [[0.0003957897, 0.89192164, 0.10768257]]\n",
            "1601         [[0.0005432406, 0.90236425, 0.09709252]]\n",
            "1602       [[0.00077794964, 0.058585245, 0.94063675]]\n",
            "1603         [[0.002763653, 0.98246956, 0.014766798]]\n",
            "1604         [[0.0020958087, 0.00195386, 0.99595034]]\n",
            "1605           [[0.03244988, 0.24832517, 0.71922493]]\n",
            "1606           [[0.025083218, 0.01491644, 0.9600004]]\n",
            "1607           [[0.003742706, 0.4797801, 0.51647717]]\n",
            "1608           [[0.060124513, 0.10982404, 0.8300515]]\n",
            "1609           [[0.028649691, 0.2466567, 0.72469366]]\n",
            "1610          [[0.027334157, 0.012187638, 0.9604782]]\n",
            "1611           [[0.03818423, 0.36885014, 0.59296566]]\n",
            "1612         [[0.0033910032, 0.018092178, 0.9785169]]\n",
            "1613           [[0.025083218, 0.01491644, 0.9600004]]\n",
            "1614        [[0.0023683945, 0.0075765606, 0.9900551]]\n",
            "1615        [[0.00010419942, 0.0074367304, 0.992459]]\n",
            "1616           [[0.00024015862, 0.139606, 0.8601539]]\n",
            "1617           [[0.026995592, 0.24295165, 0.7300528]]\n",
            "1618       [[0.00010244254, 0.0121507775, 0.9877467]]\n",
            "1619      [[0.00021145334, 0.0005915384, 0.99919707]]\n",
            "1620       [[0.00022437848, 0.0002908019, 0.9994848]]\n",
            "1621        [[0.000282143, 0.0008025034, 0.99891543]]\n",
            "1622      [[0.00017779645, 0.0004788657, 0.99934334]]\n",
            "1623         [[0.000356182, 0.0010441854, 0.9985996]]\n",
            "1624       [[0.00011757947, 0.0011718834, 0.9987105]]\n",
            "1625         [[0.0003008685, 0.004397507, 0.9953016]]\n",
            "1626        [[0.0010409032, 0.028292328, 0.97066677]]\n",
            "1627      [[0.00091503037, 0.00063333416, 0.9984516]]\n",
            "1628     [[0.00029802165, 0.00027030395, 0.99943167]]\n",
            "1629            [[0.03122576, 0.25598654, 0.7127877]]\n",
            "1630             [[0.03267817, 0.2556445, 0.7116773]]\n",
            "1631            [[0.03330031, 0.26156855, 0.7051311]]\n",
            "1632        [[0.000601976, 0.0050437986, 0.99435425]]\n",
            "1633       [[0.00019916822, 0.003944928, 0.99585587]]\n",
            "1634       [[0.00012122375, 0.0060553844, 0.9938234]]\n",
            "1635           [[0.00809156, 0.048061118, 0.9438473]]\n",
            "1636        [[0.0005097561, 0.0021121681, 0.9973781]]\n",
            "1637            [[0.01952662, 0.9203939, 0.06007951]]\n",
            "1638          [[0.0013374718, 0.27476615, 0.7238964]]\n",
            "1639          [[0.0016530463, 0.5357587, 0.46258825]]\n",
            "1640            [[0.027712038, 0.2562432, 0.7160448]]\n",
            "1641        [[0.0002829544, 0.0012739561, 0.9984432]]\n",
            "1642          [[0.0016530463, 0.5357587, 0.46258825]]\n",
            "1643       [[0.0006626044, 0.0057628215, 0.99357456]]\n",
            "1644         [[0.0013337436, 0.22188076, 0.77678555]]\n",
            "1645            [[0.005171508, 0.1295844, 0.8652441]]\n",
            "1646       [[0.0011143058, 0.0069045494, 0.99198115]]\n",
            "1647         [[0.0022319541, 0.09727517, 0.90049285]]\n",
            "1648          [[0.018944614, 0.11846066, 0.86259466]]\n",
            "1649         [[0.0005378554, 0.013408809, 0.9860533]]\n",
            "1650        [[0.00047312072, 0.018640613, 0.9808863]]\n",
            "1651          [[0.0020859037, 0.16057126, 0.8373428]]\n",
            "1652        [[0.00025245335, 0.006049839, 0.9936977]]\n",
            "1653          [[0.026806964, 0.24768578, 0.72550726]]\n",
            "1654            [[0.026365716, 0.24520625, 0.728428]]\n",
            "1655        [[0.0041636247, 0.010540879, 0.98529553]]\n",
            "1656       [[0.00040074496, 0.0024445208, 0.9971547]]\n",
            "1657         [[0.0046921847, 0.87579465, 0.11951316]]\n",
            "1658             [[0.027573606, 0.23808645, 0.73434]]\n",
            "1659          [[0.027017236, 0.24185911, 0.73112375]]\n",
            "1660        [[0.0011951115, 0.0012734096, 0.9975314]]\n",
            "1661      [[0.00031857553, 0.00040972198, 0.9992717]]\n",
            "1662         [[0.001546302, 0.021547446, 0.97690624]]\n",
            "1663          [[0.0007359407, 0.08613126, 0.9131327]]\n",
            "1664          [[0.0007359407, 0.08613126, 0.9131327]]\n",
            "1665      [[0.00026055792, 0.0023528056, 0.99738675]]\n",
            "1666        [[0.0005862024, 0.0116375275, 0.9877763]]\n",
            "1667         [[0.00029105527, 0.004671817, 0.995037]]\n",
            "1668         [[0.0015830093, 0.008998335, 0.9894187]]\n",
            "1669          [[0.0027542184, 0.18170382, 0.8155419]]\n",
            "1670        [[0.0003728737, 0.0010250463, 0.9986021]]\n",
            "1671          [[0.0002963733, 0.002924646, 0.996779]]\n",
            "1672          [[0.0051001706, 0.7400196, 0.25488025]]\n",
            "1673           [[0.004579213, 0.8495351, 0.14588569]]\n",
            "1674           [[0.010372978, 0.8759491, 0.11367794]]\n",
            "1675          [[0.0132602025, 0.9131991, 0.07354061]]\n",
            "1676          [[0.07819939, 0.88364404, 0.038156513]]\n",
            "1677            [[0.027919149, 0.24745579, 0.724625]]\n",
            "1678           [[0.030099487, 0.2682594, 0.70164114]]\n",
            "1679           [[0.019712402, 0.7526356, 0.22765198]]\n",
            "1680           [[0.027511429, 0.24246427, 0.7300243]]\n",
            "1681       [[0.00081415084, 0.009858999, 0.98932695]]\n",
            "1682      [[0.00021309542, 0.0020424207, 0.99774444]]\n",
            "1683          [[0.027297823, 0.24867961, 0.72402257]]\n",
            "1684       [[0.00025003558, 0.0001734642, 0.9995765]]\n",
            "1685        [[0.99300283, 0.005125668, 0.0018715389]]\n",
            "1686        [[0.0009955566, 0.000988121, 0.99801636]]\n",
            "1687      [[0.00049401884, 0.0005757243, 0.99893016]]\n",
            "1688       [[0.00048269014, 0.0006415875, 0.9988757]]\n",
            "1689           [[0.002754859, 0.000678107, 0.996567]]\n",
            "1690         [[9.143234e-05, 0.000526225, 0.9993824]]\n",
            "1691            [[0.015433671, 0.2974689, 0.6870975]]\n",
            "1692            [[0.6845335, 0.2609862, 0.054480307]]\n",
            "1693        [[0.0018440988, 0.102155484, 0.89600044]]\n",
            "1694          [[0.9297964, 0.06358625, 0.0066173445]]\n",
            "1695        [[0.0011656326, 0.0023971645, 0.9964372]]\n",
            "1696           [[0.03039784, 0.25108886, 0.71851325]]\n",
            "1697          [[0.002407863, 0.015594317, 0.9819978]]\n",
            "1698           [[0.0012489276, 0.47318807, 0.525563]]\n",
            "1699      [[0.00046703004, 0.0045875204, 0.99494547]]\n",
            "1700      [[0.00021730752, 0.0020019144, 0.99778074]]\n",
            "1701       [[0.00032030372, 0.009380905, 0.99029875]]\n",
            "1702         [[0.00029415745, 0.1144324, 0.88527346]]\n",
            "1703        [[0.00036535645, 0.29046592, 0.70916873]]\n",
            "1704       [[0.00023520966, 0.064555116, 0.93520963]]\n",
            "1705       [[0.0001523916, 0.00077535893, 0.9990722]]\n",
            "1706         [[0.0001584448, 0.005027739, 0.9948138]]\n",
            "1707           [[0.0004261073, 0.22493094, 0.774643]]\n",
            "1708           [[0.00048160303, 0.509957, 0.4895614]]\n",
            "1709             [[0.0451798, 0.8263093, 0.12851082]]\n",
            "1710            [[0.28379834, 0.6278034, 0.08839835]]\n",
            "1711           [[0.40600798, 0.5313708, 0.062621176]]\n",
            "1712            [[0.029476892, 0.2523519, 0.7181712]]\n",
            "1713        [[0.0041830125, 0.018902661, 0.97691435]]\n",
            "1714         [[0.0020528755, 0.30388042, 0.69406676]]\n",
            "1715              [[0.60979986, 0.380463, 0.0097371]]\n",
            "1716     [[0.000111685324, 0.0024726859, 0.99741566]]\n",
            "1717          [[0.65484524, 0.33226806, 0.012886713]]\n",
            "1718           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1719       [[0.0014618319, 0.0050422284, 0.99349594]]\n",
            "1720          [[0.9038541, 0.061310444, 0.034835503]]\n",
            "1721           [[0.21642196, 0.46371326, 0.31986484]]\n",
            "1722         [[0.0074159433, 0.9646605, 0.027923482]]\n",
            "1723          [[0.029065596, 0.24220943, 0.72872496]]\n",
            "1724           [[0.0020422614, 0.45486575, 0.543092]]\n",
            "1725     [[0.00026280576, 0.00028885374, 0.99944836]]\n",
            "1726         [[0.0021852828, 0.01198656, 0.98582816]]\n",
            "1727           [[0.028565282, 0.24275807, 0.7286766]]\n",
            "1728            [[0.0331367, 0.25052527, 0.71633804]]\n",
            "1729              [[0.034032, 0.2537298, 0.71223825]]\n",
            "1730        [[9.8555596e-05, 0.016155919, 0.9837456]]\n",
            "1731     [[0.00013757184, 0.00082344154, 0.99903905]]\n",
            "1732       [[0.00019170009, 0.0004380307, 0.9993703]]\n",
            "1733      [[0.00018520547, 0.0026964191, 0.99711835]]\n",
            "1734        [[0.00017662928, 0.004067626, 0.9957558]]\n",
            "1735          [[0.0051468993, 0.31982362, 0.6750294]]\n",
            "1736         [[0.00051353226, 0.0865885, 0.91289794]]\n",
            "1737       [[0.00021501511, 0.0015752265, 0.9982097]]\n",
            "1738       [[0.0002418631, 0.0017120015, 0.99804616]]\n",
            "1739          [[0.026544832, 0.25574642, 0.71770877]]\n",
            "1740         [[0.0008052397, 0.9450183, 0.054176465]]\n",
            "1741           [[0.020659158, 0.19556949, 0.7837714]]\n",
            "1742             [[0.0190275, 0.17695637, 0.8040162]]\n",
            "1743           [[0.20103958, 0.7216448, 0.077315584]]\n",
            "1744        [[9.709781e-05, 0.001364666, 0.99853826]]\n",
            "1745      [[0.00010779436, 0.00096051063, 0.9989317]]\n",
            "1746     [[0.00016670916, 0.00010513292, 0.99972814]]\n",
            "1747       [[0.00012956055, 0.0013606586, 0.9985098]]\n",
            "1748           [[0.6319678, 0.34827164, 0.019760577]]\n",
            "1749            [[0.09428119, 0.05363975, 0.8520791]]\n",
            "1750         [[0.0073525594, 0.022631416, 0.9700161]]\n",
            "1751         [[0.001210793, 0.0018975019, 0.9968917]]\n",
            "1752           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1753            [[0.02736831, 0.23597889, 0.7366528]]\n",
            "1754           [[0.26275662, 0.71972173, 0.01752163]]\n",
            "1755         [[0.029363874, 0.92773193, 0.042904217]]\n",
            "1756            [[0.08914756, 0.23541489, 0.6754375]]\n",
            "1757            [[0.027407866, 0.5950376, 0.3775545]]\n",
            "1758           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1759           [[0.005193775, 0.32484734, 0.6699589]]\n",
            "1760          [[0.0006276642, 0.24238208, 0.7569903]]\n",
            "1761       [[0.00024306736, 0.013737223, 0.98601973]]\n",
            "1762           [[0.004901464, 0.36225146, 0.6328471]]\n",
            "1763         [[0.0007222359, 0.03921699, 0.96006066]]\n",
            "1764       [[0.00017527716, 0.003623369, 0.99620134]]\n",
            "1765         [[0.0014004799, 0.16382428, 0.83477527]]\n",
            "1766        [[0.00013790657, 0.032798693, 0.9670634]]\n",
            "1767        [[0.00027686657, 0.044391282, 0.9553319]]\n",
            "1768          [[0.036721822, 0.26149154, 0.70178664]]\n",
            "1769        [[0.00020171591, 0.015290891, 0.9845073]]\n",
            "1770        [[9.911906e-05, 0.0032960195, 0.9966049]]\n",
            "1771           [[0.0010675392, 0.94036144, 0.058571]]\n",
            "1772        [[0.0012190734, 0.0076395776, 0.9911413]]\n",
            "1773         [[0.9925532, 0.006465464, 0.0009813774]]\n",
            "1774       [[0.00044325824, 0.096025795, 0.90353096]]\n",
            "1775           [[0.0007100114, 0.1264102, 0.8728798]]\n",
            "1776        [[0.00057231146, 0.05219357, 0.94723415]]\n",
            "1777           [[0.028867569, 0.26225126, 0.7088812]]\n",
            "1778        [[0.0016934976, 0.050439376, 0.94786716]]\n",
            "1779            [[0.005835128, 0.5693173, 0.4248476]]\n",
            "1780          [[0.0009418717, 0.30300152, 0.6960566]]\n",
            "1781            [[0.002204283, 0.5623409, 0.4354548]]\n",
            "1782          [[0.002252757, 0.83265984, 0.16508739]]\n",
            "1783       [[0.0006266869, 0.00069718756, 0.9986761]]\n",
            "1784       [[0.0004482304, 0.0016714624, 0.99788034]]\n",
            "1785         [[0.0011292804, 0.26692143, 0.73194927]]\n",
            "1786           [[0.000402201, 0.11748314, 0.8821146]]\n",
            "1787        [[0.00016330428, 0.021799041, 0.9780376]]\n",
            "1788              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1789              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1790              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1791              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1792           [[0.035873346, 0.2670274, 0.69709927]]\n",
            "1793            [[0.035602443, 0.2635899, 0.7008077]]\n",
            "1794           [[0.036830727, 0.26954353, 0.6936258]]\n",
            "1795              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1796           [[0.033192713, 0.25958496, 0.7072224]]\n",
            "1797              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1798              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1799              [[0.035445, 0.2648392, 0.69971573]]\n",
            "1800       [[0.00061765616, 0.006739301, 0.99264306]]\n",
            "1801      [[0.00025593018, 0.00026162487, 0.9994824]]\n",
            "1802         [[0.00083748915, 0.03627132, 0.9628912]]\n",
            "1803         [[0.0002026263, 0.039045084, 0.9607523]]\n",
            "1804           [[0.0009022722, 0.885972, 0.11312573]]\n",
            "1805           [[0.000649717, 0.2653381, 0.73401225]]\n",
            "1806           [[0.000824893, 0.22467323, 0.7745019]]\n",
            "1807          [[0.00055383117, 0.74450517, 0.254941]]\n",
            "1808         [[0.00039402174, 0.19360511, 0.8060009]]\n",
            "1809       [[0.000257781, 0.00024934483, 0.99949276]]\n",
            "1810         [[0.0006473993, 0.001879319, 0.9974732]]\n",
            "1811          [[0.010960878, 0.9669634, 0.022075703]]\n",
            "1812         [[0.0028399979, 0.30290776, 0.69425225]]\n",
            "1813        [[0.0004478921, 0.0008465817, 0.9987055]]\n",
            "1814         [[0.0018320169, 0.23253796, 0.76563007]]\n",
            "1815        [[0.0024115704, 0.0012821058, 0.9963063]]\n",
            "1816       [[0.00058765797, 0.00042023647, 0.998992]]\n",
            "1817          [[0.031563777, 0.24513063, 0.72330564]]\n",
            "1818         [[0.0015526157, 0.003562473, 0.9948849]]\n",
            "1819           [[0.028847177, 0.23282212, 0.7383307]]\n",
            "1820        [[0.0013328457, 0.0025125472, 0.9961546]]\n",
            "1821        [[0.00034129492, 0.001445614, 0.9982132]]\n",
            "1822       [[0.00067051034, 0.0013260023, 0.9980034]]\n",
            "1823            [[0.7869958, 0.13686277, 0.07614135]]\n",
            "1824          [[0.026846385, 0.24280283, 0.73035085]]\n",
            "1825          [[0.0013933483, 0.03301897, 0.9655876]]\n",
            "1826         [[0.006455234, 0.90014106, 0.093403704]]\n",
            "1827          [[0.0049183047, 0.9275976, 0.06748411]]\n",
            "1828          [[0.0103233615, 0.9055988, 0.08407785]]\n",
            "1829             [[0.889504, 0.07140249, 0.03909352]]\n",
            "1830             [[0.133202, 0.68244594, 0.18435198]]\n",
            "1831        [[0.0051608556, 0.0040907986, 0.9907482]]\n",
            "1832        [[0.0030856668, 0.0077120047, 0.9892023]]\n",
            "1833             [[0.03504033, 0.2608293, 0.7041304]]\n",
            "1834       [[0.0017047352, 0.0057951375, 0.99250025]]\n",
            "1835          [[0.031962607, 0.25125033, 0.71678704]]\n",
            "1836           [[0.031210847, 0.25405252, 0.7147366]]\n",
            "1837              [[0.033354856, 0.2540651, 0.71258]]\n",
            "1838          [[0.034595482, 0.27208662, 0.69331795]]\n",
            "1839          [[0.034517195, 0.26002064, 0.70546216]]\n",
            "1840             [[0.02784825, 0.241108, 0.73104376]]\n",
            "1841          [[0.028299136, 0.23408887, 0.73761207]]\n",
            "1842          [[0.029579243, 0.23015156, 0.74026924]]\n",
            "1843          [[0.030254148, 0.23381416, 0.73593163]]\n",
            "1844             [[0.02652806, 0.2314075, 0.7420644]]\n",
            "1845      [[0.00020729475, 0.00016621564, 0.9996264]]\n",
            "1846      [[0.00030605655, 0.00042712802, 0.9992668]]\n",
            "1847       [[0.00053482066, 0.0041824807, 0.9952827]]\n",
            "1848          [[0.0005449842, 0.029401997, 0.970053]]\n",
            "1849       [[0.00041747242, 0.011082167, 0.98850036]]\n",
            "1850          [[0.0051681176, 0.6706174, 0.32421455]]\n",
            "1851        [[0.00023538707, 0.005210393, 0.9945543]]\n",
            "1852        [[0.0003431308, 0.0013052868, 0.9983516]]\n",
            "1853        [[0.00021586916, 0.002302642, 0.9974815]]\n",
            "1854          [[0.0010735453, 0.01128696, 0.9876395]]\n",
            "1855           [[0.030908236, 0.8222181, 0.14687364]]\n",
            "1856           [[0.033843625, 0.26339075, 0.7027656]]\n",
            "1857          [[0.032486167, 0.25854066, 0.70897317]]\n",
            "1858           [[0.028955078, 0.24824966, 0.7227953]]\n",
            "1859       [[0.0002995517, 0.0012361117, 0.99846435]]\n",
            "1860          [[0.031431783, 0.25642085, 0.71214736]]\n",
            "1861        [[0.0004409679, 0.005502616, 0.99405646]]\n",
            "1862       [[0.00044613093, 0.009526517, 0.99002737]]\n",
            "1863            [[0.034100596, 0.2709001, 0.6949993]]\n",
            "1864      [[0.00023461174, 0.00073420285, 0.9990312]]\n",
            "1865       [[0.0008056284, 0.0076446105, 0.99154973]]\n",
            "1866            [[0.03222443, 0.2711753, 0.69660026]]\n",
            "1867        [[0.00041774407, 0.009574671, 0.9900075]]\n",
            "1868           [[0.000770707, 0.07889753, 0.9203317]]\n",
            "1869        [[0.00027187186, 0.020048885, 0.9796792]]\n",
            "1870           [[0.030318366, 0.26790953, 0.7017721]]\n",
            "1871        [[0.0002837324, 0.0034965526, 0.9962197]]\n",
            "1872          [[0.0019605013, 0.027008414, 0.971031]]\n",
            "1873         [[0.0043476545, 0.026189212, 0.9694631]]\n",
            "1874      [[0.00022494874, 0.00027729903, 0.9994978]]\n",
            "1875          [[0.028302208, 0.26166365, 0.71003413]]\n",
            "1876           [[0.009547131, 0.40122405, 0.5892288]]\n",
            "1877           [[0.00021971, 0.015622338, 0.9841579]]\n",
            "1878      [[0.00028407908, 0.0064339573, 0.99328196]]\n",
            "1879        [[0.00042801522, 0.00827929, 0.99129266]]\n",
            "1880         [[0.0007614655, 0.012707976, 0.9865305]]\n",
            "1881        [[0.00037842942, 0.004022694, 0.9955988]]\n",
            "1882         [[0.0007176465, 0.019663645, 0.9796188]]\n",
            "1883        [[0.0003018306, 0.0014519556, 0.9982463]]\n",
            "1884      [[0.00018648231, 0.0047705043, 0.99504304]]\n",
            "1885         [[0.002475776, 0.010550942, 0.98697335]]\n",
            "1886            [[0.01801234, 0.9341021, 0.04788556]]\n",
            "1887          [[0.0016160089, 0.09498973, 0.9033942]]\n",
            "1888           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1889          [[0.90796894, 0.08495692, 0.007074142]]\n",
            "1890            [[0.6760736, 0.11619293, 0.20773351]]\n",
            "1891           [[0.027274538, 0.24286881, 0.7298566]]\n",
            "1892          [[0.027192902, 0.23292318, 0.73988396]]\n",
            "1893          [[0.032393824, 0.013657813, 0.9539484]]\n",
            "1894          [[0.007663951, 0.08006507, 0.91227096]]\n",
            "1895          [[0.013009071, 0.23607555, 0.75091535]]\n",
            "1896            [[0.028253492, 0.2558547, 0.7158918]]\n",
            "1897          [[0.032822296, 0.24510235, 0.72207534]]\n",
            "1898          [[0.009149057, 0.89489615, 0.09595479]]\n",
            "1899         [[0.0074780066, 0.9832304, 0.009291617]]\n",
            "1900            [[0.032813277, 0.2438598, 0.7233269]]\n",
            "1901           [[0.029422821, 0.24628866, 0.7242885]]\n",
            "1902        [[0.0029529422, 0.006175818, 0.99087125]]\n",
            "1903          [[0.026076285, 0.007842962, 0.9660808]]\n",
            "1904          [[0.06466801, 0.034605402, 0.90072656]]\n",
            "1905           [[0.61074084, 0.31365144, 0.07560771]]\n",
            "1906         [[0.058043413, 0.89799666, 0.043959945]]\n",
            "1907       [[0.00034545496, 0.0038993475, 0.9957552]]\n",
            "1908        [[0.00048183548, 0.0032561573, 0.996262]]\n",
            "1909          [[0.030072924, 0.24903363, 0.72089344]]\n",
            "1910       [[0.0003065979, 0.00029311323, 0.9994004]]\n",
            "1911           [[0.027331723, 0.25045875, 0.7222095]]\n",
            "1912           [[0.0018064734, 0.3098695, 0.6883239]]\n",
            "1913          [[0.030208223, 0.24727026, 0.72252154]]\n",
            "1914      [[0.00039111276, 0.0012516323, 0.99835724]]\n",
            "1915           [[0.029583525, 0.24422866, 0.7261878]]\n",
            "1916          [[0.030536782, 0.24300565, 0.72645754]]\n",
            "1917            [[0.02841907, 0.25763503, 0.7139459]]\n",
            "1918          [[0.0070016994, 0.2784009, 0.71459746]]\n",
            "1919           [[0.028945718, 0.23667836, 0.7343759]]\n",
            "1920         [[0.0023015805, 0.013499169, 0.9841993]]\n",
            "1921           [[0.06748453, 0.61806744, 0.31444797]]\n",
            "1922            [[0.5689639, 0.16906029, 0.26197582]]\n",
            "1923         [[0.0020785232, 0.39844754, 0.59947395]]\n",
            "1924        [[0.0008514836, 0.008502733, 0.99064577]]\n",
            "1925      [[0.00023157561, 0.00037722953, 0.9993912]]\n",
            "1926       [[0.0001525658, 0.00073904096, 0.9991084]]\n",
            "1927       [[0.00013110382, 0.0012786337, 0.9985903]]\n",
            "1928        [[0.00041811226, 0.44900298, 0.55057895]]\n",
            "1929      [[0.00011215103, 0.0014384062, 0.99844944]]\n",
            "1930      [[0.00023647455, 0.0020416938, 0.99772185]]\n",
            "1931       [[0.00016972805, 0.00075925945, 0.999071]]\n",
            "1932      [[0.00011215103, 0.0014384062, 0.99844944]]\n",
            "1933           [[0.037282433, 0.5595898, 0.40312773]]\n",
            "1934           [[0.17427957, 0.79353464, 0.03218574]]\n",
            "1935           [[0.01693423, 0.89503735, 0.08802838]]\n",
            "1936          [[0.026758853, 0.24426985, 0.72897136]]\n",
            "1937       [[0.00019683146, 0.0007217801, 0.9990814]]\n",
            "1938           [[0.001488394, 0.39848217, 0.6000294]]\n",
            "1939           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "1940        [[0.00055214204, 0.04130333, 0.95814455]]\n",
            "1941           [[0.00562781, 0.36247197, 0.63190025]]\n",
            "1942      [[0.00023395928, 0.0029533918, 0.99681264]]\n",
            "1943           [[0.0010130453, 0.3152841, 0.6837029]]\n",
            "1944         [[0.0008497783, 0.05327029, 0.94587994]]\n",
            "1945          [[0.03324155, 0.031374406, 0.93538404]]\n",
            "1946       [[0.0006570121, 0.00062182115, 0.9987212]]\n",
            "1947          [[0.0023844934, 0.18754967, 0.8100658]]\n",
            "1948           [[0.0008454389, 0.0337347, 0.9654199]]\n",
            "1949           [[0.011566554, 0.5952134, 0.39322004]]\n",
            "1950      [[0.00037623133, 0.00095056253, 0.9986733]]\n",
            "1951       [[0.0006665731, 0.0054008206, 0.99393255]]\n",
            "1952        [[0.00051420566, 0.017959056, 0.9815267]]\n",
            "1953        [[0.0002130617, 0.0017397379, 0.9980471]]\n",
            "1954           [[0.030128006, 0.25086206, 0.7190099]]\n",
            "1955       [[0.00024131022, 0.0060326615, 0.9937261]]\n",
            "1956       [[0.00017811476, 0.026128648, 0.97369313]]\n",
            "1957          [[0.0027504296, 0.1738253, 0.82342434]]\n",
            "1958         [[0.0008992743, 0.33316338, 0.66593736]]\n",
            "1959           [[0.07148462, 0.76737124, 0.16114412]]\n",
            "1960         [[0.0031077813, 0.9145003, 0.082391925]]\n",
            "1961           [[0.029466204, 0.25851604, 0.7120178]]\n",
            "1962        [[0.00019988822, 0.027206264, 0.9725938]]\n",
            "1963         [[0.0015726438, 0.03280442, 0.96562296]]\n",
            "1964        [[0.0010173782, 0.0018319995, 0.9971506]]\n",
            "1965        [[0.0010173782, 0.0018319995, 0.9971506]]\n",
            "1966       [[0.0009546681, 0.0066366675, 0.99240863]]\n",
            "1967           [[0.030750364, 0.24513824, 0.7241113]]\n",
            "1968          [[0.018610416, 0.51175773, 0.46963182]]\n",
            "1969           [[0.55500895, 0.37099853, 0.07399251]]\n",
            "1970          [[0.013265188, 0.33655405, 0.65018076]]\n",
            "1971       [[0.00015932664, 0.002084615, 0.99775606]]\n",
            "1972       [[0.0002480161, 0.00038573061, 0.9993662]]\n",
            "1973        [[0.00013920407, 0.0050918804, 0.994769]]\n",
            "1974        [[0.00027328948, 0.008108528, 0.9916182]]\n",
            "1975          [[0.0012614661, 0.5677142, 0.43102434]]\n",
            "1976        [[0.00022119387, 0.004338887, 0.9954399]]\n",
            "1977           [[0.001954476, 0.34792107, 0.6501245]]\n",
            "1978         [[0.0009740905, 0.035010066, 0.9640159]]\n",
            "1979          [[0.030256504, 0.25383842, 0.71590513]]\n",
            "1980         [[0.0004616093, 0.005788039, 0.9937503]]\n",
            "1981         [[0.0019137075, 0.033029832, 0.9650564]]\n",
            "1982       [[0.00023364274, 0.000710198, 0.99905616]]\n",
            "1983       [[0.00025524283, 0.0027754584, 0.9969693]]\n",
            "1984      [[0.00059791503, 0.00022940797, 0.9991726]]\n",
            "1985       [[0.00050977734, 0.0004712164, 0.9990189]]\n",
            "1986         [[0.00014445244, 0.004171474, 0.995684]]\n",
            "1987          [[0.0003464641, 0.014747555, 0.984906]]\n",
            "1988          [[0.0011135939, 0.7920242, 0.20686221]]\n",
            "1989       [[0.00078021653, 0.094383575, 0.90483624]]\n",
            "1990          [[0.028718552, 0.26074636, 0.71053517]]\n",
            "1991          [[0.0033172364, 0.52756625, 0.4691165]]\n",
            "1992         [[0.00034156066, 0.08215307, 0.9175053]]\n",
            "1993       [[0.00040763302, 0.0005711095, 0.9990212]]\n",
            "1994         [[0.00090395124, 0.9282867, 0.07080941]]\n",
            "1995       [[0.00060244394, 0.051381957, 0.94801563]]\n",
            "1996            [[0.03047089, 0.26235408, 0.7071751]]\n",
            "1997             [[0.032730915, 0.2480071, 0.719262]]\n",
            "1998         [[0.0009201909, 0.011261912, 0.9878179]]\n",
            "1999          [[0.0007059493, 0.15154749, 0.8477466]]\n",
            "2000          [[0.0010533563, 0.06600591, 0.9329408]]\n",
            "2001       [[0.00052772404, 0.012827194, 0.98664504]]\n",
            "2002          [[0.001941265, 0.14955433, 0.84850436]]\n",
            "2003          [[0.0006515518, 0.33456212, 0.6647863]]\n",
            "2004          [[0.0005920808, 0.9359829, 0.06342508]]\n",
            "2005        [[0.0007533449, 0.94597334, 0.053273275]]\n",
            "2006         [[0.00049513485, 0.8580396, 0.14146526]]\n",
            "2007        [[0.0007329608, 0.0029559287, 0.9963111]]\n",
            "2008          [[0.03942477, 0.90380585, 0.056769367]]\n",
            "2009            [[0.03761783, 0.4782061, 0.48417607]]\n",
            "2010           [[0.046210483, 0.04732208, 0.9064674]]\n",
            "2011         [[0.0016336467, 0.20323075, 0.79513556]]\n",
            "2012       [[0.00049953244, 0.0036222055, 0.9958782]]\n",
            "2013        [[0.0008409602, 0.0062465924, 0.9929125]]\n",
            "2014      [[0.00058199186, 0.0024158764, 0.99700207]]\n",
            "2015        [[0.0011038556, 0.004225865, 0.99467033]]\n",
            "2016        [[0.0019056709, 0.0052845976, 0.9928098]]\n",
            "2017        [[0.0011763828, 0.015451533, 0.98337203]]\n",
            "2018          [[0.93345344, 0.032848526, 0.03369804]]\n",
            "2019       [[0.00060880167, 0.017389625, 0.98200154]]\n",
            "2020      [[0.00023752773, 0.0036135917, 0.99614894]]\n",
            "2021      [[0.00035333808, 0.0032720033, 0.99637467]]\n",
            "2022        [[0.0035624623, 0.0061253305, 0.9903122]]\n",
            "2023      [[0.0010390329, 0.00055042363, 0.99841046]]\n",
            "2024           [[0.00061769754, 0.001782259, 0.9976]]\n",
            "2025        [[0.0001575737, 0.0014711637, 0.9983713]]\n",
            "2026       [[0.00013415523, 0.006095398, 0.99377054]]\n",
            "2027        [[0.00075358216, 0.015710609, 0.9835359]]\n",
            "2028         [[0.0017517664, 0.65050185, 0.34774634]]\n",
            "2029         [[0.0004068495, 0.04740581, 0.95218736]]\n",
            "2030          [[0.000218362, 0.009372029, 0.9904096]]\n",
            "2031         [[0.0030207578, 0.043675393, 0.9533039]]\n",
            "2032         [[0.0020125387, 0.54487616, 0.45311135]]\n",
            "2033           [[0.0018508348, 0.8352668, 0.1628824]]\n",
            "2034        [[0.00014358651, 0.001509769, 0.9983467]]\n",
            "2035        [[0.00044931198, 0.21478757, 0.78476316]]\n",
            "2036         [[0.00047846712, 0.8740418, 0.12547976]]\n",
            "2037         [[0.0007615568, 0.85901976, 0.14021866]]\n",
            "2038           [[0.029702647, 0.25325912, 0.7170382]]\n",
            "2039          [[0.0006299257, 0.64818823, 0.3511818]]\n",
            "2040           [[0.031889718, 0.24824682, 0.7198635]]\n",
            "2041           [[0.032016173, 0.25129202, 0.7166918]]\n",
            "2042          [[0.032569315, 0.25018063, 0.71725005]]\n",
            "2043        [[0.0004928779, 0.001997265, 0.99750984]]\n",
            "2044           [[0.031834587, 0.2572001, 0.71096534]]\n",
            "2045            [[0.030762548, 0.24751641, 0.721721]]\n",
            "2046           [[0.031613972, 0.25188014, 0.7165058]]\n",
            "2047           [[0.031323694, 0.24748814, 0.7211881]]\n",
            "2048          [[0.72637296, 0.25029632, 0.023330754]]\n",
            "2049            [[0.60558796, 0.347769, 0.046643097]]\n",
            "2050          [[0.027555877, 0.25236484, 0.72007924]]\n",
            "2051       [[0.00012338863, 0.0038967626, 0.9959799]]\n",
            "2052      [[0.00018778628, 0.0048066047, 0.99500567]]\n",
            "2053         [[0.0001574137, 0.009838667, 0.9900039]]\n",
            "2054        [[0.00066179957, 0.52548116, 0.47385705]]\n",
            "2055       [[0.00021356271, 0.0003507601, 0.9994356]]\n",
            "2056         [[0.0014724671, 0.116485104, 0.8820424]]\n",
            "2057        [[0.00016158925, 0.002289549, 0.9975489]]\n",
            "2058        [[0.00048016038, 0.00954251, 0.98997724]]\n",
            "2059       [[0.00024698488, 0.055830568, 0.94392246]]\n",
            "2060       [[0.00029290188, 0.0039005533, 0.9958066]]\n",
            "2061        [[0.0008053971, 0.0028101457, 0.9963844]]\n",
            "2062       [[0.0011918251, 0.0055784574, 0.99322975]]\n",
            "2063          [[0.026960162, 0.23380949, 0.73923045]]\n",
            "2064      [[0.00013929831, 0.0002570922, 0.99960357]]\n",
            "2065      [[0.00020922108, 0.0006645799, 0.99912614]]\n",
            "2066           [[0.038587544, 0.6526731, 0.30873933]]\n",
            "2067          [[0.72588664, 0.25724125, 0.016872099]]\n",
            "2068       [[0.0007723831, 0.0034614557, 0.99576616]]\n",
            "2069      [[0.00027359428, 0.0046573635, 0.99506915]]\n",
            "2070       [[0.0006027566, 0.0013041674, 0.99809307]]\n",
            "2071         [[0.9820661, 0.015188562, 0.0027453299]]\n",
            "2072       [[0.00025076742, 0.002058821, 0.99769044]]\n",
            "2073         [[0.0003123886, 0.0047466247, 0.994941]]\n",
            "2074           [[0.013895523, 0.07507021, 0.9110343]]\n",
            "2075        [[0.0015718939, 0.0013784181, 0.9970497]]\n",
            "2076        [[0.9949378, 0.0034119345, 0.0016502562]]\n",
            "2077        [[0.95452714, 0.041774374, 0.0036985097]]\n",
            "2078             [[0.006354016, 0.907419, 0.0862269]]\n",
            "2079        [[0.00041061832, 0.027573174, 0.9720161]]\n",
            "2080        [[0.0002841668, 0.0036651115, 0.9960508]]\n",
            "2081        [[0.00026143529, 0.005089452, 0.9946491]]\n",
            "2082           [[0.029337415, 0.24300487, 0.7276577]]\n",
            "2083       [[0.00040286174, 0.015352439, 0.98424464]]\n",
            "2084         [[0.00038516292, 0.023585906, 0.976029]]\n",
            "2085          [[0.0005726816, 0.037299402, 0.962128]]\n",
            "2086          [[0.0006060983, 0.8717962, 0.12759763]]\n",
            "2087        [[0.0003087484, 0.0002908394, 0.9994004]]\n",
            "2088            [[0.84132284, 0.1427825, 0.01589469]]\n",
            "2089          [[0.0006820924, 0.45613953, 0.5431784]]\n",
            "2090        [[0.00015996002, 0.010672146, 0.9891678]]\n",
            "2091        [[0.0001704789, 0.0037386727, 0.9960908]]\n",
            "2092          [[0.0002842579, 0.18761288, 0.8121029]]\n",
            "2093         [[0.00030667376, 0.08653516, 0.9131582]]\n",
            "2094        [[0.00037383608, 0.003559078, 0.9960671]]\n",
            "2095           [[0.0013060884, 0.04209196, 0.956602]]\n",
            "2096        [[0.00054331956, 0.96295786, 0.03649878]]\n",
            "2097         [[0.00046398188, 0.6960661, 0.30346987]]\n",
            "2098         [[0.00030667376, 0.08653516, 0.9131582]]\n",
            "2099        [[0.00031861715, 0.052395493, 0.9472859]]\n",
            "2100        [[0.00022959954, 0.008858979, 0.9909114]]\n",
            "2101       [[0.00025823287, 0.0030841918, 0.9966576]]\n",
            "2102      [[0.00024815116, 0.0004827879, 0.99926907]]\n",
            "2103      [[0.00019869774, 0.0068318746, 0.99296933]]\n",
            "2104            [[0.02591126, 0.24660254, 0.7274863]]\n",
            "2105      [[0.00047161928, 0.0015005921, 0.99802774]]\n",
            "2106        [[0.0009621601, 0.0039672153, 0.9950707]]\n",
            "2107             [[0.9143798, 0.02080193, 0.0648183]]\n",
            "2108         [[0.0045710867, 0.000738687, 0.9946902]]\n",
            "2109          [[0.0015968608, 0.9342951, 0.06410796]]\n",
            "2110          [[0.027831642, 0.24818529, 0.72398305]]\n",
            "2111          [[0.0011489405, 0.6554325, 0.34341854]]\n",
            "2112         [[0.00044916224, 0.6513182, 0.34823266]]\n",
            "2113           [[0.00059484, 0.0138112195, 0.985594]]\n",
            "2114         [[0.0010384007, 0.006050099, 0.9929115]]\n",
            "2115          [[0.000446824, 0.021005677, 0.9785476]]\n",
            "2116      [[0.00026228532, 0.0063553187, 0.99338245]]\n",
            "2117          [[0.026282048, 0.24239908, 0.73131883]]\n",
            "2118           [[0.0007319005, 0.20727608, 0.791992]]\n",
            "2119        [[0.00025162607, 0.011208532, 0.9885399]]\n",
            "2120           [[0.027190262, 0.24605206, 0.7267577]]\n",
            "2121        [[0.00016173639, 0.07672971, 0.92310846]]\n",
            "2122          [[0.0009780434, 0.12993807, 0.8690839]]\n",
            "2123        [[0.0061551975, 0.93810636, 0.055738453]]\n",
            "2124           [[0.026801866, 0.24115698, 0.7320412]]\n",
            "2125        [[0.0015994099, 0.058345184, 0.94005543]]\n",
            "2126      [[0.00034346853, 0.0048049376, 0.99485165]]\n",
            "2127        [[0.00026611323, 0.001026579, 0.9987073]]\n",
            "2128          [[0.029284436, 0.24209954, 0.72861594]]\n",
            "2129        [[0.00032472942, 0.000317686, 0.9993575]]\n",
            "2130          [[0.78370565, 0.19633919, 0.019955248]]\n",
            "2131          [[0.82810134, 0.16521668, 0.006681964]]\n",
            "2132      [[0.00012330904, 0.0027149993, 0.99716175]]\n",
            "2133            [[0.026776928, 0.2503485, 0.7228746]]\n",
            "2134       [[0.0001249757, 0.00037154087, 0.9995035]]\n",
            "2135      [[0.00012330904, 0.0027149993, 0.99716175]]\n",
            "2136           [[0.18266396, 0.68365157, 0.13368444]]\n",
            "2137           [[0.0002278538, 0.05782018, 0.941952]]\n",
            "2138           [[0.026514519, 0.24842758, 0.7250579]]\n",
            "2139           [[0.02819429, 0.25053525, 0.72127044]]\n",
            "2140           [[0.023505446, 0.19038865, 0.7861059]]\n",
            "2141          [[0.0004528099, 0.10283802, 0.8967092]]\n",
            "2142        [[0.00038685786, 0.046233166, 0.9533799]]\n",
            "2143         [[0.00018441417, 0.005747564, 0.994068]]\n",
            "2144       [[0.00021833194, 0.0003384266, 0.9994431]]\n",
            "2145        [[0.00045973877, 0.008940438, 0.9905998]]\n",
            "2146       [[0.0014100007, 0.0016408492, 0.99694914]]\n",
            "2147          [[0.0021182953, 0.02814837, 0.9697334]]\n",
            "2148        [[0.00090284104, 0.013270593, 0.9858267]]\n",
            "2149           [[0.86632085, 0.03921052, 0.09446859]]\n",
            "2150         [[0.059766103, 0.004493637, 0.93574023]]\n",
            "2151        [[0.0031834298, 0.0007634154, 0.9960532]]\n",
            "2152            [[0.2540408, 0.21299632, 0.53296286]]\n",
            "2153           [[0.028408503, 0.2527453, 0.71884626]]\n",
            "2154        [[0.0002456451, 0.005999512, 0.99375474]]\n",
            "2155           [[0.02962011, 0.24070711, 0.72967273]]\n",
            "2156        [[0.00026831636, 0.012982043, 0.9867496]]\n",
            "2157           [[0.027212141, 0.24835292, 0.7244349]]\n",
            "2158         [[0.0060618445, 0.007305878, 0.9866323]]\n",
            "2159           [[0.028639179, 0.24666622, 0.7246946]]\n",
            "2160         [[0.0009895843, 0.005296588, 0.9937138]]\n",
            "2161         [[0.0010585205, 0.005171185, 0.9937703]]\n",
            "2162           [[0.9087898, 0.07109552, 0.020114694]]\n",
            "2163          [[0.0043992717, 0.11601191, 0.8795887]]\n",
            "2164           [[0.03561454, 0.79880464, 0.16558078]]\n",
            "2165       [[0.0003861793, 0.0010182377, 0.99859554]]\n",
            "2166      [[0.00019241513, 0.0071794325, 0.99262816]]\n",
            "2167        [[0.00037905228, 0.009545054, 0.9900759]]\n",
            "2168      [[0.00019614355, 0.0013272377, 0.99847656]]\n",
            "2169        [[0.0004478942, 0.0015821274, 0.9979699]]\n",
            "2170           [[0.008232265, 0.17718099, 0.8145867]]\n",
            "2171         [[0.9871176, 0.011228846, 0.0016535718]]\n",
            "2172          [[0.014130571, 0.04018977, 0.94567955]]\n",
            "2173           [[0.008232265, 0.17718099, 0.8145867]]\n",
            "2174           [[0.008232265, 0.17718099, 0.8145867]]\n",
            "2175           [[0.026971538, 0.24299313, 0.7300353]]\n",
            "2176         [[0.0011988172, 0.01119579, 0.98760533]]\n",
            "2177           [[0.02928947, 0.24266768, 0.72804284]]\n",
            "2178            [[0.03516241, 0.2633771, 0.70146054]]\n",
            "2179            [[0.03220264, 0.25840703, 0.7093904]]\n",
            "2180           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "2181      [[0.00033906853, 0.0010760758, 0.99858487]]\n",
            "2182          [[0.013485472, 0.002123305, 0.9843912]]\n",
            "2183          [[0.0027363189, 0.7236849, 0.27357882]]\n",
            "2184         [[0.0012692352, 0.89829427, 0.10043644]]\n",
            "2185          [[0.0019323219, 0.7623672, 0.23570047]]\n",
            "2186        [[0.00026137993, 0.078924984, 0.9208137]]\n",
            "2187        [[0.004651693, 0.0036180534, 0.99173015]]\n",
            "2188        [[0.004651693, 0.0036180534, 0.99173015]]\n",
            "2189     [[0.00022694982, 0.00035862633, 0.99941444]]\n",
            "2190       [[0.00036337294, 0.0003427878, 0.9992938]]\n",
            "2191      [[0.00027082957, 0.00022789634, 0.9995012]]\n",
            "2192        [[0.00043333104, 0.0024147676, 0.997152]]\n",
            "2193         [[0.0017814583, 0.007907146, 0.9903114]]\n",
            "2194        [[0.00078037014, 0.80706644, 0.19215325]]\n",
            "2195          [[0.0006797293, 0.12239605, 0.8769242]]\n",
            "2196         [[0.00022290631, 0.03367046, 0.9661067]]\n",
            "2197            [[0.02856387, 0.25803193, 0.7134042]]\n",
            "2198           [[0.00083961437, 0.201403, 0.7977573]]\n",
            "2199       [[0.00029358175, 0.016438426, 0.98326796]]\n",
            "2200            [[0.033101037, 0.2539099, 0.7129891]]\n",
            "2201         [[0.0011184325, 0.16095726, 0.83792424]]\n",
            "2202       [[0.00040855326, 0.011739675, 0.98785174]]\n",
            "2203           [[0.030477926, 0.24957667, 0.7199455]]\n",
            "2204            [[0.030515192, 0.2472887, 0.7221961]]\n",
            "2205        [[0.0005641195, 0.0043152766, 0.9951206]]\n",
            "2206         [[0.00048804545, 0.02782151, 0.9716905]]\n",
            "2207       [[0.00021321028, 0.0014684366, 0.9983183]]\n",
            "2208          [[0.0016964884, 0.5905907, 0.40771273]]\n",
            "2209        [[0.00052481587, 0.45247516, 0.54700005]]\n",
            "2210         [[0.0019057353, 0.18868837, 0.80940586]]\n",
            "2211      [[0.00043928644, 0.0020641403, 0.99749655]]\n",
            "2212         [[0.0026540505, 0.19590738, 0.80143857]]\n",
            "2213         [[0.0011724674, 0.68691045, 0.31191707]]\n",
            "2214         [[0.0005852115, 0.92679965, 0.07261512]]\n",
            "2215         [[0.0044643427, 0.29069856, 0.70483714]]\n",
            "2216         [[0.0026246565, 0.9420274, 0.055347916]]\n",
            "2217           [[0.8422243, 0.071706004, 0.08606971]]\n",
            "2218         [[0.006434544, 0.031420223, 0.96214515]]\n",
            "2219         [[0.114063606, 0.004709563, 0.88122684]]\n",
            "2220          [[0.027816135, 0.24485427, 0.72732955]]\n",
            "2221        [[0.0003429198, 0.0013973387, 0.9982597]]\n",
            "2222        [[0.000142504, 0.0059721675, 0.99388534]]\n",
            "2223           [[0.02785153, 0.24561219, 0.72653633]]\n",
            "2224      [[0.00024011135, 0.0006244691, 0.99913543]]\n",
            "2225        [[0.00029631448, 0.03892339, 0.96078026]]\n",
            "2226      [[0.00017674631, 0.0009083794, 0.99891496]]\n",
            "2227        [[0.00036484003, 0.037748937, 0.9618862]]\n",
            "2228           [[0.027884454, 0.23899843, 0.7331171]]\n",
            "2229     [[0.00025894068, 0.00032978324, 0.99941134]]\n",
            "2230        [[0.0001685116, 0.0022782155, 0.9975533]]\n",
            "2231      [[0.000120471545, 0.0011771164, 0.9987024]]\n",
            "2232       [[0.00020364264, 0.0006201662, 0.9991761]]\n",
            "2233            [[0.026673125, 0.2417552, 0.7315717]]\n",
            "2234       [[0.00048328447, 0.0025574684, 0.9969593]]\n",
            "2235       [[0.00048328447, 0.0025574684, 0.9969593]]\n",
            "2236      [[0.00026623518, 0.00025226962, 0.9994815]]\n",
            "2237       [[0.0002757763, 0.0010228266, 0.99870145]]\n",
            "2238       [[0.00027347278, 0.0011798189, 0.9985468]]\n",
            "2239           [[0.116965964, 0.5454109, 0.33762315]]\n",
            "2240         [[0.0005159475, 0.009631611, 0.9898525]]\n",
            "2241           [[0.9089881, 0.016274964, 0.07473684]]\n",
            "2242           [[0.024589414, 0.4584429, 0.51696765]]\n",
            "2243         [[0.0029112725, 0.41368508, 0.58340365]]\n",
            "2244       [[0.00047771502, 0.010217724, 0.98930454]]\n",
            "2245       [[0.00056088687, 0.007875719, 0.99156344]]\n",
            "2246     [[0.00013207854, 0.00053068245, 0.99933714]]\n",
            "2247       [[0.0001068489, 0.00019671889, 0.9996964]]\n",
            "2248        [[8.368928e-05, 0.0004899567, 0.9994265]]\n",
            "2249      [[9.753381e-05, 0.00020088781, 0.99970156]]\n",
            "2250       [[9.297134e-05, 0.00027885375, 0.9996282]]\n",
            "2251            [[0.03182064, 0.25435793, 0.7138214]]\n",
            "2252              [[0.197512, 0.5940458, 0.20844214]]\n",
            "2253            [[0.7326075, 0.24824816, 0.01914429]]\n",
            "2254           [[0.22721292, 0.52532274, 0.24746437]]\n",
            "2255            [[0.03390556, 0.25073683, 0.7153576]]\n",
            "2256           [[0.03234941, 0.015431147, 0.9522195]]\n",
            "2257             [[0.03381475, 0.2479222, 0.7182631]]\n",
            "2258          [[0.034871947, 0.25068802, 0.71444005]]\n",
            "2259         [[0.0008099561, 0.026465992, 0.9727241]]\n",
            "2260       [[0.00031338847, 0.004478077, 0.99520844]]\n",
            "2261       [[0.00055267813, 0.013518495, 0.98592883]]\n",
            "2262           [[0.03132441, 0.24991755, 0.71875805]]\n",
            "2263           [[0.030222626, 0.24434082, 0.7254366]]\n",
            "2264           [[0.0010046735, 0.6015465, 0.3974489]]\n",
            "2265          [[0.62324923, 0.36351502, 0.013235742]]\n",
            "2266           [[0.84834445, 0.06560271, 0.08605291]]\n",
            "2267              [[0.0369436, 0.2924391, 0.6706173]]\n",
            "2268       [[0.0001368153, 0.0003537484, 0.99950945]]\n",
            "2269        [[0.00038908847, 0.012966006, 0.9866449]]\n",
            "2270         [[0.0029395835, 0.14079331, 0.85626715]]\n",
            "2271         [[0.0029395835, 0.14079331, 0.85626715]]\n",
            "2272        [[0.00095915934, 0.010453667, 0.9885872]]\n",
            "2273           [[0.030221721, 0.24669746, 0.7230808]]\n",
            "2274         [[0.0005123397, 0.0023427154, 0.997145]]\n",
            "2275             [[0.09159394, 0.7027768, 0.2056293]]\n",
            "2276         [[0.0029395835, 0.14079331, 0.85626715]]\n",
            "2277           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "2278     [[0.00025885334, 0.00013333996, 0.99960786]]\n",
            "2279          [[0.028113784, 0.25249183, 0.71939445]]\n",
            "2280        [[0.00017364346, 0.011782008, 0.9880443]]\n",
            "2281     [[0.00014862306, 0.00048238834, 0.99936897]]\n",
            "2282     [[0.000118681135, 0.00090597325, 0.9989753]]\n",
            "2283       [[0.00089144614, 0.037423052, 0.96168554]]\n",
            "2284           [[0.027213313, 0.24681036, 0.7259763]]\n",
            "2285            [[0.02765134, 0.24840395, 0.7239447]]\n",
            "2286       [[0.00013886267, 0.0003144354, 0.9995467]]\n",
            "2287         [[0.0003070422, 0.005171568, 0.9945214]]\n",
            "2288      [[0.00026469593, 0.0039738044, 0.99576145]]\n",
            "2289     [[0.00029351359, 0.00050702214, 0.99919945]]\n",
            "2290         [[0.0016879924, 0.81273794, 0.18557408]]\n",
            "2291          [[0.0016057781, 0.27942455, 0.7189697]]\n",
            "2292          [[0.0016057781, 0.27942455, 0.7189697]]\n",
            "2293            [[0.027581716, 0.2458339, 0.7265844]]\n",
            "2294        [[0.00042144975, 0.021606712, 0.9779718]]\n",
            "2295         [[0.0007703359, 0.9618805, 0.037349127]]\n",
            "2296         [[0.0015907637, 0.30633202, 0.69207716]]\n",
            "2297         [[0.0016879924, 0.81273794, 0.18557408]]\n",
            "2298       [[0.0009428044, 0.0014516824, 0.99760544]]\n",
            "2299       [[0.00020566373, 0.0009779644, 0.9988165]]\n",
            "2300       [[0.0010536669, 0.0039032127, 0.99504304]]\n",
            "2301           [[0.02745524, 0.25229207, 0.72025263]]\n",
            "2302          [[0.029548619, 0.25520107, 0.71525025]]\n",
            "2303     [[0.00012767842, 0.00038517689, 0.99948704]]\n",
            "2304       [[0.00048227637, 0.003853129, 0.99566466]]\n",
            "2305      [[0.00014288216, 0.0004620543, 0.99939513]]\n",
            "2306           [[0.028751444, 0.2415284, 0.72972006]]\n",
            "2307           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "2308          [[0.001165361, 0.003567811, 0.9952669]]\n",
            "2309       [[0.00020218884, 0.0005662048, 0.9992317]]\n",
            "2310            [[0.02760603, 0.23559855, 0.7367954]]\n",
            "2311           [[0.029032664, 0.22959246, 0.7413749]]\n",
            "2312      [[0.00027321075, 0.0028538927, 0.99687296]]\n",
            "2313         [[0.00035434603, 0.11712216, 0.8825235]]\n",
            "2314           [[0.8830738, 0.03674754, 0.080178626]]\n",
            "2315         [[0.00041643626, 0.9133238, 0.08625974]]\n",
            "2316          [[0.0004506219, 0.08894629, 0.9106031]]\n",
            "2317         [[0.0005453967, 0.93656486, 0.06288974]]\n",
            "2318            [[0.004523036, 0.15685296, 0.838624]]\n",
            "2319           [[0.026862165, 0.24725711, 0.7258808]]\n",
            "2320           [[0.0011631547, 0.0156623, 0.9831746]]\n",
            "2321           [[0.55019104, 0.4363847, 0.013424267]]\n",
            "2322           [[0.55019104, 0.4363847, 0.013424267]]\n",
            "2323      [[0.00016266698, 0.00080963277, 0.9990277]]\n",
            "2324        [[0.0004921719, 0.0006520865, 0.9988558]]\n",
            "2325       [[0.00013936078, 0.0013222675, 0.9985384]]\n",
            "2326            [[0.43271285, 0.1762178, 0.39106932]]\n",
            "2327        [[0.00022243735, 0.0002135258, 0.999564]]\n",
            "2328           [[0.026775617, 0.24324101, 0.7299833]]\n",
            "2329       [[0.00023704364, 0.002455347, 0.99730754]]\n",
            "2330        [[0.00021844155, 0.022114113, 0.9776675]]\n",
            "2331           [[0.026636187, 0.24897602, 0.7243878]]\n",
            "2332      [[0.00022214526, 0.0003546829, 0.99942315]]\n",
            "2333    [[0.000120787736, 0.00029304725, 0.99958616]]\n",
            "2334           [[0.028596252, 0.24054511, 0.7308587]]\n",
            "2335          [[0.027791942, 0.24690259, 0.72530544]]\n",
            "2336         [[0.00067930546, 0.18601738, 0.8133033]]\n",
            "2337     [[0.00023217224, 0.00016127378, 0.99960667]]\n",
            "2338           [[0.029005319, 0.24363877, 0.7273559]]\n",
            "2339        [[0.0005794051, 0.003005841, 0.99641466]]\n",
            "2340          [[0.0024858697, 0.82287496, 0.1746391]]\n",
            "2341         [[0.0006785756, 0.13751632, 0.86180514]]\n",
            "2342       [[0.00019927757, 0.0028029531, 0.9969977]]\n",
            "2343       [[0.00017777146, 0.0003982186, 0.9994241]]\n",
            "2344       [[0.00019380957, 0.0005764648, 0.9992298]]\n",
            "2345     [[0.00016570154, 0.00029207655, 0.99954224]]\n",
            "2346           [[0.029314717, 0.24827847, 0.7224068]]\n",
            "2347          [[0.028334197, 0.24716103, 0.72450477]]\n",
            "2348     [[0.00021716478, 0.00030961243, 0.99947315]]\n",
            "2349        [[0.0012076334, 0.104666404, 0.89412594]]\n",
            "2350         [[0.00036729148, 0.05923112, 0.9404016]]\n",
            "2351        [[0.0013009927, 0.048038505, 0.95066047]]\n",
            "2352         [[0.00058353867, 0.26668653, 0.7327299]]\n",
            "2353       [[0.0003380589, 0.0018225753, 0.99783933]]\n",
            "2354         [[0.0004008906, 0.010702346, 0.9888967]]\n",
            "2355          [[0.010357138, 0.9667264, 0.022916446]]\n",
            "2356            [[0.16250871, 0.6414458, 0.19604552]]\n",
            "2357      [[0.00048496344, 0.0048867357, 0.99462837]]\n",
            "2358       [[0.00015259172, 0.0008178844, 0.9990295]]\n",
            "2359         [[0.0005499044, 0.009811314, 0.9896388]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_raw_know_val_f1_0.7602'\n",
        "pretrained_bert_name = 'indobenchmark/indobert-large-p2'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_raw_know_val_f1_0.7602\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "UYemAJugmwo4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aJGLwkbnUuL"
      },
      "source": [
        "## large state_dict/bert_spc_combined_padanan_trim_val_f1_0.7908"
      ],
      "id": "3aJGLwkbnUuL"
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ta-dictabsa/infer_example.py'\n",
        "with open(path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "lines[255] = f\"    test_infer = pd.read_csv('./datasets/ulasan_combined/k_insert_padanan_trimmed_knowledge/dev.tsv', sep='\\t', usecols=['review', 'aspect'])\\n\"\n",
        "with open(path, 'w') as file:\n",
        "    file.writelines(lines)"
      ],
      "metadata": {
        "id": "PIKxnupHnUub"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PIKxnupHnUub"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "66729ae6-4a42-4340-b13c-bed99cc32d56",
        "id": "YSrTYQnhnUuc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 2.00/2.00 [00:00<00:00, 14.3kB/s]\n",
            "vocab.txt: 100% 229k/229k [00:00<00:00, 17.7MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 840kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.53k/1.53k [00:00<00:00, 9.39MB/s]\n",
            "pytorch_model.bin: 100% 1.34G/1.34G [00:43<00:00, 30.8MB/s]\n",
            "loading model bert_spc ...\n",
            "/content/ta-dictabsa/infer_example.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "0         [[3.5213903e-05, 0.0050324756, 0.99493235]]\n",
            "1            [[0.00016466204, 0.01929201, 0.9805433]]\n",
            "2             [[0.27820912, 0.68967235, 0.032118518]]\n",
            "3              [[0.958447, 0.026585076, 0.014967996]]\n",
            "4              [[0.7051303, 0.21626048, 0.078609236]]\n",
            "5         [[0.00016585329, 0.00024047703, 0.9995937]]\n",
            "6           [[0.0001637569, 0.0061730966, 0.9936632]]\n",
            "7           [[6.817177e-05, 0.0013925488, 0.9985392]]\n",
            "8           [[9.331751e-05, 0.004453902, 0.99545276]]\n",
            "9            [[0.00012689785, 0.005117162, 0.994756]]\n",
            "10             [[0.0011486138, 0.2913301, 0.7075213]]\n",
            "11           [[0.00033843677, 0.09015798, 0.9095037]]\n",
            "12            [[0.0003583283, 0.31924048, 0.6804012]]\n",
            "13         [[0.00010726683, 0.95792854, 0.041964218]]\n",
            "14          [[0.00015590456, 0.105489664, 0.8943545]]\n",
            "15        [[0.0004978092, 0.00024428443, 0.99925786]]\n",
            "16             [[0.6872224, 0.048914727, 0.26386285]]\n",
            "17         [[0.000131339, 0.00054742227, 0.99932134]]\n",
            "18        [[0.00014980581, 0.00054442376, 0.9993057]]\n",
            "19         [[0.00012946615, 0.020483369, 0.97938716]]\n",
            "20          [[0.00020475042, 0.006914339, 0.9928808]]\n",
            "21       [[0.00022332091, 0.00045575565, 0.99932086]]\n",
            "22        [[0.00022454113, 0.00018029177, 0.9995952]]\n",
            "23              [[0.5660139, 0.29490304, 0.13908312]]\n",
            "24           [[8.126205e-05, 0.49275762, 0.50716114]]\n",
            "25            [[7.001282e-05, 0.8403479, 0.15958214]]\n",
            "26       [[0.00024366268, 0.000107011714, 0.9996493]]\n",
            "27       [[0.00016885584, 0.00011905002, 0.99971205]]\n",
            "28         [[9.9347475e-05, 0.002257777, 0.99764293]]\n",
            "29         [[5.4689743e-05, 0.0013512446, 0.9985941]]\n",
            "30           [[0.00022666994, 0.02087655, 0.9788968]]\n",
            "31        [[0.00014464537, 0.00015085068, 0.9997044]]\n",
            "32            [[0.000617818, 0.023289844, 0.9760922]]\n",
            "33         [[0.0003448624, 0.0003392931, 0.99931586]]\n",
            "34           [[0.0006909137, 0.082132824, 0.9171763]]\n",
            "35         [[0.00079425855, 0.0024732556, 0.9967325]]\n",
            "36            [[0.0017806384, 0.6035196, 0.39469972]]\n",
            "37            [[0.6354895, 0.35871372, 0.0057967776]]\n",
            "38            [[0.07731009, 0.024310187, 0.89837974]]\n",
            "39        [[0.00038429504, 0.00028112315, 0.9993345]]\n",
            "40         [[0.00033215273, 0.006100953, 0.99356693]]\n",
            "41          [[0.0004277467, 0.0002875757, 0.9992847]]\n",
            "42          [[0.0005163394, 0.0013917651, 0.9980919]]\n",
            "43          [[5.124757e-05, 0.000347206, 0.99960154]]\n",
            "44           [[0.0005077862, 0.68799233, 0.31149983]]\n",
            "45          [[0.00040032284, 0.91246974, 0.08712989]]\n",
            "46        [[0.00025153504, 0.0015537498, 0.99819475]]\n",
            "47            [[0.0011662955, 0.74111634, 0.2577173]]\n",
            "48          [[0.00014847076, 0.001014289, 0.9988373]]\n",
            "49             [[0.000867494, 0.9243602, 0.07477232]]\n",
            "50         [[4.7274112e-05, 0.0023461522, 0.9976065]]\n",
            "51         [[0.0003069791, 0.0029123412, 0.99678075]]\n",
            "52         [[0.00074910437, 0.041380674, 0.95787024]]\n",
            "53             [[0.0032262085, 0.4607182, 0.5360556]]\n",
            "54            [[0.0010473891, 0.33734334, 0.6616093]]\n",
            "55           [[0.008221661, 0.96966994, 0.022108387]]\n",
            "56              [[0.14380504, 0.36938733, 0.4868077]]\n",
            "57           [[0.005184443, 0.97141504, 0.023400508]]\n",
            "58           [[0.0016254189, 0.024869263, 0.9735054]]\n",
            "59            [[0.0028707415, 0.9228003, 0.07432895]]\n",
            "60       [[0.00078264595, 0.00061258115, 0.99860483]]\n",
            "61          [[0.0002646568, 0.008677634, 0.99105775]]\n",
            "62           [[0.00044200968, 0.015468927, 0.984089]]\n",
            "63         [[0.00016949761, 0.010126481, 0.98970395]]\n",
            "64          [[0.0006405637, 0.0018850364, 0.9974744]]\n",
            "65           [[0.96615535, 0.015040701, 0.018803995]]\n",
            "66         [[0.0007616426, 0.00012915062, 0.9991092]]\n",
            "67             [[0.22696272, 0.7238053, 0.049231958]]\n",
            "68             [[0.06366371, 0.021572968, 0.9147633]]\n",
            "69           [[0.060538802, 0.91485864, 0.024602572]]\n",
            "70            [[0.06612049, 0.9320343, 0.0018452087]]\n",
            "71           [[0.061071225, 0.93238246, 0.006546281]]\n",
            "72        [[0.000116979354, 0.0011320488, 0.9987509]]\n",
            "73           [[7.080356e-05, 0.050808668, 0.9491205]]\n",
            "74           [[0.00022203423, 0.28453153, 0.7152464]]\n",
            "75              [[0.31448668, 0.08470913, 0.6008042]]\n",
            "76            [[0.0015563217, 0.30883208, 0.6896116]]\n",
            "77            [[0.44123256, 0.022410735, 0.53635675]]\n",
            "78        [[0.00058680464, 0.0008871102, 0.99852604]]\n",
            "79         [[0.0003286993, 0.00028485726, 0.9993864]]\n",
            "80          [[0.00012146085, 0.0049134563, 0.994965]]\n",
            "81        [[0.00027361923, 0.0013811189, 0.99834526]]\n",
            "82          [[0.0009860898, 0.0014509893, 0.9975629]]\n",
            "83            [[0.89523184, 0.08234028, 0.022427814]]\n",
            "84          [[0.00026790626, 0.005761046, 0.9939711]]\n",
            "85           [[0.112530306, 0.86311066, 0.024358984]]\n",
            "86             [[0.95807, 0.036085647, 0.0058444226]]\n",
            "87        [[0.00019775172, 0.00019169021, 0.9996105]]\n",
            "88          [[0.0019088924, 0.96816564, 0.029925494]]\n",
            "89          [[0.00060933153, 0.04173889, 0.95765185]]\n",
            "90       [[0.00026505705, 0.00041413147, 0.99932086]]\n",
            "91           [[0.0018818207, 0.9898212, 0.008297022]]\n",
            "92           [[0.0016306057, 0.53292936, 0.46544003]]\n",
            "93             [[0.4269671, 0.097678445, 0.47535452]]\n",
            "94         [[0.0021289168, 0.00092053704, 0.9969505]]\n",
            "95            [[0.005832007, 0.028857209, 0.9653108]]\n",
            "96           [[0.00049324316, 0.25533625, 0.7441705]]\n",
            "97          [[9.234142e-05, 0.000440189, 0.99946743]]\n",
            "98         [[7.357881e-05, 0.0003285504, 0.99959797]]\n",
            "99        [[0.00032238034, 0.00023523445, 0.9994424]]\n",
            "100         [[0.0001703728, 0.0003032191, 0.9995264]]\n",
            "101            [[0.000714721, 0.25434884, 0.7449365]]\n",
            "102       [[0.00027898772, 0.00046027137, 0.9992607]]\n",
            "103         [[0.00016931178, 0.011078945, 0.9887518]]\n",
            "104       [[0.00046530954, 0.0010632266, 0.99847144]]\n",
            "105            [[0.5061544, 0.45511025, 0.038735323]]\n",
            "106           [[0.00020304974, 0.39406496, 0.605732]]\n",
            "107        [[0.00028969796, 0.027462246, 0.97224796]]\n",
            "108      [[0.00019397833, 0.00065838074, 0.99914753]]\n",
            "109        [[5.7292298e-05, 0.0006919024, 0.9992508]]\n",
            "110         [[7.9258396e-05, 0.90520257, 0.09471814]]\n",
            "111        [[0.00010770288, 0.0007350995, 0.9991572]]\n",
            "112          [[0.00036313734, 0.25191668, 0.7477201]]\n",
            "113       [[0.00013076645, 0.00025820744, 0.9996111]]\n",
            "114            [[0.2814822, 0.7126572, 0.0058606123]]\n",
            "115         [[0.0015815846, 0.9969637, 0.0014547441]]\n",
            "116        [[0.00029266137, 0.9983613, 0.0013459836]]\n",
            "117        [[0.000252821, 0.00021105642, 0.99953616]]\n",
            "118          [[0.00047868546, 0.13788372, 0.8616376]]\n",
            "119          [[0.0028868287, 0.66520685, 0.33190632]]\n",
            "120          [[0.0002259224, 0.87017655, 0.12959759]]\n",
            "121           [[0.001380983, 0.04778051, 0.95083857]]\n",
            "122        [[0.00025546015, 0.0018692815, 0.9978752]]\n",
            "123       [[0.0005290159, 0.00056538335, 0.99890554]]\n",
            "124          [[0.0002171971, 0.002215157, 0.9975677]]\n",
            "125        [[0.00021139422, 0.0037106203, 0.9960781]]\n",
            "126            [[9.276889e-05, 0.1274594, 0.8724478]]\n",
            "127           [[0.0005422377, 0.6916304, 0.30782732]]\n",
            "128          [[0.00016195467, 0.25248575, 0.7473523]]\n",
            "129       [[0.00041059617, 0.00031704063, 0.9992724]]\n",
            "130        [[0.00025119848, 0.0030493864, 0.9966994]]\n",
            "131             [[0.7525381, 0.2358827, 0.011579246]]\n",
            "132          [[0.91236436, 0.071769714, 0.015865942]]\n",
            "133           [[0.0005715246, 0.07612886, 0.9232996]]\n",
            "134         [[0.059508257, 0.93809474, 0.0023970476]]\n",
            "135         [[0.0015805376, 0.9921698, 0.0062497114]]\n",
            "136           [[0.0011053889, 0.17098275, 0.8279119]]\n",
            "137       [[0.00031862615, 0.0005701976, 0.99911124]]\n",
            "138         [[0.0005622894, 0.0016964648, 0.9977412]]\n",
            "139         [[0.00024567542, 0.0016652243, 0.998089]]\n",
            "140       [[0.0002613414, 0.00020461867, 0.99953413]]\n",
            "141            [[0.022371678, 0.11119826, 0.8664301]]\n",
            "142             [[0.002261157, 0.8444433, 0.1532955]]\n",
            "143          [[0.00022975811, 0.07716401, 0.9226062]]\n",
            "144            [[0.029229784, 0.10957857, 0.8611917]]\n",
            "145      [[0.00038981705, 0.00019307598, 0.99941707]]\n",
            "146           [[0.002904641, 0.025202366, 0.9718929]]\n",
            "147           [[0.0024231782, 0.7127587, 0.28481805]]\n",
            "148         [[0.015313925, 0.98274463, 0.0019414477]]\n",
            "149         [[0.0001213288, 0.0025068661, 0.9973718]]\n",
            "150       [[0.00062478153, 0.0057401154, 0.99363506]]\n",
            "151           [[0.0025393665, 0.5107164, 0.48674428]]\n",
            "152         [[0.0007131857, 0.0013572512, 0.9979296]]\n",
            "153        [[0.0015427134, 0.9980318, 0.00042553598]]\n",
            "154          [[0.00010514973, 0.04884932, 0.9510456]]\n",
            "155          [[0.00029690436, 0.9176659, 0.08203716]]\n",
            "156          [[0.00039609396, 0.96320033, 0.0364036]]\n",
            "157          [[0.0016387743, 0.9501677, 0.048193455]]\n",
            "158         [[0.0003086257, 0.999574, 0.00011741925]]\n",
            "159        [[0.0010228051, 0.9985629, 0.00041439178]]\n",
            "160          [[0.0019812863, 0.96690345, 0.03111521]]\n",
            "161      [[0.00010546037, 0.00020565341, 0.99968886]]\n",
            "162        [[0.00015179653, 0.0003465722, 0.9995016]]\n",
            "163           [[0.0008254452, 0.14959176, 0.8495828]]\n",
            "164         [[9.334247e-05, 0.0001045094, 0.9998022]]\n",
            "165        [[0.0012379852, 0.0010861809, 0.99767584]]\n",
            "166            [[0.022952745, 0.66475093, 0.3122963]]\n",
            "167       [[0.00029746222, 0.00030627986, 0.9993962]]\n",
            "168          [[0.00045394385, 0.16578948, 0.8337566]]\n",
            "169         [[0.00044585572, 0.06445915, 0.93509495]]\n",
            "170          [[0.0003943997, 0.010626091, 0.9889796]]\n",
            "171         [[0.0002469733, 0.0034537404, 0.9962993]]\n",
            "172        [[7.284198e-05, 0.0041479184, 0.99577916]]\n",
            "173        [[3.1012263e-05, 0.0021663113, 0.9978027]]\n",
            "174         [[3.801397e-05, 0.9974553, 0.0025067197]]\n",
            "175       [[0.00016288075, 0.0003520067, 0.99948514]]\n",
            "176         [[0.00010422634, 0.004007429, 0.9958883]]\n",
            "177       [[0.000105116844, 0.0012744315, 0.9986205]]\n",
            "178         [[0.0006383423, 0.121107124, 0.87825453]]\n",
            "179         [[0.0014232767, 0.063798405, 0.93477833]]\n",
            "180         [[0.98814386, 0.005317907, 0.0065383143]]\n",
            "181       [[0.00032480588, 0.00035110247, 0.9993241]]\n",
            "182          [[0.0001652256, 0.040539637, 0.9592951]]\n",
            "183         [[0.00014853138, 0.026486775, 0.9733647]]\n",
            "184        [[0.00053725444, 0.0003638806, 0.9990989]]\n",
            "185      [[0.00014553413, 0.00036921538, 0.99948525]]\n",
            "186          [[0.0007631584, 0.001600736, 0.9976361]]\n",
            "187        [[0.00021881949, 0.0016126024, 0.9981686]]\n",
            "188       [[0.00024322455, 0.00024394027, 0.9995129]]\n",
            "189           [[9.173364e-05, 0.9677055, 0.03220281]]\n",
            "190        [[9.3076276e-05, 0.98898697, 0.010919951]]\n",
            "191          [[0.0045767855, 0.72249675, 0.27292642]]\n",
            "192         [[0.00054776296, 0.71370834, 0.28574395]]\n",
            "193       [[0.00016806643, 0.00040845337, 0.9994235]]\n",
            "194       [[0.000117770694, 0.0024233938, 0.9974589]]\n",
            "195           [[0.0053080847, 0.07641062, 0.9182813]]\n",
            "196       [[0.00013672774, 0.99581194, 0.0040513664]]\n",
            "197            [[0.0005497869, 0.2668336, 0.7326166]]\n",
            "198           [[0.0018437797, 0.09661817, 0.9015381]]\n",
            "199        [[0.0005861325, 0.0013684343, 0.99804544]]\n",
            "200            [[0.38072202, 0.55989933, 0.05937859]]\n",
            "201             [[0.572697, 0.038770944, 0.38853216]]\n",
            "202       [[0.00029642342, 0.0003675918, 0.99933594]]\n",
            "203             [[0.9100762, 0.05663355, 0.03329022]]\n",
            "204           [[0.0010327738, 0.5596684, 0.43929884]]\n",
            "205           [[0.000535266, 0.0064737494, 0.992991]]\n",
            "206        [[0.00061094435, 0.9926428, 0.0067462763]]\n",
            "207         [[0.0023975598, 0.006149283, 0.99145305]]\n",
            "208         [[0.00084657094, 0.005359338, 0.9937941]]\n",
            "209         [[8.470293e-05, 0.0004210279, 0.9994942]]\n",
            "210        [[0.00012290674, 0.0051656403, 0.9947115]]\n",
            "211        [[0.00016138518, 0.0010648163, 0.9987739]]\n",
            "212        [[0.0006134514, 0.00032013687, 0.9990664]]\n",
            "213          [[0.0008363381, 0.029981611, 0.9691821]]\n",
            "214         [[5.9251965e-05, 0.012818874, 0.9871219]]\n",
            "215          [[0.00010241566, 0.09296634, 0.9069312]]\n",
            "216          [[0.00028525348, 0.08209118, 0.9176235]]\n",
            "217          [[0.00016363437, 0.03532297, 0.9645135]]\n",
            "218       [[9.7763565e-05, 0.0025640745, 0.99733824]]\n",
            "219       [[0.00010470012, 0.0011416288, 0.99875367]]\n",
            "220        [[0.0002663191, 0.0010596864, 0.99867404]]\n",
            "221       [[0.00039664644, 0.00027971392, 0.9993236]]\n",
            "222       [[0.00066982856, 0.0005043009, 0.99882585]]\n",
            "223          [[0.0007759706, 0.9795035, 0.019720504]]\n",
            "224         [[0.0006337467, 0.0007586634, 0.9986076]]\n",
            "225          [[0.0014238065, 0.026356375, 0.9722198]]\n",
            "226           [[0.006205567, 0.95488375, 0.03891062]]\n",
            "227        [[0.00028466084, 0.0060275467, 0.9936878]]\n",
            "228          [[0.00018079742, 0.5356943, 0.46412492]]\n",
            "229        [[0.00019594493, 0.0068659014, 0.9929382]]\n",
            "230          [[0.00028706106, 0.03253815, 0.9671747]]\n",
            "231         [[0.00026339764, 0.004773289, 0.9949633]]\n",
            "232         [[0.00046977127, 0.026950156, 0.9725801]]\n",
            "233        [[0.00017393855, 0.0013342483, 0.9984919]]\n",
            "234            [[0.09017031, 0.8941143, 0.015715415]]\n",
            "235         [[0.0025199545, 0.0015455529, 0.9959345]]\n",
            "236       [[0.00037157294, 0.00022729769, 0.9994011]]\n",
            "237       [[0.00037696303, 0.00069303176, 0.9989299]]\n",
            "238            [[0.8248403, 0.13711575, 0.038043905]]\n",
            "239        [[0.0012366554, 0.00096175267, 0.9978015]]\n",
            "240         [[0.0014685632, 0.0036147796, 0.9949167]]\n",
            "241           [[0.0033909385, 0.17883578, 0.8177733]]\n",
            "242        [[0.00033599196, 0.95658404, 0.043079976]]\n",
            "243          [[0.0033779328, 0.9763901, 0.020231962]]\n",
            "244       [[0.00019585965, 0.0120308455, 0.98777336]]\n",
            "245            [[0.0012884168, 0.824143, 0.17456858]]\n",
            "246         [[0.0043076547, 0.001072417, 0.99461985]]\n",
            "247             [[0.12098891, 0.15897888, 0.7200322]]\n",
            "248       [[0.00040048675, 0.0013609487, 0.99823856]]\n",
            "249      [[0.00022669234, 0.00032194355, 0.99945134]]\n",
            "250        [[0.00027507037, 0.0016524681, 0.9980724]]\n",
            "251         [[0.000354011, 0.00023791655, 0.9994081]]\n",
            "252      [[0.00022599055, 0.00057847286, 0.99919564]]\n",
            "253       [[0.000119630386, 0.0012598195, 0.9986205]]\n",
            "254         [[0.00025964077, 0.023588326, 0.9761521]]\n",
            "255        [[0.00034134806, 0.027121043, 0.97253764]]\n",
            "256           [[0.0005873075, 0.5642254, 0.43518734]]\n",
            "257      [[0.00021618578, 0.00036559821, 0.99941814]]\n",
            "258       [[0.00015095298, 0.0005032229, 0.99934584]]\n",
            "259        [[0.00011442356, 0.94323367, 0.056651894]]\n",
            "260       [[0.00032616116, 0.9994929, 0.00018092264]]\n",
            "261          [[0.00037430914, 0.43470222, 0.5649235]]\n",
            "262          [[0.00017390534, 0.32609868, 0.6737274]]\n",
            "263            [[0.36305916, 0.5695203, 0.067420535]]\n",
            "264           [[0.9130115, 0.042821124, 0.044167355]]\n",
            "265          [[0.0048027616, 0.15511268, 0.84008455]]\n",
            "266            [[0.0022897355, 0.683965, 0.31374526]]\n",
            "267            [[0.13334404, 0.012075128, 0.8545808]]\n",
            "268            [[0.13334404, 0.012075128, 0.8545808]]\n",
            "269          [[0.0029340847, 0.0022829385, 0.994783]]\n",
            "270          [[0.011214828, 0.0010463663, 0.9877387]]\n",
            "271            [[0.7359826, 0.21515132, 0.048866093]]\n",
            "272        [[0.00084024755, 0.010092837, 0.98906696]]\n",
            "273       [[8.2482526e-05, 0.0007806293, 0.99913687]]\n",
            "274       [[0.00013780067, 0.0005852023, 0.99927694]]\n",
            "275         [[9.092976e-05, 0.0062446552, 0.9936644]]\n",
            "276          [[0.00011449423, 0.32899514, 0.6708904]]\n",
            "277       [[4.4306053e-05, 0.0008374338, 0.99911827]]\n",
            "278       [[0.0003491727, 0.00070711353, 0.99894375]]\n",
            "279        [[8.0269565e-05, 0.0051004854, 0.9948192]]\n",
            "280        [[0.00012746328, 0.0005288199, 0.9993437]]\n",
            "281          [[0.00015950107, 0.04244013, 0.9574004]]\n",
            "282       [[0.00026508557, 0.00027212084, 0.9994628]]\n",
            "283          [[0.00017768776, 0.47095123, 0.5288711]]\n",
            "284        [[0.00030462473, 0.025148494, 0.97454685]]\n",
            "285          [[5.333301e-05, 0.99734074, 0.00260596]]\n",
            "286          [[0.00022827994, 0.8565677, 0.14320402]]\n",
            "287         [[9.498099e-05, 0.0011637419, 0.9987413]]\n",
            "288             [[0.003280817, 0.0956445, 0.9010747]]\n",
            "289       [[0.00017072725, 0.00030277125, 0.9995265]]\n",
            "290             [[0.003280817, 0.0956445, 0.9010747]]\n",
            "291         [[9.517344e-05, 7.457899e-05, 0.9998301]]\n",
            "292          [[0.00016452537, 0.09023169, 0.9096038]]\n",
            "293        [[0.00013531717, 0.0017033872, 0.9981614]]\n",
            "294       [[0.00013893933, 0.0072349566, 0.99262613]]\n",
            "295         [[0.00013887997, 0.17216992, 0.82769114]]\n",
            "296           [[0.00011497343, 0.8422328, 0.1576522]]\n",
            "297           [[7.425732e-05, 0.9778421, 0.02208361]]\n",
            "298        [[0.00020487755, 0.98601043, 0.013784672]]\n",
            "299        [[0.0006509041, 0.0012884609, 0.99806064]]\n",
            "300        [[0.00062397635, 0.0016658136, 0.9977102]]\n",
            "301            [[0.0005891547, 0.8399719, 0.1594389]]\n",
            "302          [[0.00083736377, 0.9794327, 0.01972998]]\n",
            "303         [[0.00015582204, 0.9936878, 0.006156414]]\n",
            "304        [[0.00028694666, 0.0014648375, 0.9982482]]\n",
            "305            [[0.0002815357, 0.5807971, 0.4189214]]\n",
            "306       [[0.000104853934, 0.0043562595, 0.9955388]]\n",
            "307         [[7.408391e-05, 0.007076675, 0.99284923]]\n",
            "308          [[0.0011171632, 0.70087636, 0.29800653]]\n",
            "309        [[0.00063290814, 0.057542212, 0.94182485]]\n",
            "310       [[0.00050593866, 0.00037238328, 0.9991216]]\n",
            "311        [[0.0003704023, 0.00032274637, 0.9993069]]\n",
            "312            [[0.0011285129, 0.7550313, 0.2438402]]\n",
            "313            [[0.0026397638, 0.1605497, 0.8368105]]\n",
            "314       [[9.5618845e-05, 0.0038432095, 0.99606115]]\n",
            "315            [[0.0009842487, 0.169491, 0.82952476]]\n",
            "316       [[0.00016754515, 0.0018635748, 0.99796885]]\n",
            "317         [[6.149192e-05, 0.0021839554, 0.9977545]]\n",
            "318        [[2.4815594e-05, 0.002267163, 0.99770796]]\n",
            "319           [[0.0015032481, 0.9344244, 0.06407235]]\n",
            "320          [[0.00036660433, 0.2946123, 0.70502114]]\n",
            "321           [[0.0005568852, 0.4532248, 0.54621834]]\n",
            "322       [[0.00012293419, 0.00010590941, 0.9997712]]\n",
            "323         [[0.0002066822, 0.00018041949, 0.999613]]\n",
            "324            [[0.02962882, 0.10940228, 0.86096895]]\n",
            "325       [[0.00019641516, 0.00080611475, 0.9989975]]\n",
            "326           [[0.002854473, 0.013816835, 0.9833287]]\n",
            "327        [[0.00019880425, 0.0001943546, 0.9996069]]\n",
            "328            [[0.9162513, 0.07303166, 0.010717028]]\n",
            "329              [[0.20429164, 0.10591936, 0.689789]]\n",
            "330               [[0.4665018, 0.5142374, 0.0192608]]\n",
            "331            [[0.004412031, 0.27225634, 0.7233316]]\n",
            "332         [[0.0034428143, 0.023498159, 0.97305906]]\n",
            "333      [[0.00017819885, 0.00023770216, 0.99958414]]\n",
            "334         [[0.058922093, 0.93953204, 0.0015458129]]\n",
            "335           [[0.0004784757, 0.8228977, 0.17662384]]\n",
            "336           [[0.14179194, 0.83562624, 0.022581842]]\n",
            "337         [[0.0024872741, 0.0014181214, 0.9960945]]\n",
            "338       [[0.0001841576, 0.00040267585, 0.99941313]]\n",
            "339             [[0.5239077, 0.08463864, 0.39145362]]\n",
            "340          [[0.49798393, 0.49700534, 0.0050107376]]\n",
            "341       [[0.00023566057, 0.00020786423, 0.9995565]]\n",
            "342           [[7.0693e-05, 0.0007736988, 0.9991555]]\n",
            "343        [[2.4631767e-05, 0.0012902308, 0.9986852]]\n",
            "344         [[0.010033435, 0.0015644684, 0.98840207]]\n",
            "345        [[0.00069049175, 0.0016859521, 0.9976236]]\n",
            "346          [[0.0010732489, 0.009094444, 0.9898323]]\n",
            "347               [[0.9567, 0.012049924, 0.03125004]]\n",
            "348      [[0.00022608123, 0.00017541274, 0.99959856]]\n",
            "349         [[9.109565e-05, 0.0007736864, 0.9991352]]\n",
            "350            [[0.39868492, 0.32933524, 0.27197984]]\n",
            "351           [[0.9805879, 0.01383361, 0.0055784388]]\n",
            "352          [[0.0005950216, 0.011066341, 0.9883387]]\n",
            "353        [[0.00022870077, 0.026406247, 0.97336507]]\n",
            "354         [[0.0006123336, 0.0015119709, 0.9978757]]\n",
            "355       [[0.00077225774, 0.00037448868, 0.9988532]]\n",
            "356          [[0.0004640308, 0.016373482, 0.9831625]]\n",
            "357          [[0.0026011406, 0.22125445, 0.77614444]]\n",
            "358         [[0.0056765913, 0.115803845, 0.87851965]]\n",
            "359         [[0.0011642505, 0.095715955, 0.90311974]]\n",
            "360              [[0.10609997, 0.5741848, 0.3197152]]\n",
            "361          [[0.0015932301, 0.9688802, 0.029526602]]\n",
            "362           [[0.0008274591, 0.8491707, 0.15000187]]\n",
            "363        [[0.00035684992, 0.0016210084, 0.9980222]]\n",
            "364          [[0.00018206719, 0.7860932, 0.21372473]]\n",
            "365        [[6.707045e-05, 0.9998778, 5.5129723e-05]]\n",
            "366         [[2.909576e-05, 0.9999299, 4.103453e-05]]\n",
            "367          [[0.0003898191, 0.03096371, 0.96864647]]\n",
            "368         [[0.00065527187, 0.31451797, 0.68482673]]\n",
            "369      [[0.00017716968, 0.00040415625, 0.99941874]]\n",
            "370         [[0.0002418898, 0.019677771, 0.98008037]]\n",
            "371        [[0.00035478198, 0.014906817, 0.98473847]]\n",
            "372          [[0.0002758892, 0.045129195, 0.9545949]]\n",
            "373        [[0.00027616604, 0.0004653161, 0.9992586]]\n",
            "374          [[0.0001405122, 0.008837909, 0.9910217]]\n",
            "375        [[8.713966e-05, 8.326233e-05, 0.99982953]]\n",
            "376        [[0.0003950393, 0.0009887144, 0.99861634]]\n",
            "377          [[0.005189719, 0.0033954626, 0.9914147]]\n",
            "378           [[0.0015746786, 0.7267705, 0.27165478]]\n",
            "379         [[0.00057912356, 0.28423458, 0.71518624]]\n",
            "380          [[0.0003779815, 0.90765154, 0.09197052]]\n",
            "381        [[0.0004079868, 0.0011734912, 0.99841845]]\n",
            "382             [[0.2544577, 0.60361785, 0.14192446]]\n",
            "383        [[0.00031040693, 0.0032645138, 0.9964251]]\n",
            "384          [[0.003474419, 0.9926852, 0.0038403717]]\n",
            "385            [[0.06462949, 0.9220894, 0.013281063]]\n",
            "386        [[0.00015115623, 0.00020094965, 0.999648]]\n",
            "387           [[0.0002477227, 0.45445794, 0.5452944]]\n",
            "388       [[0.00015900965, 0.0014712197, 0.99836975]]\n",
            "389       [[0.00012352275, 0.0077879434, 0.99208856]]\n",
            "390          [[0.0002780922, 0.002027879, 0.9976941]]\n",
            "391        [[6.597665e-05, 0.00016890684, 0.9997651]]\n",
            "392        [[0.00019223009, 0.0034123776, 0.9963954]]\n",
            "393      [[0.00016876373, 0.00064358255, 0.99918765]]\n",
            "394       [[0.00081549125, 0.0031047014, 0.99607974]]\n",
            "395          [[0.0001476705, 0.9948795, 0.004972863]]\n",
            "396         [[0.00095992244, 0.9648838, 0.034156263]]\n",
            "397         [[0.0006668275, 0.95245516, 0.046877973]]\n",
            "398        [[0.00016778913, 0.022186473, 0.97764575]]\n",
            "399        [[0.00016111443, 0.0017017197, 0.9981371]]\n",
            "400         [[0.00012696454, 0.97463226, 0.02524077]]\n",
            "401           [[0.00052710064, 0.7054997, 0.2939732]]\n",
            "402          [[0.00047240185, 0.4240438, 0.57548386]]\n",
            "403          [[0.00019149325, 0.2122335, 0.78757495]]\n",
            "404         [[0.00010159682, 0.9748302, 0.025068177]]\n",
            "405         [[5.845881e-05, 0.99468166, 0.005259861]]\n",
            "406        [[2.3089897e-05, 0.9985663, 0.0014105871]]\n",
            "407        [[0.00056479423, 0.97844213, 0.020993121]]\n",
            "408          [[0.00035877727, 0.9351668, 0.06447443]]\n",
            "409           [[0.0005825778, 0.03923898, 0.9601784]]\n",
            "410           [[0.0033899888, 0.07331572, 0.9232943]]\n",
            "411           [[0.010729548, 0.14128426, 0.84798616]]\n",
            "412           [[0.0011343576, 0.3998522, 0.59901345]]\n",
            "413         [[0.0016108587, 0.96429646, 0.034092627]]\n",
            "414          [[0.00080184464, 0.9816722, 0.01752591]]\n",
            "415           [[0.9806771, 0.014445295, 0.004877519]]\n",
            "416       [[0.00016707381, 0.0006002432, 0.99923265]]\n",
            "417              [[0.33318728, 0.13226376, 0.534549]]\n",
            "418          [[0.0006170663, 0.002642734, 0.9967403]]\n",
            "419          [[0.0005709601, 0.027805923, 0.9716232]]\n",
            "420         [[0.0002170812, 0.0010727004, 0.9987103]]\n",
            "421       [[0.00019361023, 0.0016976872, 0.99810874]]\n",
            "422           [[0.0005579374, 0.45114687, 0.5482952]]\n",
            "423          [[0.0007958276, 0.021819055, 0.9773852]]\n",
            "424        [[0.00011673095, 0.0018465539, 0.9980368]]\n",
            "425           [[0.81709653, 0.031228632, 0.15167487]]\n",
            "426        [[0.0018858847, 0.0009975601, 0.99711657]]\n",
            "427        [[0.00010529441, 0.0007275507, 0.9991672]]\n",
            "428            [[0.000646478, 0.4897368, 0.50961673]]\n",
            "429        [[0.00086741266, 0.0007414645, 0.9983911]]\n",
            "430      [[0.00014158142, 0.00020259242, 0.99965584]]\n",
            "431        [[0.00010490847, 0.0027796284, 0.9971154]]\n",
            "432       [[0.00027838777, 0.00042411024, 0.9992975]]\n",
            "433       [[0.00029571337, 0.00032238112, 0.9993819]]\n",
            "434           [[0.021788035, 0.009077108, 0.9691349]]\n",
            "435         [[0.00086738693, 0.9834394, 0.015693255]]\n",
            "436      [[0.000100407975, 0.00088013115, 0.9990195]]\n",
            "437        [[7.852739e-05, 0.00019477648, 0.9997267]]\n",
            "438        [[0.00010379607, 0.0005961022, 0.9993001]]\n",
            "439         [[0.00017704006, 0.78313756, 0.21668537]]\n",
            "440        [[0.00016601506, 0.9895371, 0.0102968905]]\n",
            "441       [[0.00013111733, 0.0062430757, 0.99362576]]\n",
            "442           [[0.0004261968, 0.6952338, 0.30433995]]\n",
            "443        [[4.5387755e-05, 0.0016023787, 0.9983523]]\n",
            "444         [[0.00018564957, 0.09122937, 0.90858495]]\n",
            "445        [[0.00021083571, 0.0030326715, 0.9967565]]\n",
            "446         [[0.0001681618, 0.0014325371, 0.9983993]]\n",
            "447       [[5.1852043e-05, 0.00053940254, 0.9994087]]\n",
            "448          [[0.00019816488, 0.027788932, 0.972013]]\n",
            "449       [[0.00013605524, 0.9998056, 5.8277994e-05]]\n",
            "450       [[7.8771765e-05, 0.9993094, 0.00061175344]]\n",
            "451           [[0.0005407316, 0.6563652, 0.34309405]]\n",
            "452           [[0.0009957061, 0.73263955, 0.2663647]]\n",
            "453            [[0.023323108, 0.8873781, 0.08929881]]\n",
            "454         [[0.00025366424, 0.68253016, 0.31721613]]\n",
            "455          [[0.00044741572, 0.20204395, 0.7975086]]\n",
            "456      [[0.00018038315, 0.00012388748, 0.99969566]]\n",
            "457            [[0.000632613, 0.02855559, 0.9708118]]\n",
            "458      [[0.00028000944, 0.00030856518, 0.99941146]]\n",
            "459       [[0.00012044425, 0.000107538865, 0.999772]]\n",
            "460        [[0.00012523112, 0.000499048, 0.99937576]]\n",
            "461         [[0.00016629268, 0.0006087016, 0.999225]]\n",
            "462          [[0.00044633672, 0.47211224, 0.5274414]]\n",
            "463       [[0.00013928997, 0.00019316084, 0.9996675]]\n",
            "464        [[0.00023444014, 0.0061646975, 0.9936009]]\n",
            "465       [[0.00019801271, 0.0003736719, 0.99942833]]\n",
            "466            [[0.0003361519, 0.531525, 0.46813884]]\n",
            "467      [[0.00028347704, 0.00059599505, 0.99912053]]\n",
            "468             [[0.5204146, 0.32467017, 0.15491515]]\n",
            "469         [[0.00023656803, 0.021127017, 0.9786364]]\n",
            "470         [[0.00021353297, 0.008958451, 0.9908279]]\n",
            "471              [[0.2257135, 0.04280997, 0.7314765]]\n",
            "472        [[2.8755372e-05, 0.003147594, 0.99682367]]\n",
            "473              [[0.2257135, 0.04280997, 0.7314765]]\n",
            "474         [[2.8173688e-05, 0.014811073, 0.9851607]]\n",
            "475            [[6.83701e-05, 0.3159409, 0.68399066]]\n",
            "476       [[2.6179163e-05, 0.00035532578, 0.9996184]]\n",
            "477        [[0.00015646298, 0.003985864, 0.99585766]]\n",
            "478         [[0.0006634283, 0.011746725, 0.98758984]]\n",
            "479         [[0.0003432776, 0.0011704031, 0.9984863]]\n",
            "480           [[0.00018258586, 0.147169, 0.85264844]]\n",
            "481       [[0.00014018973, 0.0029041462, 0.99695563]]\n",
            "482        [[8.2728206e-05, 0.049501438, 0.95041585]]\n",
            "483         [[3.3045828e-05, 0.000995281, 0.9989717]]\n",
            "484       [[2.5397288e-05, 0.0013625341, 0.99861205]]\n",
            "485        [[0.00034897303, 0.0007242408, 0.9989267]]\n",
            "486           [[0.00022384078, 0.3729034, 0.6268727]]\n",
            "487           [[0.0001294991, 0.8721015, 0.12776901]]\n",
            "488           [[0.00025398892, 0.4407369, 0.5590092]]\n",
            "489         [[0.0001802339, 0.050158836, 0.94966096]]\n",
            "490        [[0.00030803925, 0.0019811736, 0.9977108]]\n",
            "491       [[0.00015117583, 0.00019994107, 0.9996488]]\n",
            "492       [[0.00020044479, 0.00018294793, 0.9996166]]\n",
            "493        [[0.00026420262, 0.0011196473, 0.9986162]]\n",
            "494        [[7.327189e-05, 0.00087788654, 0.9990489]]\n",
            "495         [[9.456366e-05, 0.017260736, 0.98264474]]\n",
            "496            [[0.001283279, 0.00285528, 0.9958615]]\n",
            "497           [[0.9722178, 0.018980844, 0.008801325]]\n",
            "498       [[0.0002241905, 0.00014233586, 0.99963355]]\n",
            "499          [[0.0025808725, 0.014263055, 0.9831561]]\n",
            "500       [[0.00039312665, 0.00022946396, 0.9993774]]\n",
            "501        [[0.00082404347, 0.0012417104, 0.9979342]]\n",
            "502         [[0.0003298365, 0.014350043, 0.98532015]]\n",
            "503          [[0.0030318513, 0.017970234, 0.9789979]]\n",
            "504      [[0.00010009931, 0.00062166766, 0.99927825]]\n",
            "505         [[0.0002619853, 0.97861755, 0.021120442]]\n",
            "506          [[0.00030561732, 0.07565588, 0.9240386]]\n",
            "507             [[4.93894e-05, 0.991876, 0.00807453]]\n",
            "508         [[0.00010498643, 0.9688163, 0.031078758]]\n",
            "509      [[0.00015339999, 0.00032491723, 0.99952173]]\n",
            "510       [[8.6584165e-05, 0.0013892119, 0.99852425]]\n",
            "511         [[8.188252e-05, 0.0001298695, 0.9997882]]\n",
            "512          [[6.40097e-05, 0.0003392851, 0.9995968]]\n",
            "513       [[8.016196e-05, 0.00016875342, 0.99975103]]\n",
            "514      [[0.00016505187, 8.7053726e-05, 0.99974793]]\n",
            "515         [[0.0002455536, 0.0026255315, 0.9971289]]\n",
            "516        [[0.00015641874, 0.0010885127, 0.9987551]]\n",
            "517          [[0.0005216632, 0.09817105, 0.90130734]]\n",
            "518           [[0.0010933649, 0.8952028, 0.10370379]]\n",
            "519         [[0.00026947365, 0.037552048, 0.9621785]]\n",
            "520         [[0.00026549882, 0.08023642, 0.91949815]]\n",
            "521        [[0.00013742555, 0.005980554, 0.99388206]]\n",
            "522         [[0.0001759911, 0.0008805583, 0.9989435]]\n",
            "523         [[9.600855e-05, 0.00020089041, 0.999703]]\n",
            "524       [[0.00076428056, 0.0041199424, 0.99511576]]\n",
            "525            [[0.0006164701, 0.0061338, 0.9932498]]\n",
            "526          [[0.0001954931, 0.003833032, 0.9959714]]\n",
            "527         [[0.0002539718, 0.0015614887, 0.9981845]]\n",
            "528       [[0.00015535022, 0.00034303355, 0.9995016]]\n",
            "529        [[0.00017983941, 0.025422594, 0.97439754]]\n",
            "530           [[0.00868682, 0.051973987, 0.93933916]]\n",
            "531        [[0.0017783219, 0.0020770815, 0.99614465]]\n",
            "532         [[0.0005094188, 0.0031060586, 0.9963845]]\n",
            "533      [[0.00020799585, 0.00044912138, 0.99934286]]\n",
            "534           [[0.0004051215, 0.9162993, 0.08329556]]\n",
            "535          [[0.00092188764, 0.9496728, 0.04940526]]\n",
            "536         [[0.0012808229, 0.92063016, 0.078088984]]\n",
            "537        [[0.00029094855, 0.0014399106, 0.9982691]]\n",
            "538         [[0.91706777, 0.079316325, 0.0036158126]]\n",
            "539          [[0.0061287098, 0.9428411, 0.051030204]]\n",
            "540            [[0.56531185, 0.40352628, 0.03116186]]\n",
            "541            [[0.5662043, 0.4327999, 0.0009957519]]\n",
            "542           [[0.0016507608, 0.7958458, 0.20250346]]\n",
            "543       [[0.00012933581, 0.0031042993, 0.99676645]]\n",
            "544       [[4.8790007e-05, 0.0015966991, 0.99835455]]\n",
            "545       [[5.756192e-05, 0.00026175365, 0.99968076]]\n",
            "546            [[0.0002471398, 0.5003778, 0.4993751]]\n",
            "547           [[0.0041886847, 0.00260598, 0.9932053]]\n",
            "548      [[0.00027360336, 0.00039221073, 0.99933416]]\n",
            "549         [[0.00057355495, 0.001268587, 0.9981579]]\n",
            "550          [[0.9809207, 0.0036146569, 0.015464622]]\n",
            "551           [[0.000907986, 0.68599695, 0.31309506]]\n",
            "552          [[0.00016932336, 0.8763638, 0.12346686]]\n",
            "553          [[0.0008337598, 0.08109186, 0.91807437]]\n",
            "554         [[0.00049963937, 0.22809775, 0.77140266]]\n",
            "555           [[0.00012990383, 0.41198805, 0.587882]]\n",
            "556        [[9.999031e-05, 0.00062689773, 0.9992731]]\n",
            "557       [[0.00014004108, 0.0005829311, 0.99927694]]\n",
            "558          [[0.00057771715, 0.0008122854, 0.99861]]\n",
            "559         [[0.00052907114, 0.17989388, 0.81957704]]\n",
            "560           [[7.530999e-05, 0.019282695, 0.980642]]\n",
            "561        [[2.5761965e-05, 0.005929432, 0.99404484]]\n",
            "562        [[0.00013940489, 0.019844586, 0.98001605]]\n",
            "563         [[2.0262087e-05, 0.004548976, 0.9954307]]\n",
            "564       [[0.00011999276, 0.0050375643, 0.99484247]]\n",
            "565           [[7.480501e-05, 0.02509485, 0.9748303]]\n",
            "566         [[0.00032146682, 0.13723595, 0.86244255]]\n",
            "567          [[0.0001839528, 0.010874756, 0.9889414]]\n",
            "568         [[3.5626457e-05, 0.03944146, 0.96052295]]\n",
            "569        [[0.00014999464, 0.0060908054, 0.9937593]]\n",
            "570         [[0.00026237554, 0.002244994, 0.9974927]]\n",
            "571            [[0.0002907044, 0.16634132, 0.833368]]\n",
            "572        [[0.00012299183, 0.0035015198, 0.9963755]]\n",
            "573        [[6.0676703e-05, 0.005143533, 0.99479574]]\n",
            "574           [[0.0006015694, 0.014935485, 0.984463]]\n",
            "575        [[0.00018837176, 0.024066858, 0.97574484]]\n",
            "576          [[0.0003033342, 0.16254283, 0.83715373]]\n",
            "577          [[0.00034273253, 0.1401603, 0.85949695]]\n",
            "578            [[0.9255813, 0.03271736, 0.041701317]]\n",
            "579         [[0.000650705, 0.0006923549, 0.99865687]]\n",
            "580         [[0.9895214, 0.0076367576, 0.0028419045]]\n",
            "581              [[0.1353695, 0.5462534, 0.31837714]]\n",
            "582         [[0.00019221661, 0.001978866, 0.9978289]]\n",
            "583       [[6.3263935e-05, 0.00019842313, 0.9997383]]\n",
            "584            [[0.014488516, 0.8170792, 0.16843228]]\n",
            "585        [[7.6917815e-05, 0.0034410881, 0.9964819]]\n",
            "586           [[0.33463997, 0.65894085, 0.006419259]]\n",
            "587        [[0.0007728534, 0.0028799125, 0.99634725]]\n",
            "588            [[0.03369739, 0.9465676, 0.019734982]]\n",
            "589            [[0.04726264, 0.9307813, 0.021955999]]\n",
            "590          [[0.0006527947, 0.002898308, 0.9964489]]\n",
            "591        [[0.0004049241, 0.0014187284, 0.99817634]]\n",
            "592         [[0.0014274258, 0.0004060992, 0.9981665]]\n",
            "593         [[0.019331064, 0.0013208431, 0.97934806]]\n",
            "594        [[0.00037084127, 0.0004314515, 0.9991978]]\n",
            "595          [[0.00064496644, 0.78856015, 0.2107949]]\n",
            "596         [[0.0057053226, 0.0008493418, 0.9934454]]\n",
            "597        [[0.00042305642, 0.0003296546, 0.9992473]]\n",
            "598       [[0.0002919182, 0.00030282926, 0.99940526]]\n",
            "599         [[0.00026285453, 0.055967957, 0.9437692]]\n",
            "600        [[0.0001241358, 0.0006838482, 0.99919206]]\n",
            "601          [[0.0036711006, 0.04656839, 0.94976056]]\n",
            "602        [[0.0001805009, 0.0014394404, 0.99838006]]\n",
            "603      [[0.00010996586, 0.00040237655, 0.99948764]]\n",
            "604           [[0.048227634, 0.08096998, 0.87080246]]\n",
            "605         [[0.00061878125, 0.13055052, 0.86883074]]\n",
            "606            [[0.001049218, 0.3307695, 0.66818124]]\n",
            "607         [[0.0007100918, 0.0021334928, 0.9971564]]\n",
            "608        [[0.00012900216, 0.0005075157, 0.9993635]]\n",
            "609           [[0.0054752403, 0.0410109, 0.95351386]]\n",
            "610       [[0.00030539467, 0.0007195097, 0.99897516]]\n",
            "611       [[0.00016437151, 0.0011199183, 0.99871564]]\n",
            "612           [[0.005213229, 0.009254921, 0.9855318]]\n",
            "613       [[0.00021944047, 0.00074010366, 0.9990404]]\n",
            "614            [[0.001570805, 0.37853196, 0.6198972]]\n",
            "615            [[0.76542133, 0.12245096, 0.11212775]]\n",
            "616            [[0.18725772, 0.046080478, 0.7666618]]\n",
            "617            [[0.124861345, 0.05891015, 0.8162285]]\n",
            "618          [[0.0004302955, 0.0013437595, 0.998226]]\n",
            "619         [[0.00011654519, 0.93587947, 0.06400392]]\n",
            "620         [[0.00041276743, 0.89486456, 0.10472263]]\n",
            "621       [[1.8159804e-05, 0.99860173, 0.0013801635]]\n",
            "622           [[0.00059958966, 0.5297627, 0.4696377]]\n",
            "623          [[0.00012222528, 0.944273, 0.055604782]]\n",
            "624         [[0.00029696026, 0.995933, 0.0037700112]]\n",
            "625        [[0.000120825694, 0.9895837, 0.010295494]]\n",
            "626         [[0.0001017164, 0.0022405253, 0.9976578]]\n",
            "627         [[0.0026803748, 0.94754976, 0.049769804]]\n",
            "628         [[0.00042639408, 0.29270133, 0.70687234]]\n",
            "629      [[0.000108522836, 0.99629575, 0.0035957182]]\n",
            "630       [[3.4191467e-05, 0.0017851307, 0.99818075]]\n",
            "631          [[0.00012546421, 0.0053545847, 0.99452]]\n",
            "632        [[5.737797e-05, 0.00036228163, 0.9995803]]\n",
            "633      [[0.00010985141, 0.00036143317, 0.99952877]]\n",
            "634      [[3.7577458e-05, 0.000113287155, 0.9998492]]\n",
            "635        [[0.0003679834, 0.00023570642, 0.9993963]]\n",
            "636        [[0.00011327989, 9.120342e-05, 0.9997956]]\n",
            "637           [[0.0052702436, 0.15020509, 0.8445247]]\n",
            "638          [[0.96465135, 0.007424014, 0.027924705]]\n",
            "639          [[0.9862825, 0.0022585671, 0.011458915]]\n",
            "640        [[0.0002161261, 0.00060842535, 0.9991755]]\n",
            "641      [[0.00029224152, 0.99947745, 0.00023031041]]\n",
            "642          [[0.0077046817, 0.005455432, 0.9868399]]\n",
            "643         [[9.910878e-05, 0.0003518018, 0.9995491]]\n",
            "644        [[0.00015511573, 0.002004198, 0.99784064]]\n",
            "645        [[0.00015863117, 0.0023698395, 0.9974716]]\n",
            "646         [[0.00017127076, 0.26408896, 0.73573977]]\n",
            "647         [[0.0002454447, 0.020087011, 0.97966754]]\n",
            "648         [[0.00080742815, 0.63292325, 0.36626935]]\n",
            "649           [[0.00038826634, 0.5468738, 0.4527379]]\n",
            "650             [[0.000790125, 0.25330088, 0.745909]]\n",
            "651          [[0.0010621167, 0.014987505, 0.9839504]]\n",
            "652            [[0.8370219, 0.16009994, 0.002878215]]\n",
            "653           [[0.92834365, 0.05597067, 0.015685631]]\n",
            "654        [[0.00016837691, 0.0013109313, 0.9985207]]\n",
            "655         [[0.0002270991, 0.0005933744, 0.9991794]]\n",
            "656            [[0.006786412, 0.42093834, 0.5722752]]\n",
            "657         [[0.000200388, 0.0019059931, 0.99789363]]\n",
            "658       [[0.00034508057, 0.00090308225, 0.9987519]]\n",
            "659          [[0.00071372057, 0.16440542, 0.8348808]]\n",
            "660            [[0.000162348, 0.34647086, 0.6533668]]\n",
            "661         [[8.743843e-05, 0.020049589, 0.97986287]]\n",
            "662        [[0.00017195723, 0.007088875, 0.99273914]]\n",
            "663        [[0.00017080817, 0.0061252145, 0.9937039]]\n",
            "664        [[0.00015050401, 0.0010318205, 0.9988176]]\n",
            "665           [[8.31182e-05, 0.011415012, 0.9885019]]\n",
            "666         [[0.00016085982, 0.02629408, 0.97354513]]\n",
            "667           [[0.0006474278, 0.75402164, 0.2453309]]\n",
            "668         [[0.00044463525, 0.022589274, 0.9769661]]\n",
            "669            [[0.003591657, 0.43218976, 0.5642186]]\n",
            "670          [[0.00046756314, 0.07761063, 0.9219219]]\n",
            "671      [[0.00010925151, 0.00045548126, 0.99943525]]\n",
            "672          [[0.00073017704, 0.17717472, 0.8220951]]\n",
            "673            [[0.001741784, 0.8763132, 0.12194497]]\n",
            "674           [[0.00015329702, 0.7624888, 0.2373579]]\n",
            "675           [[0.09122262, 0.004381407, 0.90439594]]\n",
            "676             [[0.5529359, 0.27720323, 0.16986085]]\n",
            "677          [[0.027077602, 0.96268666, 0.010235712]]\n",
            "678         [[0.0031541078, 0.99064296, 0.006202889]]\n",
            "679           [[0.008019749, 0.9867482, 0.005232046]]\n",
            "680           [[0.020192727, 0.9552908, 0.024516482]]\n",
            "681         [[0.94427377, 0.0072020395, 0.048524283]]\n",
            "682             [[0.6074071, 0.09387835, 0.29871452]]\n",
            "683          [[0.10564913, 0.88347393, 0.0108769145]]\n",
            "684           [[0.083711825, 0.24460272, 0.67168546]]\n",
            "685        [[0.0014155972, 0.00040207143, 0.9981823]]\n",
            "686          [[0.00022180635, 0.18718477, 0.8125934]]\n",
            "687          [[0.00055170915, 0.6936062, 0.30584207]]\n",
            "688           [[9.486411e-05, 0.9584934, 0.04141169]]\n",
            "689           [[0.91392004, 0.010011407, 0.07606856]]\n",
            "690       [[0.0008015845, 0.00043324404, 0.99876523]]\n",
            "691       [[0.00018660577, 0.0032034032, 0.99660987]]\n",
            "692         [[0.000109334746, 0.9072973, 0.09259329]]\n",
            "693           [[0.00024222433, 0.19737682, 0.802381]]\n",
            "694         [[0.00022750387, 0.029376136, 0.9703963]]\n",
            "695          [[0.0008218375, 0.9869573, 0.012220838]]\n",
            "696           [[0.0006757428, 0.5314947, 0.46782956]]\n",
            "697        [[0.00040616255, 0.0007348758, 0.9988589]]\n",
            "698         [[0.0002949881, 0.0052650166, 0.9944401]]\n",
            "699       [[0.00017713825, 0.00023530317, 0.9995875]]\n",
            "700       [[0.00023210545, 0.0031944863, 0.99657345]]\n",
            "701       [[8.3732775e-05, 0.0015338676, 0.99838233]]\n",
            "702         [[6.495642e-05, 0.0008004881, 0.9991346]]\n",
            "703       [[0.000115797244, 0.0010675758, 0.9988166]]\n",
            "704           [[0.00016384975, 0.03812114, 0.961715]]\n",
            "705         [[0.00017439068, 0.0032316172, 0.996594]]\n",
            "706           [[0.0020330194, 0.35134152, 0.6466255]]\n",
            "707         [[0.0001330853, 0.99353725, 0.006329687]]\n",
            "708         [[0.00016952821, 0.16848943, 0.83134097]]\n",
            "709        [[0.00015004278, 0.061574027, 0.93827605]]\n",
            "710           [[0.0011760469, 0.20118305, 0.7976409]]\n",
            "711        [[0.00018729853, 0.9842258, 0.0155868055]]\n",
            "712        [[0.00023852744, 0.9964797, 0.0032818504]]\n",
            "713           [[0.0005478531, 0.51748127, 0.4819709]]\n",
            "714       [[0.00016634926, 0.00086803554, 0.9989656]]\n",
            "715        [[0.00017854267, 0.111673616, 0.88814783]]\n",
            "716        [[0.0002619457, 0.0047691213, 0.99496895]]\n",
            "717           [[0.001643767, 0.9836152, 0.014741057]]\n",
            "718        [[9.861925e-05, 0.9992384, 0.00066306983]]\n",
            "719         [[0.0003882224, 0.0116436025, 0.9879682]]\n",
            "720           [[0.00020304485, 0.865371, 0.13442595]]\n",
            "721          [[0.0004625029, 0.9653009, 0.034236614]]\n",
            "722             [[0.019449947, 0.1118417, 0.8687083]]\n",
            "723          [[0.00039787265, 0.007674146, 0.991928]]\n",
            "724            [[0.7458158, 0.24246708, 0.011717076]]\n",
            "725         [[0.9958197, 0.0017466974, 0.0024335794]]\n",
            "726           [[0.68477386, 0.29053748, 0.024688654]]\n",
            "727            [[0.07134773, 0.047104683, 0.8815475]]\n",
            "728           [[0.0050335946, 0.46560183, 0.5293645]]\n",
            "729         [[0.0009751022, 0.000438891, 0.99858606]]\n",
            "730        [[0.00019583374, 0.0025216741, 0.9972825]]\n",
            "731         [[0.0003934189, 0.006082673, 0.99352384]]\n",
            "732        [[0.00018718159, 0.0017251272, 0.9980877]]\n",
            "733         [[0.00043948085, 0.77555937, 0.22400114]]\n",
            "734         [[0.0012277601, 0.0008644111, 0.9979079]]\n",
            "735         [[0.009555846, 0.0021719544, 0.98827213]]\n",
            "736             [[0.004800044, 0.8155531, 0.1796468]]\n",
            "737           [[0.003141264, 0.16335592, 0.83350277]]\n",
            "738           [[0.0009196201, 0.9807153, 0.01836512]]\n",
            "739         [[0.009555846, 0.0021719544, 0.98827213]]\n",
            "740          [[0.0013317702, 0.9590401, 0.039628092]]\n",
            "741         [[0.00014422642, 0.003589585, 0.9962663]]\n",
            "742       [[0.00015949935, 0.0046758913, 0.99516463]]\n",
            "743          [[7.862456e-05, 0.13102572, 0.86889565]]\n",
            "744        [[0.00013941295, 0.026350679, 0.97350997]]\n",
            "745           [[0.0002677988, 0.5078286, 0.49190366]]\n",
            "746          [[0.00020478402, 0.24340604, 0.7563892]]\n",
            "747         [[0.0029396538, 0.003441451, 0.99361897]]\n",
            "748         [[7.780315e-05, 0.0053795013, 0.9945427]]\n",
            "749        [[0.00019127097, 0.0029949474, 0.9968137]]\n",
            "750          [[0.00026219196, 0.20132728, 0.7984105]]\n",
            "751         [[0.0009732997, 0.0019955572, 0.9970311]]\n",
            "752             [[0.023488311, 0.3700746, 0.6064371]]\n",
            "753         [[8.531125e-05, 0.0011581203, 0.9987565]]\n",
            "754         [[6.482801e-05, 0.016809301, 0.98312587]]\n",
            "755        [[0.00012617903, 0.002749526, 0.99712425]]\n",
            "756           [[0.00026152356, 0.5196184, 0.4801201]]\n",
            "757         [[7.018299e-05, 0.0001530479, 0.9997768]]\n",
            "758         [[0.00018765629, 0.035605676, 0.9642066]]\n",
            "759         [[0.00023706473, 0.002270587, 0.9974923]]\n",
            "760      [[0.000119015116, 0.0003399225, 0.99954104]]\n",
            "761           [[0.0012932724, 0.9452922, 0.05341454]]\n",
            "762        [[0.00016319414, 0.97349596, 0.026340839]]\n",
            "763         [[0.0007367048, 0.0003553749, 0.9989079]]\n",
            "764          [[0.0018409648, 0.023277197, 0.9748819]]\n",
            "765             [[0.03640067, 0.8081668, 0.15543252]]\n",
            "766              [[0.0013327012, 0.50191, 0.4967573]]\n",
            "767           [[0.027357904, 0.51608026, 0.45656186]]\n",
            "768        [[9.9293604e-05, 0.0001289824, 0.9997718]]\n",
            "769        [[0.00030972034, 0.0025928465, 0.9970974]]\n",
            "770            [[0.0054631447, 0.284172, 0.71036476]]\n",
            "771         [[0.0071981945, 0.0037103842, 0.9890914]]\n",
            "772       [[0.00040083524, 0.0005318633, 0.99906725]]\n",
            "773          [[0.0002083535, 0.99121827, 0.00857333]]\n",
            "774           [[0.00045397412, 0.891291, 0.10825504]]\n",
            "775            [[0.002009158, 0.10801576, 0.8899751]]\n",
            "776        [[0.00013990268, 0.0024729709, 0.9973871]]\n",
            "777         [[9.81036e-05, 0.0003338735, 0.99956805]]\n",
            "778         [[0.00078074215, 0.25438964, 0.74482965]]\n",
            "779         [[0.00030912433, 0.01135907, 0.98833174]]\n",
            "780      [[0.00012599248, 0.00021188857, 0.99966216]]\n",
            "781       [[6.5420245e-05, 0.00077255286, 0.9991621]]\n",
            "782         [[0.00024762587, 0.32196745, 0.67778486]]\n",
            "783        [[5.6558998e-05, 0.0002500822, 0.9996934]]\n",
            "784          [[7.47165e-05, 0.0025734652, 0.9973519]]\n",
            "785          [[0.0011064406, 0.055855885, 0.9430377]]\n",
            "786           [[0.8917617, 0.099078305, 0.009159959]]\n",
            "787       [[0.0010944926, 0.00072262896, 0.99818283]]\n",
            "788        [[0.000991167, 0.00033409978, 0.99867475]]\n",
            "789        [[0.0003301765, 0.0051637734, 0.99450606]]\n",
            "790             [[0.92871, 0.030450817, 0.040839188]]\n",
            "791            [[0.9272475, 0.060809053, 0.01194352]]\n",
            "792           [[0.9766119, 0.002078942, 0.021309186]]\n",
            "793           [[0.00047057602, 0.4531868, 0.5463426]]\n",
            "794        [[3.3625984e-05, 0.99603444, 0.003931882]]\n",
            "795         [[0.00013910237, 0.9853607, 0.014500254]]\n",
            "796          [[0.00016989962, 0.9464061, 0.05342393]]\n",
            "797         [[0.00025589985, 0.91249305, 0.08725103]]\n",
            "798       [[0.00011973238, 0.9991364, 0.00074390485]]\n",
            "799          [[0.0056713815, 0.92854136, 0.06578731]]\n",
            "800           [[0.0004201961, 0.91494155, 0.0846382]]\n",
            "801           [[0.7792965, 0.21573137, 0.0049720597]]\n",
            "802           [[0.07304427, 0.89227164, 0.034684107]]\n",
            "803          [[9.805359e-05, 0.001058784, 0.9988432]]\n",
            "804        [[0.00018540159, 0.0002743742, 0.9995402]]\n",
            "805          [[0.00025998533, 0.3863199, 0.61342007]]\n",
            "806             [[0.5497893, 0.13920556, 0.31100515]]\n",
            "807           [[0.001397602, 0.21816465, 0.78043777]]\n",
            "808         [[0.00021779649, 0.070863605, 0.9289186]]\n",
            "809          [[0.00096639735, 0.6558711, 0.34316257]]\n",
            "810           [[0.63323075, 0.031810872, 0.33495834]]\n",
            "811       [[0.00078331836, 0.00032719696, 0.9988895]]\n",
            "812           [[0.0002851086, 0.7352043, 0.26451063]]\n",
            "813            [[9.838275e-05, 0.4123988, 0.5875028]]\n",
            "814          [[0.00031256245, 0.9016126, 0.09807486]]\n",
            "815        [[0.0009036229, 0.99737954, 0.0017168277]]\n",
            "816           [[0.00576358, 0.98764974, 0.006586714]]\n",
            "817          [[0.0003615793, 0.13729136, 0.86234707]]\n",
            "818           [[0.0016633887, 0.7633127, 0.23502396]]\n",
            "819      [[0.00012448993, 0.00040499365, 0.99947053]]\n",
            "820       [[5.8765243e-05, 0.00017817024, 0.9997631]]\n",
            "821          [[0.0001611188, 0.022689598, 0.9771493]]\n",
            "822        [[0.00029782887, 0.003053149, 0.99664897]]\n",
            "823       [[0.00025960116, 0.00015521953, 0.9995851]]\n",
            "824           [[0.9873182, 0.003232613, 0.009449189]]\n",
            "825            [[0.9638832, 0.005066405, 0.03105035]]\n",
            "826       [[0.00066401885, 0.00071812636, 0.9986179]]\n",
            "827       [[0.0004845298, 0.00049318786, 0.99902225]]\n",
            "828        [[0.00033799285, 0.013050554, 0.98661137]]\n",
            "829       [[0.00027179462, 0.0035112011, 0.99621695]]\n",
            "830       [[0.00023456111, 0.00020094478, 0.9995646]]\n",
            "831      [[0.00022949213, 0.00019982996, 0.99957067]]\n",
            "832         [[0.00033450045, 0.007547706, 0.9921178]]\n",
            "833        [[0.00021364476, 0.0054704305, 0.9943159]]\n",
            "834       [[0.00023519543, 0.0034381154, 0.99632674]]\n",
            "835           [[0.0004368999, 0.0005830267, 0.99898]]\n",
            "836          [[0.0012218982, 0.20367374, 0.79510444]]\n",
            "837          [[6.463611e-05, 0.9761987, 0.023736643]]\n",
            "838          [[0.00039005972, 0.39719173, 0.6024182]]\n",
            "839        [[0.00024254802, 0.0003204585, 0.9994369]]\n",
            "840        [[0.0015202925, 0.0022435512, 0.99623626]]\n",
            "841            [[0.91346794, 0.01653635, 0.06999561]]\n",
            "842        [[0.00022189652, 0.0016396075, 0.9981384]]\n",
            "843        [[0.0003518502, 0.00035570379, 0.9992924]]\n",
            "844          [[0.0006579178, 0.63193876, 0.36740327]]\n",
            "845          [[0.00035321058, 0.00437659, 0.9952702]]\n",
            "846         [[0.0014184624, 0.0018959731, 0.9966857]]\n",
            "847          [[0.00014412003, 0.0007958841, 0.99906]]\n",
            "848            [[8.173266e-05, 0.00852221, 0.991396]]\n",
            "849          [[4.814582e-05, 0.0013868872, 0.998565]]\n",
            "850       [[4.8797472e-05, 0.0002748972, 0.99967635]]\n",
            "851       [[2.9231061e-05, 0.00019650321, 0.9997743]]\n",
            "852      [[5.4678974e-05, 0.00074575405, 0.99919957]]\n",
            "853         [[6.8657e-05, 0.00045090175, 0.99948055]]\n",
            "854          [[8.044537e-05, 0.03489088, 0.96502876]]\n",
            "855            [[0.00027820608, 0.165355, 0.8343668]]\n",
            "856             [[0.002607131, 0.30142394, 0.695969]]\n",
            "857        [[0.00021043993, 0.0029201787, 0.9968694]]\n",
            "858             [[0.7249564, 0.11079291, 0.16425073]]\n",
            "859            [[0.0006970169, 0.08135496, 0.917948]]\n",
            "860        [[0.98381686, 0.0021054577, 0.0140776755]]\n",
            "861       [[0.00020196447, 0.00031970648, 0.9994784]]\n",
            "862          [[0.0011976198, 0.87788665, 0.12091573]]\n",
            "863         [[0.0010755112, 0.9962304, 0.0026940014]]\n",
            "864         [[0.0006607069, 0.9981969, 0.0011424705]]\n",
            "865       [[0.00012494765, 0.0005845178, 0.99929047]]\n",
            "866             [[0.001831738, 0.7083629, 0.2898054]]\n",
            "867           [[0.0003926826, 0.032450303, 0.967157]]\n",
            "868      [[0.00010217356, 0.00071829587, 0.99917954]]\n",
            "869          [[0.008036431, 0.9902152, 0.0017483662]]\n",
            "870           [[0.00044417294, 0.988424, 0.01113184]]\n",
            "871          [[0.0025049208, 0.9533607, 0.044134445]]\n",
            "872          [[0.0025049208, 0.9533607, 0.044134445]]\n",
            "873           [[0.0023463315, 0.53864616, 0.4590075]]\n",
            "874           [[0.001166925, 0.23007666, 0.76875645]]\n",
            "875          [[0.0010104968, 0.026968444, 0.9720211]]\n",
            "876           [[0.0028827703, 0.06265237, 0.9344649]]\n",
            "877        [[0.00017484247, 0.022709308, 0.97711587]]\n",
            "878          [[6.2344436e-05, 0.00653769, 0.9934001]]\n",
            "879       [[0.00013326593, 0.0010995674, 0.99876726]]\n",
            "880           [[0.0008293358, 0.012317576, 0.986853]]\n",
            "881       [[0.0024678316, 0.99720407, 0.00032818364]]\n",
            "882             [[0.39347214, 0.5819657, 0.02456216]]\n",
            "883        [[0.0004264604, 0.0019019061, 0.99767154]]\n",
            "884          [[0.0003308531, 0.030168416, 0.9695007]]\n",
            "885         [[0.0009768974, 0.0015067521, 0.9975164]]\n",
            "886       [[5.6684738e-05, 0.0006183344, 0.99932504]]\n",
            "887           [[0.0003293557, 0.26112247, 0.7385482]]\n",
            "888          [[0.0002855287, 0.66867596, 0.33103856]]\n",
            "889         [[0.0035061508, 0.002892598, 0.99360126]]\n",
            "890       [[0.00012960185, 0.0009974625, 0.99887294]]\n",
            "891        [[0.00044702957, 0.005534931, 0.99401796]]\n",
            "892             [[0.001155884, 0.0560438, 0.9428003]]\n",
            "893         [[0.0012726206, 0.0013927385, 0.9973347]]\n",
            "894      [[0.000102985905, 0.99816614, 0.0017308693]]\n",
            "895            [[0.0011140497, 0.41768995, 0.581196]]\n",
            "896         [[0.00028211318, 0.16091311, 0.83880484]]\n",
            "897        [[6.495415e-05, 0.0010202562, 0.99891484]]\n",
            "898       [[6.474006e-05, 0.00028549836, 0.99964976]]\n",
            "899         [[6.968364e-05, 0.0023234715, 0.9976069]]\n",
            "900      [[1.8318104e-05, 0.00013262454, 0.99984896]]\n",
            "901          [[0.0015758231, 0.20762569, 0.79079854]]\n",
            "902           [[0.061951634, 0.054032493, 0.8840159]]\n",
            "903           [[0.0011568862, 0.09504623, 0.9037968]]\n",
            "904           [[0.1630558, 0.8365531, 0.00039109527]]\n",
            "905       [[0.0063285334, 0.99326855, 0.00040292184]]\n",
            "906            [[0.017288936, 0.5027073, 0.48000377]]\n",
            "907           [[0.12378184, 0.8736653, 0.0025528853]]\n",
            "908           [[0.014437801, 0.03440686, 0.95115536]]\n",
            "909         [[0.00610314, 0.00091930566, 0.99297756]]\n",
            "910            [[0.8048935, 0.034334194, 0.16077237]]\n",
            "911             [[0.01711231, 0.9105375, 0.07235023]]\n",
            "912            [[0.8818349, 0.08630802, 0.031857103]]\n",
            "913           [[0.5692527, 0.41994992, 0.0107973935]]\n",
            "914           [[0.48069072, 0.058398493, 0.46091074]]\n",
            "915        [[0.00042239268, 0.0018848262, 0.9976928]]\n",
            "916            [[0.7123814, 0.26413083, 0.023487795]]\n",
            "917           [[0.9226816, 0.057859372, 0.019458914]]\n",
            "918        [[0.0003586852, 0.9994912, 0.00015009548]]\n",
            "919         [[0.0022713242, 0.053700753, 0.94402796]]\n",
            "920           [[0.010033246, 0.30017766, 0.68978906]]\n",
            "921             [[0.7696831, 0.13084884, 0.09946799]]\n",
            "922            [[0.07729508, 0.8938588, 0.028846154]]\n",
            "923        [[0.0001656929, 0.0035075531, 0.99632674]]\n",
            "924          [[0.0060488405, 0.14399731, 0.84995383]]\n",
            "925        [[0.00074809836, 0.055015557, 0.94423634]]\n",
            "926           [[0.0002629019, 0.9029992, 0.09673785]]\n",
            "927         [[0.00015972524, 0.9853188, 0.014521468]]\n",
            "928         [[0.00023578371, 0.004634456, 0.9951297]]\n",
            "929         [[0.0001491221, 0.0062095765, 0.9936413]]\n",
            "930          [[6.443503e-05, 0.020005865, 0.9799296]]\n",
            "931          [[0.00015289897, 0.03018945, 0.9696576]]\n",
            "932        [[0.00011607431, 0.9950335, 0.0048504765]]\n",
            "933          [[0.00010581144, 0.02445411, 0.9754401]]\n",
            "934          [[0.015828583, 0.0014240148, 0.9827474]]\n",
            "935          [[0.015828583, 0.0014240148, 0.9827474]]\n",
            "936       [[0.00020378672, 0.0021145358, 0.99768174]]\n",
            "937        [[0.00096909737, 0.035340156, 0.96369076]]\n",
            "938         [[0.0001553941, 9.880625e-05, 0.9997458]]\n",
            "939        [[0.00054033956, 0.0149428705, 0.9845168]]\n",
            "940          [[9.358885e-05, 0.013918281, 0.9859882]]\n",
            "941         [[0.00020992926, 0.16749908, 0.83229095]]\n",
            "942           [[0.004011848, 0.37350586, 0.62248224]]\n",
            "943         [[7.941253e-05, 0.0001640732, 0.9997565]]\n",
            "944       [[0.00022193597, 0.0003952801, 0.99938273]]\n",
            "945           [[0.0001982828, 0.33772448, 0.6620773]]\n",
            "946        [[0.00026767084, 0.0036468124, 0.9960855]]\n",
            "947        [[0.000101793856, 0.003399318, 0.9964988]]\n",
            "948           [[0.00023636036, 0.3495199, 0.6502437]]\n",
            "949        [[8.803403e-05, 0.0006035699, 0.99930835]]\n",
            "950              [[0.0003173186, 0.61687, 0.3828127]]\n",
            "951            [[0.00958812, 0.9757499, 0.014661947]]\n",
            "952         [[0.00025408407, 0.02996343, 0.96978253]]\n",
            "953          [[0.00012809543, 0.04540655, 0.9544653]]\n",
            "954            [[0.004189861, 0.8599904, 0.13581972]]\n",
            "955         [[0.00019036978, 0.007852335, 0.9919573]]\n",
            "956       [[0.00010259953, 0.0014574875, 0.99843997]]\n",
            "957         [[0.0027016297, 0.0045411056, 0.9927573]]\n",
            "958          [[0.003012519, 0.0036658018, 0.9933216]]\n",
            "959              [[0.527955, 0.4580229, 0.014022172]]\n",
            "960       [[0.00041890406, 0.0016478403, 0.99793327]]\n",
            "961          [[0.000153036, 0.000933203, 0.99891376]]\n",
            "962         [[0.00032018742, 0.005089537, 0.9945903]]\n",
            "963       [[0.00018453597, 0.00031925912, 0.9994962]]\n",
            "964           [[0.03796601, 0.91348404, 0.048549946]]\n",
            "965         [[0.000231978, 0.00077373034, 0.9989943]]\n",
            "966           [[0.08362927, 0.040356196, 0.87601453]]\n",
            "967           [[0.08362927, 0.040356196, 0.87601453]]\n",
            "968            [[0.009932899, 0.18331407, 0.8067531]]\n",
            "969       [[0.00068000035, 0.00050066784, 0.9988193]]\n",
            "970         [[0.0024867742, 0.055696156, 0.94181716]]\n",
            "971          [[0.0040762294, 0.010725054, 0.9851987]]\n",
            "972         [[0.00010590026, 0.025190668, 0.9747035]]\n",
            "973      [[0.00024240506, 0.00070396316, 0.99905366]]\n",
            "974        [[0.0002657016, 0.0010328655, 0.99870133]]\n",
            "975        [[0.0002657016, 0.0010328655, 0.99870133]]\n",
            "976       [[0.00033858308, 0.0032450175, 0.99641645]]\n",
            "977         [[0.00023066309, 0.027902454, 0.9718669]]\n",
            "978          [[0.00044276819, 0.03700843, 0.9625488]]\n",
            "979            [[0.000453586, 0.29359582, 0.7059506]]\n",
            "980         [[0.001109528, 0.00046233225, 0.9984282]]\n",
            "981         [[0.017103117, 0.00073111046, 0.9821659]]\n",
            "982           [[0.0019341258, 0.6956352, 0.30243066]]\n",
            "983        [[0.00027273726, 0.0019239818, 0.9978033]]\n",
            "984          [[0.0053524673, 0.021058949, 0.9735885]]\n",
            "985         [[0.017103117, 0.00073111046, 0.9821659]]\n",
            "986           [[0.00048824816, 0.13294381, 0.866568]]\n",
            "987        [[0.0006106455, 0.0006956175, 0.99869376]]\n",
            "988         [[0.0022158662, 0.020052422, 0.97773176]]\n",
            "989       [[0.00011747057, 0.0002741084, 0.99960846]]\n",
            "990       [[0.00041558297, 0.0027206126, 0.99686384]]\n",
            "991          [[0.00010702765, 0.987324, 0.012568912]]\n",
            "992        [[4.883703e-05, 0.00028737902, 0.9996637]]\n",
            "993        [[0.00021770115, 0.0025878972, 0.9971944]]\n",
            "994       [[0.00023136666, 0.0026637204, 0.99710494]]\n",
            "995            [[0.0002132675, 0.3734669, 0.6263199]]\n",
            "996          [[0.0004169273, 0.047408726, 0.9521743]]\n",
            "997          [[0.0019157088, 0.121049434, 0.8770349]]\n",
            "998         [[0.00031760248, 0.002401025, 0.9972813]]\n",
            "999       [[0.00017671412, 0.0006938739, 0.99912935]]\n",
            "1000      [[5.5291377e-05, 0.0013655929, 0.99857914]]\n",
            "1001        [[0.00018254001, 0.000629272, 0.9991881]]\n",
            "1002        [[0.00019576303, 0.0070221927, 0.992782]]\n",
            "1003           [[0.011109344, 0.33634955, 0.6525411]]\n",
            "1004     [[0.00013707852, 0.00016541747, 0.99969757]]\n",
            "1005           [[0.00016965, 0.005323518, 0.9945068]]\n",
            "1006       [[0.0002735089, 0.0064011565, 0.99332523]]\n",
            "1007       [[0.0002735089, 0.0064011565, 0.99332523]]\n",
            "1008       [[0.00038576845, 0.0007597159, 0.9988545]]\n",
            "1009         [[0.0126302345, 0.37115765, 0.61621207]]\n",
            "1010      [[0.00021091546, 0.00033065915, 0.9994585]]\n",
            "1011        [[0.00012546394, 0.0014595417, 0.998415]]\n",
            "1012        [[0.0002517555, 0.007058016, 0.99269027]]\n",
            "1013       [[0.0001197902, 0.00035202524, 0.9995283]]\n",
            "1014          [[0.89100194, 0.053488445, 0.05550965]]\n",
            "1015         [[0.002381465, 0.0025272607, 0.9950912]]\n",
            "1016       [[0.0004411363, 0.00048103175, 0.9990778]]\n",
            "1017      [[0.00013462125, 0.0057667387, 0.99409866]]\n",
            "1018      [[0.00031480187, 0.00017243862, 0.9995128]]\n",
            "1019       [[0.0003740701, 0.00087714754, 0.9987488]]\n",
            "1020     [[0.00020824697, 0.00012459877, 0.99966717]]\n",
            "1021          [[0.0007369507, 0.4023924, 0.59687066]]\n",
            "1022         [[0.0014279064, 0.04623797, 0.95233405]]\n",
            "1023          [[0.001086189, 0.84893453, 0.14997934]]\n",
            "1024          [[0.0011754619, 0.7092263, 0.28959826]]\n",
            "1025           [[0.55218786, 0.09506877, 0.35274333]]\n",
            "1026         [[0.0013426322, 0.020204961, 0.9784524]]\n",
            "1027       [[0.00058882195, 0.0015300681, 0.9978811]]\n",
            "1028            [[0.014188039, 0.1088732, 0.8769387]]\n",
            "1029       [[0.00028602884, 0.0006336426, 0.9990803]]\n",
            "1030         [[0.00025080354, 0.01643738, 0.9833118]]\n",
            "1031       [[0.00047297069, 0.072808385, 0.92671865]]\n",
            "1032           [[0.0007467492, 0.040903304, 0.95835]]\n",
            "1033            [[0.8871677, 0.02263229, 0.09020001]]\n",
            "1034      [[0.00012882064, 0.0002783338, 0.99959284]]\n",
            "1035     [[0.00011965818, 0.00063341117, 0.99924695]]\n",
            "1036        [[0.0003649336, 0.0036502308, 0.9959848]]\n",
            "1037        [[6.284469e-05, 0.006220471, 0.99371666]]\n",
            "1038           [[6.270301e-05, 0.001297234, 0.99864]]\n",
            "1039       [[9.909326e-05, 0.0024460473, 0.99745494]]\n",
            "1040       [[0.00022787522, 0.0005206276, 0.9992514]]\n",
            "1041         [[0.00017329473, 0.9078814, 0.09194528]]\n",
            "1042         [[9.233926e-05, 0.9810922, 0.018815428]]\n",
            "1043        [[0.00038545136, 0.98043746, 0.01917711]]\n",
            "1044       [[0.000110950146, 0.015216611, 0.9846725]]\n",
            "1045       [[0.00014917161, 0.0002015522, 0.9996493]]\n",
            "1046       [[0.0003686179, 0.00087764225, 0.9987538]]\n",
            "1047       [[0.00033408028, 0.0013572143, 0.9983088]]\n",
            "1048             [[0.056684308, 0.190514, 0.7528017]]\n",
            "1049         [[0.92463523, 0.021155454, 0.054209284]]\n",
            "1050            [[0.6062434, 0.34033054, 0.05342607]]\n",
            "1051        [[0.00031057815, 0.004737746, 0.9949516]]\n",
            "1052         [[0.0016591845, 0.01826501, 0.98007584]]\n",
            "1053       [[0.0003234916, 0.0018974936, 0.99777895]]\n",
            "1054         [[0.0006731151, 0.001501421, 0.9978255]]\n",
            "1055      [[0.00034315116, 0.00052164396, 0.9991352]]\n",
            "1056       [[0.00010840344, 0.006411153, 0.99348044]]\n",
            "1057        [[0.00047112588, 0.42276075, 0.57676816]]\n",
            "1058         [[9.91873e-05, 0.006783942, 0.99311686]]\n",
            "1059       [[0.00016068236, 0.0137490835, 0.9860902]]\n",
            "1060       [[0.0001819557, 0.0018240353, 0.99799407]]\n",
            "1061        [[9.369781e-05, 0.001617966, 0.99828833]]\n",
            "1062     [[0.00012265169, 0.00033166714, 0.99954575]]\n",
            "1063         [[0.0005618688, 0.022661759, 0.9767765]]\n",
            "1064             [[0.8070267, 0.167409, 0.025564386]]\n",
            "1065         [[0.00045690793, 0.8885392, 0.11100391]]\n",
            "1066        [[0.0002885395, 0.0040194215, 0.9956921]]\n",
            "1067         [[0.00068937487, 0.8005699, 0.19874075]]\n",
            "1068      [[0.000103424994, 0.0035268208, 0.9963697]]\n",
            "1069      [[0.00013630003, 0.0021355029, 0.99772817]]\n",
            "1070     [[0.000101851234, 0.0008549251, 0.99904317]]\n",
            "1071        [[0.00013351795, 0.001661074, 0.9982054]]\n",
            "1072       [[0.0001897772, 0.0027750595, 0.99703515]]\n",
            "1073        [[0.0008697074, 0.0031724258, 0.9959579]]\n",
            "1074          [[0.014922697, 0.51615614, 0.46892115]]\n",
            "1075       [[0.0007585992, 0.0018546834, 0.99738675]]\n",
            "1076          [[0.00035553702, 0.7128391, 0.2868053]]\n",
            "1077       [[0.00014411927, 0.0006696263, 0.9991862]]\n",
            "1078      [[0.00015385986, 0.0003762018, 0.99947006]]\n",
            "1079       [[0.00021300043, 0.0005948778, 0.9991922]]\n",
            "1080         [[0.0020519448, 0.90353805, 0.09441004]]\n",
            "1081           [[7.00146e-05, 0.9326982, 0.06723184]]\n",
            "1082        [[0.0001820004, 0.92183733, 0.077980705]]\n",
            "1083      [[0.00015943691, 0.00038132092, 0.9994593]]\n",
            "1084     [[7.7313445e-05, 0.00033731337, 0.99958533]]\n",
            "1085           [[0.0002731462, 0.055576887, 0.94415]]\n",
            "1086       [[0.00016488206, 0.0119120255, 0.9879231]]\n",
            "1087       [[0.00015819451, 0.004554238, 0.99528754]]\n",
            "1088        [[0.00014729214, 0.025724042, 0.9741287]]\n",
            "1089        [[0.00093087833, 0.52419597, 0.47487316]]\n",
            "1090         [[0.0034053277, 0.57669336, 0.41990128]]\n",
            "1091            [[0.02646812, 0.8497412, 0.12379069]]\n",
            "1092       [[0.0010952814, 0.00041989613, 0.9984848]]\n",
            "1093          [[0.68447435, 0.29543146, 0.020094138]]\n",
            "1094           [[0.07084049, 0.9267683, 0.002391187]]\n",
            "1095        [[0.0034735906, 0.007564186, 0.98896223]]\n",
            "1096      [[0.00015163855, 0.0014213398, 0.99842703]]\n",
            "1097         [[0.000270154, 0.0010125735, 0.9987173]]\n",
            "1098      [[0.00053236267, 0.0014859032, 0.99798167]]\n",
            "1099       [[0.00036292808, 0.0003018652, 0.9993352]]\n",
            "1100       [[0.00032659483, 0.003320817, 0.99635255]]\n",
            "1101        [[0.000244867, 0.0004946525, 0.99926037]]\n",
            "1102       [[6.475168e-05, 0.00081135985, 0.9991239]]\n",
            "1103        [[0.00039369875, 0.007458091, 0.9921482]]\n",
            "1104        [[0.0005584702, 0.0061373515, 0.9933042]]\n",
            "1105       [[0.00012292126, 0.0017447773, 0.9981323]]\n",
            "1106       [[0.00013930592, 0.0006780633, 0.9991825]]\n",
            "1107        [[0.0002594337, 0.0005890428, 0.9991516]]\n",
            "1108        [[5.522378e-05, 0.0031179844, 0.9968267]]\n",
            "1109      [[0.00032115087, 0.0019416941, 0.99773717]]\n",
            "1110       [[0.00024449377, 0.0008929583, 0.9988626]]\n",
            "1111       [[0.00022417544, 0.0017724414, 0.9980034]]\n",
            "1112        [[0.00016329305, 0.017918974, 0.9819178]]\n",
            "1113       [[0.00019670987, 0.016152937, 0.98365027]]\n",
            "1114     [[0.000121186604, 0.0026883155, 0.99719054]]\n",
            "1115      [[9.6321826e-05, 0.0015127078, 0.99839103]]\n",
            "1116          [[0.001393946, 0.013897701, 0.9847083]]\n",
            "1117        [[9.388491e-05, 0.008391591, 0.99151456]]\n",
            "1118       [[4.0612715e-05, 0.0021610362, 0.9977984]]\n",
            "1119      [[4.8833655e-05, 0.0014227942, 0.99852836]]\n",
            "1120         [[0.0010233483, 0.75024265, 0.24873401]]\n",
            "1121        [[0.0010668748, 0.0016066302, 0.9973264]]\n",
            "1122           [[0.979045, 0.015404655, 0.005550474]]\n",
            "1123          [[0.0042072325, 0.2345641, 0.76122874]]\n",
            "1124       [[0.0004918948, 0.0016636427, 0.99784446]]\n",
            "1125      [[0.00034974056, 0.00033977668, 0.9993105]]\n",
            "1126        [[0.000111837806, 0.74921054, 0.2506776]]\n",
            "1127           [[0.0007627325, 0.7889014, 0.2103359]]\n",
            "1128         [[0.0006663439, 0.9021219, 0.097211756]]\n",
            "1129        [[7.807739e-05, 0.99132735, 0.008594585]]\n",
            "1130     [[0.00016984364, 0.00087549794, 0.99895465]]\n",
            "1131        [[0.00054104364, 0.050130762, 0.9493281]]\n",
            "1132         [[0.002168197, 0.0085860845, 0.9892457]]\n",
            "1133     [[0.00025861055, 0.00046994345, 0.99927145]]\n",
            "1134            [[0.00304975, 0.04147806, 0.9554723]]\n",
            "1135        [[0.0006276492, 0.055158284, 0.94421417]]\n",
            "1136        [[0.00047775282, 0.008864403, 0.9906579]]\n",
            "1137         [[0.00023184443, 0.05470577, 0.9450624]]\n",
            "1138       [[0.00016516623, 0.017957332, 0.98187757]]\n",
            "1139           [[0.000122281, 0.06352482, 0.9363529]]\n",
            "1140        [[0.00011068715, 0.0008083732, 0.999081]]\n",
            "1141           [[0.0006075916, 0.3198076, 0.6795848]]\n",
            "1142         [[0.0005491161, 0.26244894, 0.73700196]]\n",
            "1143       [[0.0010078143, 0.0013614113, 0.99763083]]\n",
            "1144         [[0.0015502776, 0.00081966363, 0.99763]]\n",
            "1145            [[0.9168464, 0.04387277, 0.03928085]]\n",
            "1146       [[0.0005188274, 0.00010777396, 0.9993734]]\n",
            "1147       [[0.0004797061, 0.00021914444, 0.9993011]]\n",
            "1148       [[0.00019208487, 7.200772e-05, 0.9997359]]\n",
            "1149        [[0.00062642456, 0.000938885, 0.9984347]]\n",
            "1150        [[0.00012286192, 0.005041712, 0.9948354]]\n",
            "1151          [[0.0007008001, 0.21576357, 0.7835356]]\n",
            "1152        [[0.00013508454, 0.009867072, 0.9899978]]\n",
            "1153       [[7.8988145e-05, 0.004264154, 0.99565697]]\n",
            "1154         [[0.0011206033, 0.91692024, 0.08195918]]\n",
            "1155          [[0.8632415, 0.13481662, 0.0019418544]]\n",
            "1156       [[0.00018073883, 0.000247978, 0.99957126]]\n",
            "1157      [[7.350025e-05, 0.00066057866, 0.99926597]]\n",
            "1158       [[7.2462666e-05, 0.0003898236, 0.9995377]]\n",
            "1159            [[0.00058765, 0.2905498, 0.70886254]]\n",
            "1160         [[0.00020992826, 0.18563704, 0.8141531]]\n",
            "1161       [[0.00062998506, 0.015518944, 0.98385113]]\n",
            "1162          [[0.0019927958, 0.06383952, 0.9341677]]\n",
            "1163         [[0.0014145989, 0.02253394, 0.97605145]]\n",
            "1164      [[5.012771e-05, 0.00037751568, 0.99957234]]\n",
            "1165       [[0.00013789193, 0.0004868483, 0.9993753]]\n",
            "1166       [[0.00031195636, 0.022261366, 0.97742665]]\n",
            "1167        [[0.0001588711, 0.0062956773, 0.9935455]]\n",
            "1168      [[0.00022679419, 0.0006125447, 0.99916065]]\n",
            "1169        [[7.885031e-05, 0.0010644468, 0.9988568]]\n",
            "1170           [[0.0002575007, 0.31128356, 0.688459]]\n",
            "1171      [[0.00018942443, 0.00093586877, 0.9988747]]\n",
            "1172         [[8.911465e-05, 0.0035079066, 0.996403]]\n",
            "1173         [[8.388195e-05, 0.9405522, 0.059363913]]\n",
            "1174           [[0.8376855, 0.065388545, 0.09692596]]\n",
            "1175         [[0.043601725, 0.9533625, 0.0030358026]]\n",
            "1176        [[0.0047191717, 0.9950864, 0.0001944112]]\n",
            "1177       [[0.00036292194, 0.0065841763, 0.9930529]]\n",
            "1178      [[0.00031632502, 0.00028492135, 0.9993987]]\n",
            "1179        [[0.0002567944, 0.0007107564, 0.9990325]]\n",
            "1180     [[0.000116614894, 0.00017854956, 0.9997048]]\n",
            "1181      [[0.00017594942, 0.00027475326, 0.9995492]]\n",
            "1182     [[0.00016402964, 0.00026287814, 0.99957305]]\n",
            "1183        [[5.740995e-05, 0.0056500603, 0.9942926]]\n",
            "1184       [[5.5915763e-05, 0.0035558548, 0.9963882]]\n",
            "1185      [[0.0001424366, 0.00056138216, 0.99929607]]\n",
            "1186          [[0.013961239, 0.27130136, 0.71473736]]\n",
            "1187          [[0.001519266, 0.034815125, 0.9636656]]\n",
            "1188       [[0.00047640456, 0.0021473023, 0.9973763]]\n",
            "1189        [[0.0010437878, 0.0020399706, 0.9969163]]\n",
            "1190       [[0.00059204886, 0.0047043813, 0.9947036]]\n",
            "1191        [[0.0003375794, 0.004001006, 0.99566144]]\n",
            "1192       [[0.00016751733, 0.013988898, 0.98584366]]\n",
            "1193          [[0.0004108595, 0.01929452, 0.9802946]]\n",
            "1194      [[0.0011156992, 0.00031843912, 0.99856585]]\n",
            "1195     [[0.00047020783, 0.00025722999, 0.99927264]]\n",
            "1196        [[0.00014973604, 0.001541426, 0.9983089]]\n",
            "1197        [[5.9693008e-05, 0.003220519, 0.9967198]]\n",
            "1198       [[0.00010960241, 0.0028907552, 0.9969997]]\n",
            "1199       [[4.2179716e-05, 0.0006250999, 0.9993327]]\n",
            "1200         [[0.00015832148, 0.007834608, 0.992007]]\n",
            "1201      [[0.00036175427, 0.00037718314, 0.9992611]]\n",
            "1202       [[9.474735e-05, 0.0006880896, 0.99921715]]\n",
            "1203             [[0.00781331, 0.034996778, 0.95719]]\n",
            "1204          [[0.08789327, 0.048950795, 0.86315596]]\n",
            "1205       [[0.0002228061, 0.0029777016, 0.99679947]]\n",
            "1206        [[9.540372e-05, 0.005975473, 0.99392915]]\n",
            "1207      [[0.000119018994, 0.0012554241, 0.9986255]]\n",
            "1208    [[0.000109791035, 0.00015028182, 0.99973994]]\n",
            "1209          [[0.036312167, 0.9625568, 0.001131132]]\n",
            "1210       [[0.0052177133, 0.98932207, 0.0054602004]]\n",
            "1211        [[0.0036697388, 0.97866243, 0.017667878]]\n",
            "1212          [[0.44986495, 0.50757253, 0.042562492]]\n",
            "1213      [[9.2897964e-05, 0.00027683657, 0.9996302]]\n",
            "1214      [[0.00016681322, 0.0007280094, 0.99910516]]\n",
            "1215       [[0.00013259414, 0.0006613654, 0.9992061]]\n",
            "1216          [[0.0006867182, 0.14517274, 0.8541405]]\n",
            "1217        [[0.00045058108, 0.87124586, 0.12830359]]\n",
            "1218      [[0.00021319253, 0.00028939595, 0.9994974]]\n",
            "1219       [[9.3380906e-05, 0.0024018618, 0.9975048]]\n",
            "1220     [[0.00019142254, 0.00015455385, 0.99965405]]\n",
            "1221      [[0.00028456838, 0.00022317654, 0.9994923]]\n",
            "1222        [[0.00040149817, 0.01502111, 0.98457736]]\n",
            "1223            [[0.43630293, 0.4667958, 0.09690129]]\n",
            "1224           [[0.000713174, 0.11749434, 0.8817924]]\n",
            "1225       [[5.1353807e-05, 7.700529e-05, 0.9998716]]\n",
            "1226        [[0.0007658031, 0.0029311376, 0.9963031]]\n",
            "1227       [[9.776272e-05, 0.00014143206, 0.9997608]]\n",
            "1228           [[0.001083999, 0.4218465, 0.57706946]]\n",
            "1229     [[0.00028309933, 0.00022860672, 0.99948823]]\n",
            "1230     [[0.00029824398, 0.00020912265, 0.99949265]]\n",
            "1231       [[0.0001663503, 0.00022999643, 0.9996037]]\n",
            "1232          [[0.36889935, 0.58130974, 0.049790874]]\n",
            "1233          [[0.0005729391, 0.05278317, 0.9466439]]\n",
            "1234       [[0.00010594231, 0.0007313611, 0.9991628]]\n",
            "1235          [[0.020827744, 0.9569494, 0.022222891]]\n",
            "1236           [[0.0013313482, 0.1516729, 0.8469957]]\n",
            "1237       [[0.0003729142, 0.0005164863, 0.99911064]]\n",
            "1238       [[0.00012699123, 0.0009652424, 0.9989078]]\n",
            "1239      [[5.8919723e-05, 0.0013845476, 0.99855655]]\n",
            "1240     [[0.00084634614, 0.00023999697, 0.99891376]]\n",
            "1241      [[0.00010346516, 0.00019542941, 0.9997011]]\n",
            "1242      [[0.00028078322, 0.0109222885, 0.98879695]]\n",
            "1243            [[0.002234343, 0.3490283, 0.6487373]]\n",
            "1244           [[0.0006213411, 0.5918611, 0.4075175]]\n",
            "1245        [[9.848854e-05, 0.0015639317, 0.9983375]]\n",
            "1246         [[0.00024922442, 0.2504721, 0.74927866]]\n",
            "1247       [[0.00015339258, 0.0022510048, 0.9975956]]\n",
            "1248       [[0.00010463898, 0.0005114042, 0.9993839]]\n",
            "1249           [[0.64913017, 0.3400009, 0.010868867]]\n",
            "1250       [[3.188129e-05, 0.9995266, 0.00044152117]]\n",
            "1251           [[0.7219142, 0.22483747, 0.053248458]]\n",
            "1252        [[0.0001488113, 0.0014155806, 0.9984357]]\n",
            "1253         [[0.0004329564, 0.54991716, 0.44964987]]\n",
            "1254       [[0.00057373854, 0.011711456, 0.98771477]]\n",
            "1255       [[0.00020860638, 0.0023669263, 0.9974246]]\n",
            "1256        [[0.00032360997, 0.002450567, 0.9972258]]\n",
            "1257       [[0.00046072406, 0.0077476474, 0.9917916]]\n",
            "1258       [[0.00057887076, 0.034984212, 0.96443695]]\n",
            "1259      [[0.00014152785, 0.0041226703, 0.99573576]]\n",
            "1260        [[0.00023547867, 0.92757225, 0.07219226]]\n",
            "1261        [[0.00040421824, 0.004601255, 0.9949945]]\n",
            "1262      [[0.0003543235, 0.00029973616, 0.99934596]]\n",
            "1263           [[0.6511615, 0.32226717, 0.026571363]]\n",
            "1264      [[0.00027386742, 0.0005877746, 0.99913836]]\n",
            "1265           [[0.0004108544, 0.1251939, 0.8743952]]\n",
            "1266       [[0.00019926958, 0.0049486784, 0.9948521]]\n",
            "1267         [[0.0006407829, 0.004814117, 0.9945451]]\n",
            "1268         [[0.0010143969, 0.9728238, 0.026161782]]\n",
            "1269            [[0.06776858, 0.918836, 0.013395453]]\n",
            "1270           [[0.0358694, 0.90686387, 0.057266686]]\n",
            "1271           [[0.9594582, 0.03401828, 0.006523537]]\n",
            "1272        [[0.00021566669, 0.9906104, 0.009173858]]\n",
            "1273        [[0.0001597056, 0.9970874, 0.0027528992]]\n",
            "1274       [[0.00026210016, 0.00034287057, 0.999395]]\n",
            "1275     [[0.00010359666, 0.00031654147, 0.99957997]]\n",
            "1276           [[0.00253805, 0.9378316, 0.059630334]]\n",
            "1277          [[0.009592532, 0.9303158, 0.060091723]]\n",
            "1278       [[0.0001960207, 0.00042162932, 0.9993824]]\n",
            "1279          [[0.0028535214, 0.04446063, 0.9526858]]\n",
            "1280        [[0.0029608367, 0.115808085, 0.88123107]]\n",
            "1281         [[0.00075786456, 0.15233447, 0.8469076]]\n",
            "1282      [[7.518401e-05, 0.00027266084, 0.99965215]]\n",
            "1283     [[0.000118083226, 0.0060103764, 0.99387145]]\n",
            "1284        [[0.0001620453, 0.012551136, 0.98728687]]\n",
            "1285         [[6.953944e-05, 0.008337355, 0.9915931]]\n",
            "1286      [[0.00018249272, 0.0039377343, 0.99587977]]\n",
            "1287       [[0.00023888425, 0.0006690324, 0.9990921]]\n",
            "1288         [[0.00030942468, 0.992826, 0.006864644]]\n",
            "1289        [[0.0028613384, 0.9944218, 0.0027169415]]\n",
            "1290           [[0.23077129, 0.31832725, 0.45090148]]\n",
            "1291      [[0.00048597693, 0.00065273244, 0.9988613]]\n",
            "1292         [[0.011070476, 0.008396823, 0.98053265]]\n",
            "1293       [[0.00032899165, 0.0005932097, 0.9990778]]\n",
            "1294        [[0.0007619035, 0.0010248793, 0.9982132]]\n",
            "1295           [[0.3216285, 0.61957085, 0.058800597]]\n",
            "1296           [[0.04573679, 0.007102297, 0.9471609]]\n",
            "1297       [[0.0005657798, 0.0026640568, 0.99677026]]\n",
            "1298         [[0.0004923625, 0.9423486, 0.057159025]]\n",
            "1299       [[0.00023904367, 0.003794585, 0.99596643]]\n",
            "1300        [[0.0005802516, 0.0020270296, 0.9973928]]\n",
            "1301         [[0.0015459685, 0.06703553, 0.93141854]]\n",
            "1302        [[0.0014771686, 0.005056874, 0.99346596]]\n",
            "1303          [[9.1619804e-05, 0.8833169, 0.1165915]]\n",
            "1304         [[0.00018732225, 0.2887199, 0.71109277]]\n",
            "1305          [[0.0002206583, 0.58876514, 0.4110142]]\n",
            "1306       [[0.0008308337, 0.0015395004, 0.99762964]]\n",
            "1307      [[0.00010731738, 0.00017217569, 0.9997205]]\n",
            "1308      [[0.00022112203, 0.00030907357, 0.9994698]]\n",
            "1309       [[0.0001780566, 0.00042693436, 0.9993949]]\n",
            "1310       [[0.00030152677, 0.0001147066, 0.9995838]]\n",
            "1311         [[0.00043907602, 0.03178676, 0.9677741]]\n",
            "1312        [[8.9861e-05, 0.00053959445, 0.99937063]]\n",
            "1313       [[0.0005834945, 0.0038000501, 0.99561656]]\n",
            "1314      [[0.00014767417, 0.0043359688, 0.99551636]]\n",
            "1315           [[0.0012428085, 0.27674323, 0.722014]]\n",
            "1316          [[0.0034860657, 0.28532133, 0.7111926]]\n",
            "1317      [[0.0002043624, 0.00035978813, 0.99943584]]\n",
            "1318       [[0.0003286176, 0.0002638095, 0.99940765]]\n",
            "1319      [[0.00020390055, 0.0011904564, 0.99860567]]\n",
            "1320     [[0.00016230943, 0.00017755589, 0.99966013]]\n",
            "1321       [[0.00013537501, 0.0016489206, 0.9982157]]\n",
            "1322         [[0.0009726107, 0.10874317, 0.89028424]]\n",
            "1323          [[0.0059149982, 0.7157931, 0.27829188]]\n",
            "1324          [[0.0010143095, 0.37680197, 0.6221837]]\n",
            "1325           [[0.0010714169, 0.2745877, 0.7243409]]\n",
            "1326       [[9.897988e-05, 0.99483156, 0.0050693913]]\n",
            "1327        [[0.00052869413, 0.009617458, 0.9898539]]\n",
            "1328        [[0.00020843088, 0.021401076, 0.9783905]]\n",
            "1329        [[0.00020784592, 0.034333505, 0.9654587]]\n",
            "1330          [[0.0002549768, 0.9387115, 0.06103348]]\n",
            "1331         [[0.00030373476, 0.00618401, 0.9935122]]\n",
            "1332       [[0.00012882764, 0.0051493673, 0.9947219]]\n",
            "1333       [[0.00033644313, 0.038278032, 0.96138555]]\n",
            "1334       [[3.3886372e-05, 0.9987734, 0.0011926485]]\n",
            "1335     [[0.000104864484, 0.00088812504, 0.9990069]]\n",
            "1336           [[0.8218487, 0.12609076, 0.052060507]]\n",
            "1337           [[0.0006534685, 0.40844056, 0.590906]]\n",
            "1338      [[0.00025616074, 0.00071575557, 0.9990281]]\n",
            "1339        [[0.0010805109, 0.0022379656, 0.9966815]]\n",
            "1340    [[0.000100919955, 0.00093576795, 0.99896336]]\n",
            "1341        [[0.0005804201, 0.0005119342, 0.9989077]]\n",
            "1342      [[0.00035484784, 0.0007880456, 0.99885714]]\n",
            "1343            [[0.11725393, 0.03485936, 0.8478866]]\n",
            "1344            [[0.2025786, 0.64729923, 0.15012223]]\n",
            "1345        [[0.00040786405, 0.80294937, 0.19664273]]\n",
            "1346        [[0.00026025283, 0.12970614, 0.87003356]]\n",
            "1347        [[0.00015644319, 0.004374979, 0.9954686]]\n",
            "1348        [[0.00019302295, 0.0010379364, 0.998769]]\n",
            "1349       [[0.000235715, 0.00075843197, 0.99900585]]\n",
            "1350        [[0.00040980644, 0.035343822, 0.9642464]]\n",
            "1351     [[0.00029976154, 0.00084801606, 0.99885225]]\n",
            "1352       [[0.00032124063, 0.008400432, 0.99127835]]\n",
            "1353        [[0.0014397098, 0.0009865506, 0.9975737]]\n",
            "1354       [[0.00055660156, 0.00020032897, 0.999243]]\n",
            "1355          [[0.002217527, 0.028936697, 0.9688458]]\n",
            "1356     [[0.00017450814, 0.00072503195, 0.99910057]]\n",
            "1357         [[0.0033468634, 0.88927186, 0.10738134]]\n",
            "1358      [[0.00035688205, 0.00023893881, 0.9994041]]\n",
            "1359        [[0.0001549208, 0.015525365, 0.98431975]]\n",
            "1360      [[0.00030122162, 0.0001948254, 0.99950397]]\n",
            "1361          [[0.0032455642, 0.03582398, 0.9609304]]\n",
            "1362             [[0.2917787, 0.3702068, 0.33801445]]\n",
            "1363        [[0.00024513644, 0.01756868, 0.98218614]]\n",
            "1364       [[0.00017019428, 0.0065990263, 0.9932308]]\n",
            "1365           [[0.00024252993, 0.7095535, 0.290204]]\n",
            "1366         [[0.0014582791, 0.76523954, 0.23330215]]\n",
            "1367     [[0.00042254635, 0.00037513225, 0.99920243]]\n",
            "1368          [[0.0003488734, 0.56400394, 0.4356472]]\n",
            "1369         [[0.00018963161, 0.8349432, 0.16486716]]\n",
            "1370      [[0.00056348625, 0.99764097, 0.0017955849]]\n",
            "1371       [[0.00012509164, 0.0057543805, 0.9941204]]\n",
            "1372      [[0.00027150076, 0.00031925688, 0.9994092]]\n",
            "1373       [[0.0023111815, 0.0010657824, 0.99662304]]\n",
            "1374       [[0.00014802697, 0.0058088508, 0.9940432]]\n",
            "1375        [[7.88001e-05, 0.99282634, 0.0070948307]]\n",
            "1376         [[0.00042049357, 0.7358876, 0.26369193]]\n",
            "1377       [[4.9581464e-05, 0.000834733, 0.99911577]]\n",
            "1378       [[5.857494e-05, 0.0006712721, 0.99927014]]\n",
            "1379       [[5.517276e-05, 0.00039954667, 0.9995453]]\n",
            "1380         [[0.84595495, 0.15255019, 0.0014948277]]\n",
            "1381        [[0.0005570286, 0.00043804522, 0.999005]]\n",
            "1382          [[0.9777763, 0.011505709, 0.010717884]]\n",
            "1383           [[0.4991844, 0.49275014, 0.008065417]]\n",
            "1384           [[0.47270995, 0.5044087, 0.022881316]]\n",
            "1385      [[0.00030569697, 0.0004671772, 0.99922717]]\n",
            "1386     [[0.00030576906, 0.00042966107, 0.99926454]]\n",
            "1387       [[0.00025397423, 0.016773479, 0.98297256]]\n",
            "1388        [[0.00049165677, 0.013018586, 0.9864898]]\n",
            "1389       [[0.00044699313, 0.0012238127, 0.9983292]]\n",
            "1390        [[0.00075800944, 0.9908117, 0.008430316]]\n",
            "1391       [[0.00030214823, 0.0005066989, 0.9991911]]\n",
            "1392       [[0.00017413663, 0.0073677325, 0.9924581]]\n",
            "1393     [[0.00035882136, 0.00018614669, 0.99945503]]\n",
            "1394       [[0.00025021122, 0.0002244293, 0.9995253]]\n",
            "1395         [[0.0009691336, 0.9682122, 0.030818643]]\n",
            "1396         [[0.0005120754, 0.9759728, 0.023515169]]\n",
            "1397         [[0.00042269423, 0.14335194, 0.8562254]]\n",
            "1398       [[0.00018401227, 0.023128597, 0.97668743]]\n",
            "1399        [[0.00013498821, 0.9846721, 0.015192833]]\n",
            "1400      [[7.5729244e-05, 0.99929726, 0.0006269514]]\n",
            "1401      [[0.00031213666, 0.00038422763, 0.9993037]]\n",
            "1402          [[0.000524843, 0.11529206, 0.88418317]]\n",
            "1403         [[0.0020979098, 0.01404244, 0.98385966]]\n",
            "1404       [[0.00018803163, 0.0019240075, 0.9978879]]\n",
            "1405          [[0.0059793578, 0.48260486, 0.5114157]]\n",
            "1406          [[0.043975912, 0.9540571, 0.001966995]]\n",
            "1407           [[0.45507306, 0.5369505, 0.007976416]]\n",
            "1408            [[0.000481836, 0.1344053, 0.8651129]]\n",
            "1409         [[0.0015136774, 0.9280874, 0.070398904]]\n",
            "1410          [[0.0010155465, 0.2581178, 0.74086666]]\n",
            "1411         [[0.00069916126, 0.6851928, 0.31410804]]\n",
            "1412           [[0.00035581, 0.71032983, 0.28931436]]\n",
            "1413      [[0.00016480163, 0.00022265488, 0.9996126]]\n",
            "1414      [[0.00012909531, 0.00017574886, 0.9996952]]\n",
            "1415        [[0.00011272317, 0.009977781, 0.9899095]]\n",
            "1416          [[0.0009863182, 0.22368549, 0.7753282]]\n",
            "1417         [[0.0016213075, 0.99557436, 0.00280431]]\n",
            "1418       [[0.00019614026, 0.0002570908, 0.9995467]]\n",
            "1419      [[0.00011751902, 0.0009351004, 0.99894744]]\n",
            "1420        [[0.0004366547, 0.0031173346, 0.9964461]]\n",
            "1421       [[0.0001036366, 0.0025833577, 0.99731296]]\n",
            "1422      [[5.7540336e-05, 0.0017148147, 0.99822766]]\n",
            "1423           [[0.0048907967, 0.929702, 0.06540724]]\n",
            "1424         [[0.038571537, 0.95608103, 0.005347495]]\n",
            "1425         [[0.00019099642, 0.03267581, 0.9671331]]\n",
            "1426         [[0.0008291209, 0.008512314, 0.9906585]]\n",
            "1427        [[0.00021678073, 0.010719355, 0.9890638]]\n",
            "1428         [[0.0019848868, 0.21192677, 0.78608835]]\n",
            "1429         [[0.0014546161, 0.076283336, 0.9222621]]\n",
            "1430        [[0.0014498468, 0.013600614, 0.98494947]]\n",
            "1431    [[0.00027135652, 0.000114720446, 0.99961394]]\n",
            "1432       [[0.0014701709, 0.0021820248, 0.99634784]]\n",
            "1433          [[0.0032071422, 0.48399276, 0.5128001]]\n",
            "1434          [[0.0018163559, 0.11238092, 0.8858027]]\n",
            "1435          [[0.0007595388, 0.00700446, 0.9922361]]\n",
            "1436         [[0.0029237936, 0.50998724, 0.48708895]]\n",
            "1437        [[0.00052086526, 0.044909928, 0.9545692]]\n",
            "1438        [[5.937547e-05, 0.0012215212, 0.9987191]]\n",
            "1439        [[0.0013495209, 0.023743864, 0.97490656]]\n",
            "1440       [[0.00015372783, 0.0043954058, 0.9954509]]\n",
            "1441           [[0.0005968714, 0.87699, 0.122413054]]\n",
            "1442           [[0.0014618492, 0.663765, 0.33477315]]\n",
            "1443           [[0.001399725, 0.15762946, 0.8409708]]\n",
            "1444            [[0.004338486, 0.6605054, 0.3351561]]\n",
            "1445         [[0.00040456967, 0.11312581, 0.8864696]]\n",
            "1446      [[0.0005732956, 0.00031492597, 0.99911183]]\n",
            "1447       [[0.00029242982, 0.0005252196, 0.9991824]]\n",
            "1448      [[0.00051499315, 0.0028307748, 0.99665415]]\n",
            "1449         [[0.047507457, 0.014064213, 0.93842834]]\n",
            "1450        [[0.00021347191, 0.018837286, 0.9809492]]\n",
            "1451       [[0.00012694891, 0.068364486, 0.93150854]]\n",
            "1452         [[0.00039332532, 0.1598346, 0.83977205]]\n",
            "1453       [[6.389952e-05, 0.99895394, 0.0009821609]]\n",
            "1454       [[0.00026632322, 0.94169843, 0.058035307]]\n",
            "1455      [[0.00017867306, 0.0027386295, 0.99708265]]\n",
            "1456        [[0.0033873552, 0.98594356, 0.010669068]]\n",
            "1457        [[0.00050799217, 0.9886129, 0.010879052]]\n",
            "1458          [[0.0008448103, 0.0905256, 0.90862966]]\n",
            "1459       [[0.0002189481, 0.00038842284, 0.9993926]]\n",
            "1460     [[0.00018304675, 0.00082715164, 0.99898976]]\n",
            "1461      [[0.00017575636, 0.00018473147, 0.9996395]]\n",
            "1462       [[6.739006e-05, 0.00025899804, 0.9996737]]\n",
            "1463       [[0.00023071878, 0.0034004508, 0.9963689]]\n",
            "1464      [[0.00010300931, 0.0037951393, 0.99610186]]\n",
            "1465          [[8.240929e-05, 0.07511983, 0.9247977]]\n",
            "1466          [[9.555461e-05, 0.24299958, 0.7569049]]\n",
            "1467       [[2.6273774e-05, 0.022304103, 0.97766966]]\n",
            "1468      [[2.6938382e-05, 0.0010531365, 0.99891996]]\n",
            "1469       [[0.00013510173, 0.0002783411, 0.9995865]]\n",
            "1470       [[0.00037769487, 0.0006259245, 0.9989963]]\n",
            "1471       [[0.00023804785, 0.0046492065, 0.9951127]]\n",
            "1472       [[0.00039864954, 0.013582784, 0.98601854]]\n",
            "1473          [[0.8458063, 0.117926866, 0.036266774]]\n",
            "1474      [[0.00020093049, 0.00014171674, 0.9996574]]\n",
            "1475      [[0.00016444449, 0.0005803486, 0.99925524]]\n",
            "1476            [[0.032538675, 0.4726935, 0.4947678]]\n",
            "1477       [[7.528955e-05, 0.00018493966, 0.9997397]]\n",
            "1478         [[0.0006807715, 0.32368672, 0.67563254]]\n",
            "1479          [[0.9377031, 0.05998246, 0.0023144463]]\n",
            "1480         [[0.018953854, 0.96657974, 0.014466403]]\n",
            "1481           [[0.10477738, 0.050146334, 0.8450763]]\n",
            "1482          [[0.76381683, 0.23184407, 0.004339096]]\n",
            "1483           [[0.7310233, 0.26543793, 0.003538799]]\n",
            "1484             [[0.4241382, 0.03348647, 0.5423753]]\n",
            "1485          [[0.45284298, 0.53909206, 0.008064982]]\n",
            "1486            [[0.31384012, 0.6145432, 0.07161663]]\n",
            "1487            [[0.8500786, 0.1022112, 0.047710188]]\n",
            "1488         [[0.009828077, 0.011803853, 0.97836804]]\n",
            "1489          [[0.12655392, 0.86869645, 0.004749675]]\n",
            "1490            [[0.2765804, 0.69942915, 0.02399044]]\n",
            "1491        [[0.00040022476, 0.008155426, 0.9914444]]\n",
            "1492        [[0.0011278827, 0.0027587973, 0.9961133]]\n",
            "1493       [[0.00037075087, 0.0060351947, 0.9935941]]\n",
            "1494       [[0.0004974022, 0.0011329722, 0.99836963]]\n",
            "1495         [[0.0002462119, 0.19905433, 0.80069953]]\n",
            "1496         [[0.00044114908, 0.38742128, 0.6121376]]\n",
            "1497         [[0.0015838369, 0.9888659, 0.009550292]]\n",
            "1498        [[0.02514476, 0.97447395, 0.00038129932]]\n",
            "1499        [[0.0027013517, 0.99318165, 0.004116951]]\n",
            "1500       [[0.00016258236, 0.0005968786, 0.9992405]]\n",
            "1501       [[0.00020207894, 0.00045297475, 0.999345]]\n",
            "1502        [[0.00024931418, 0.028189864, 0.9715607]]\n",
            "1503       [[0.00014656258, 0.0022821387, 0.9975713]]\n",
            "1504      [[0.00027941362, 0.00061645504, 0.9991041]]\n",
            "1505     [[0.00010234957, 0.00045429045, 0.99944335]]\n",
            "1506      [[0.00031003603, 0.00025817988, 0.9994318]]\n",
            "1507       [[0.0002070799, 0.00031276752, 0.9994802]]\n",
            "1508        [[0.00039637458, 0.19649173, 0.80311185]]\n",
            "1509       [[0.00011193034, 0.009884349, 0.99000376]]\n",
            "1510        [[0.00027216287, 0.02338516, 0.97634274]]\n",
            "1511       [[0.0004700532, 0.0046023326, 0.99492764]]\n",
            "1512     [[6.991472e-05, 0.000118795964, 0.99981123]]\n",
            "1513     [[0.00021771117, 0.00044259825, 0.99933964]]\n",
            "1514     [[8.8491644e-05, 0.00024320783, 0.99966824]]\n",
            "1515      [[0.00013649712, 0.00081273034, 0.9990508]]\n",
            "1516      [[0.00017536242, 0.00032788393, 0.9994967]]\n",
            "1517       [[6.282709e-05, 0.0008646783, 0.99907243]]\n",
            "1518     [[0.00012535405, 0.00035916574, 0.99951553]]\n",
            "1519             [[0.44131133, 0.07118464, 0.487504]]\n",
            "1520           [[0.46877664, 0.25638616, 0.27483717]]\n",
            "1521             [[0.3280529, 0.2133495, 0.45859766]]\n",
            "1522        [[0.034910865, 0.96005505, 0.0050340407]]\n",
            "1523      [[0.00076153403, 0.0009334667, 0.99830496]]\n",
            "1524        [[0.0012657997, 0.0026959933, 0.9960381]]\n",
            "1525          [[0.0013714958, 0.32004702, 0.6785815]]\n",
            "1526           [[0.9004719, 0.012781916, 0.08674615]]\n",
            "1527       [[0.0004386711, 0.0008624355, 0.99869883]]\n",
            "1528         [[0.0037984701, 0.34916276, 0.64703876]]\n",
            "1529         [[0.0022356429, 0.008876116, 0.9888882]]\n",
            "1530         [[0.0022356429, 0.008876116, 0.9888882]]\n",
            "1531      [[0.00015563829, 0.0005089784, 0.99933547]]\n",
            "1532      [[0.00012350682, 0.00056862086, 0.9993079]]\n",
            "1533        [[0.00033265643, 0.002776759, 0.9968906]]\n",
            "1534        [[0.0004057542, 0.053825863, 0.94576836]]\n",
            "1535         [[0.00043210958, 0.008541805, 0.991026]]\n",
            "1536            [[0.14795807, 0.7387637, 0.11327824]]\n",
            "1537           [[0.08574895, 0.82159656, 0.09265449]]\n",
            "1538           [[0.23168461, 0.7336343, 0.034681085]]\n",
            "1539      [[0.0006913883, 0.00064014073, 0.99866843]]\n",
            "1540        [[0.00026405248, 0.005755598, 0.9939804]]\n",
            "1541      [[0.00026849483, 0.0017843614, 0.99794716]]\n",
            "1542        [[0.0002810294, 0.007492139, 0.99222684]]\n",
            "1543       [[0.00017983268, 0.0011152907, 0.9987048]]\n",
            "1544          [[0.0005496901, 0.016374227, 0.983076]]\n",
            "1545        [[0.00046198367, 0.005684838, 0.9938532]]\n",
            "1546       [[0.00040544773, 0.0005681721, 0.9990264]]\n",
            "1547      [[0.00012276239, 0.00079557876, 0.9990816]]\n",
            "1548     [[0.00012867822, 0.000109731336, 0.9997615]]\n",
            "1549           [[0.009082552, 0.3703031, 0.62061435]]\n",
            "1550          [[0.003021159, 0.96279705, 0.03418176]]\n",
            "1551       [[0.00045431912, 0.001212015, 0.99833375]]\n",
            "1552         [[0.0005227074, 0.01905449, 0.98042285]]\n",
            "1553      [[0.0007772566, 0.00024502265, 0.99897766]]\n",
            "1554     [[0.00017127334, 0.00032167856, 0.99950707]]\n",
            "1555        [[0.0004924805, 0.0007970515, 0.9987104]]\n",
            "1556       [[0.00040334306, 0.0041748853, 0.9954217]]\n",
            "1557       [[0.00019443732, 0.0002938361, 0.9995117]]\n",
            "1558          [[0.018736063, 0.15510124, 0.82616276]]\n",
            "1559         [[0.00092385337, 0.060012117, 0.939064]]\n",
            "1560       [[0.00012413053, 0.9990544, 0.0008214615]]\n",
            "1561           [[0.0007134116, 0.94883, 0.050456606]]\n",
            "1562          [[0.0037396306, 0.8213183, 0.17494202]]\n",
            "1563      [[0.00026232775, 0.0028271656, 0.99691063]]\n",
            "1564            [[0.0033486, 0.03463972, 0.96201164]]\n",
            "1565         [[0.0005849625, 0.009956115, 0.9894589]]\n",
            "1566        [[0.0007214623, 0.9941531, 0.0051254514]]\n",
            "1567           [[0.13552296, 0.7409375, 0.123539604]]\n",
            "1568     [[2.0803565e-05, 0.99926764, 0.00071158237]]\n",
            "1569      [[2.4051322e-05, 0.99926406, 0.0007118873]]\n",
            "1570         [[9.999095e-05, 0.9842874, 0.015612641]]\n",
            "1571       [[0.00013729694, 0.030600507, 0.96926224]]\n",
            "1572        [[0.0005709131, 0.95698804, 0.042441037]]\n",
            "1573        [[0.00065219053, 0.9578279, 0.041519854]]\n",
            "1574         [[0.90396535, 0.032473326, 0.063561276]]\n",
            "1575          [[0.18898863, 0.009835074, 0.80117625]]\n",
            "1576         [[0.9910426, 0.007535019, 0.0014222828]]\n",
            "1577           [[0.993068, 0.0028997571, 0.00403226]]\n",
            "1578        [[0.0015846556, 0.0004584371, 0.9979569]]\n",
            "1579    [[0.000104078885, 0.00019914817, 0.99969685]]\n",
            "1580        [[8.32516e-05, 0.00025688187, 0.9996598]]\n",
            "1581         [[0.00011363814, 0.025320359, 0.974566]]\n",
            "1582       [[0.000117399555, 0.004482746, 0.9953999]]\n",
            "1583          [[0.0012936858, 0.6727603, 0.32594603]]\n",
            "1584          [[0.0016730527, 0.0534914, 0.94483554]]\n",
            "1585            [[0.09241496, 0.53176016, 0.3758249]]\n",
            "1586      [[0.0002694778, 0.00053307123, 0.99919754]]\n",
            "1587          [[0.008043891, 0.9677921, 0.024164006]]\n",
            "1588         [[0.001975887, 0.96193016, 0.036094025]]\n",
            "1589          [[0.009936046, 0.011361268, 0.9787027]]\n",
            "1590         [[0.000495817, 0.0008177034, 0.9986865]]\n",
            "1591        [[0.00043719454, 0.012936653, 0.9866261]]\n",
            "1592            [[0.19581486, 0.6317491, 0.17243612]]\n",
            "1593              [[0.10645054, 0.5033005, 0.390249]]\n",
            "1594             [[0.019752994, 0.026447015, 0.9538]]\n",
            "1595       [[0.00019636925, 0.0045671593, 0.9952366]]\n",
            "1596            [[0.004082443, 0.15521258, 0.840705]]\n",
            "1597       [[0.00047810192, 0.97801363, 0.021508206]]\n",
            "1598         [[0.0012585999, 0.9824818, 0.016259637]]\n",
            "1599        [[6.3977546e-05, 0.9915456, 0.008390401]]\n",
            "1600        [[7.046389e-05, 0.98445547, 0.015474103]]\n",
            "1601       [[4.8750615e-05, 0.9943684, 0.0055828798]]\n",
            "1602       [[0.00023788908, 0.0029755016, 0.9967866]]\n",
            "1603       [[2.9783945e-05, 0.9978415, 0.0021287485]]\n",
            "1604     [[0.00015229777, 0.00043701156, 0.99941075]]\n",
            "1605         [[0.0046690754, 0.04145066, 0.95388025]]\n",
            "1606        [[0.0007953985, 0.0029760117, 0.9962286]]\n",
            "1607        [[0.00039626553, 0.019261008, 0.9803427]]\n",
            "1608          [[0.9864807, 0.004890317, 0.008628943]]\n",
            "1609             [[0.875997, 0.07518091, 0.04882204]]\n",
            "1610          [[0.010351655, 0.40485904, 0.58478934]]\n",
            "1611          [[0.00106755, 0.98798275, 0.010949706]]\n",
            "1612        [[0.00081342226, 0.92967933, 0.06950729]]\n",
            "1613      [[0.00026432192, 0.00091244385, 0.9988232]]\n",
            "1614      [[0.00042953787, 0.0021982882, 0.99737215]]\n",
            "1615      [[0.000112574155, 0.0011059842, 0.9987815]]\n",
            "1616         [[0.0001726861, 0.035516724, 0.9643106]]\n",
            "1617       [[6.234408e-05, 0.00045879092, 0.9994789]]\n",
            "1618      [[0.00018621478, 0.0019440951, 0.99786973]]\n",
            "1619     [[0.00017880904, 0.00019569772, 0.99962544]]\n",
            "1620        [[0.0016959178, 0.0014238494, 0.9968803]]\n",
            "1621          [[0.0021308702, 0.04600398, 0.9518652]]\n",
            "1622      [[0.00024029514, 0.00072107004, 0.9990386]]\n",
            "1623      [[0.00028291866, 0.00043126862, 0.9992859]]\n",
            "1624      [[0.00023761041, 0.0009880003, 0.99877435]]\n",
            "1625        [[0.00034987062, 0.015611171, 0.9840389]]\n",
            "1626        [[0.00031629804, 0.0010457614, 0.998638]]\n",
            "1627      [[0.000118062366, 0.0004667258, 0.9994153]]\n",
            "1628      [[0.0002032332, 0.00010068758, 0.99969614]]\n",
            "1629      [[0.00030702824, 0.00025373776, 0.9994392]]\n",
            "1630      [[0.00014277878, 0.0004002558, 0.99945706]]\n",
            "1631        [[0.00024414418, 0.007172437, 0.9925835]]\n",
            "1632        [[0.0001823055, 0.015448464, 0.98436916]]\n",
            "1633       [[0.00014710105, 0.0014427409, 0.9984101]]\n",
            "1634       [[8.4657084e-05, 0.0037162686, 0.9961991]]\n",
            "1635      [[0.00033133282, 0.0005559438, 0.99911267]]\n",
            "1636       [[0.00052452827, 0.0024496021, 0.9970259]]\n",
            "1637         [[0.0077162436, 0.9318028, 0.060480893]]\n",
            "1638        [[0.00015149987, 0.998417, 0.0014315055]]\n",
            "1639        [[5.6438377e-05, 0.998458, 0.0014855523]]\n",
            "1640             [[0.21982187, 0.076166, 0.70401216]]\n",
            "1641       [[0.00013337393, 0.0014313338, 0.9984352]]\n",
            "1642         [[0.0008096482, 0.09457968, 0.90461063]]\n",
            "1643         [[0.0008813423, 0.006470352, 0.9926483]]\n",
            "1644         [[0.0011922157, 0.84630424, 0.15250354]]\n",
            "1645          [[0.0029471733, 0.5376949, 0.45935798]]\n",
            "1646       [[0.0011466426, 0.00070653216, 0.9981468]]\n",
            "1647          [[0.004214791, 0.004549835, 0.9912354]]\n",
            "1648          [[0.012034197, 0.84521055, 0.14275526]]\n",
            "1649         [[0.00064994383, 0.7845669, 0.21478315]]\n",
            "1650        [[0.00087418914, 0.18575226, 0.81337357]]\n",
            "1651       [[0.00013800118, 0.92273104, 0.077130966]]\n",
            "1652         [[0.00041319302, 0.04213614, 0.9574506]]\n",
            "1653        [[0.0002680861, 0.0004927521, 0.9992391]]\n",
            "1654      [[0.00022146471, 0.00010115307, 0.9996774]]\n",
            "1655        [[0.0013206946, 0.002664125, 0.99601513]]\n",
            "1656        [[0.0003134002, 0.0032054603, 0.9964812]]\n",
            "1657            [[0.04976541, 0.6547248, 0.29550982]]\n",
            "1658       [[9.695865e-05, 0.00015459277, 0.9997484]]\n",
            "1659    [[0.00015918355, 0.000119957775, 0.99972075]]\n",
            "1660       [[0.0001427423, 0.0005631009, 0.99929416]]\n",
            "1661       [[0.00010705857, 0.0005400606, 0.9993529]]\n",
            "1662           [[0.0011940266, 0.7383733, 0.2604327]]\n",
            "1663       [[0.00027337257, 0.050248608, 0.94947803]]\n",
            "1664         [[0.00036644816, 0.09384496, 0.9057886]]\n",
            "1665          [[0.0012961588, 0.003441768, 0.995262]]\n",
            "1666       [[0.00045255016, 0.010337148, 0.98921025]]\n",
            "1667       [[0.00015066881, 0.008584707, 0.99126464]]\n",
            "1668        [[0.0033643898, 0.007514747, 0.98912084]]\n",
            "1669           [[0.002542351, 0.8302891, 0.16716848]]\n",
            "1670      [[0.00016657324, 0.0012604361, 0.99857306]]\n",
            "1671      [[0.00056471507, 0.0050426633, 0.99439263]]\n",
            "1672           [[0.0039860695, 0.5822724, 0.4137415]]\n",
            "1673         [[0.0005364097, 0.9835698, 0.015893763]]\n",
            "1674        [[0.00058931473, 0.9895918, 0.009818985]]\n",
            "1675             [[0.15936942, 0.5086809, 0.3319497]]\n",
            "1676         [[0.003003893, 0.98364323, 0.013352883]]\n",
            "1677           [[0.007997493, 0.34135407, 0.6506484]]\n",
            "1678          [[0.028190356, 0.8868746, 0.084935054]]\n",
            "1679            [[0.010634442, 0.4861647, 0.5032009]]\n",
            "1680      [[0.00033171332, 0.00043608053, 0.9992322]]\n",
            "1681         [[0.0009725895, 0.015092846, 0.9839346]]\n",
            "1682        [[0.0003607453, 0.0010542036, 0.9985851]]\n",
            "1683     [[0.00024338461, 0.00014760363, 0.99960905]]\n",
            "1684       [[0.00063675654, 0.0003229813, 0.9990402]]\n",
            "1685          [[0.9855306, 0.010633812, 0.003835512]]\n",
            "1686        [[0.0001426824, 0.0009300749, 0.9989273]]\n",
            "1687       [[0.00023071705, 0.002259427, 0.99750984]]\n",
            "1688       [[0.0020449099, 0.0013127504, 0.99664235]]\n",
            "1689       [[0.0005254034, 0.00046612538, 0.9990085]]\n",
            "1690        [[0.0006001442, 0.002132102, 0.99726784]]\n",
            "1691           [[0.019422812, 0.57883453, 0.4017426]]\n",
            "1692            [[0.0658855, 0.9224797, 0.011634736]]\n",
            "1693       [[0.00032407115, 0.048417192, 0.95125866]]\n",
            "1694          [[0.8998033, 0.095997594, 0.004199105]]\n",
            "1695       [[0.00032149345, 0.0041246694, 0.9955538]]\n",
            "1696      [[0.00017632321, 0.00017106613, 0.9996525]]\n",
            "1697         [[0.0101497285, 0.027629979, 0.9622203]]\n",
            "1698         [[0.0040660817, 0.35711783, 0.63881606]]\n",
            "1699       [[0.00020222967, 0.00027182527, 0.999526]]\n",
            "1700       [[0.00017537436, 0.0071490733, 0.9926756]]\n",
            "1701        [[0.00070473313, 0.088291526, 0.9110037]]\n",
            "1702        [[0.00020307432, 0.93622315, 0.06357376]]\n",
            "1703           [[0.00020984093, 0.67336, 0.32643014]]\n",
            "1704       [[0.00029218773, 0.98466265, 0.015045157]]\n",
            "1705      [[0.00023169446, 0.0017999499, 0.99796826]]\n",
            "1706       [[0.00039211236, 0.030838143, 0.96876985]]\n",
            "1707        [[0.00013270769, 0.025862228, 0.9740051]]\n",
            "1708         [[0.0004834894, 0.48357728, 0.51593924]]\n",
            "1709           [[0.10927512, 0.74038917, 0.15033574]]\n",
            "1710             [[0.2904303, 0.6550951, 0.05447457]]\n",
            "1711            [[0.8985691, 0.07804532, 0.02338557]]\n",
            "1712            [[0.06874807, 0.7796417, 0.15161017]]\n",
            "1713       [[0.00018498849, 0.009252703, 0.99056226]]\n",
            "1714       [[0.00047137562, 0.046947554, 0.95258105]]\n",
            "1715          [[0.9535632, 0.024758302, 0.021678442]]\n",
            "1716        [[0.00013312357, 0.007387087, 0.9924798]]\n",
            "1717           [[0.013624498, 0.11419964, 0.8721758]]\n",
            "1718     [[0.00014304601, 0.00043814385, 0.99941874]]\n",
            "1719       [[0.00014487775, 0.0016613272, 0.9981938]]\n",
            "1720           [[0.8879576, 0.03631241, 0.075730056]]\n",
            "1721              [[0.10712047, 0.5927475, 0.300132]]\n",
            "1722          [[0.0006625992, 0.5696788, 0.42965856]]\n",
            "1723     [[0.00081302336, 0.00045293212, 0.99873406]]\n",
            "1724        [[0.00038914845, 0.55424756, 0.44536328]]\n",
            "1725       [[0.00086167257, 0.0004115199, 0.9987269]]\n",
            "1726            [[0.18260913, 0.24125327, 0.5761376]]\n",
            "1727       [[0.00024445297, 0.0005137459, 0.9992418]]\n",
            "1728           [[0.89320576, 0.02965083, 0.07714339]]\n",
            "1729           [[0.8406642, 0.14669673, 0.012639104]]\n",
            "1730       [[5.8589972e-05, 0.0077419654, 0.9921995]]\n",
            "1731        [[8.619865e-05, 0.0004257761, 0.9994881]]\n",
            "1732       [[0.0004971637, 0.00056081114, 0.9989421]]\n",
            "1733          [[0.0025261508, 0.5833255, 0.41414833]]\n",
            "1734        [[0.0003644309, 0.056846272, 0.94278926]]\n",
            "1735         [[0.013723062, 0.93623245, 0.050044518]]\n",
            "1736        [[0.00059647835, 0.016615871, 0.9827877]]\n",
            "1737      [[7.660892e-05, 0.00020274705, 0.99972063]]\n",
            "1738     [[0.00023206163, 0.00026286702, 0.99950504]]\n",
            "1739         [[0.0002026534, 0.44433418, 0.55546314]]\n",
            "1740          [[0.0001869807, 0.16008638, 0.8397266]]\n",
            "1741           [[0.01168502, 0.42187932, 0.56643564]]\n",
            "1742          [[0.0069067366, 0.8364022, 0.15669103]]\n",
            "1743          [[0.006251802, 0.9750284, 0.018719846]]\n",
            "1744       [[0.00020752483, 0.0015006985, 0.9982918]]\n",
            "1745     [[0.000109088105, 0.00067338755, 0.9992175]]\n",
            "1746      [[0.00019901746, 0.00013975505, 0.9996612]]\n",
            "1747        [[0.0001173665, 0.0013931126, 0.9984895]]\n",
            "1748            [[0.054318164, 0.642356, 0.30332583]]\n",
            "1749              [[0.229757, 0.5921446, 0.17809846]]\n",
            "1750          [[0.55325174, 0.34177604, 0.104972206]]\n",
            "1751         [[0.0021041771, 0.010789591, 0.9871062]]\n",
            "1752      [[0.00022261598, 0.00039169003, 0.9993856]]\n",
            "1753        [[0.0004023422, 0.034113467, 0.96548414]]\n",
            "1754          [[0.035412233, 0.9485186, 0.016069211]]\n",
            "1755           [[0.52499044, 0.38364553, 0.09136405]]\n",
            "1756         [[0.018422792, 0.92016065, 0.061416533]]\n",
            "1757          [[0.0046911477, 0.3402022, 0.65510666]]\n",
            "1758       [[0.0003221829, 0.00013768274, 0.9995402]]\n",
            "1759         [[0.0005183568, 0.9577352, 0.041746456]]\n",
            "1760        [[0.00036652663, 0.37051496, 0.62911856]]\n",
            "1761       [[6.989477e-05, 0.0020260978, 0.99790394]]\n",
            "1762        [[0.0003375567, 0.064077586, 0.93558484]]\n",
            "1763        [[0.0003200766, 0.068090044, 0.93158984]]\n",
            "1764       [[0.0003780271, 0.0053358003, 0.99428624]]\n",
            "1765        [[0.0006445569, 0.062590346, 0.93676513]]\n",
            "1766      [[4.2785905e-05, 0.0011748057, 0.99878246]]\n",
            "1767          [[0.00040291445, 0.2332416, 0.7663555]]\n",
            "1768         [[9.348267e-05, 0.0008604626, 0.999046]]\n",
            "1769        [[7.886843e-05, 0.0007661889, 0.9991549]]\n",
            "1770       [[3.769479e-05, 0.0014443077, 0.99851793]]\n",
            "1771         [[0.00048274992, 0.8978901, 0.10162713]]\n",
            "1772          [[0.0013314567, 0.18229835, 0.8163702]]\n",
            "1773          [[0.9622305, 0.009899986, 0.027869528]]\n",
            "1774         [[0.00023954755, 0.32035133, 0.6794091]]\n",
            "1775        [[0.00070946274, 0.014832968, 0.9844577]]\n",
            "1776         [[0.0006384898, 0.05368103, 0.94568044]]\n",
            "1777       [[0.00031054585, 0.0026310857, 0.9970584]]\n",
            "1778       [[0.00033519772, 0.0036597445, 0.9960051]]\n",
            "1779            [[0.0008673925, 0.09828265, 0.90085]]\n",
            "1780           [[0.0019991687, 0.3478461, 0.6501548]]\n",
            "1781           [[0.001731138, 0.9239021, 0.07436679]]\n",
            "1782        [[0.0002188053, 0.0012536589, 0.9985275]]\n",
            "1783      [[8.577405e-05, 0.00052023825, 0.99939394]]\n",
            "1784         [[0.0003712363, 0.025392309, 0.9742364]]\n",
            "1785        [[0.00047060248, 0.45901012, 0.54051924]]\n",
            "1786          [[7.077474e-05, 0.00373776, 0.9961915]]\n",
            "1787       [[0.00011897215, 0.005911007, 0.99397004]]\n",
            "1788      [[4.3402575e-05, 0.0017167606, 0.99823976]]\n",
            "1789         [[9.905486e-05, 0.006578621, 0.9933223]]\n",
            "1790         [[0.0003390751, 0.041108813, 0.9585521]]\n",
            "1791             [[0.0309233, 0.36045513, 0.6086216]]\n",
            "1792          [[0.0008475033, 0.05122076, 0.9479317]]\n",
            "1793          [[0.000889362, 0.06820206, 0.93090856]]\n",
            "1794           [[0.006089564, 0.7525957, 0.24131474]]\n",
            "1795          [[0.040017042, 0.42664096, 0.53334194]]\n",
            "1796         [[0.0005505259, 0.058867205, 0.9405822]]\n",
            "1797       [[6.416027e-05, 0.0009502913, 0.99898547]]\n",
            "1798        [[0.00046231525, 0.039633386, 0.9599044]]\n",
            "1799        [[0.00019521518, 0.013766978, 0.9860378]]\n",
            "1800         [[0.00010981215, 0.0015501498, 0.99834]]\n",
            "1801      [[0.00037978537, 0.00048544238, 0.9991347]]\n",
            "1802         [[0.0019456063, 0.38032478, 0.61772954]]\n",
            "1803        [[0.00011937364, 0.00250013, 0.99738044]]\n",
            "1804       [[0.00030168693, 0.97534966, 0.024348652]]\n",
            "1805          [[0.00013462258, 0.8626847, 0.1371807]]\n",
            "1806         [[3.7121397e-05, 0.9006425, 0.09932029]]\n",
            "1807         [[9.8602424e-05, 0.6672831, 0.33261833]]\n",
            "1808       [[0.00046855013, 0.105660826, 0.89387065]]\n",
            "1809       [[0.00038709148, 0.0008327729, 0.9987802]]\n",
            "1810        [[0.00031108403, 0.011010727, 0.9886783]]\n",
            "1811        [[0.0022575953, 0.9901391, 0.0076032775]]\n",
            "1812        [[0.0020156156, 0.081250556, 0.91673386]]\n",
            "1813       [[0.0005633066, 0.00096978014, 0.9984668]]\n",
            "1814        [[0.00053946604, 0.043008327, 0.9564522]]\n",
            "1815          [[0.023867795, 0.017612923, 0.9585193]]\n",
            "1816      [[0.00083501753, 0.0003990701, 0.99876595]]\n",
            "1817      [[0.00056975026, 0.00073519826, 0.9986951]]\n",
            "1818          [[0.000545014, 0.0025059506, 0.996949]]\n",
            "1819            [[0.4174458, 0.16377033, 0.41878384]]\n",
            "1820       [[0.0005878367, 0.00029788952, 0.9991142]]\n",
            "1821        [[0.00023043637, 0.005269266, 0.9945003]]\n",
            "1822      [[0.0026350191, 0.00076120056, 0.99660385]]\n",
            "1823          [[0.011206947, 0.49436125, 0.49443173]]\n",
            "1824         [[0.94140714, 0.023371141, 0.035221647]]\n",
            "1825        [[0.00010155293, 0.0041944054, 0.995704]]\n",
            "1826          [[0.0036410864, 0.23569876, 0.7606602]]\n",
            "1827          [[0.0027259153, 0.6912867, 0.30598742]]\n",
            "1828          [[0.0013592349, 0.8480705, 0.15057021]]\n",
            "1829          [[0.07025018, 0.0057114437, 0.9240384]]\n",
            "1830           [[0.08656248, 0.8783336, 0.035103917]]\n",
            "1831      [[0.0009040502, 0.00023563302, 0.99886036]]\n",
            "1832       [[0.00022543405, 0.0015345268, 0.9982401]]\n",
            "1833       [[0.0002513102, 0.0063361847, 0.99341255]]\n",
            "1834       [[0.00025637625, 0.005597981, 0.99414563]]\n",
            "1835       [[0.0002679213, 9.721418e-05, 0.99963486]]\n",
            "1836            [[0.016322589, 0.2304605, 0.7532169]]\n",
            "1837        [[0.0024236273, 0.0058630896, 0.9917133]]\n",
            "1838             [[0.0736666, 0.7429883, 0.18334511]]\n",
            "1839            [[0.638112, 0.3604879, 0.0014001253]]\n",
            "1840      [[0.0001706278, 0.00013690026, 0.99969244]]\n",
            "1841        [[9.389092e-05, 0.0016654257, 0.9982407]]\n",
            "1842      [[0.00011031619, 0.0001290715, 0.99976057]]\n",
            "1843      [[0.00018294332, 0.00030186833, 0.9995153]]\n",
            "1844      [[0.00018375204, 0.00043819775, 0.9993781]]\n",
            "1845      [[0.00053295644, 0.00048751044, 0.9989795]]\n",
            "1846       [[0.00014224193, 0.0023908473, 0.9974669]]\n",
            "1847        [[0.00038273857, 0.016922371, 0.9826949]]\n",
            "1848         [[0.0004082884, 0.79820424, 0.20138748]]\n",
            "1849          [[0.0012823101, 0.19505535, 0.8036623]]\n",
            "1850           [[0.001767869, 0.5280312, 0.47020096]]\n",
            "1851          [[0.0003706074, 0.03931038, 0.9603191]]\n",
            "1852         [[0.00022565239, 0.00065502, 0.9991192]]\n",
            "1853       [[0.00046229988, 0.0015920328, 0.9979457]]\n",
            "1854        [[0.00042169538, 0.01012471, 0.98945355]]\n",
            "1855         [[0.043786056, 0.9548343, 0.0013796787]]\n",
            "1856         [[0.021461315, 0.0012796775, 0.9772589]]\n",
            "1857       [[0.00043736768, 0.0005296073, 0.9990331]]\n",
            "1858      [[0.00039444672, 0.00051483687, 0.9990907]]\n",
            "1859      [[0.00021021091, 0.0005538547, 0.99923587]]\n",
            "1860      [[0.00041867548, 0.00046469725, 0.9991166]]\n",
            "1861         [[0.0015329274, 0.010871705, 0.9875953]]\n",
            "1862           [[0.0038954995, 0.2915529, 0.7045516]]\n",
            "1863       [[0.0007733307, 0.0003730537, 0.99885356]]\n",
            "1864        [[0.00039962013, 0.000539553, 0.9990609]]\n",
            "1865               [[0.002631179, 0.0768, 0.9205688]]\n",
            "1866           [[0.001368362, 0.4407128, 0.55791885]]\n",
            "1867         [[0.00076390355, 0.12814075, 0.8710954]]\n",
            "1868         [[0.0020543158, 0.41124737, 0.58669823]]\n",
            "1869      [[0.00012027819, 0.0042170133, 0.99566275]]\n",
            "1870        [[0.00019305025, 0.039003048, 0.9608039]]\n",
            "1871        [[0.00016362949, 0.00038642425, 0.99945]]\n",
            "1872        [[0.00030688872, 0.02518501, 0.97450805]]\n",
            "1873      [[0.000113835595, 0.0021496098, 0.9977366]]\n",
            "1874         [[0.00029612138, 0.0009538644, 0.99875]]\n",
            "1875        [[0.00014352884, 0.021802561, 0.9780539]]\n",
            "1876          [[0.0009636612, 0.6790496, 0.31998676]]\n",
            "1877        [[0.00022282336, 0.004034121, 0.9957431]]\n",
            "1878        [[0.00015141361, 0.002313032, 0.9975356]]\n",
            "1879        [[0.00014184011, 0.009047043, 0.9908111]]\n",
            "1880       [[0.00046607293, 0.011264444, 0.98826945]]\n",
            "1881       [[0.0008608987, 0.0014324298, 0.99770665]]\n",
            "1882        [[0.00051096384, 0.011609232, 0.9878798]]\n",
            "1883       [[0.00028275163, 0.0015821153, 0.9981351]]\n",
            "1884         [[0.0003418313, 0.004918723, 0.9947395]]\n",
            "1885        [[0.00047860786, 0.006511568, 0.9930098]]\n",
            "1886           [[0.098511465, 0.8793832, 0.02210536]]\n",
            "1887            [[0.03460578, 0.7881251, 0.17726912]]\n",
            "1888         [[0.009840607, 0.0015006593, 0.9886587]]\n",
            "1889           [[0.9915985, 0.0051424, 0.0032590886]]\n",
            "1890           [[0.5518714, 0.41567236, 0.032456238]]\n",
            "1891      [[0.00019613178, 9.1570655e-05, 0.9997123]]\n",
            "1892       [[0.00031987688, 0.007316813, 0.99236333]]\n",
            "1893            [[0.042762354, 0.01894374, 0.938294]]\n",
            "1894        [[0.00019214787, 0.0012699091, 0.998538]]\n",
            "1895        [[0.00060738286, 0.012993219, 0.9863994]]\n",
            "1896      [[7.386107e-05, 0.00014150908, 0.99978465]]\n",
            "1897        [[0.0043660756, 0.9925592, 0.0030747082]]\n",
            "1898         [[0.016825652, 0.98175883, 0.001415458]]\n",
            "1899      [[0.0020165679, 0.99771345, 0.00026996975]]\n",
            "1900       [[0.0054517835, 0.9943668, 0.00018141925]]\n",
            "1901       [[0.00051170256, 8.857163e-05, 0.9993998]]\n",
            "1902      [[0.0001394373, 0.00046729637, 0.99939334]]\n",
            "1903           [[0.00858962, 0.004349469, 0.9870609]]\n",
            "1904           [[0.8415604, 0.013528475, 0.14491108]]\n",
            "1905         [[0.95383686, 0.0047230595, 0.04144015]]\n",
            "1906          [[0.04190112, 0.9577766, 0.0003223058]]\n",
            "1907     [[0.00019727233, 0.00094236137, 0.99886036]]\n",
            "1908        [[0.0006260707, 0.0022252619, 0.9971487]]\n",
            "1909         [[0.013670922, 0.038456522, 0.94787246]]\n",
            "1910       [[0.0005353636, 0.0007638308, 0.99870074]]\n",
            "1911      [[0.00019868385, 0.00024154413, 0.9995598]]\n",
            "1912        [[0.00068270304, 0.36072445, 0.63859284]]\n",
            "1913       [[0.00015061845, 0.0005258569, 0.9993236]]\n",
            "1914         [[0.000353601, 0.0009029178, 0.9987435]]\n",
            "1915     [[0.00023058218, 0.00018467802, 0.99958473]]\n",
            "1916      [[0.00025201513, 0.0011680805, 0.99857986]]\n",
            "1917         [[0.00032481196, 0.35896552, 0.6407097]]\n",
            "1918        [[0.00053926633, 0.9286532, 0.070807494]]\n",
            "1919      [[0.00022364082, 0.00013318274, 0.9996431]]\n",
            "1920           [[0.0012206887, 0.47949535, 0.519284]]\n",
            "1921         [[0.0024068772, 0.9402614, 0.057331745]]\n",
            "1922             [[0.2562327, 0.4577797, 0.28598762]]\n",
            "1923        [[0.00090029876, 0.37536818, 0.62373155]]\n",
            "1924       [[8.4431675e-05, 0.0058297096, 0.9940859]]\n",
            "1925     [[0.00015797516, 0.00027209244, 0.99956995]]\n",
            "1926      [[0.00013200419, 0.00034908295, 0.9995189]]\n",
            "1927         [[8.433097e-05, 0.0010806537, 0.998835]]\n",
            "1928        [[0.00015483309, 0.44766438, 0.55218077]]\n",
            "1929        [[0.00010420016, 0.01733224, 0.98256344]]\n",
            "1930        [[0.0005387889, 0.0014439732, 0.9980172]]\n",
            "1931      [[0.00021259021, 0.0016994353, 0.99808794]]\n",
            "1932       [[6.051609e-05, 0.0039289542, 0.99601054]]\n",
            "1933           [[0.06506844, 0.77535796, 0.15957357]]\n",
            "1934          [[0.040139556, 0.9383427, 0.021517782]]\n",
            "1935           [[0.02223944, 0.9699654, 0.007795132]]\n",
            "1936            [[0.09047743, 0.895966, 0.013556618]]\n",
            "1937      [[0.00034684816, 0.00046070892, 0.9991924]]\n",
            "1938          [[0.009403305, 0.90927666, 0.08132007]]\n",
            "1939     [[0.00016231403, 0.00016743687, 0.99967027]]\n",
            "1940         [[0.00073515746, 0.49125192, 0.5080129]]\n",
            "1941        [[0.0005040296, 0.012914915, 0.98658097]]\n",
            "1942       [[0.00017912783, 0.0016873039, 0.9981336]]\n",
            "1943          [[0.00031839707, 0.03689767, 0.962784]]\n",
            "1944       [[0.0003129958, 0.0028787758, 0.99680823]]\n",
            "1945           [[0.4410914, 0.082223855, 0.47668472]]\n",
            "1946      [[0.0002519852, 0.00022068433, 0.99952734]]\n",
            "1947       [[0.0006028266, 0.0017696418, 0.99762756]]\n",
            "1948           [[0.033514272, 0.4780407, 0.48844504]]\n",
            "1949         [[0.0008897053, 0.72537804, 0.27373222]]\n",
            "1950        [[0.00015635365, 0.002316822, 0.9975268]]\n",
            "1951        [[0.00021458276, 0.07425942, 0.92552596]]\n",
            "1952         [[0.0010473114, 0.022121036, 0.9768316]]\n",
            "1953      [[0.00027028105, 0.0013601192, 0.99836963]]\n",
            "1954        [[0.00015877762, 0.003091821, 0.9967494]]\n",
            "1955       [[6.501735e-05, 0.0013650524, 0.99856997]]\n",
            "1956       [[0.00014096619, 0.016248027, 0.98361105]]\n",
            "1957        [[0.00010515448, 0.17140955, 0.82848525]]\n",
            "1958        [[0.00018956947, 0.11896577, 0.88084465]]\n",
            "1959           [[0.047027256, 0.6634199, 0.28955284]]\n",
            "1960       [[0.0001585687, 0.9995683, 0.00027312202]]\n",
            "1961          [[0.00027001227, 0.0668523, 0.9328777]]\n",
            "1962         [[0.0003444439, 0.95182186, 0.04783371]]\n",
            "1963          [[0.000374757, 0.18616386, 0.81346136]]\n",
            "1964       [[0.0010599841, 0.00067787786, 0.9982622]]\n",
            "1965       [[0.0010599841, 0.00067787786, 0.9982622]]\n",
            "1966         [[0.0004331327, 0.035645656, 0.9639213]]\n",
            "1967         [[0.0002188393, 0.9646417, 0.035139516]]\n",
            "1968       [[0.00019108797, 0.98416686, 0.015642105]]\n",
            "1969           [[0.18222721, 0.60433376, 0.21343902]]\n",
            "1970         [[0.0050395243, 0.44862282, 0.54633766]]\n",
            "1971        [[6.853059e-05, 0.0007611639, 0.9991704]]\n",
            "1972       [[0.00019694144, 0.0077364747, 0.9920666]]\n",
            "1973        [[6.7214474e-05, 0.03486378, 0.96506906]]\n",
            "1974       [[4.846464e-05, 0.0014458082, 0.99850583]]\n",
            "1975         [[0.0013911733, 0.9216372, 0.076971605]]\n",
            "1976       [[9.5304036e-05, 0.048881575, 0.95102304]]\n",
            "1977           [[0.005584763, 0.7019001, 0.29251507]]\n",
            "1978         [[0.0012745388, 0.041990407, 0.9567351]]\n",
            "1979       [[0.00032891883, 0.031535793, 0.96813536]]\n",
            "1980          [[0.002021278, 0.008133959, 0.9898447]]\n",
            "1981       [[0.00033009754, 0.95417386, 0.045496065]]\n",
            "1982       [[0.00042802532, 0.0016265396, 0.9979455]]\n",
            "1983      [[0.00011761037, 0.0032598728, 0.99662256]]\n",
            "1984     [[6.2025996e-05, 4.2023523e-05, 0.99989593]]\n",
            "1985      [[0.00019857117, 0.00016893663, 0.9996325]]\n",
            "1986       [[0.00011440167, 0.0015395023, 0.9983461]]\n",
            "1987         [[6.896502e-05, 0.002205836, 0.9977252]]\n",
            "1988        [[0.00091052044, 0.9752686, 0.023820864]]\n",
            "1989         [[0.0022721891, 0.09043775, 0.90729004]]\n",
            "1990        [[0.00057146355, 0.70095116, 0.29847732]]\n",
            "1991            [[0.00155227, 0.8280843, 0.17036341]]\n",
            "1992         [[0.00014741122, 0.05125456, 0.9485979]]\n",
            "1993      [[0.00021348866, 0.00045062433, 0.9993358]]\n",
            "1994         [[0.00044276853, 0.8392953, 0.16026197]]\n",
            "1995        [[0.00022748398, 0.00989109, 0.98988134]]\n",
            "1996             [[0.008580224, 0.696507, 0.2949128]]\n",
            "1997         [[0.00017425435, 0.9574813, 0.04234443]]\n",
            "1998          [[0.002075168, 0.75415623, 0.24376854]]\n",
            "1999         [[0.00024694388, 0.6682971, 0.33145592]]\n",
            "2000           [[0.000802171, 0.8649158, 0.13428204]]\n",
            "2001         [[0.0010735906, 0.049995236, 0.9489311]]\n",
            "2002           [[0.001080388, 0.4397975, 0.55912215]]\n",
            "2003       [[0.0002764042, 0.98817354, 0.0115500325]]\n",
            "2004       [[0.00026825085, 0.98882014, 0.010911624]]\n",
            "2005      [[8.8293375e-05, 0.9989716, 0.00094012154]]\n",
            "2006         [[0.0002851229, 0.39328045, 0.60643446]]\n",
            "2007        [[0.0005566451, 0.0025884043, 0.9968549]]\n",
            "2008         [[0.03239919, 0.96477157, 0.0028292462]]\n",
            "2009           [[0.029449241, 0.3997701, 0.57078063]]\n",
            "2010           [[0.65293366, 0.3383248, 0.008741563]]\n",
            "2011           [[0.0001830275, 0.557415, 0.44240192]]\n",
            "2012      [[0.00025680984, 0.0011708539, 0.99857235]]\n",
            "2013      [[0.00016200062, 0.0043561477, 0.99548185]]\n",
            "2014      [[0.00056957605, 0.0100557245, 0.98937476]]\n",
            "2015           [[0.05363396, 0.15667787, 0.78968817]]\n",
            "2016      [[0.00062408973, 0.00027319323, 0.9991027]]\n",
            "2017            [[0.001209399, 0.3404514, 0.6583392]]\n",
            "2018            [[0.6271166, 0.22442065, 0.14846268]]\n",
            "2019          [[0.00022254205, 0.04934148, 0.950436]]\n",
            "2020      [[6.2691135e-05, 0.0072465283, 0.99269074]]\n",
            "2021       [[0.00013461053, 0.033065494, 0.96679986]]\n",
            "2022           [[0.09223661, 0.112198204, 0.7955652]]\n",
            "2023       [[0.00043380645, 0.0008478182, 0.9987184]]\n",
            "2024         [[0.0044376967, 0.012723658, 0.9828387]]\n",
            "2025       [[0.00033387388, 0.000983166, 0.99868304]]\n",
            "2026       [[0.0001713645, 0.0015028851, 0.99832577]]\n",
            "2027       [[0.00013255872, 0.0005956916, 0.9992717]]\n",
            "2028       [[0.00033871635, 0.022855258, 0.97680604]]\n",
            "2029        [[0.00010269988, 0.013093156, 0.9868041]]\n",
            "2030       [[0.00013211163, 0.008967747, 0.99090016]]\n",
            "2031           [[0.015634416, 0.23420662, 0.7501589]]\n",
            "2032          [[0.00082501076, 0.837448, 0.16172701]]\n",
            "2033          [[0.0017637453, 0.64835984, 0.3498764]]\n",
            "2034       [[0.000116048504, 0.012187073, 0.9876968]]\n",
            "2035         [[0.00012641554, 0.9202919, 0.07958172]]\n",
            "2036         [[6.9643436e-05, 0.5094091, 0.49052122]]\n",
            "2037          [[6.97728e-05, 0.52528834, 0.47464186]]\n",
            "2038        [[0.00010244886, 0.78405076, 0.21584682]]\n",
            "2039           [[8.120258e-05, 0.7370039, 0.2629149]]\n",
            "2040        [[0.00085230276, 0.16411588, 0.83503187]]\n",
            "2041        [[0.00022074333, 0.0027022616, 0.997077]]\n",
            "2042       [[0.00022499438, 0.023174718, 0.97660017]]\n",
            "2043      [[0.00090745266, 0.0016049746, 0.99748766]]\n",
            "2044           [[0.0004348875, 0.3513277, 0.6482374]]\n",
            "2045         [[0.00039745672, 0.5300093, 0.46959323]]\n",
            "2046      [[0.000102620994, 0.97718656, 0.022710843]]\n",
            "2047        [[0.00028801183, 0.067856714, 0.9318552]]\n",
            "2048         [[0.75974816, 0.23815706, 0.0020947321]]\n",
            "2049          [[0.9053385, 0.087607145, 0.007054267]]\n",
            "2050      [[0.00027263354, 0.00069565896, 0.9990318]]\n",
            "2051        [[0.00023844875, 0.005935343, 0.9938261]]\n",
            "2052          [[0.006750051, 0.11673759, 0.87651235]]\n",
            "2053        [[0.00023815308, 0.014884057, 0.9848778]]\n",
            "2054       [[0.00011801638, 0.98635745, 0.013524571]]\n",
            "2055      [[0.00018757938, 0.00039030786, 0.9994222]]\n",
            "2056        [[8.320419e-05, 0.023005545, 0.97691125]]\n",
            "2057        [[8.202999e-05, 0.0015077263, 0.9984102]]\n",
            "2058      [[0.00011285081, 0.0028845877, 0.99700254]]\n",
            "2059        [[4.0053274e-05, 0.007897808, 0.9920621]]\n",
            "2060      [[0.00011222843, 0.0005948201, 0.99929297]]\n",
            "2061       [[0.00011007682, 0.00017393587, 0.999716]]\n",
            "2062         [[0.002890658, 0.011208368, 0.98590106]]\n",
            "2063       [[0.00024464834, 6.203614e-05, 0.9996933]]\n",
            "2064       [[7.957902e-05, 0.0002973505, 0.99962306]]\n",
            "2065      [[0.00025684235, 0.0004545869, 0.99928856]]\n",
            "2066           [[0.16814591, 0.8153406, 0.016513512]]\n",
            "2067            [[0.54516834, 0.397145, 0.057686605]]\n",
            "2068       [[0.00029483036, 0.0002933873, 0.9994117]]\n",
            "2069         [[0.0003711335, 0.14215593, 0.85747296]]\n",
            "2070          [[0.00010296236, 0.028937021, 0.97096]]\n",
            "2071           [[0.87517047, 0.07058394, 0.05424562]]\n",
            "2072      [[0.00016005684, 0.0005147164, 0.99932516]]\n",
            "2073        [[8.888534e-05, 0.009271542, 0.99063957]]\n",
            "2074         [[0.003359349, 0.013109805, 0.98353094]]\n",
            "2075           [[0.010149679, 0.02677034, 0.9630799]]\n",
            "2076          [[0.9794222, 0.006740495, 0.013837327]]\n",
            "2077           [[0.8570025, 0.13743035, 0.005567152]]\n",
            "2078           [[0.026234895, 0.26916152, 0.7046036]]\n",
            "2079     [[0.000100299694, 0.0014129566, 0.99848664]]\n",
            "2080       [[7.154605e-05, 0.0015202014, 0.99840826]]\n",
            "2081          [[4.9385802e-05, 0.00170261, 0.998248]]\n",
            "2082      [[0.000119909615, 0.0003853208, 0.9994948]]\n",
            "2083        [[0.00019923225, 0.71312475, 0.28667602]]\n",
            "2084         [[8.8113426e-05, 0.05424095, 0.9456709]]\n",
            "2085      [[0.00018130639, 0.0046042586, 0.99521446]]\n",
            "2086        [[0.00013019064, 0.9699523, 0.029917553]]\n",
            "2087      [[0.00023149177, 0.00035132308, 0.9994172]]\n",
            "2088        [[0.98322487, 0.012107108, 0.0046680355]]\n",
            "2089         [[0.00040782194, 0.23114246, 0.7684497]]\n",
            "2090      [[0.00014616773, 0.00055323227, 0.9993006]]\n",
            "2091         [[0.0004492443, 0.018536046, 0.9810147]]\n",
            "2092       [[0.00013077307, 0.010795367, 0.98907393]]\n",
            "2093         [[0.0009992381, 0.0012537942, 0.997747]]\n",
            "2094        [[0.0021437104, 0.0020447657, 0.9958116]]\n",
            "2095          [[0.0007684381, 0.021469625, 0.977762]]\n",
            "2096          [[0.0011608176, 0.57620573, 0.4226335]]\n",
            "2097        [[0.00035204279, 0.9488505, 0.050797436]]\n",
            "2098          [[0.00054566003, 0.6697696, 0.3296848]]\n",
            "2099       [[0.00017435283, 0.0044699768, 0.9953557]]\n",
            "2100        [[0.00013221007, 0.01721209, 0.98265564]]\n",
            "2101      [[5.552227e-05, 0.00076173065, 0.99918276]]\n",
            "2102      [[0.00030964904, 0.0008412957, 0.99884903]]\n",
            "2103       [[6.8731606e-05, 0.035633337, 0.96429795]]\n",
            "2104     [[0.00017471165, 0.00018421911, 0.99964106]]\n",
            "2105     [[0.00024290204, 0.00096013653, 0.99879694]]\n",
            "2106       [[0.00047928476, 0.009236002, 0.99028474]]\n",
            "2107           [[0.872601, 0.0024042272, 0.12499475]]\n",
            "2108          [[0.44040805, 0.0026222714, 0.5569697]]\n",
            "2109         [[0.00010987864, 0.7335765, 0.26631364]]\n",
            "2110          [[0.0035531623, 0.08127364, 0.9151732]]\n",
            "2111        [[0.00049980014, 0.60129935, 0.39820087]]\n",
            "2112       [[0.000100223784, 0.02461092, 0.97528887]]\n",
            "2113        [[0.00019444707, 0.9643048, 0.035500783]]\n",
            "2114      [[0.00029618462, 0.0020572057, 0.99764663]]\n",
            "2115      [[0.00022602492, 0.0019605558, 0.99781346]]\n",
            "2116         [[0.00010383144, 0.009631169, 0.990265]]\n",
            "2117       [[0.00016070194, 0.003082495, 0.99675685]]\n",
            "2118        [[0.00018063434, 0.39904502, 0.60077435]]\n",
            "2119         [[0.00043022592, 0.06507652, 0.9344933]]\n",
            "2120      [[0.00020719772, 0.0004075957, 0.99938524]]\n",
            "2121       [[0.00017505011, 0.0015676755, 0.9982572]]\n",
            "2122           [[0.002709563, 0.30433822, 0.6929522]]\n",
            "2123         [[0.0017506222, 0.69498837, 0.30326104]]\n",
            "2124         [[0.00047207592, 0.00076488, 0.9987631]]\n",
            "2125        [[0.0014254003, 0.009797745, 0.98877686]]\n",
            "2126        [[0.0018186979, 0.075643815, 0.92253757]]\n",
            "2127      [[0.00013997547, 0.00016422446, 0.9996958]]\n",
            "2128       [[0.00016730439, 0.0016029492, 0.9982298]]\n",
            "2129     [[0.00035797537, 0.00024228606, 0.99939966]]\n",
            "2130           [[0.38778296, 0.5952981, 0.016918847]]\n",
            "2131            [[0.6334252, 0.3551843, 0.011390481]]\n",
            "2132       [[0.00012710052, 0.0025424853, 0.9973304]]\n",
            "2133        [[0.0001598295, 0.0019086883, 0.9979315]]\n",
            "2134      [[6.872616e-05, 0.00024687266, 0.99968433]]\n",
            "2135        [[0.00025572255, 0.00042486, 0.99931943]]\n",
            "2136            [[0.16630441, 0.7175619, 0.11613366]]\n",
            "2137         [[9.648136e-05, 0.008767745, 0.9911357]]\n",
            "2138     [[0.00015557557, 0.00012561186, 0.99971884]]\n",
            "2139      [[0.00016194394, 0.00012632538, 0.9997117]]\n",
            "2140         [[0.0011575693, 0.93265396, 0.06618849]]\n",
            "2141       [[0.00010378086, 0.020060508, 0.97983575]]\n",
            "2142         [[0.0005929233, 0.66217303, 0.33723402]]\n",
            "2143          [[0.00013594501, 0.0144394, 0.9854247]]\n",
            "2144       [[0.0004159601, 0.00024085211, 0.9993431]]\n",
            "2145        [[0.0018553352, 0.005053745, 0.99309087]]\n",
            "2146        [[0.00031261798, 0.004728773, 0.9949586]]\n",
            "2147            [[0.2256843, 0.47038874, 0.30392691]]\n",
            "2148         [[0.0014569305, 0.02414888, 0.97439414]]\n",
            "2149           [[0.78750926, 0.09811634, 0.11437429]]\n",
            "2150           [[0.80911577, 0.018041153, 0.1728431]]\n",
            "2151      [[0.0007584253, 0.00017882143, 0.99906284]]\n",
            "2152               [[0.1961088, 0.163314, 0.6405772]]\n",
            "2153       [[0.00032234943, 0.0011398271, 0.9985378]]\n",
            "2154      [[0.00041498797, 0.0023315775, 0.99725336]]\n",
            "2155         [[0.001167986, 0.0021715236, 0.9966605]]\n",
            "2156        [[0.0002506014, 0.0015178298, 0.9982316]]\n",
            "2157     [[0.00014204305, 0.00040781312, 0.99945015]]\n",
            "2158      [[0.00086746307, 0.0012183498, 0.99791414]]\n",
            "2159        [[0.00032896182, 0.026347803, 0.9733233]]\n",
            "2160          [[0.0004186191, 0.28553686, 0.7140445]]\n",
            "2161       [[0.00075750594, 0.0009920148, 0.9982504]]\n",
            "2162        [[0.99476177, 0.0015256562, 0.003712524]]\n",
            "2163         [[0.00035831152, 0.8613455, 0.13829619]]\n",
            "2164           [[0.065137506, 0.8256949, 0.10916759]]\n",
            "2165          [[0.0072131893, 0.35231817, 0.6404686]]\n",
            "2166       [[0.00027129162, 0.0012455889, 0.9984831]]\n",
            "2167        [[0.00013609084, 0.008626373, 0.9912375]]\n",
            "2168      [[0.00010118234, 0.0033136634, 0.99658513]]\n",
            "2169         [[0.0009404926, 0.003411248, 0.9956482]]\n",
            "2170          [[0.0010868084, 0.4397533, 0.55915993]]\n",
            "2171            [[0.9770001, 0.0181115, 0.004888321]]\n",
            "2172          [[0.0003907696, 0.8376995, 0.16190976]]\n",
            "2173         [[0.00049703446, 0.7431606, 0.25634232]]\n",
            "2174           [[0.0010308526, 0.4468566, 0.5521125]]\n",
            "2175      [[0.0008661544, 0.00028955567, 0.99884427]]\n",
            "2176         [[0.0014369439, 0.009308364, 0.9892547]]\n",
            "2177          [[0.004681034, 0.09493243, 0.90038645]]\n",
            "2178            [[0.38030094, 0.4251044, 0.19459465]]\n",
            "2179        [[0.0074760118, 0.002640735, 0.98988336]]\n",
            "2180        [[0.00023004659, 0.0014679533, 0.998302]]\n",
            "2181     [[0.00022548922, 0.00038790537, 0.99938655]]\n",
            "2182       [[0.00019761354, 0.0012305347, 0.9985719]]\n",
            "2183         [[0.0030847287, 0.9741765, 0.022738704]]\n",
            "2184        [[0.00049702823, 0.68705314, 0.31244987]]\n",
            "2185          [[0.0011706757, 0.7575045, 0.24132486]]\n",
            "2186          [[9.869618e-05, 0.019618293, 0.980283]]\n",
            "2187         [[0.0074341227, 0.001872468, 0.9906934]]\n",
            "2188         [[0.0074341227, 0.001872468, 0.9906934]]\n",
            "2189     [[0.00030337763, 0.00078677933, 0.99890983]]\n",
            "2190       [[0.00012300977, 6.64247e-05, 0.99981064]]\n",
            "2191      [[0.00034495906, 0.00031753848, 0.9993375]]\n",
            "2192       [[0.0005253905, 0.0032744175, 0.99620014]]\n",
            "2193           [[0.019007726, 0.6428051, 0.33818716]]\n",
            "2194         [[0.0006938357, 0.69082606, 0.30848008]]\n",
            "2195         [[0.0006017978, 0.47548154, 0.52391666]]\n",
            "2196        [[0.00031944708, 0.07092434, 0.92875624]]\n",
            "2197      [[0.00011982779, 0.0043103397, 0.99556977]]\n",
            "2198         [[0.0006781602, 0.90760595, 0.09171584]]\n",
            "2199        [[0.00015103357, 0.009318124, 0.9905309]]\n",
            "2200      [[0.00039670765, 0.0061366893, 0.99346656]]\n",
            "2201          [[0.0011379337, 0.5621854, 0.43667662]]\n",
            "2202        [[0.00026833126, 0.006370707, 0.9933609]]\n",
            "2203       [[0.00012678832, 0.0004745242, 0.9993987]]\n",
            "2204     [[0.00016330011, 0.00025984427, 0.99957687]]\n",
            "2205        [[0.00025731593, 0.0043616965, 0.995381]]\n",
            "2206          [[0.0005420102, 0.27035317, 0.7291048]]\n",
            "2207      [[0.0010762236, 0.00073594064, 0.99818784]]\n",
            "2208        [[0.0005296339, 0.96925956, 0.030210849]]\n",
            "2209           [[0.0006481223, 0.44145793, 0.557894]]\n",
            "2210         [[0.0010202398, 0.17504697, 0.82393277]]\n",
            "2211      [[0.00020317403, 0.00013242099, 0.9996644]]\n",
            "2212       [[0.00011445011, 0.0040092194, 0.9958763]]\n",
            "2213        [[0.00034909503, 0.09734296, 0.90230805]]\n",
            "2214        [[0.00011795096, 0.9792935, 0.020588443]]\n",
            "2215        [[8.8106244e-05, 0.9854022, 0.014509623]]\n",
            "2216          [[0.00012227226, 0.3647245, 0.6351532]]\n",
            "2217          [[0.89209837, 0.08654791, 0.021353748]]\n",
            "2218            [[0.41442654, 0.08825822, 0.4973153]]\n",
            "2219        [[0.0007477334, 0.00014421716, 0.999108]]\n",
            "2220          [[0.9067838, 0.061749477, 0.031466726]]\n",
            "2221        [[9.409143e-05, 0.0009310545, 0.9989749]]\n",
            "2222       [[6.334215e-05, 0.0014106694, 0.99852604]]\n",
            "2223           [[0.04773289, 0.07654802, 0.87571913]]\n",
            "2224     [[0.00014145175, 0.00031521104, 0.99954337]]\n",
            "2225       [[8.710801e-05, 0.0021893377, 0.99772364]]\n",
            "2226      [[0.00021310916, 0.0010414502, 0.99874544]]\n",
            "2227       [[0.00013716042, 0.0051509063, 0.9947119]]\n",
            "2228       [[0.0002677333, 0.0015646403, 0.99816763]]\n",
            "2229       [[0.0006241752, 0.0103168115, 0.98905903]]\n",
            "2230        [[0.000163013, 0.00046061914, 0.9993765]]\n",
            "2231      [[0.00033973999, 0.0003223706, 0.99933785]]\n",
            "2232      [[0.00027962212, 0.0003522922, 0.99936813]]\n",
            "2233        [[0.00017876226, 0.06220019, 0.93762106]]\n",
            "2234      [[0.00027353934, 0.0026745407, 0.99705195]]\n",
            "2235       [[0.00041482906, 0.096902885, 0.90268224]]\n",
            "2236       [[0.00015733553, 6.42599e-05, 0.99977845]]\n",
            "2237      [[0.00022461986, 0.0004750561, 0.99930024]]\n",
            "2238           [[0.042709015, 0.14050433, 0.8167866]]\n",
            "2239           [[0.04171434, 0.83826435, 0.12002124]]\n",
            "2240        [[0.0014367835, 0.9930536, 0.0055095456]]\n",
            "2241          [[0.95100784, 0.001346012, 0.04764614]]\n",
            "2242           [[0.047065765, 0.8177225, 0.13521172]]\n",
            "2243       [[0.00029562178, 0.011619677, 0.98808473]]\n",
            "2244      [[0.00010021759, 0.0057388856, 0.99416083]]\n",
            "2245         [[0.00077411265, 0.25857908, 0.7406467]]\n",
            "2246     [[0.00022278546, 0.00035166086, 0.99942553]]\n",
            "2247         [[0.000100983, 0.000119088996, 0.99978]]\n",
            "2248     [[2.0758464e-05, 0.00021759425, 0.99976164]]\n",
            "2249      [[2.1135043e-05, 0.00023367727, 0.9997452]]\n",
            "2250       [[5.750802e-05, 0.00012652918, 0.9998159]]\n",
            "2251          [[0.89681983, 0.014380824, 0.08879935]]\n",
            "2252        [[0.00071153144, 0.95530546, 0.04398298]]\n",
            "2253           [[0.0010988095, 0.704356, 0.29454517]]\n",
            "2254           [[0.002526441, 0.42611328, 0.5713603]]\n",
            "2255        [[0.004680309, 0.0033061646, 0.99201363]]\n",
            "2256       [[0.0006545332, 0.0076284995, 0.99171704]]\n",
            "2257         [[0.010646533, 0.009359386, 0.97999406]]\n",
            "2258          [[0.038747802, 0.04820374, 0.91304845]]\n",
            "2259           [[0.007915455, 0.31065696, 0.6814276]]\n",
            "2260        [[0.0002908277, 0.0005014559, 0.9992077]]\n",
            "2261        [[0.00043438553, 0.013250747, 0.9863149]]\n",
            "2262         [[5.8786394e-05, 0.11985319, 0.8800881]]\n",
            "2263      [[0.00012899766, 0.00066052057, 0.9992105]]\n",
            "2264          [[0.00031425655, 0.02846774, 0.971218]]\n",
            "2265           [[0.074157335, 0.20641044, 0.7194323]]\n",
            "2266           [[0.68790424, 0.17620671, 0.13588902]]\n",
            "2267         [[0.0022688843, 0.21096537, 0.78676575]]\n",
            "2268       [[0.0008214357, 0.0021476848, 0.99703085]]\n",
            "2269      [[0.00013661859, 0.0058992305, 0.99396414]]\n",
            "2270       [[0.00036258742, 0.112552755, 0.88708466]]\n",
            "2271         [[0.0014107202, 0.44184914, 0.55674016]]\n",
            "2272       [[0.00018258751, 0.0014562778, 0.9983612]]\n",
            "2273       [[0.00029191325, 0.0005341878, 0.9991738]]\n",
            "2274       [[0.00014002502, 0.0042361286, 0.9956239]]\n",
            "2275          [[0.20663197, 0.77998114, 0.013386921]]\n",
            "2276         [[0.00028362844, 0.14430809, 0.8554083]]\n",
            "2277       [[0.00019282657, 0.0002493934, 0.9995578]]\n",
            "2278     [[0.00033121082, 0.00016367815, 0.99950504]]\n",
            "2279           [[0.011494983, 0.45472848, 0.5337765]]\n",
            "2280      [[0.00021206128, 0.0050223013, 0.99476564]]\n",
            "2281       [[8.866235e-05, 0.00066552154, 0.9992459]]\n",
            "2282    [[0.000117438954, 0.00027722307, 0.99960536]]\n",
            "2283          [[0.0011209579, 0.6728908, 0.32598826]]\n",
            "2284      [[0.00012192765, 0.00013422676, 0.9997439]]\n",
            "2285     [[0.00010125374, 0.00022115743, 0.99967754]]\n",
            "2286       [[0.00010725798, 0.0006473051, 0.9992455]]\n",
            "2287         [[0.00022711336, 0.03642994, 0.9633429]]\n",
            "2288         [[0.00031549315, 0.04623722, 0.9534472]]\n",
            "2289      [[0.00030967602, 0.0006465797, 0.99904376]]\n",
            "2290           [[0.0005289301, 0.1340369, 0.8654341]]\n",
            "2291           [[0.000304586, 0.16340324, 0.8362922]]\n",
            "2292            [[0.00567388, 0.9498057, 0.04452037]]\n",
            "2293          [[0.0024191136, 0.5141217, 0.48345917]]\n",
            "2294           [[0.000273313, 0.02137284, 0.9783539]]\n",
            "2295         [[0.0002638714, 0.15210631, 0.84762985]]\n",
            "2296        [[0.00034279388, 0.12055512, 0.87910205]]\n",
            "2297        [[0.00023645359, 0.82530856, 0.17445502]]\n",
            "2298      [[0.00019360732, 0.0006032213, 0.99920326]]\n",
            "2299      [[0.0002747335, 0.00055460393, 0.99917066]]\n",
            "2300        [[0.00021702016, 0.03944512, 0.96033776]]\n",
            "2301         [[0.0013875322, 0.76183975, 0.23677272]]\n",
            "2302           [[0.48427346, 0.47197658, 0.04375005]]\n",
            "2303        [[0.00021689635, 0.000532989, 0.9992501]]\n",
            "2304       [[0.00022301875, 0.0054769875, 0.9942999]]\n",
            "2305      [[0.00015439013, 0.00037397773, 0.9994716]]\n",
            "2306             [[0.4071089, 0.5246659, 0.06822524]]\n",
            "2307     [[0.00020903916, 0.00027235935, 0.99951863]]\n",
            "2308       [[0.00022379251, 0.0029785922, 0.9967976]]\n",
            "2309       [[0.00012343179, 0.0014052015, 0.9984713]]\n",
            "2310       [[9.016252e-05, 0.0008551694, 0.99905473]]\n",
            "2311       [[0.00014282679, 0.0004301539, 0.9994271]]\n",
            "2312       [[0.0005148251, 0.0028482757, 0.99663687]]\n",
            "2313          [[0.0001322536, 0.003633727, 0.996234]]\n",
            "2314          [[0.9483948, 0.025186114, 0.026419079]]\n",
            "2315          [[0.0003573828, 0.49075013, 0.5088925]]\n",
            "2316          [[7.939986e-05, 0.9050729, 0.09484768]]\n",
            "2317         [[0.00016316741, 0.90710926, 0.0927276]]\n",
            "2318       [[0.0004225457, 0.0077948794, 0.99178255]]\n",
            "2319         [[0.00048872264, 0.0046479, 0.99486333]]\n",
            "2320        [[0.0020345321, 0.054605868, 0.94335955]]\n",
            "2321            [[0.013127641, 0.7461235, 0.2407489]]\n",
            "2322            [[0.013127641, 0.7461235, 0.2407489]]\n",
            "2323       [[0.0002219846, 0.00037745407, 0.9994006]]\n",
            "2324      [[0.00017809712, 0.0003662689, 0.99945563]]\n",
            "2325           [[5.86825e-05, 0.12156874, 0.8783726]]\n",
            "2326         [[0.0023439848, 0.001160661, 0.9964953]]\n",
            "2327      [[0.00025195107, 0.00022830146, 0.9995197]]\n",
            "2328      [[0.00027233592, 0.0048387996, 0.99488896]]\n",
            "2329       [[0.00016357051, 0.008113092, 0.99172324]]\n",
            "2330        [[0.00025394993, 0.27605087, 0.72369516]]\n",
            "2331       [[0.00017886647, 0.0017401373, 0.9980811]]\n",
            "2332       [[9.174045e-05, 0.00096559874, 0.9989427]]\n",
            "2333      [[0.000102102844, 0.0010936311, 0.9988042]]\n",
            "2334          [[0.008839334, 0.035535555, 0.9556251]]\n",
            "2335         [[0.0061408193, 0.13563378, 0.85822535]]\n",
            "2336       [[8.4754756e-05, 0.0060400353, 0.9938752]]\n",
            "2337      [[0.00016682771, 0.00016567584, 0.9996675]]\n",
            "2338         [[7.428384e-05, 0.00085322, 0.99907243]]\n",
            "2339       [[0.00035757202, 0.006075968, 0.99356645]]\n",
            "2340        [[9.219845e-05, 0.99754494, 0.002362815]]\n",
            "2341         [[0.00010278399, 0.20395766, 0.7959396]]\n",
            "2342        [[6.721296e-05, 0.0004976079, 0.9994351]]\n",
            "2343        [[7.616351e-05, 0.0009056536, 0.9990181]]\n",
            "2344       [[2.4632729e-05, 0.0058428016, 0.9941326]]\n",
            "2345     [[4.4753862e-05, 0.00011564347, 0.99983966]]\n",
            "2346       [[6.169397e-05, 0.00028470578, 0.9996536]]\n",
            "2347      [[7.937617e-05, 0.00010999857, 0.99981064]]\n",
            "2348       [[0.0003760604, 0.0005157497, 0.99910825]]\n",
            "2349          [[0.00013822383, 0.0409457, 0.9589161]]\n",
            "2350        [[0.0001082232, 0.015073701, 0.98481804]]\n",
            "2351          [[0.0013860234, 0.22208078, 0.7765331]]\n",
            "2352           [[0.0003962482, 0.433244, 0.56635976]]\n",
            "2353        [[0.00011821875, 9.18772e-05, 0.9997899]]\n",
            "2354       [[9.422757e-05, 0.0016003136, 0.99830544]]\n",
            "2355        [[0.00031690302, 0.9602596, 0.039423462]]\n",
            "2356          [[0.0063759615, 0.9217926, 0.07183144]]\n",
            "2357       [[4.475833e-05, 0.0021581457, 0.99779713]]\n",
            "2358        [[0.00013564483, 0.0023082974, 0.997556]]\n",
            "2359       [[0.00058951415, 0.048424505, 0.95098597]]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "state_dict = 'state_dict/bert_spc_combined_padanan_trim_val_f1_0.7908'\n",
        "pretrained_bert_name = 'indobenchmark/indobert-large-p2'  # bert-base-uncased, indolem/indobert-base-uncased, indobenchmark/indobert-base-p1, indobenchmark/indobert-large-p2\n",
        "infer_param(state_dict, pretrained_bert_name)\n",
        "\n",
        "# state_dict/bert_spc_combined_padanan_trim_val_f1_0.7908\n",
        "!cd /content/ta-dictabsa/ && python3 infer_example.py"
      ],
      "id": "YSrTYQnhnUuc"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5c8aa038-18bb-4141-a50a-83ff41246bfb",
        "092c9164-1ed1-4f22-8aa1-8de6333a8859",
        "617b218f-1d4b-4768-94e0-f5fbc92fbb31",
        "pssq6u_KYLX9",
        "coyAZT8JND-0",
        "9W1ucQNMYe7R",
        "e3245243-fd59-4086-a095-466d984cd3e8",
        "c9108c5a-3eb2-4fc2-b013-17bab67379b6",
        "MhiXDrOyYtNl",
        "IZIIIipzY1lp",
        "jFM2KFuqZG60",
        "zyVpCf3XNQ1A",
        "07438f4a-c61f-4611-99f9-2abed1b78294",
        "ff3acfb4-3583-49b3-8405-6721ea61fdbc",
        "9d729ffc-1372-4ff0-939b-4cc9cb3d445b",
        "134b0bdc-bec1-4300-9e51-fab24dcc3d10",
        "a4379c4a-eadf-420d-82e8-2a399d98e515",
        "9ba96fdc-0583-492a-a690-78c94ed037ef",
        "550b9503-a399-48e5-bab1-80e691479d49",
        "bZo-sUicrfBv",
        "jwrEwOAVLKIj",
        "v3n4L5tgrygD",
        "ilOVKHz0sFPY",
        "N1aJBtaPzN_W",
        "12c5fc89-de88-4e24-a35c-b3a2c7a7e19b",
        "d52c0a96-4002-4cce-aa88-eb1aed3a6003",
        "6d9f7f83-9452-4bd9-9c7c-791781a6a718",
        "_mN5Z6dWZ0HE",
        "5xzmZnZyqkXU",
        "dE0V9_yPyi5G",
        "lLD66QjayunZ",
        "e79e311a-a4fd-424e-99ad-25d8f7c7bd47",
        "d420709e-ffd1-431a-a87d-ff0c2e0e7f9c",
        "4b2d3059-b28b-493e-89eb-114c6a0ce4c9",
        "0a91b6b8-722f-4da5-879f-27c09bfc6050",
        "zpN-kVHeDUds",
        "Y5GtT4vyLkb0",
        "243488f2-d0c3-41ed-8055-c7c76fa12bb4",
        "OM93XXKgtGxJ",
        "47e503c6-6788-410b-9282-90dad704246f",
        "83067f58-9c4f-4d4a-be69-f7fb82f313da",
        "2dd0ee17-26ed-4d14-bf47-e6015b03d2e2",
        "8e6e0f13-09ff-4bb3-9c34-d9bf0c9ccc87",
        "cM3ES7E2ZWfY",
        "-THgj03Ks4Pd",
        "JFm2oYwPZd6B",
        "3734cb39-a204-4298-9a96-a74e8495b310",
        "be48146d-0ae0-4309-bfbc-440c1b7d2617",
        "874c3402-b340-4746-bcb6-12481d3709db",
        "fbb59289-e7a6-4d9f-a70f-66f60a0722c3",
        "iiozdtyLL2zu",
        "Yr-A9dFmFa3d",
        "cgMezYFUFcQk",
        "QE3GNHfJFpft",
        "lxZaPdywuDAr",
        "fa239464-3344-40e3-afc8-d0b2e3c941e8",
        "0f514246-fcb1-4626-b682-7e2e3926678c",
        "bb83e078-4462-4287-aaa4-2b9c5e753517",
        "93af8e56-4b8c-4e83-b915-cddf2aa6aee0",
        "mb9xFOubKmQg",
        "0hVNXHyFt2xP",
        "b88182e7-b832-43af-b972-5dccecd7d6ea",
        "05b7fcd9-724d-4f1d-bb65-4f79a761a1f6",
        "2bd46a3c-729e-467e-a5ef-710f670d5fa0",
        "fbd9c5b5-0545-4a35-a1f5-58d2463cefec",
        "9e6f5e28-aebb-43a4-b3ec-f18c01ba8f1d",
        "Z3XDC8PBDtfs",
        "meO51jA3Dtft",
        "XXzxg7D5MRNU",
        "PrWvKmo3Dtft",
        "ePn-N2eiDtfu",
        "vObxa6H8Dtfu",
        "YFvdvgI_Dtfv",
        "709kKZUnDtfw",
        "7JhvOg-aDtfw",
        "xygiGKGsMfS1",
        "qC5eBizEDtft",
        "azVTRILuDtfu",
        "OpnRU2-bDtfv",
        "7oAyZNS2Dtfv",
        "yiIAnJyDDtfw",
        "hLoIkR7qDtfx",
        "a1ywJ3X2_HB4",
        "32bf8ab3-1013-42bd-813c-67a96d0ee4b0",
        "uB_57JpCIn79",
        "fUnNl3owFKXG",
        "CK27GNT1AojQ",
        "JNy7_84NIR-Z",
        "jy54z5NwOp1_",
        "OsP7y_hxKu0R",
        "Q5z5liKWl1_c",
        "QuFQ3Bwimwoy",
        "3aJGLwkbnUuL"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}